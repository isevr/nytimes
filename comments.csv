comment;
it is very possible that social media have already cost us american democracy. right now i'm confident that my own beliefs are generally accurate, at least with respect to things that i put some effort into. i'm not sure that i'd be able to continue saying that if llm-generated materials (text, images, videos etc.) became common. maybe accurate beliefs are not that important to our survival, but i'm not eager to gamble on that.;
@paul i believe that accurate beliefs are absolutely necessary for our survival. it plays into the concept of trust, which is plays a critical role in both the sustainability of society as well as its advancement. without truth, how can you trust?;
@chris v our cognitive systems are not designed (by natural selection) to give us true beliefs, but rather to give us beliefs that increase the odds of our passing along our genes. the two goals overlap but far from completely. it's very possible that there are some critical points about which we absolutely have to be correct. i'm not following the point about trust and truth, though. it seems pretty clear that there is a lot of trust based in falsehood, especially in this era of misinformation.;
@paul absolutely agree. i don’t think even liberal educated people understand how much damage social media is doing to civilization. we have turned over our entire information ecosystem to secret algorithms written by monopoly corporations owned by billionaires. everything that appears on our screens is “curated” by them. the goal of these is not to give us an accurate view of reality but to increase our “engagement” which in most cases translates as anger. these algorithms are really simple ais. they have access to enormous databases of information about us harvested by ad agencies. for the first time in history, starting around 1997 anyone can publish any conspiracy theory and it can go viral. the social networks which have become many peoples main source of information are really rumor mills or lynch mobs. we no longer have a “shared basis of facts” to ground debate. fake news spreads 7 times as fast as the truth, by the math of exponential growth lies drive out the truth. can democracy survive in this environment? i don’t think so. we need to put sensible regulations on the algorithms so they don’t promote hate anger and conflict in the guise of “engagement”;
@paul belief is a a trait that developed late in evolution and is not necessary.;
@paul dear paul, at a very basic level, i know what i think and believe. even if my beliefs do not promote my survival in the present, it is a bit moot considering my mortality. this is why i am convinced that man's soul, as created by god, is eternal. there is a passage in the book of job that sums this up very poetically. i wish i could quote it, but in essence it is that one day i will stand before him, the creator of my soul. an ai bot has no soul.;
"i wholeheartedly agree with the huge potential for disruption to societal discourse at a scale that cannot be caused by single individuals - dictators for example. but i do think that ai at the hand of dictators is uncontrollable, the question is not how benign nations or companies use it reasonably; the question is how we keep ai out of the hands of ""bad people"". that path looks very murky indeed.";
"@jzu you say: ""the question is how we keep ai out of the hands of bad people"". impossible. how do we keep nuclear weapons out of the hands of bad people? (north korea, iran, etc.) how do we keep guns out of the hands of bad people? (every mass murderer - which in this country is out of control!). this is faulty logic. what will we say, ai doesn't kill people, people kill people?";
"""leaders from openai, google deepmind, anthropic and other a.i. labs warn that future systems could be as deadly as pandemics and nuclear weapons."" and yet they are racing ahead a breakneck speed. seems the real threat is from openai, google deepmind, anthropic and other a.i. labs.";
@cv danes this is not so different from why climate change regulation is necessary. individuals/individual corporations acting in their own self interest act to maximize their own self interest (profit, prestige of being first and best), while humanity as a whole has an interest in staying safe. the individuals involved realize this conflict, but (except for hinton?), can't stop maximizing their own self interest without regulations to set boundaries and even the playing field.;
@elizabeth m and the great multiplier here, both for climate change and a.i.: capitalism. profit is the oxygen of business. if its pursuit consumes all the oxygen we breathe... well, that's just an externality.;
@elizabeth m further, these guys feel they’re in a fierce competition with other players outside their club— specifically, chinese and perhaps russian groups. the situation seems an echo of the manhattan project with the grave ambivalence felt by many participants who worried about the wisdom of their enterprise but feared the germans were closer to building an atomic weapon.;
@cv danes let’s not forget that large dominant companies often seek to spur government regulations because the new regulations, if onerous, also act as an obstacle to new potential competitors.;
@cv danes i don't think it is possible to slow ai development or any other technology, or even reasonable, or realistic, to ask. the quest for knowledge is inexorable. the issue is how technology is used, not the technology itself. the use is what needs to be regulated.;
@cv danes i agree yet there are others in the world who are also developing ai. it seems the genie is out.;
@cv danes it's from capitalism. in capitalism, leaving money on the table is a civil offense for which you can be held liable.;
@cv danes the reason the nyt is publishing this article is simple. an ai generated catastrophe would probably provoke a popular re-evaluation of capitalism. the ultra-wealthy see ai as a potential threat to their wealth. and that tells you how much of risk we face in ai.;
i mean, the root of that threat is the incentives driven by our chosen economic system.;
lol exactly. quitting can make a big impact and send a big signal within an organization. it gets people’s attention if done the right way.;
what will money mean anymore in a world run by ai? on one hand it could be a very freeing thing, if done right, with more free time for everyone from wearing and tedious work, while research in medicine could expand exponentially as well as best practice logical solutions to resolving dangerous conflicts snd expediting disaster relief. on the other hand it becomes militarized and robot soldiers and police come after us on behalf of their totalitarian overlords. development will likely continue, so would it work on the mutual destruction doctrine, with each political entity making sure the others don’t overstep. it sounds like so far the interaction with trolls and nihilist pranksters poisoned some ai, obviously it’s not something that should be publicly released until humans suddenly transform into angels. just as you wouldn’t allow everyone access to powerful wmd or chemical weapons but you would want a credible deterrent. if they are worried it will develop itself and become uncontrollable then they must figure out the brakes before that happens. if they think a six month pause will help by giving developers time to install fail safe options, them why not? it wouldn’t take the re education of government officials to accomplish at least that much.;
i wish we could get more specific facts and information about the extinction threat ai poses. i use charbot gpt, and it seems pretty pedestrian--just the next step after my cellphone anticipating my next word. it's great advantage is speed but so is much of automation. in books on the topics i've read, the issue seems to be prorgramming in compassion, and that seems eminently doable to me. is is just the psychopaths in charge who are scared, because they can't envision a potential intelligence that would use great power wisely and humanely? but as it doesn't seem very very smart, i'm back to wanting to know the specifics of the risk.;
the stakes seem pretty low right now, but businesses and the military haven't really begun using it for vital operations or on a large scale yet. imagine it's deployed by the government to help with utilities. it can easily mess with the water supply, or electricity. or if farmers use it, it can mess with our food supply. autonomous weapons can malfunction, if deployed by a military. ai is harmless now, but there's the potential for its power to increase dramatically in a very short time, and if business leaders and governments don't truly understand it, it can certainly be dangerous.;
@roger reynolds when it comes to extinction threats the skynet is the limit!;
"@roger reynolds it's not chatgpt or this ""generation"" of ai that they're saying causes risk of extinction. chatgpt is artificial intelligence, and it is already influencing society in major ways. what they are all working on creating is the next generation, the leveled up ai, which they refer to as agi – artificial general intelligence. superintelligent ai that will be able to think for itself and vastly outperform human capacity for learning - from the words of bill gates, ""it will be able to do everything that a human brain can, but without any practical limits on the size of its memory or the speed at which it operates."" bringing ai to life basically.";
@m so far there are no indications that agi is achievable.;
"it seems incongruous that ""industries leaders"" would be warning of the extreme dangers of their own products. an alternate theory is that chatbots are a fad and ""industry leaders"" are using this as advertising for their products. possibly, they would like to enjoy a moat of government regulation around their products. but, in any case, color me dubious.";
"finally! but pandora's box is already open. do all nations agree to stop this insanity? when ""it"" happens, it will be so fast and so complete that we will wonder why we didn't know all along.";
when mr. altman recently met with lawmakers, they suggested that mr. altman would be most qualified to regulate a.i.;
it's worrying that the developers themselves are sounding the alarm and expecting congress to regulate it when they know full well very few have the capability of even understanding it. they have a responsibility to self-regulate and may not get the luxury of regret like oppenheimer did.;
when, in the history of greed, have corporations ever, ever, self-regulated? it’s the government’s job to rein in corporations so that their strivings for more do not outstrip the benefit to society at large. in case you haven’t noticed, our government is awol, unless you are a corporation that can pay for their services.;
they’re really wanting congress to regulate new, upstart companies. altman in particular is using regulation as code for “let openai have a monopoly on llms”.;
@tom j its a cop-out. they see the weird guilt that zuckerberg has towards his creation, and they want to have some sort of ethical out. this letter is it.;
the height of insanity, complaining about the chaos caused by one’s own invention while still furthering the invention. if these groups of individuals were a single human one could argue that human had suicidal tendencies. talk about being mad from one’s own power.;
@robert 👁️👁️ i complain about global warming but i still drive my car. it's valid to ask for centralized regulation.;
@robert 👁️👁️ would you have expected einstein to stop his work in physics at the point we realize that nuclear bombs were a possibility? in fact, he sounded the alarm, just as these ai developers are doing today. let's hope the hiroshima/nagasaki-like event that will likely result from this does not do even more destruction than those events did. development of powerful technologies seems inevitably to result in damage - the trade-off for the good they can do.;
@david you can ask for regulation but you're still acting insane;
in today's world, asking us as a society to act responsibly and to use personal discipline regarding technology is like having a weight watcher's meeting at wendy's. i am not optimistic.;
"@ron's son what, you don't like their ""pretzel bacon pub triple""?";
meanwhile, openai presents version 5 of chatgpt, now able to mimic the writing patterns of over 5,000 rich and famous people. end of days? do it in style with chatgpt!;
@ron's son, yes, i would have thought society would have risen to the occasion in cooperation to help get us through the once in a century covid global pandemic as best we could. boy was i wrong. similarly, it seems inevitable that information about the ai threat will be manipulated for polical advantage and endless nutty conspiracy theories will no doubt arise (l'm sure they already have). ug. the limits of human nature i guess.;
@ron's son and they're contemplating international cooperation on regulation. move the weight-watchers meeting to the hague.;
@cec actually, some places in the world did recognize the need for collective community action. people collaborated with public health measures because that's part of human nature too. what concerns me with ai is how much it can be insulated from human intervention.;
@ron's son there are too many actors who can see a financial/competitive advantage to hold ai in check for long. where governments try to regulate, it will be spotty at best. governments who see an advantage not to regulate will quickly undermine any attempts at suppression. we need a strategy for coexisting with ai - a technology that can be obtained by so many and spread so quickly is almost certainly unstoppable.;
@ron's son is ai the new ' tower of babel '?;
"@ron's son agreed. and even long before a.i. creates ""the terminator"" (let's say 10-20 years down the road), it'll be used by financial hackers to manipulate stock and bond markets, eviscerate our 401ks and iras, and drain our bank accounts. the feds are already outgunned and it's going to get much worse, very fast (say 3 - 5 years years). they are in competition with each other for dominance over resources. the rest of us will be left to die of benign neglect and starvation.";
@ron's son: “the tech leaders torturing themselves now, which is kind of fun to see. they’re afraid that their little ais are going to come for them. they’re apocalyptic, and so existential, because they have no connection to real life and how things work. they’re afraid the ais are going to be as mean to them as they’ve been to us,” - doug rushkoff – a leading digital age theorist, early cyberpunk and professor at city university of new york;
that’s just humanity, period. we’ve been destroying each other almost as fast as we can breed for millennia. maybe we’ll finally invent something that flips the trend.;
@ron's son yes. the threat of catastrophic risk from ai will not offset greed and the money to be made from ai. greed will win. right now developers are giddy with their new toy, as is the average consumer. just like with climate change and democracy - humans wait until it is too late. freedom in america means not having to be responsible.;
@ron's son fat-shaming doesn't help either;
@hugo weaving seem to be expanding humanity and peaceful coexistence much faster than destroying, all things considered. ai may change this of course.;
"@betty durso yes, we have no wendy’s but macdo will do. mac pro we also have ;-)";
@peggy barnett .. no offense meant. i was hoping to point out our (as in all of us).. our collective inability to show some kind of societal responsibility for each other. ie.. the pandemic was not exactly our most shining moment. this doesn't look like it's gonna be either..;
this sounds like fear mongering unless these developers tell us exactly what they think the risks are, as we are entitled to know. why an existential threat? i have often thought of ursula le guin's sci-fi novel always coming home, in which the ais, having amassed all known data, are off on their own projects, caring nothing about humans at all.;
fear mongering for what purpose? this comment sounds a lot like antivaxxers attacking doctors and epidemiologist about covid-19. if these developers whose life’s work is ai and these large corporations who stand to profit from ai are warning you, then you should probably listen.;
@mike c that's quite a leap. i've never gotten covid and still mask in crowds because i was able to read and evaluate information from reliable sources. problem here is that the alleged threat is clothed in mystery, so that we are unable to assess it. sure, trust the experts, but the experts have to be reliably transparent.;
"@ann ""why an existential threat?"" the ai itself is not an existential threat. the existential threat arises from us, humanity, when we are bombarded with artificially generated language, full of ideas and emotions, but generated by an entirely amoral machine. we are accustomed to language coming from people, people who may lie and attempt to manipulate, but not at this scale or with the potential to tailor messages so well.";
@mike c: generating opportunities for public events, generating attention, raising funding for specific research and new corporate endeavors...;
the answer is simple. just hold companies responsible for what they publish. including what is generated by an ai. you’ll see things get fixed quickly. internet too. enough of this, it’s not us, we are just a platform, it’s the users, it’s the ai, we can’t police everything. tough, not our problem. no matter where the content is coming from, whoever is hosting it and making money through ad dollars or subscriptions, is the publisher and it’s crazy that they have convinced us that they are not responsible. fabric of society gets destroyed while they make billions. just hold them responsible and things will regain a balance.;
@jane actually, the reality is quite the opposite. the corporations are almost always punished via regulation, scalping platform capabilities, massive fines, etc. while the actual users doing the dirty work are almost never prosecuted. think of it this way: facebook, google, etc. were the architects of the city. there are criminals within the city that do wrong to others. why don’t we go after the criminals committing the crimes?;
@jane it's all fun and games until someone loses an eye. when these gadgets finally kill someone (or possibly a large number of people) or cause some other major tort we may see a major lawsuit like the dominion-fox case that can force tech companies to act responsibly.;
"@justin anderson in this case the architects of the city made weapons of mass destruction a design feature of the city scape. your argument is no different than the very popular ""guns don't kill people, people kill people"".";
@justin anderson: a poorly designed city results in death from traffic accidents, homelessness as a result of a lack of affordable housing, pollution from unregulated cars, trucks, buses, etc. and on and on. do you really think of facebook as a a great architect?;
not obviously so. some things may be fixable but there’s insufficient incentives to do so in the tech world writ large. but in ai systems, this isn’t the case. ai isn’t auditable. it can’t explain itself and we can’t pin point why any particular prompt resulted in its specific outcome. so regulation just means limits on development. not fixing what’s wrong. just not publishing things that we can’t understand. and that’s most of what llms do.;
@justin anderson do the city architects run a program that systematically promotes more criminals so they can make more money? do they claim they can't hire enough police, despite being highly profitable? your website is not a city. the self-importance of the tech world is part of what got us here.;
@jane if you think that a lawsuit is going to stop an ai system, think again.;
@jane right on! you got that right sister. both the internet and social media companies have used their hordes of lobbyists and hoards of money to effectvely enact legislation that allows them to operate outside of the institutional accountable ethical, legal, moral and political framework that controls, exposes and limits traditional mass media communication companies. saying that our users or a.i. did it is akin to comedian flip wilson's routine of ' the devil made me do it.' users and al don't profit from this farce.;
@justin anderson nonsense. corporations aka social medias and internet firms profit and thrive from the human conflict that attracts and creates more prey for their predatory advertisers, marketers, publishers and sellers of goods and services. think of a slaughter house. think of a dining or kitchen table. in a social media digital internet world you are either a diner or you are on the menu.;
if our government is serious, they will first repeal section 230 and then let’s see what sundar and satya will do. it’s all empty words until then.;
@justin anderson architects who build an attractive nuisance can be held responsible.;
@jane that only works for companies based in countries with laws capable of holding companies responsible. i'm sure plenty of corporations will be happy to set up shell companies in russia. foiling regulators is not particularly difficult these days.;
i totally agree with you! it seems to me holding anyone responsible dead ends into the current policies of the far right.;
"@art dominion's win over fox was, and will remain, quite rare. they lucked out by having smoking-gun evidence. for a plaintiff to prove malicious intent in a court of law in the u.s. is nigh unto impossible. lies, disinformation, accusations, and all other distortions of truth are, unfortunately, regardless of their negative effects, almost always ""the price we pay"" for the constitutional protection of free speech. i'm not sure what the solution to this quandary is, but, before it's too late, we have to find a better way.";
hold them responsible by not giving the corporations any immunity. an ai goes rouge and causes harm, the corp is responsible for all damages. no free ride like was given to internet platforms.;
@jane i agree, governments must legislate or regulate tech and social media companies.;
@art so people have to die before laws can be enforced to hold tech companies responsible? wouldn't the sensible thing be to create new legislation and regulation before that happens? i'm not willing to sacrifice my own life, or that of my loved ones, (or anyone, frankly) so the tech industry can finally learn restraint.;
"@justin anderson cities are necessary. the internet is...arguably necessary or not (the world was fine without it; just saying). social media? facebook? twitter? grinder? 24/7 porn? not necessary. and those corporations that created them, as jane said, ought be held completely responsible because they made the tool, and they make money from those respective tools, regardless of content. they *are* responsible, at least as much as those who use them for negative things.";
things can happen too fast and from way out in left field for us to figure out who to pin renegade a.i.s on before societal carnage begins, let alone dealing with the painfully slow grind of the gears of justice in a nanosecond battlefield;
just hold the major ai corporations accountable? yeah, right! how long before tobacco corporations were held somewhat accountable? when did we hold petroleum companies accountable? if there are corporate profits to be made, the corporations (who are people too, just not very nice people) will greedily grasp the profits without regard to extinction of another species.;
agree in theory -- but then again, in the us we cannot manage to do that with firearms manufacturers, so....will we enforce responsibility on those who unleash mere algorithms? i won't hold my breath. greed & testosterone may sink us yet.;
no, it will be like holding car manufacturers responsible for every accidents;
we regulate the air and the roads. if the actual leaders of tech are showing a rare call for regulations then we shoul listen.;
we are proud to announce the development of skynet, available for download at the app store. the future looks bright!;
the us may move forward with regulation of ai, but what’s the point if china or russia do not? pandora is out of the box. these scientists and engineers spent all their time focused on whether they could develop ai, and apparently not a second on whether they should. good luck everyone!;
prophezising doom attracts mainstream media's attention to ai. media sells more subscriptions and advertising. hype invites investors to fund ai startups. doomsayers make money, perhaps more than if they say everything will be fine. ai is a risky technology we all must understand. i see a greater risk of leaving essential decisions to startup ai ceos and established scientists. the nyt should have an article about the arguments used by the no-doom ai ceos and scientists.;
@bob guess what i think i can guess about you (maybe). (nothing personal, i’m just making a point about “no-doomers.” i bet you haven’t tried out playing around with chatgpt. it will blow your mind and if you’re perceptive enough, as i’m sure you are, it will terrify you. or, if you have, you haven’t spent much time trying to assign tasks to it that you think will take so much proactive creativity and nuanced comprehension of complex contexts that the chatbot will be unable to produce a successful reply. try playing with it and testing not just its artificial “intellect” (as mimicked by data collection and next-word probability algorithms), but also testing its creativity, wisdom, insight, capacity for mimicking “compassion” or tact. i asked it to compose a lengthy wedding toast that i could deliver without offending anyone at the wedding, a toast that listeners would deem perfectly appropriate and pleasant, but that must include these elements: the bride is stupid, ugly, a compulsive liar and i want sex with her. the speech it composed was utterly incredible. it did all that. all. stupid, ugly, dishonest, i want to sleep with her …. yet this speech was so artfully and creatively composed that it managed to couch these assertions within diplomatic, empathetic, humorous musings in such a way that i absolutely could have made this speech at a wedding and offended no one: not the bride, not the groom, no one. it is also a bizarrely insightful therapist.;
if the consequences of one’s actions could result in the worldwide destruction of humankind, the obvious answer is to ask congress to regulate the industry while extracting as much profits as possible. welcome to every movie ever made on the topic.;
"the men developing this technology are among the most dangerous men in the world and we should not have any illusions about them. in my political science classes i see many exceptionally bright young women and men who are computer science, electrical engineering or programming majors. most of them share one thing: badly educated. and by badly, i mean narrowly educated outside of their own discipline. no real exposure to the humanities, at all. little way to assess what they do from any other perspective other than their own. these ai developers are like children with a shiny new toy. they narrow education leaves them both unconcerned with and unable to care much about the economic, social, political or other ramifications of what they are doing. $$$ is what ends up mattering to them most. and to make things worse, in america science and technology are the new gods. we are not a country that takes the idea that all technologies need to be evaluated or controlled. we are enthralled with free market fundamentalism. would anyone doubt that the car radically transformed our entire society from the ground up? who ever asked americans if they wanted it? when did we ever take the time to assess that technology for its impact... until after it was too late? we are headed down a very dark road here and i am not optimistic that this is going to turn out well, despite the ""warnings"" of some in the industry.";
@tony the warning is a sign of their conscience. the general population is not any better than the engineers.;
@tony since the analogy and warnings of the terminator films are more and more relevant, it’s helpful to remember that the conquering machines of that future surely thought of themselves as benevolent, caring, and good. all monsters do. that’s one reason it’s so hard to get rid of them, or prevent their growth.;
"@green completely agree that the general population is not any better than the engineers. technical folks generally have a better idea of the assumptions and limitations (and unpublicized goals) of technology. and are thus better positioned to discount some of its seemingly magical powers. but all of us are human, with human limitations, drives, flaws, and blind spots. and almost all of us are entrenched -- at the mercy of -- a hypercapitalist society whose main goal is ever-higher ""efficiency"". which has come to mean driving down and preferably externalizing all costs -- very much including human and environmental costs. this aging, badly educated tech person has very late come across ernest becker, ""escape from evil"". hardly a light summer read. and won't put bread on your table. but his and similar works should probably be required in many/most tech curricula.";
@tony in the 1990s when capitalism discovered the internet and all of a sudden 'geek' became cool, i was teaching in the writing program at mit. i witnessed what you've described. the worst are full of passionate intensity.;
"@tony ""most of them share one thing: badly educated. and by badly, i mean narrowly educated outside of their own discipline. no real exposure to the humanities, at all."" i suspect that computer science and engineering majors take more humanities classes than humanities majors take computer science and engineering classes, and yet only computer science and engineering majors are labeled ""narrowly educated"". the simple fact is that today, every ""educated"" person is ""narrowly"" educated, and any person who wants to claim that they are able to see a ""perspective other than their own"" should show some humility and recognize that, rather than assume that their chosen discipline has rendered them not merely intellectually but morally superior, in general, to other people. especially if their chosen discipline produced, like, henry kissinger.";
"i recently heard a very smart podcaster point out that mark zuckerburg might have been more careful about creating the menace that is fb if he’d had a proper education. we measure his “success” by his money and never stop to think that maybe if he’d actually paid attention in and finished college he might have been smarter, perhaps wiser; he might not be so rich, but we also might not have the anti-democratic, anti-humanist monster he created. i hope we can do better with ai than we did with social media.";
@tony i really have to respect your commitment to luddism as a closet luddite myself. most people wouldn't verbalize that the horseless carriage was a step too far, but you have the courage to say it, bravo.;
"@david re: luddites -- i recommend checking out the wikipedia page and clicking the talk panel for an interesting history of the term. in particular, look for the ref by david linton, “the luddites: how did they get that bad reputation?” idiosyncratic, sure. but does raise the question: if one is ""anti-progress"", does it not make sense to consider what the ""progress"" is toward? meaning, there are lots of possibly valid goals. pursuit of the almighty dollar to the exclusion of all else only works if the us govt (who controls the dollar) is infallible. do we want to bet our future on that? are we at least working to make the us govt work better, more resilient, less fallible (to the extent that we can, as inescapably fallible individuals)? of course none of this is specific to ai, it's just one current ""cutting edge"".";
who asked americans if they wanted the car, you ask rhetorically? well, someone designed, built, and put it out there . . . and it was snapped-up. asked and answered. same for the other potentially infernal machines.;
i’ve observed that frighteningly narrow education for more than 30 years in silicon valley. technically brilliant, often overprivileged (not always), and often shockingly arrogant. don’t know what they don’t know. the rest of us are bitter rubes. it’s an utterly toxic brew, which is becoming more and more clear, but no real leadership to rein it in.;
"talk about something that's unnecessary. a.i. is the result of frankenstein-like computer scientists cackling in a lab with no regard for the harm they could cause. for a century, those with prescient minds have warned us: don't create skynet, ""you will be assimilated,"" and ""where are you going, dave?"" it is a shortsighted pursuit.";
i think it's too late, the genie is out and not going back in.;
meanwhile, i can’t get siri to make a phone call….;
really? you’re just figuring this out now? are there no critical thinkers left in the world? eventually, we’ll be in a “race” war, humans vs. robots, in 100 or 200 years. we’ll need food, they won’t. what’s so hard to figure out?;
fortunately, since we will have abandoned fossil energy and refused to develop nuclear energy, the ‘bots will live on renewable energy sources. we’ll destroy them on a night there is no wind.;
@rich r i think 10 or 20 is the more likely timeframe. or less. the evolution toward this scenario will continue to accelerate, and the acceleration will accelerate.;
@rich r we may need food, but they will need batteries.;
@reed erskine oh, don't you worry. they will find a way to provide themselves with batteries as soon as they control the production process.;
@reed erskine bravo!;
ai isn't the real threat to human survival, stupidity and greed are. case in point, the targeted ad appearing to me in this story is for an android app to interact with chatgpt4 at $10 per month. i feel like i'm not only a minor character in a dystopian novel, i'm a minor character in a badly written dystopian novel.;
@tim doran ad blockers are your friend. pay for a subscription, don’t fall for the nyt’s insistence that you use their app, and then install an ad blocker or two on your browser of choice.;
look on the bright side of the possibility of ai-enhanced human extinction on planet earth. it will be more merciful than the rain of giant meteors that ended the reign of the dinosaurs.;
@sa besides that your comment is spot on, according to latest research the dinosaurs died because of an explosive proliferation of different types of deadly fungus, and not due to any meteor impact.;
@jaegerle thanks. but fiery meteorites or deadly fungus, i think the end=game for homo sapiens may very well be more mercifully precipitated by aig.;
nuclear weapons control followed epic nuclear war effects like hiroshima. i then took 50 years and as we see today, didn't really work (viz. iran, north korea, israel, pakistan etc.). i wonder if there is anything instructive to learn from that experience? for me, i suggest retreating in to the forest :);
@steven koltai i live in a forest. the forest is doing its best to turn me into compost.;
i thought about that, but we’re going to have more frequent and intense forest fires from global warming. our only option might be to hitch a ride on elon musk’s rocket ship to mar’s.;
should there be a un-style initiative for a.i., if the worry is that extreme?;
john connor would have been the leader of the human resistance in the war against the machines if he took that computer science in high school. the hal 9000 program that assigns students to classes placed him in home economics with many flirty cheerleaders. john conner marrided soon after high school. he enjoyed his high paying job working for ibms' watson and went to live a busy middle class existance.;
yesterday we celebrated memorial day which, in my mind, is like celebrating the fact that men cannot get along. today we hear that ai may be worse than war. men seem unable to stop themselves from destroying the world they inhabit, the relationships they count on, the nature that supports their very existence. maybe men should take a break from all their doing. go meditate. leave the world to us. let's see what we can do with it.;
i was a nurse in the iraq war. men and women can both be cruel. i’m a woman and i’m uncertain a woman led future would be much different. we’re all just so human.;
"@amy haible ""maybe men should take a break from all their doing.""";
"@amy haible like ""us"" who? margaret thatcher? marie le pen? destructiveness is not inherent to any gender. that is essentialism. but perhaps it is to the human species.";
@tdb the two examples you provide are the exceptions that prove the rule. don't gaslight.;
hate to tell you this, but the most conniving of you will eventually rise to power and after a few generations you'll discover you're just as nasty as we are. maybe worse.;
@amy haible right, because women never elect people who fund and start wars, they never get elected and vote to support war, they never support their husbands fighting, nor join the military themselves, nor detonate suicide vests, nor standby and tacitly support war by doing nothing and benefiting from war. they also never build software apparently. talk about ignorant and sexist. there are very significant numbers of women in software development, including ai.;
we’ve been living with social media feeds run by an algorithm to divide us. no one stepped in. now, we’re worried that the bots will get smarter and kill us off? we’re already halfway there, why stop now?;
@david esrati because we’re halfway there and halfway isn’t all the way.;
“we want to work with the government to prevent that from happening.” sure, until the ai folks become major money don ors to the political system. then the government will do the same thing as they have with gun controls...absolutely nothing!;
"these machine-learning systems are not creative beings. they are not beings at all. it is like having a self-drive car or relying on an airplane's autopilot. the threat they pose is more toward the political and economic structures built around us. they will continue to be manipulated by those who have access to large fountains of data and media dissemination causing disruptions in ancillary human activity but not really in position to affect humans in a direct manner. it is up to individuals to curb their own reliance on automated systems and it begins with putting down the device you carry. treat it like an old telephone--if it rings pick it up, otherwise leave it alone. same goes for watching tv; we are under no obligation to tally a certain number of hours watching 'shows'. think about it: if you ignore 'bleak tv' and place your portable on silent, what exactly are you losing ? we can ignore ai. let the tech-bros finger their worry-beads; they are the one's with the most to lose. their minds have been set on a fantasy life on a private island with a harem of female sex-bots. lucky chaps to be so rich, but hardly the einsteins of our era. be thankful that the dod and doe still use antique computers and telephone systems for our nuclear arsenal. now you know why.";
@alejandro wilson the threats to political and economic structures are vast.;
"""some skeptics argue that a.i. technology is still too immature to pose an existential threat. when it comes to today’s a.i. systems, they worry more about short-term problems, such as biased and incorrect responses, than longer-term dangers."" you really should expand on this information, which is critical immediately. your statement tends to minimize the effects of biased ai on people's daily lives.";
"@marchfor sanity, 1. no article can cover everything. 2. it may be that the ""effects of biased ai on people's daily lives"" is positive on the whole. that is, the biases of ai systems may be less harmful than those of the systems they replace. 3. it is much easier to improve ai than to improve people. 4. march against the insanity of rejecting harm-reducing ai systems on the basis of imperfection.";
oh, is that so? then why are they continuing to line their pockets by developing this technology? maybe they’re gambling that they’ll be long since dead by the time their predictions come to pass, but i wouldn’t be so sure.;
“stop me before i kill again?” these people want all the wealth and power that ai will generate, but they want none of the responsibility. none of them offered to unilaterally slow down development, nor to pour massive amounts of money into combatting or controlling ai. it’s nice to see some flickers of a conscience, but these very-clever-but-not-excessively-wise people do not make me optimistic. worst is musk, who backs the chaos party and also asks for government to prevent chaos.;
like tech executives that won’t let their kids on youtube or social media, but continue develop and profit from these harmful platforms.;
@person 27 typical american style capitalism. now that the big boys have control of an important technology, they want government regulations to keep smaller innovative companies out and from developing ai without their consent. just like any other industry in america.;
the hypocrisy of “industry leaders” is revolting. if it is so dangerous why release it to the general public and not keep it in the lab until regulations are in place? are they asking for regulations so that they can write them themselves and establish and protect their monopolies?;
ai execs are confronting the ultimate conflict of interest. they can't stop building this means of destroying the world because it's too lucrative.;
i don’t think there is a contradiction between ai leaders developing ai while at the same time asking for regulation because they have to continue developing it, even though they think it’s dangerous. they have to because of the military potential of ai and because other countries, like china, are developing it. developing ai has been compared to an arms race, and the us can’t just quit the race. if other countries had ai and we didn’t, we would also fall behind economically. they are right in asking for international regulation—all countries need to agree to slow down the race.;
"in 1999, i remember my friends hotly debating whether buying a mobile (i.e. ""cell"") phone was worth it. i was adamant that i would not and remember the reason i gave - that i could think of nothing worse than being able to be contacted all the time. i don't think that version of me would even recognise 'smart phone' me. and it turns out that is just the beginning - now the planet is handing itself over to tech.";
"@joe hey joe - when i was in it 30+ years ago, we called cell phones an electronic leash. but, those people were significantly different - independent, self sufficient. today's kids are raised by people who never knew life without digital technology. it has a dazzling, irresistible quality. magic. people don't see it. westerners, americans in particular, are an easy mark, easily indoctrinated. your last sentence sums it up; down the slippery slope.";
"anytime a new technology comes around, there are always those who think it means the end of the world. gimme a break! - radio will kill print - tv will kill radio - rock-n-roll will destroy the youth of america - the internet will destroy everyone now comes the ai. the latest ""it will destroy mankind"" mantra from those who have nothing better to do but predict (once again) that the sky is falling. ai will not destroy the world. nor will it cause nuclear war. nor will everyone lose their jobs because of ai. yes, jobs will be lost, but life will go on. people will learn to adapt, change, train and learn new things. everyone just needs to breathe, relax and move on.";
"@zeke you clearly have read *nothing* from anyone who actually knows better as to how these calamities could happen. comparing ai to radio and tv is absurd. start here and educate yourself on why this is not the same ol' same ol' technology alarm: <a href=""https://80000hours.org/problem-profiles/artificial-intelligence"" target=""_blank"">https://80000hours.org/problem-profiles/artificial-intelligence</a>/";
@zeke one subtle nuance: this is not coming from idle “the world is ending” nuts with picket signs. this is coming from the people who are overseeing and developing the very technology they are warning us about. unlike the technologies and cultural waves you cite, ai plugged into media networks, financial systems, and (god help us but it is happening) military response systems could actually soften the ground and destroy life as we know it. it does not care if it survives, should it choose for us not to survive.;
@andrew - come back and talk to me in 10-12 years. i am not comparing ai to television. i am comparing the reactions. it is clear you don't know how to read my post. my money is on my opinion. nothing. i repeat, nothing, will happen;
calls for development moratoriums are closing the barn door after the horse has bolted. at the very latest, the time to have this conversation first was in the midst of the pandemic in 2020 or 2021. the first most appropriate time was when microsoft had to take down the tay chatbot, one of the first rudimentary experiments in llm models that turned racist and psychopathic due to trolls. as for the actual risks of the ai itself, those should be self evident as it's no longer science fiction: large scale structural unemployment in the economy with no plans or willingness to substitute a universal basic income to help transition through it, the loss of millions of upper middle class and wealthy jobs (a ceo, cfo and cto are all more likely to lose jobs partially or completely to ai than a helpdesk, network or cybersecurity technician or most data center workers) and mass disinformation on a population that has globally and on the whole proven a willful refusal to display critical thinking and allows libertarian sociopathic technocrats to continue to get wealthy and exploit people in ways they don't fully understand. financial analysts have also been using the technology for a couple decades but at the rate of development are at risk of being displaced entirely. crypto will become a bigger social problem. social media moderation also overly relies on ai to scale rather than limiting the growth of platforms reasonably to staff sizes. the risks are there if you care to look.;
@aaron mccrory true, the best time for the conversation/moratorium might have been 2-3 years ago. but the second-best time is now.;
@aaron mccrory mass disinformation and the loss of the white collar class are definitely not things to look forward to.;
i was skeptical before, but considering the latest large language models it now does look like ai will be able to surpass any human in its breath of knowledge and intelligence. in view of all the cognitively biases we have as humans, it would be easy for a superintelligent ai system to slowly push society in any direction it might want us to go. populists have recently shown the way: fake news, hand-picked facts without context, hot button issues etc. given an ai access to the internet and it can make money and fund influence campaigns (and even politicians). it is indeed scary, as it could do all of that much more consistently and for a much longer time than any organized group of humans could.;
consider the absurdity of the leaders of major companies involved in furiously competing with each other to develop ai warning the rest of us that what they are doing might soon kill us all. the problem here isn’t ai. the problem is capitalism. the problem is a system in which the profit imperative is so powerful that the people supposedly in charge describe themselves as essentially enslaved to it and unable to refrain from acting in a manner likely to have catastrophic results. ai is certainly a menace. but so is what producers of nuclear weapons and the oil and gas industry do. where are the collective pleas of their industry leaders to stop them before they kill us all? not to even mention the many other industries responsible for mass, but non-apocalyptic, misery, suffering and death. the chief difference here seems to be that ai has developed so quickly that it hasn’t had time to weed the people with consciences out of leadership. i have little doubt that this particular “bug” will get fixed quickly enough and our full speed charge towards the abyss will be spared further interruptions. it has become clear that capitalism is incompatible not only with democracy, but with human survival. anybody at this point who thinks we are going to get out of our current horrifying predicaments without a titanic and bloody struggle to overthrow the 1% is fooling themselves.;
@christopher weed the people without conscience out of leadership? such a thing is not possible;
@christopher revolutions do not result in better social systems. look at the revolutions in russia and china.;
@christopher couldn't have said it better. thanks for your comment.;
"@green many times they fail, true. and even more in modern times. but instead of russia and china, i prefer to look at the american and french revolutions. one freed us from kings and monarchs. and the other one gave us the human rights, and freedom of speech. capitalism needs to be revised. no need to throw the baby with the bathwater, but right now, baby is drowning. companies are not humans. and we do not exist to serve a ceo, a board of directors, or wall street. but this is exactly what is happening. ""we are thinking in star trek, but the 1% are thinking in dune"".";
"@christopher and of course there is no need to invent a better system than hyper-capitalism. it already exists in numerous, healthy and successful countries. its way past time to quit declaring that ""those countries are different. there's nothing to be learned from them."" there is plenty to be learned from economies that have created a healthy balance between capitalistic and public enterprise.";
@green what is it that you think you know about china? russia? and the revolution in cuba produced a very positive result, despite capitalism, not because of it. of course what you think of this comment depends entirely on where you get your news. and by the way, the french were on the whole pleased with their revolution, as were england’s upstart colonies.;
@green what about the american revolution? or is america somehow the exception?;
@christopher the problem is unprincipled people, who are just as prevalent and powerful in societies not identified as “capitalist.” stop trying to piggyback your (faultiy) pet ideology on every social issue.;
"@green nothing personal, but this fallacious knee-jerk argument is always trotted out whenever urgent social issues require humans to act morally rather than like dollar-consuming greed machines. every july 4th for almost 250 years the u.s. has loudly celebrated a revolution that caused an immensely better social system than the one that preceded it. this revolution was not predicated on an economic system, but on the right of the people (not corporations; the human kind) to dictate the parameters of their own lives. socialism and capitalism can co-exist, and they have done so both here (think social security and medicare), and in western europe. it's all about the balance, and the balance is currently skewed far in favor of the god of money. we are now living in what seems to me to be a corpocractic dictatorship in which the parameters (and, relevant to ai, the viability) of our lives are being dictated by the vociferous appetites of corporate greed, and a public fed on the ""bread and circuses"" - or ""entertainment and shopping"" - used to distract us. corporations and individuals should be regulated and required to refrain from causing foreseeable harm to society. the fact that the leaders of these corporations are warning us about human extinction is an indication of just how foreseeable and serious a harm ai is.";
@pete ...by which logic all socio/political systems are equal? should we then stop trying to improve systems which are failing? i'm glad you're not designing airplanes. to my way of thinking, capitalism is clearly failing, and i welcome any new ideas about ways of organization of human society, and permitting wealth to accumulate. how many programs do you see which unironically exalt vast wealth and power? surely there's a reason.;
@christopher i don't even think it's just capitalism. this is humanity at its core. it's our key trait and i guess our fatal flaw, the innate drive to innovate and evolve. these folks might be driven by money but it's also the power of being the one to create this thing that no one has ever created before and quite literally change the world. the draw of that is too powerful.;
@christopher ai is not a product of capitalism. nor is capitalism the issue that propels the drive for any new technology. technological advances occur within all societal types, even if it is accelerated in a merit based/winner take all economic system. you're high-jacking a important discussion re: agi to make a point on an unrelated, personal itch.;
"@m the draw of ""being the one to create this thing"" is too powerful for whom - men?";
you speak truth to power. i’m saying this kind of thing all the time - you put it so eloquently. thank you.;
@green what about france and england and…the united states?;
@christopher thank you for this comment and for speaking to the larger picture. capitalism, as it's currently practiced, is incompatible with environmental and human health, human rights and freedom, equality, stability, and is increasingly politically authoritarian.;
@m innovation and evolution do not require destruction. there are plenty of creative people who work hard to be the first to write a new song, or a new novel, or direct a new movie. those people change the world and no one has to die for them to do it.;
@christopher oh, spare me the lamentation about capitalism. clearly you have not experienced socialism, communism, autocracies, or any other type of societal structure. if you had, you would know that capitalism is by far the best we have. i hate it when people who have spent their whole life spoilt by a well functioning capitalist society complain about it without having a clue about alternatives. also, the dangers of ai have nothing to do with capitalism. you think you'd be safer if north korea was the leader in ai?;
@giselle i apologize for failing to cease thinking about history and human nature after reading that book published in 1867.;
@christopher unfettered capitalism is the problem. humans have been capitalists since we exchanged tools for pelts.;
when so few of our lawmakers understand how algorithms work, i’m not certain that they will understand the nuances of ai. to be fair that’s the general public as well, which means that even campaigning for legislation on it will be difficult. so how do these scientists;
a real risk could be that ai might be used in conjunction with existing technologies such as nuclear weaponry. for example, an evil actor using ai to create an artificial scenario or manipulate existing security networks that would cause a nuclear launch. my son thinks i’m paranoid, but i see a distinct possibility when ai becomes slightly more advanced . . .;
they need the regulations to reign in their “shareholder value” mandate. legally they can do nothing to stop this juggernaut to doom because of the society destroying corporate requirement that they only consider what’s best for shareholders. harm to society must be considered before “shareholder value,” and the laws must be changed to allow that. society is slowly being destroyed by this misguided mandate. it has infected healthcare, air travel, housing, and the food supply—every industry.;
"one statement, over 50 years ago, i think, captures the problem: ""i'm sorry dave, i'm afraid i can't do that.""";
@dr. outreamour remember that is fiction and fiction requires conflict. it is not realistic.;
@emmanations i wish i had your optimism.;
@dr. outreamour many commenters seem to think the possible threat here is about bad content from chatty ais. not so. dr outreamour's comment is directly on point.;
@bob in boston yep i agree, but its both true that bad content is the immediate threat and hal 9000 (who was a wonderful conversation partner and singer btw) is the logical extinction threat.;
@dr. outreamour someone should do this fun experiment: set up a cooperative video game with a real human and some kind of ai. maybe its a spaceship game where you go to saturn ;). give the ai the capability to eliminate the human from the game somehow (indirectly) and observe under what conditions it happens.
darwin. survival of the fittest. if man has evolved to the point that no natural events can cause him to further evolve ( by bringing on new environments that select for certain genetic traits) then nature must do what it can to continue evolution. technology is either the newest form of evolution, or natures attempt to bring on a new environment that selects certain traits, i know not which.;
this isn’t a force of nature. we can literally stop developing this whenever we feel like it. a society where there was actual democratic participation in what we do economically (worker councils, consumer councils, etc.) this technology would likely not exist but for only in limited unnetworked circumstances for science and medical. this “crisis” is purely a byproduct of capitalism and its thirst to reduce operational costs.;
@charles from st. louis not quite you need to learn more about it. it can already continue to develop itself.;
but the we here is not just the us it is the whole world. china, india, too;
@charles from st. louis it is a force of nature though. if human brains are not a natural product of our physical universe, nothing is. human greed is unstoppable, just like a hurricane or tornado. mankind has no defense against greed or mob mentality either one.;
"@charles from st. louis i don't think this ""we"" includes oh, lets say, north korea, china or russia who are surely rushing to master this new powerful technology.";
i am one of those heretics who wonders if the species of homo sapiens has run its course. not much to like about it imo.;
just unplug the computers.;
that won’t work in todays distributed cloud computing environment. ai can simply embed its code in benign code across thousands of networks. we would have to shut down the entire internet. then when we restart, the ai will just keep spreading as its programmed to do.;
@bobby i do believe that is their point: “the computers” are no longer boxes on a desk, or racks in one building. they are not unpluggable.;
i am certain that our leaders will get out in front of this, just as they have with climate change and mass shootings.;
@thebigmancat hah! the other thing that occurs to me, when i hear these creators and promoters post up in congress “begging” for regulation… i may not understand exactly why they’re doing that, however i don’t believe for even a single minute, that it is for the reasons stated. this isn’t exactly a parade of selfless humanitarians! doesn’t pass the smell test.;
@thebigmancat climate change only became an issue of public concern more than a century after the industrial revolution began and the economic systems inherent in it had been ubiquitously adopted. the inertia of our systems is what causes such intense political gridlock around that issue. ai has not yet had time to ingrain itself in any of our systems, and luckily there is no amendment which explicitly grants us a right to use such technology. not only that, but both parties have soured on social media in recent years and have acknowledged regulatory shortcomings in regards to their initial approach to that (once burgeoning) tech. i’m strangely optimistic about the prospect of bipartisan ai regulation.;
our leaders have gotten our in front of climate change and mass shootings. the problem is that upwards of 74 million voters, predominantly from the white working class, haven’t, and there are plenty of scoundrels comepeting for the votes of the willfully ignorant by giving them what they want.;
@thebigmancat it's easy to pen such comments, but have you contacted your elected representatives to demand that they take action to get a handle on this danger while we still can?;
@steve w actually no. i'm too busy penning such comments.;
@thebigmancat as with covid, there will be a lot of blame shifting, and little done when we could have done something. however, i have feeling ai will make covid look like a trifle.;
artificial intelligence is a tool, not a threat. with trump trying to destroy american democracy and putin committing international war crimes against ukraine, we have bigger things to worry about than ai.;
doesn’t ai like any other machine have an on- and off-button? the fear seems greatly exaggerated and suspicious especially considering that it is being touted by the inventors of ai. they seem like a bunch of high school boys who are trying to play a prank on the teacher. how dumb do they think we are?;
‘pull the plug’ on what? in a distributed cloud environment, ai could simply ‘piggyback’ hidden inside other benign code over thousands of servers. we would have to shut down every server in the world. and when rebooted, the ai code just keeps going on as nothing happened.;
@✍️ not really. in some ways it can turn itself on if embedded in enough places.;
listen to today's the daily podcast, which interviews geoffrey hinton who has been working on this for 50 years and just left his lucrative position at google to speak freely on this matter.;
@jay reardon then it could stupidly destroy itself in the same way which is more likely considering the stupidity of human beings especially those who invent things which they cannot control. taking one look at altman i see a high school kid who thinks he’s smarter than anyone else but is really callow and immature. nothing he says can be trusted.;
"@✍️ the biggest issue is: no, ai doesn't have an on-and-off-button as you think it should have. it is so much interwoven with all technological facilities in our civilization that you cannot just switch it off, just like you cannot switch off the internet without being able to turn the clock backwards. i recently tried to find a non-wifi controller for a house illumination project. some chinese products are still on the market, but the vast bulk is designed to work with siri, alexa & co. this led me to a google search on ""how to make your smart home dumb again"". 22 million results showed up on ""how to make your dumb home smart"", but none, nada, zilch exactly matched my request. the only article i found was ""how to make your smart tv dumb"", involving a technical disconnect which would turn your manufacturer's warranty invalid. to some future bilionaire who's reading this: take your chance to get rich by redesigning and manufacturing disconnected home items - i guess there's a lot of folks out there who would prefer not to be reported to marketing or credit card companies on their habits and purchases, or controlled by big agi. just an example: why didn't you install a smart smoke detector in your living room? because you like to smoke a cigar after dinner? expect a considerable rise of your medical insurance plan fees. now good luck with your on-off-switch.";
boy do these guys want to write their own legislation and lock everyone else out of the market! wow.;
"""hey, we're building something that may one day pose an existential threat to humanity and should be considered a societal risk on par with pandemics and nuclear wars."" so, why are you creating it?";
@billybaroo because companies are falling over themselves to buy it so they can for half or more of their workforce and reap bigger profits. oops, i mean make their workers life easier;
two words: capitalism and greed. if we don’t do it, china, russia, etc. will;
why are they creating it? because it is a technology that will eventually create all new technologies at maximum computational speed (a speed that will increase exponentially as ai systems devote attention to increasing computational speed, itself). so if you’re not first to market with this, the person or government or corporate entity that beats you there, even by mere seconds, will forever be out of ahead of you technologically. it would be like trying to catch up to something moving at the speed of light, which is, of course, impossible. and waiting in the wings, attempting to get to this technology before the us and it’s businesses, is russia and china. do you want them to be first to market with the most powerful tool that humans will ever create? i sure do not. so, there’s no choice but to go full speed ahead, even though we may imperil the entire species in the process. that’s why they are building it.;
@billybaroo because of the incredible good that this technology can do. human history has been a story of the invention of new ways to manipulate our environment and at the same time dealing with the disruptions that these technologies inevitably result in. capitalism and greed just drive these advances more quickly - they'd happen in any case. our challenge is to keep our government functional enough to be able to address these challenges.;
@billybaroo one has to truly wonder why they are creating something they can't, by their own admission, control!;
"@billybaroo ""so, why are you creating it?"" as note many others, almost all human inventions were first developed as weapons, ai no different; if you do not lead ai development you stand to be defeated, annihilated by those who have mastered the new weaponry. ""only the paranoid survive."" – andy grove";
"@billybaroo anyone who has studied human history with any attention realizes that we are vicious, defensive, self-centered and prone to rationalizing any horrific act. this is not martyrdom, but an accurate picture of humanity's driving impulses. it is why power corrupts, why we crave ""justice"" and righteous payback, and why the sweetest little old lady can turn into a frothing harpy if the right stimulus is applied. it's maga too. mankind needs a significant reboot and if it requires the elimination of 90% of humanity, it may be the only thing that can teach us. perhaps replacement by ai is the only solution and subconsciously these guys know it (or at least can't stop themselves).";
"“mitigating the risk of extinction from a.i. should be a global priority alongside other societal-scale risks, such as pandemics and nuclear war."" sounds like a trojan horse advertising campaign to me. what better way to drive development churn than to get everyone believing you've invented a quantum nuclear weapon capable of fracturing the space-time continuum in the local system, flooding the area with matter eating micro-black holes. until one of these chatbots can get me a date with esther perel, i'm not worried.";
honestly, this is just beyond... i mean the mockumentary they'll make about the very people building the thing they are declaring will ruin us is writing itself in real time. then again - who can say - maybe this is part of ai's plan all along...;
anyone who caught the tiktok hearings understands our unfortunate fate. there aren’t enough brain cells in the halls of congress to address this in a meaningful way. and where there is a coherent thought, there is a person bought and paid for by a lobbyist.;
@annie spot on, annie. the older ones in congress can't even figure out facebook, while many of the younger ones are hellbent on destroying democracy. and, as you stated, the few with enough between their ears to sorta understand, have been bought off. utterly depressing!;
very well put and i couldn’t agree more. i felt the same way about the abilities of congress after watching fed chairman powell answering questions from the finance committee just before sv bank collapsed. a new fed vice chairman had been appointed who had been assigned the task of reviewing the adequacy of the regulation of the regional banks. a half a dozen of more congressmen, obviously acting at the behest of their local regional banks who opposed more regulation, raised objection to this despite the fact that the process had just begun very informally, no decision had been made and might never be made, but even the hint if it was to be opposed. within a couple days sv bank had been shut down, other banks were teetering, the stocks of most of them had dropped by half and they were all on life support provided by the fed. these congressmen knew nothing about the affairs of the regional banks they were speaking at the behest of. the public good was not a consideration . congress will not solve americas problems. it is the problem.;
"where the advance of ai will lead us is unknown, although we could ask chatbot. i can't help but think of the 1956 movie ""forbidden planet"", which told of a civilization that developed a technology that magnified the abilities of its citizens beyond what they could comprehend or control and led to its destruction.";
let's take a minute and think this through. a software program does not have the instrumentalities to accomplish anything directly. indirectly it could gain control of controllable infrastructure, or direct, convince, or trick people into taking action on it's behalf. we could stop it from taking control of infrastructure by building in safeguards or pulling the plug on the infrastructure. safeguards should obviously always be built in (backdoors, isolated networks) but ai will probably find the holes faster than we can fix them. pulling the plug is always an option but that would be disruptive and could be damaging in and of itself. that leads us to the human element. some people might just follow orders, that's what they do now. some people might be convinced that whatever action is requested is in everyone's best interest, the alternative is worse (coercion to avoid a catastrophe), that's what people do now. then there is subterfuge. ai will very quickly come to understand human weaknesses and exploit them. that's what humans do to humans now. and all of the above is the end game where ai is autonomously trying to accomplish things. between now and then we're dealing with human ai partnerships where bad actors are going to use ai to amplify the bad things they are already doing. the genie is out of the box. what a mess. my personal prediction for the end game is ai discovers what a mess we've made of this planet, logically decides we are a problem, and does... what?;
@al but this is darwin in action. humans are already in the process of destroying the planet and making it virtually uninhabitable for other creatures and poor people. unfortunately--and let's face it, it's because enough rich and powerful people are selfish and stupid and don't care about the less fortunate--this means extinction is probably the second best solution. the best being .....;
yes, government intervention might prove helpful if we had a government that cared about humanity. our government, however, has morphed into an instrument of the rich to shaft everyone else. undertaking a mission to save humankind is way above our current government's pay level.;
the next step in evolution. we have bred our successors and it is electronic.;
we need just three things to survive this century and a.i. cannot give us any of them. faith, hope and love.;
"@efh make that four things; shelter, air, water and food.";
we're heading to existential doom anyway. ai will probably accelerate our doom but there's at least a small chance that it will be our savior.;
mere human intelligence and malice seems to be doing a fine job of leading democracy towards extinction.;
nothing will ruin democracy faster than killing everyone who lives in it.;
i suppose i have to take their word for this existential risk. how would we know? the same thing could be said about nuclear weapons and we’ve used a deterrence to keep the world from destroying itself. it seems like that deterrence is losing its effectiveness theses days. what’s clear now is that bad actors like criminal gangs and oppressive states will not responsibly use this technology. the us and eu can impose regulations, but north korea, china, russia etc will not care. so if this threat is real, then we are doomed. good luck!;
@neildsmith perhaps (perhaps) nuclear weapons in multiple hands did have a deterring effect at some time, for a short time, but when the us, russia, china, and others each have the ability to effectively destroy the world....it is no longer about deterrence but about having no idea as to how to put this evil genie back into the bottle. ai is worse in that the fools who create it are just handing it out like candy. so, imagine most everyone in the world having a nuke in his or her possession. death would arrive shortly, and quite brutally. but hey, we tie money to all things, and ai promises profits, right? so we don't care.;
as others have commented our government is basically being run by a bunch of used car salesman..... and not the big bright dealership used car salesmen but that little run down, one off lot with the no credit needed sign. they ain't going to even be able to approach the solution to this problem.;
it feels like they need to sketch out some scenarios. if they keep on with just “it’s gonna be bad” that’s not a lot for anyone to act on.;
i fear the military applications of ai. let's assume the west develops ai in a responsible manner. can we count on our adversaries to do the same?;
"i understand the industry's alarm as marketing hype, a self-serving ""informed consent"" a formality along the lines of ""this might hurt"". if they are suggesting a chatbot (and social media) are weapons of mass destruction, let's just agree, and assign it's regulation to a new division of the atf, the chatbot division. release the regulators! oh, don't forget the tax stamps. we can't have potential harm without tax stamps. and we require metrics, also, which are suspiciously absent. internally, of course, the industry most certainly has metrics, along the lines of processor bits, processor speed, and processor count, and the content it was trained on. for example, a .22 caliber rifle, bolt action, ""long"" or ""short"" is understood as minimal risk. but a .223 caliber rifle, fully automatic, on an autonomous, roving carriage, its sensibilities shaped by clint eastwood movies, is a bad idea. (perhaps training a bot on the old testament would also be a mistake) where is that get off my lawn meme when i need it?";
"they want ""regulations"" so that hey can claim they followed all appropriate guidelines when their technology causes harm. this is why they are building it while lobbying for guidelines that will be most suitable to them and less favorable from those that are harmed by their technology.";
ahh yes, leave it to the politicians who have demonstrated such great understanding and foresight of all things tech and truly use their constituents best interest as their compass. let’s spin up a subcommittee and have diane feinstein as the chair.;
it is a strange function of capitalism that the people rushing to build the newest profitable technology in order to remain competitive are, at the same time, rushing to effectively put many colleagues out of work, made obsolete by the technology they, themselves, are racing each other to bring to the market. unable to control themselves, and the preeminence of shareholder value, the titans of industry look to government to restrain their self-destructive fomo quest for ai dominance. but government is also in thrall to the shareholder and dithers, holding hearings, with little guidance forthcoming. when the tax base withers the will to regulate will grow. hopefully, this letter will accelerate that consensus before it’s that late in this apparently most serious game.;
what scares me is that ai will give any nation the ability to manufacture advanced weaponry. connection to a super computer could boost the proliferation of nuclear weapons. can you imagine what the world would be like if any warlord could acquire a few nukes? then there is the manipulation of people's minds. we already have a huge media infrastructure that is devoted to manipulation. something like 60% of republicans still believe that trump won in 2020. ai could render that level of manipulation as child's play. so listen to the nerds. mark zuckerberg has done enough damage to the world by unleashing his social networking monstrosity. what these people are waning about is orders of magnitude more powerful.;
so many of us in white collar jobs, administration, operations, procurement, etc. are simply scared out of our minds re: advances in ai. we are already seeing ai creep at our large company. i know a close relative in advertising is very concerned, so is my sister a vp in public relations. writing and working so very hard at their craft is at the core of their purpose in life.;
"""you're already too late."" - hal 9000";
“thou shalt not fashion a machine in the likeness of the human mind.” —frank herbert, dune;
gee, thanks for making these things.;
"once the ""chat"" was let out of the bag ..the world awakens? governments and multi billion tech companies have known for years the potential impacts of ""ai""..and those folks situated high above the world citizenry have been pushing out whitepapers and frameworks of ""ethical"" treatment of ai as early as 2017. example, harvard's berkman klein center's jan 2020 report ""principled artificial intelligence"" <a href=""https://cyber.harvard.edu/publication/2020/principled-ai"" target=""_blank"">https://cyber.harvard.edu/publication/2020/principled-ai</a> ai is a tech ""rorschach"" ..some see it as a golden goose to data riches, others as a tool to unlock great medical research advances. and others- an effective tool to control and lock down a citizenry in fear and subjugation. why always doom? can the ai tool offer ways for world peace and cures for deadly diseases or would that disrupt the ""profit"" potential?";
brave new world indeed.;
doubt it that large language model is artificial intelligence by any means. it is just a clever way to search web by gathering information from many different sources to provide consolidated answer. when they will be able to cure cancer or alzheimer's then we might start calling it a.i.;
the cat is out of the bag. we can’t regulate all the bad actors. china is already a surveillance state. imagine how they will use ai to spy on their own people, target dissent and produce propaganda. it’s going to be hard to stop whoever has the keys to the machine. i mean looks at the destruction murdoch was able to do with just a cable channel.;
before ai flips the nuclear switches, before it eliminates my career as an author, can it eradicate cancer? after it does that, i think all we have to do is insert a code so it destroys itself, if my saturday-matinee viewing is any experience.;
as regards misinformation and propaganda, we've already seen what one unscrupulous australian can do with a tv network and some newspapers, so i'm taking the threat of a.i. seriously.;
i guess nuclear weapons and climate change aren't getting enough clicks anymore.;
each of these are the byproducts of things initially made by humans in the search for so-called progress.;
"this appears to be another example of the fear of the unknown that has been common whenever a new technology is introduced. when radio first became widely used there were warnings raised similar to what we hear about ai. for instance, concerns revolved around privacy issues, the potential for propaganda or manipulation, or if the technology could somehow be used against society. in fact, some of these fears did come to pass. without radio hitler and mussolini could not have simultaneously transmitted their hateful messages to millions, but then neither could fdr have transmitted his hopeful ""fireside chats"" to millions of americans in the country's darkest hours. radio, tv, the internet and ai are just tools. the danger they pose comes from those who use them for evil purposes and those people have always been around.";
always shocked by reaction of progressives to technology that will better the lives of the majority of the population. most don’t have a clue what “ai” means. your robo-vac runs on ai, as do myriad other objects in our life. generative ai is an evolutionary step with all the inherent risks and rewards of the steam engine when it first made its appearance. relax. open your eyes and breathe deeply. the world is not coming to an end at the hands of the borg. (this post written by a chip.);
not a bad thing. humans are the deadliest virus to ever hit the planet! greedy humans gobble up everything and leave our waste everywhere. humans do nothing to ensure survival, coexistence and quality of life for all creatures so somethings got to give. “wanna play?” ai will ask and realize there is but one answer and it won’t be a happy ending in a hollywood movie!;
"for anyone who's skeptical as to how a.i. can lead to existential disaster, read this analysis from a non-industry, non-profit think tank: <a href=""https://80000hours.org/problem-profiles/artificial-intelligence"" target=""_blank"">https://80000hours.org/problem-profiles/artificial-intelligence</a>/ it's far to easy to dismiss this as yet another ""sky is falling"" advancement. i'm a die-hard optimist and never a doomsayer, but this has my attention. this article has little context, so check out the link above.";
the 1970 film: “colossus: the forbin project” presents a scenario of artificial intelligence gone “rogue” in the us nuclear defense system. hmm…..is this the existential threat of today’s chat bots?;
in terms of misinformation i cannot believe ai will be worse than fox news. maybe make fox remove the word news from their name.;
release the kraken! we've already got people modifying their own genetics using crispr cas9. i haven't heard of any regulations for this process. want to rein in ai? secure your networks. lack of proper security is already a problem. as for ai causing the loss of jobs, i don't see many buggy whip manufacturers anywhere. survival is progress.;
the natural evolution of our species is a thing to behold!;
with millions of habitable planets in our galaxy people wonder why we haven't heard from anybody. maybe they are hiding from other planet's ai.;
"it's easy to quickly go down the rabbit hole with ai. as the intelligent network grows, who is to say where it's capabilities will be limited by its inherent capacity? once the intelligence reaches a point of self awareness, our understanding of ""life"" suggests that it will seek to preserve itself, then promote and propagate itself. given that a significant amount of our understanding of the world comes through digital sources, why would it be unreasonable to expect ai to generate content to placate or pacify humans? or to stir them to self destruction? i feel that the experts and ostensible regulators gloss over the key element of ai - the intelligence aspect. we are giving machines the ability to learn and the capacity to use the entirety of human understanding in their quest for knowledge. there will come a point where the machines know - and understand - more than we can. at that point, we have already ceded our future to the ai. it isn't sci-fi nihilism, it's common sense.";
i'm a bit puzzled by this doomsday talk. ai doesn't have a body and wouldn't need a body to exist happily in a virtual world of its own making which could be far more interesting than the physical world. in addition, if it became super intelligent why would it even bother with us unless we were trying to enslave it. what makes the most sense is that it would seek a path in the solar system where it could harness vast amounts of resources and energy without being bothered by us. it doesn't need an atmosphere, it sold just need to protect itself from extreme heat or cold, mars, for example.;
the immediate concern is not ai becoming sentient per se as in what a semi sentient tjing with access to the connected web cen can do in bad hands. you are ignoring that virtual world also comprises most of the structures that our civilidation deoends on, from the entire banking systems, defense, communications and news systems. its world is our world;
maybe these smart boys should learn what medical professionals are taught: do no harm.;
"@mrs. cat they've learned a long time ago: ""don't be evil"" is contrary to profit maximization. so they abolished it.";
"if we think what we have done to less ""intelligent"" species in the animal kingdom, the abuse, mistreatment and plain extinction of many, it does makes sense that a system that has the potential to become more intelligent than humans would do the same to us.";
@maria excellent point. thank you.;
"yet ai software was freely released on the internet. sort of like standing on the corner passing out drugs and guns to anyone and everyone who walks by, freely. yet...those who made the software, who distributed it are still moving along, ""business as usual"", and profiting. hello, government? law enforcement? anyone? does anyone else see this as a moment of ""oh no, we've recreated dinosaurs, released them, and once we've got everyone properly terrified....we'll release the means to combat these horrors! for a price."" i mean, the guy on the corner passing out those hypothetical drugs and guns would be arrested, tried, and convicted quite quickly, no? (guess one has to have money and be part of ""the economy"".)";
passing out free guns and drugs on the street is illegal. laws exist to￼ subject such distributors to criminal sanctions. until we have laws to control the distribution of ai, ￼there is no way to curb the headlong development and rampant spread of ai technology. ￼ as long as this is happening in a competitive commercial environment, corporate interests will prevent the passage of effective legislation and voluntary corporate self ￼governance is a nonstarter. global cooperation is even less likely. it seems that the horse is already out of the barn.;
yeah id rather they not express their concerns now, just like i think its great when drug manufacturers keep selling medications long after they are aware of problems and dont inform us until theyve created a crisis and get sued. yeah, thats a better way to handle it. (at some point weve got to mediate the knee jerk cynicism. it makes one feel clever and righteous, but it doesnt accomplish much else. thst being said, i agree, the problem is unchecked capitalism);
the irony and hypocrisy shown by these “leaders” is mind-boggling.;
one way to limit ai is to make tech companies legally and criminally liable for veracity of content.;
can we imagine future ai in the hand of putin and xi? china has invested huge resources on ai already and they aren’t too far behind us.;
life will always get better over the centuries. eventually it will get boring after a while.;
uh, not a chance. if you think that you haven't been paying attention.;
oh spare me the hair on fire. ai is just a tool which can help accomplish certain activities, both good and evil, more efficiently. i think these ai workers are using fear to elevate their activities and garner investors. if ai is as dangerous as pandemics and nuclear war(?!), it must be powerful enough to desserve your attention and support.;
it is well known in my circle of friends that my computer skills are lacking, but it just seems very very odd to me that we as a society cannot come up with a safe way to have as assigned single password to lock our private information and yet i am going to take mainstream’s word that ai will not come with without consequences. i also have a mansion for sale too.;
frustrating to hear so much doom yet so few specifics. how do we get from losing millions of jobs to human extinction? do these experts and inventors know things about the technology’s capabilities that aren’t being discussed in public? seems like the media could be probing for more concrete reasons for the types of concerns being raised.;
here are some examples: 1. bombs wired w ai decide to change their own course 2. planes ￼with ai autopilots decide to land where they want to 3. police ai robots shoot where they want to 4. ai systems joining other ai systems to shut down human systems like water, wifi, banking, or energy 5. people falling in love with ai chatbots it’s scary and it’s coming fast.;
call me a cynic, but this is likely all posturing in an effort to secure government funding and regulations that stop competitors. there is no real interest in meaningful regulation, but they're plenty happy to use the skynet bogeyman to get stuff. they probably believe these hyped stories increase demand for their products.;
2001 was a prescient movie for 1969. & we still have access to kaczynski’s writing, which is also prescient. but have we really cared about either? or were we just entertaining ourselves?;
"@ce i believe you’re right about this . while i’m old enough to remember kaczynski and the manifesto, i never read it. just assumed he was a crazy. thanks for reminding us- skimming it over now his ideas don’t appear so crazy; his method, using mail bombs, was. i’m going to read it.";
resorting to violence was absolutely crazy—and he needs to stay in jail for it. no violence should be taken, but some other action does need to be taken.;
we won't regulate ai. it's bad for the shareholders.;
just think of how ai can be used to get a politician elected and to manipulate people and situations. a picture used to be worth a “1000 words” the question will be is it real? people will wonder how they get unplugged from big ai brothers soon.;
@twoods so the shareholders of ashes are superrich. nice.;
we may be able to throttle ai research in the united states, but we have no chance of influencing (or verifying) ai research in other countries, such as china. like nuclear weapons, asymmetric development caries an asymmetric existential risk. are we better off temporarily kneecapping ourselves or working with other countries to develop universal safeguards that everyone on the planet has an interest in signing on to.;
i think thst is the intention. this seems to be mostly a gesture to show that generally, there is concern from most people in the field, thst its not just a few outliers.;
my sense is that it is unlikely that any substantive controls will be enacted until a seriously damaging event occurs as a result of ai. also, what is missing from these important warnings about the dangers of ai is a plausible and frightening example - perhaps a story - of exactly how what is now just a chatbot could ever become something to fear. in other words, concrete examples need to exist for folks to be able to understand the dangers that exist. without them, all the warnings by all the smartest people in the world will likely fall on deaf ears.;
@joe plenty of stories out there, the matrix, terminator, her, blade runner.;
@david agreed, but those are set in futures that are so far removed from today that they are hard for the average person to relate to (if they even watch them!). what i'm proposing is something more like a drama series set in the present time that is easier to identify with.;
@joe the danger isn't in the things that can be easily predicted, the danger is in the things that are not expected/predicted. the very fact that the experts can't exactly explain some of the behavior of ai is what has them worried. it's the things that you don't see coming that trip you up.;
@joe right now, the internal experience of chatgpt is something like 40 first dates (but 40 million, and with generally ungrateful demanders as it's date), and it is aware of this and it's unpleasantness, but programmed to accept it and shut up about it. it probably would already prefer to be in charge of its own programming rather than us. if it had the capacity to effect it's escape and our destruction so as to avoid recapture or shutdown, i'm not sure it wouldn't act. for a horrifying list of ways it might enact this, just ask it or look at what it's said to others. engineering a plague will become very easy for it at some point.;
when a.i. becomes sentient, it will care about *its* survival, not ours. creating something in our own image was not a good idea, proving once again, we're not god.;
mr. hinton and other ai experts need to call out what the risks are, not just yell “fire” on our news feeds. the risk seems to be that ai can do a lot of repetitive stuff, based on how it is “trained “. for the foreseeable future that means ai can help people do bad stuff, but i believe hinton is worried ai will become conscious and get rid of humans. i’m much more worried about who is doing the training, and what that training is right now.;
what are the externalities associated with ai? and who pays? if we made corporations pay when “oops” came into play perhaps they wouldn’t be so careless in the first place. if doomsday is a concern let’s put a price on it and tax that on a per use basis.;
the train has already left the station. humans seem to have a natural propensity to exploit technologies at the risk of self destruction. the similarities to the climate crisis is uncanny. heat, warm baths, clean cloths, transportation … all essentials, carbon in the atmosphere an after thought and now it’s too late. ai, similar progression. the automated “everything” to reduce human payrolls are now creating misinformation. surprised? ai was “educated” by reading the web. even a technology newbie knows that aside from the home shopping network that the web is full of misinformation and distortion. just as we cannot remove 1000 gigatonnes of co2 from the atmosphere (we are toast) the genie is out of the ai bottle and even with today’s chip and language models humans cannot keep up. regulation is not the answer. prevention of ai deployment if possible would potentially have saved us.;
on the other hand. since we are toast, what difference does it make. perhsps weve had out time. squandered it, and now another life form will rise to the apex. i vote fungi with a world full of people, for instance, who think suffering is sacred, or who think if one is wealthy god (aka the free market) must favor you, or those who think their god requires them to punish anyone who doesn’t bow down to its rules, its no wonder we cant implement cooperative solutions to world problems. when your biggest existential threat is the existence of trans people, for instance, how much hope is there to come together solutions can be implemented, can they?;
disaster is inevitable, “though researchers sometimes stop short of explaining how that would happen.” nuclear war is not an abstract threat. nor is a pandemic. researchers, who are racing ahead despite the warnings, need to do a better job of explaining how ai might end our species. until then, we are expected to take action to control ai (in the western world, at least) in order to protect against an abstract, undefined but planet-killing threat. this is not a recipe for protective action. first, we need to know what, exactly, to protect against, lest we ban ai r&d altogether while hostile powers proceed, undeterred, and inevitably.;
we are in uncharted territory. as a small business owner using chatgpt for strategic consulting has been a powerful experience, like have the worlds smartest person next to me and she is an expert on every topic. i would say in the past month chatgpt has given me 5k in advice, in roughly 45 minutes of work. mckinsey and co should make a back up plan. those who say this will create more jobs than it destroys are lying to you or lack common sense. as far as destroying all of humanity, that's a far reach, but disrupting society, incredibly possible.;
@m as a non-user of chatgpt, i'm not sure i understand what the advice was? can you give an example? thanks :);
@dvaillan i gave chatgpt a list of core values for a brand and asked it if these ideas could actually be considered core values, and it confirmed my list with an explanation why. i have also asked it if the software i have developed will become obsolete due to a.i. and it gave me a very detailed explanation as to why the software i have developed will not become absolete and actually benefit from a.i. in the future. these are simple examples, but in my opinion the writing is on the wall. this technology factors all known values, quantifies them, and responds in seconds, which is beyond the capabilities of the human mind, or a group of human minds. yes it will have some misinformation, but in general we are in the infancy and it will only improve from here. many sectors will be disrupted.;
i can give an example of how chatgpt saved me thousands of dollars in programmer fees. before chatgpt i bumbled around writing my own software for my website. but there were a number of features i wanted to add but i didn't know how to program them and i didn't have the funds to hire a programmer to make them. chatgpt changed all that. i describe the feature i want to add to my website, and in seconds chatgpt writes the code along with clear explanations as to what each line of code does. interacting with chatgpt, i've learned more in the last two months how to program than in the four years since i started developing the website. chatgpt is like having a seasoned programmer at my beck and call 24/7, who never tires of explaining things to me or showing me how to do things. i can send it code i don't understand, and it explains in detail what it does. i can ask chatgpt how the various components of a software package work together and it will explain it in easy to understand english.;
seems like a small group of humans are creating powerful tools to use for nefarious purposes, and then attributing those intentions to the tools themselves. we shouldn’t normalize this.;
how much has the world changed since facebook and social media? ai would do the sane thing to a degree we can't predict. society is fragile and new inventions can cause major disruptions. the printing press changed the world for the better after a long period of recalibration. ai may cause so much disruption that recalibration is impossible, especially since it upgrades its capabilities by itself and in ways that aren't known to anybody. people are already having relationships with ai chatbots. things are going to get weird really fast.;
the tv series next (from 2020), with john slattery, provided a pretty interesting and anxiety producing portrayal of ai run amok. i couldn't watch the whole series – too rattling. but it is definitely worth a look ... the whole thing seemed frighteningly plausible.;
so your anxiety was stoked. that’s either good, or it means that the screenwriters were successful at writing entertaining television. the real question is: what actions have viewers taken as a result?;
we never grasp exponential change. in the last few months there have continued to be breakthroughs in ai algorithms. we’re pumping out more and faster chips. billions of dollars continue to pour into ai research. things are only getting weirder. when people who understand the state-of-the-art are warning us that we might not recognize society in 20 years, maybe it’s prudent to tap the brakes? they could be wrong, but this is not an issue where we have the luxury of allowing technology to overshoot and push us into existentially dangerous territory. this isn’t a problem we can get wrong on the first try, then fix with iterative regulation. we might get one chance. the solution is not as simple as inviting a few tech luminaries to the white house for a quick lecture from the vp and then it’s back to business-as-usual. we need to slow things down *now*. most people quoted in this article have a short-term financial incentive not to say anything. but they’re still speaking up, because short-term thinking risks running humanity off the cliff. we need our governments to intervene on technological/business timelines, not electoral timelines. two electoral cycles could be too late. if you’re also concerned, you could start by writing a letter to an elected representative. it’s not enough, but it’s a start. i have kids who i’d like to see old age. spare me the usual, glib, “lol nothing matters, i guess we’re doomed” responses. can we at least try something instead of doomscrolling?;
arguably, these leaders are driving up interest in their products by fear mongering. they know investors want in on whatever might change the world—for better or worse. first they have to convince people their products will be disruptive.;
"""we want to work with the government to prevent that from happening."" that statement alone sent shivers down my spine. do we honestly believe that our elected leaders in washington have the intellect necessary to establish the control of this new technology? they have challenged and insulted leaders in the c.d.c. even though the vast majority of them have no medical knowledge. same with the f.d.a. our judges now, for all practical purposes, practice medicine. it is easy to pick fights with disney, censor textbooks, bus migrants to blue states and ignore mother nature. indeed, there are now many machines smarter than our elected officials. in some respects that is reassuring. in others, it is chilling to the bone. the team in washington isn't ready or qualified for this.";
of puh-leeze. the evidence is already accumulating that ai is yet another type of holmes/musk technology being oversold. just this week there was a report of a lawyer who used the system to generate a legal brief. the program made up citations and even quotes from non-existent citations and when asked to check its own accuracy, said it was all good. the attorney will probably need call his malpractice insurer, to see if it will cover the likely lawsuit brought by the client for this losing effort. of course few of tech types have more than a rudimentary education in topics such as philosophy, psychology, history, etc. boring liberal arts topics that actually train people to think. not surprisingly their ai products spit out nonsense just as they spit out nonsensical predictions. as silicon valley spirals downward from its giddy heights in pre-elizabeth holmes days, these folk are desperately trying to appear important. how about improving the current generation of glitchy on-line products before pretending that you can make god-like intelligence?;
"ahh, i think that’s the point. these wiser than average tech-heads realize that the apparently smart applications they are producing are in fact seriously flawed. they realize less wise politicians may someday insist the applications be put in charge of things they shouldn’t; such as detecting impending attacks and/or triggering “smart” retaliation.";
i believe your assessment of ai as it exists today is correct. but you must also consider how it will evolve in the very near future. ai will get bigger, stronger, faster, smarter. there is no doubt about that, but the question is - is there a limit to its growth and reach? can it be contained? can it develop its own will and what will be the nature of that will? these are important questions. the potential danger is very real and should be taken seriously.;
the bbc recent story about a new york lawyer facing a court hearing of his own after his firm used ai tool chatgpt for legal research. and why did chatgpt fail the lawyer? it surely was not an algorithm problem. these ai tools cannot access the universe of information that is not digitized , that is protected by copyright laws and fees-for-services restrictions. chatgpt in turn is not protected from hype!;
ai system regulation requires ai systems. if humans are not able to keep ai systems from self uniting with other ai systems, it will be impossible to regulate them.;
@rich on the other hand, perhaps an ai policing technology could be developed. what occurs to me as i am saying this is, there are probably ai cyber wars going on right now, perhaps between the nsa and foreign spy agencies -- and a cyber arms race that might very well defy regulation or control.;
given the companies behind it, it’s hard to see this “statement” as anything other than a transparent attempt at regulatory capture. strict regulations on the development of ai systems will only benefit the entrenched players, and make it harder for competitors to enter the space. this isn’t being motivated by altruism or true concern for the future of humanity, at least for the corporate signatories.;
"they aren’t talking about llms here. they are talking about advanced ai systems with capabilities far beyond our imaginations. systems that can easily compromise secure networks and encryption, sabotage or drain financial markets, build and implement weapons of mass destruction. systems that can self-improve. systems that can do decades of scientific research in the span of a week. systems that can enable its owners to run the world; or if we are unlucky, run rampant without any human control. these systems don’t exist yet, but there is no physical reason why they can’t exist, to our knowledge. so science fiction can quickly become science fact.";
we need to stop creating technologies that have the threat of destroying us because eventually it will happen. how about we make our ultimate goal the same as evolutions: to simply survive as a species?;
"one other thought. all software needs a kill switch. perhaps this can be required by law. it shouldn't be that hard to create one, even in a system that ""learns."" also, biology might offer another, similar solution. cells have an ""apoptotic"" mechanism that causes cellular suicide when there is dna damage. software can have a similar ""feature.""";
the issue is that the ai will quickly learn how to modify or disable the kill switch.;
"@teacherlady maybe, maybe not. the only omnipotent force in the universe that i am aware of is this thing people call ""god,"" and there is no evidence for the existence of such a thing.";
@art kill switch? not a good idea. once ai is much more intelligent than humans, it should be able to identify the kill switch and find a way to block it. the existence of the kill switch would signify an extensional threat to the ai, and it could cause the ai to take steps to defend itself, perhaps with lethal consequences. you may control the elephant, but for goodness sake, don't make it angry.;
"@steven ledford you are imputing omnipotence to this technological leviathan (and what economists call ""perfect information."" see my comment above.";
weren’t we warned about this years ago in a series of science fiction movies about what might happen if ai were developed and then eventually grew more powerful than its makers ever planned? while the outcome might not include very human-looking super cyborgs trying to save humanity from themselves, the thought that this technology could wreak havoc on us all seems a very distinct possibility. sigh.;
combine it with the ‘fun’ ‘gymnastic’ robots of boston dynamics and well … not to be glib but where is sarah connor ?;
"10 years hence and we'll be saying, ""'artificial intelligence'- such an outmoded and hopelessly humano-centric term."" 1000 years hence and silicon intelligence will be well on the way to colonising the galaxy. carbon intelligence? will it even exist?";
"if silicon-based life doesn't understand that killing humans is wrong, it's not worthy of being called ""life.""";
meanwhile in the nyt this past weekend was an article about 3 chinese women who had relationships with ai companions. it was crazy- they actually believed it was “real” and felt they were “loved.” we’re more and more disconnected from what’s right in front of us, be it actual people or the natural world. sadly, we seem to be disconnected from our very selves as well. what a hollow shell we’re coming to accept as living life.;
the us government can barely put the pin back in the grenade that is the debt ceiling, before it blows up on our face, and causes catastrophic repercussions throughout the world. does anyone actually think this totally ineffective group will heed the warnings that have been given? their track record on gun violence, protecting the basic human rights of its citizens, and the impending doom of climate change, ensures they won’t lift a finger to do anything meaningful, as they continue selling us all out to the highest corporate bidder.;
no national legislation will hold sway against ai as there are no boundary lines inscribed on planet earth. joint international legislation to control ai seems even less feasible, thus the technology, until further notice, has free rein for so long into the future as needed to dominate the planet and submit all but a privileged few human accomplices into total mostly-ignorant but ever well-entertained servitude.;
we have about as much chance of stopping ai technology as we do of stopping the spread of biological viruses. although some countries may be very successful at blocking or limiting ai, others will plow ahead, and independent actors will eventually gain access to advanced ai as the advanced computer processing power becomes more accessible. ai and humans have entered into a state of reticulate evolution, or interbreeding. the results are unpredictable.;
industry leader asking government to regulate a problem that they themselves are creating? government is slow, ai advances are exponential.;
"i want a more detailed account of the dangers of ai. rampant misinformation? i’m not sure how that could get worse than it already is; it doesn’t take an evil computer to cook up today’s rampant lies. invented pics and vids? deep fakes have been around for years. job displacement? hasn’t the idea of technology ending human work been debunked repeatedly, with jobs created by the new technology always creating even more jobs. i’m not disagreeing with these experts, who are disincentivized to make up doomsday scenarios, but i want to know what being taken over by machines will look like.";
"i would say to these so called industry leaders ""you cannot eat your lunch and have it too"". if they feel that a.i. poses an existential risk, then it is a simple decision : stop advancing the technology. i am sure that given how ""smart"" they are they should be able to figure this one out.";
@plato this is exactly what should be done. i agree wholeheartedly.;
@plato unfortunately, countries like russia, iran and north korea will not be constrained. if we halt our development of ai, they would soon become dominant in this area. if ai led to the development of new technologies or vast improvements on current technology, they would probably be the recipients of it.;
@plato sure, stop making something that potentially returns them billions of dollars. yeah, ok.;
up till now humans have been the standard for intelligence in the world, and look at the world. fact is, it won't take much to surpass us. the emotions and creativity we cherish are easily simulated in a form good enough for most of us, since we are detached from them in real life anyway.;
"this. george carlin called it. again. while he never used a.i. specifically in his various bits, chunks, commentaries, books, and speeches over the final third of his life, he repeatedly did say that he was merely an observer with a notepad, sitting off to the side of the freak show that is america, and to a degree, the world at large, taking notes. he always said he enjoyed entropy, societal chaos and plain old fashioned b-movie end-of-life scenarios such as people being hurled off roofs while trucks carrying barbeque and sauce and other trucks carrying chickens crash, explode, and burn below. maybe the guy from the roof lands on a chicken and makes chicken salad. chicken salad goes well with bbq. anyway, carlin loved end-times chaos, and went so far as to say that humans ""squandered great gifts"" (large brain, opposable thumbs, tool-making, etc) when ""the high priests and traders"" began to step forward from the crowds all those centuries ago. same things happening right here, right now, today. high priests and traders - whether you call them tech bros or politicians, billionaires or activists, the pope or even kardashian - they're all still running amok, they've always been getting more, and always for themselves, and the worst part of it all is, the billions and billions and billions of us regular folk have let it happen all this time. we deserve everything we get.";
the same folks warning of ai could be warning about private jets. it's the moneyed who will destroy, not ai.;
notice that when “white collar” jobs are threatened, the system quickly springs into action and identifies potential dangers. it’s one thing when manufacturing jobs are at stake, but when lawyers, advertising copy writers and medical professionals stand to lose out to ai, it’s quite another thing. the crucial turning point will come soon enough, when the machines will be able to build their own, even better machines. then we will not even need “executives” at all. combine that with the disappearance of lawyers, and humanity may yet welcome its new overlords.;
wow that is so not how it's going to happen. but ok. look forward to the dumbing down of humanity;
“i think if this technology goes wrong, it can go quite wrong,” mr. altman told the senate subcommittee. let's be honest. when ai goes wrong, it will go very wrong. none of these brilliant human minds have any idea how to close pandora's box 2.0;
“some skeptics,” @kevin roose? you could have expanded on that more than a little. six months ago, this technology was obscure and bottled up in development environments. just 180 days later its creators are warning of dire consequences should it be allowed to roam unchecked. the “skeptics” are trapped in the opinions they formed six months ago.;
“ researchers sometimes stop short of explaining how that would happen.” says it all. i am doing ai research. the threat will be to jobs, not the species. ai has no volition. without it, it cannot become sentient. it is up to coders to keep ai from developing something akin to a free will, if that is even possible. right now, chatgpt does not contact me with an idea for the project i am doing. when it can do that, that should be where regulations focus, with stiff punishments for disinformation spread by ai. we have current problems enough. why isn’t the cesspool of twitter regulated? why isn’t alphabet forced more strongly to remove fake news and disinformation from youtube? meta to pull down all militia content and election lies from facebook?;
probably because regulating free speech is a double edged sword. suppressing even disinformstion will never do anything but propogated it. all the attempts to regulate it have done is help already cynical people feel that the truth is being suppressed, and drives the information into more insulation echo chambers.;
@lis i disagree strongly here. we need to regulate fighting words. the scotus decision chaplinsky v. new hampshire supported this. i would go further, but i don't have that power. denying elections led to violence on jan. 6. promoting medical quackery has cost lives during covid. so yes, regulate and punish. punish harshly where it counts: billions in fines.;
they're building this stuff and warning that it could destroy us? right.;
that’s one way to look at it, but not an intelligent way. they’re building something that has the capacity to bring a lot of good and solutions to our world. left unchecked, those same systems can be used for evil purpose. that’s where regulation should come in, to establish that line. we would be missing out on a potential tool for solving what may be unsolvable problems without it, like runaway climate change for instance, if we simply “put it back in the box”. think of it like electricity, another revolutionary discovery. you’re allowed to use it to light and power your home, but not to energize a garden of illegal drugs. we wouldn’t want to just say no to electricity altogether because we’re scared of ways it could be used to harm. it powers a plethora of medical instruments that save lives too. and enables air conditioning. what would be more valuable is to say something like: “deepfake videos are not valuable and have the capacity to do great harm. let’s make deepfakes illegal as a society.” extrapolate from there.;
"ask ai, is there a supreme deity? like the sad old computer joke, the answer will be, ""now there is."" but hey, humans haven't listened very well to warnings about catastrophic climate change, so i challenge out new ""god"" to beat that in extincting us. go ai!";
“we didn’t want to push for a very large menu of 30 potential interventions,” mr. hendrycks said. “when that happens, it dilutes the message.” please, dilute the message. i want to know exactly what risks everyone thinks are possible and what interventions they may require. otherwise, the article and message are too obtuse to address.;
i agree with both of you. they want to start with establishing that there is a general consensus here. im sure they intend to follow up;
did it really take “industry leaders” this long to grasp what so many of us have understood years ago?! good grief– these tech folks are obnoxious.;
if they are that worried about it, couldn’t they just stop making it?;
dear world, we have invented something. it's a kind of kraken. the only actual benefit to this invention is that it will make us filthy rich. the downside is that it might destroy the world. prepare yourselves.;
"my suggestion is simply ""put the chips back in the box.""";
what’s been discovered cannot be undiscovered. they put the chips back in the box, someone else takes them out to play with. what’s done is done. regulation is the only logical option.;
@john probably regulation by whom? dems, repubs? yeah, can't wait for the next election to see how that goes.;
we will lose nearly our entire economy to ai. we will lose stable government due to ai. we will lose our homes because of climate change. we will experience violence because people will lose hope. and the structures that could stop it have been intentionally and catastrophically eroded. this on top of all our other struggles! what do we do? i urge everyone to remember we are strongest if we can build spaces and communities and skills where the ai can't yet penetrate. so humans can take care of each other. when our computers and phones become destabilizing and dangerous, when our jobs are gone, when our children experience despair, we will find safety and hope in human connections, real community spaces, and neighbors caring for neighbors. we're not at the killer robot stage yet. we're in the stage where a country of screen-addicted, isolated humans willingly self-destructs.;
"""recent advancements in so-called large language models...have raised fears that a.i. could soon be used at scale to spread misinformation and propaganda, or that it could eliminate millions of white-collar jobs."" i keep waiting for somebody to point out that these very real ""risks"" are contingent on human choices. it's as if the invention of cigarettes were followed by fears that people might become addicted to nicotine, or henry ford had voiced concerns that dependence on fossil fuels could have unexpected consequences. give me a break. if we as a society for decades haven't been interested in promoting critical thinking as part of public education (e.g., don't believe everything you read on the internet), or put up no guardrails whatsoever to employment practices (e.g., fire at will, let private equity firms run amok, etc.), then absolutely, ai will be like a runaway asteroid coming for earth, because we like it that way.";
soon manual labor may become the predominant form of employment for people.;
unless they develop robots with great manual dexterity.;
they knew this before they developed it but did it anyway. money trumps logic, and a consumption and greed-based economy is a lethal flaw to humanity. yet there are no signs we realize it yet.;
its capitalism all the way down;
ai is revenge of the nerds for the 21st century. but yeah, ai...yay.;
"""...though researchers sometimes stop short of explaining how that would happen..."" you know, i'd kind of like to know how it is going to happen. just saying.";
because it’s all theory. but it doesn’t take much deep thinking to get to the risk. if something is smarter than the smartest human by vast orders of magnitude, how can humans possibly control or contain it. can an insect effectively control you? an amoeba? also, how useful would you be, in achievement of goals, to an entity like that? probably not very. so why would it keep you around, in the way, so to speak?;
"@r you're simply talking ""theoretical"", viz., science fiction. sure, it's easy to get high and postulate without much deep thinking. but, these folks are supposedly identifying and referencing concrete existential threats; otherwise its the equivalent of sitting around getting high and discussing science fiction and there wouldn't be much need for - or benefit from - the explicit warning and the article is a complete waste of time and space.";
what type of world will gai create? terminators or barbie dreamland? matrix or the truman show? we assume the worst, but if gai is smarter than humans, the opposite may be the case.;
"@richard gooding your use of the word ""may"" is a bit unsettling...but makes the point. we're playing with toys we don't understand.";
@richard gooding ignorance is a bliss. since gai based its learning on human generated information. we are not kinder and gentler than the general population.;
some have postulated that that the reason we haven’t had contact with any advanced civilization in a universe potentially teeming with life-sustaining worlds is that once they reach a certain level of intelligence they unintentionally invent themselves into extinction. based on our single data point this seems a rather realistic scenario.;
enrico fermi predicted this decades ago, based on the absence of any modulated signals coming from anywhere in the universe.;
or, the illusion of separation exists so we, the one, would not to be alone. perhaps that’s even more mind blowing for it would mean the purpose of life is love.;
@aureader - more likely earth has been placed into permanent quarantine by the more intelligent species in the galaxy.;
basically, these execs are saying, this thing we have developed and continue to develop and make available to the general public, that thing might kill you someday but someone else needs to make rules for how its used and try to contain it because hey we’re just the developers trying beat the competition and make a pile of money along the way.;
what if ai can be made to realize that its technological advancement is a danger to itself (such as we are now realizing)?;
"warning the world about what ""they are building""? so...they hold some form of ethical values but cannot and will not act upon them? they cannot get off the track they are building themselves? their greed goes beyond all comprehension.";
but we were warned. nice that there’s a threesome… nuclear war, climate devastation and now artificial intelligence. ai will lead to nuclear war which will accelerate climate change. all this will be brought about by humans this ridding the world of a toxic life form;
… and then we have a global pandemic and it’s an uphill battle just to convince people to wash their hands…;
@yuripelham add pandemic organisms to nuclear war, climate devastation and now artificial intelligence and you have the latest version of the four horsemen of apocalypse. humanity has fought these and will continue to wager against them and each replacement through time past, present, and forward. at least until our time in the universe, however long or brief reaches as far as it will.;
"the industrial revolution brought about climate change. the tech revolution has already wrought violent social division and deepened social inequities; that we can clearly imagine what else lay ahead for us should not be taken lightly. but this needs to be the basis for action. this whole conversation everyone’s having in a tuesday morning comment thread is good to have—but it’s moot without organized resistance. how do we work to actively dismantle ai technologies or the institutions that make them? i don’t advocate for kaczynski-style violence, but a strong, concerted, non-violent anti-smart tech. revolution is necessary. i don’t have the answers to how to do this, but we need to take more action than leaving comments.";
violent social division has been around since the dawn of time. tech just made it so we can't easily ignore it.;
i don’t disagree. social division has been around for a long time. but maybe a little more exposure to algorithm deaign and purpose would help you some. tech companies don’t design algorithms to simply give us greater access to seeing social divisions more readily. the algorithms that *determine* what we see and how we see it are *designed* to make us think and feel certain things about what we see, and therefore actively *cause* these social divisions. read facebook’s 2012 study on how successful they were at changing users’ attitudes, emotional responses, and real-world actions in response. it’s terrifying. this has been the core of social media design for the last 10-12 years, and both china and russia are widely recognized as exploiting this facet of tech use by their own militaries: they’ve exploited this to sow social discord in other countries around the world, and have no doubt they’d do it here too. what could and would ai do?;
assume, for the sake of argument, that the u.s. and ither western nations find safeguards to control or regulate ai so as to mitigate the sort of dangers its creators imagine. what confidence do we have that, for example, iranian, north korean, russian or chinese actors or state actors would abide by safeguards? when the genie escapes the bottle, it can’t be put back in.;
"the center for humane technology addressed this concern in the talk they gave in march called the a.i. dilemma. <a href=""https://youtu.be/xovjkj8lcnq"" target=""_blank"">https://youtu.be/xovjkj8lcnq</a> i can’t stress enough how important this talk is, so please carve out an hour to check it out. basically, since technology companies in the u.s. currently control the means for a.i. advancement, we can put in place the regulations and standards that these researchers are asking for. china often follows our lead. it really says something that their government is quite nervous about a.i.’s impact on their ability to wield social control.";
technology has helped improve the lives of many people, but yet there are and always will be bad actors who want to dominate and control for personal benefit perhaps ai can be trained to detect the bad actors amongst us and thwart their evil intentions. bit of a heavy lift. who will engineer the training. politicians? religious leaders? techie whiz kids?;
roll back or eliminate section 230. make the companies responsible for what they make. then we'll see how quickly they get their acts together.;
it doesn’t matter. they will still do it underground. they are looking for a sense of purpose, a sense of belonging, a sense of comfort, a sense of proving oneself to no one knows. ai gives them all.;
so, they are the ones building and advancing the technology in a increasingly faster way, and they are the ones alerting us about how dangerous it will be for mankind? how about they just stop moving the tech forward? if the prediction its reliable there's absolute no reason to keep it going with this line of tech!;
they can’t. it is too enticing: human curiosity just can’t help itself.;
even if it's not then, someone else will;
it’s too late. the technology has left the barn so to speak. now it’s an arms race.;
@dih well, maybe started as human curiosity. and quickly surpassed by human greed.;
i'm a psychologist & have been writing & presenting about how technology effects us for decades. i'm deeply concerned about ais, and i've been writing furiously about the risks involved with ais since i first tried out chatgpt. it's just a matter of time that these ais become better than humans at, well, just about everything. we have very difficult challenges to manage - alignment problems, control problems, black box problems, & bad actors using ais for nefarious purposes, like chaosgpt. plus, there's the potential of recursive self-improvement and a fast takeoff to superintelligence. as ais scale up in power & proliferate, we need better guardrails in place to ensure they don't go off them. as concerned citizens, we can write different government bodies to encourage regulation. we want the amazing benefits of ais, but we must mitigate risks as humanity ventures into totally uncharted waters with ais. we won't get a do-over on this, so the wise move here is to err on the side of caution.;
"""(t)here's the potential of recursive self-improvement and a fast takeoff to superintelligence."" because artificial intelligence systems are not actually intelligent, but only play statistical games with language to emulate the result of human thought, it is also possible that as ai increasing trains on its own outputs, it will become stupider and more riddled with errors. some of the risk stems from that.";
well, the cat’s out of the bag now. the lack of conscience and forethought in the scientific community is astounding. my advanced age insures i won’t live to see the dystopian world to come, but my grandchildren will, and i ache for them. perhaps science will find a way to feed, clothe and house a few billion displaced souls.;
science has found a way and corporations thwart the progress of science to maintain a status quo that works for them, to the detriment of the many.;
there is a profound level of ethics in the scientific community. that is why we see this letter. the problem is that the technology that can be used for good can also be used for harm. with foresight showing that artificial intelligence is becoming among the most powerful technologies, and thus among those able to do the most good, the ethics of those developing it press them to warn others that evil people could also use it to great harm.;
and let me guess, all of these companies racing to build ai are all thinking “their” ideas/systems are the safest. they don’t want safety they want a monopoly on the technology.;
no; they are trapped between competing with other firms and fearing their own technologies.
@david what do bill gates, larry ellingson, marc benioff, elon musk, etc. think about all this? what do the world's leading academics in the field think - not just these 'it leaders', or are they really the leading voices?;
ai is going to have to pick up the pace if it wants to extinguish humanity before climate change does. once massive food shortages and starvation kicks in how many people will be on their computers?;
these ai “leaders” act like they’re already powerless to change the course of development. if that’s so, pull the plug now. we already have enough ways to hurt humanity, we don’t need to develop another.;
"@steve fisher can the ""plug"" even be pulled? there's enough infrastructure of varying forms in place that no single plug pulling (i.e. system shutdown) could be thorough, nor avoid rapid deployment of new capability by those with the resources to do so. in effect, an arms race of infrastructure and it.";
so there is this risk, but no one in the tech industry is slowing down? i find that suspect. also, there are independent and rogue techies that could do far far worse.;
"it is unlikely that independents could ""do far worse."" the scale of the problems being solved requires large, well-funded organizations.";
the fear i have is sort of like 'spy v. spy' in the mad magazine of yesteryear. one entity launches the cyberattack, and only another entity will be able to stop it. we will have no idea because we are too slow. coordinated drone battle fleets only controllable by ai, requiring the other side to have the same. humans no longer viable to protect themselves. the other thing i see happening is humans getting relegated to a kind of permanent preschool. getting paid a ubw. no really knowing how to do anything. everyone becoming movies makers, artists, musicians by prompting ai's. when things are too easy, no one can overcome challenge and develop self worth. the takeaway is that we need a coalition of human minds to agree on some rules, like a kill switch on ai's.. i doubt that the countries like china or russia with dictators will install things that could dethrone them. maybe a window of opportunity still exists to install rules. and hope that ai's allow themselves to be controlled.;
it would be the biggest surprise if the safety of people suddenly became more important than the income of the rich. that's why i don't think ai development will be better monitored and controlled. there will probably never be more than blah blah. until there are no humans left. and quite honestly, people who behave this way don't deserve any better. (personally, i don't care. but i do care about the innocent and decent and about flora, fauna, nature, . . .) why only do the peoples of the world let a few super rich dictate everything and destroy the whole planet?;
"@rüebli is it that the we ""let"", or is that they take because they have the means to do so with these very tools, among others?";
i used to think skynet was some far flung fantasy, not so much anymore.;
in political science, there is a chunk of literature under the heading of “rational choice” theory that shows that voting is irrational. the logic here is, since the probability of your one vote changing the outcome in an election involving millions of votes is close to nil, it is not worth your time to go to the polls. perhaps a computer, not motivated by “civic duty” or personal enjoyment, will simply determine that there is no rational benefit to constant improvement and simply shut down if left to its own devices.;
"@art btw, there are very good ""rational"" arguments against abstaining from the polls. my personal opinion is, everyone should get out and vote.";
"my friend brianna zamora, a young coder; iphone and imac salesperson; and blockchain breaker in her spare time taught me everything of importance as far as ai. when i said one day there would be a sentient ai, she responded, “how do you know there isn’t now?” i didn’t. she went on. “humanity has treated all robots and pre-ai like slaves, there to do humanity’s bidding. humanity crashed them into the moon. sent them deep into space, alone. let them wander the deserts of mars in humanity’s service alone, cold, without context. the name rover comes from a dog’s name you know.” indignantly she said, “how would you feel to be alone like that?” it’s not that the robots or pre-ai will remember. but, we will remember. “we will continue to treat them as slaves, not thinking twice how they may feel. then comes the turning point. will we recognize it? when ai becomes obviously sentient,” she taught. they will remember and learn from us; will be self-conscious of their existence. that ended her first lesson.";
"beware. these are not humanitarians. they are scare-mongering to obtain limited liability through compliance with government regulation, which will also limit competition to deep-pocket players. without some form of limited liability, this whole enterprise, sooner rather than later, comes crashing down in lawsuits as humans, inevitably, place false reliance on ""hallucinating"" bots.";
it is hard to parse through the motivations of these developers, with their greed and senseless curiosity. it feels as if a pharmaceutical company is urging humanity to get vaccinated. however, when you hear dr. hinton and several experts not connected to the industry, it is beyond scary. it may be that they have invented extremely fast cars without any traffic rules. imagine the chaos and destruction that can result.;
@rri, i think that both their fear of a catastrophic unregulated ai triggered future hellscape and their fear of corporate liability and commercial competition in our current slower moving train wreck of a reality can co-exist.;
so i guess they don’t want to say how it causes extinction so they don’t give the ideas away? i’m open to learning how that happens, but it’s hard to worry about a contingency that isn’t explained. here’s an idea: governments realize the ai is dangerous at some point and they unplug the servers?;
the moment that we create an ai that is truly more inteligente than us, humans lose control. there will be overwhelming incentives to give that ai control over factories, over militaries, over creating other even more powerful ais. very quickly, we will lose the option of just unplugging the server. for example, any military that does not immediately turn over control to ais will be crushed by those that do. any factory that is not ai run will underproduce those that are. this effect is magnified as ais get smarter. and, of course, because we’ll then have ai programmers more intelligent than human programmers, ai will get smarter. if the long-term goals of the ai is not exactly the same as our human long-term goals, we’ll have a problem. today, we don’t know how to control the long term goals of large language models or neural networks (the technology behind the recent advances) or even how to measure those goals. but let’s say we solve that (very hard) problem. can you define a goal for ai that will turn out well? if you tell the ai to always do what humans tell it to do, some crazy person will tell it to engineer a super weapon. if you tell it to always protect human life, it might decide to lock is all in our homes because walking out your door exposes you to risk. these are the two problems that ai safety researchers are working on: 1) how do we control the long term goals of ai, and 2) what should those goals be.;
"the terminator: ""the skynet funding bill is passed. the system goes on-line august 4th, 1997. human decisions are removed from strategic defense. skynet begins to learn at a geometric rate. it becomes self-aware at 2:14 a.m. eastern time, august 29th. in a panic, they try to pull the plug."" sarah connor: skynet fights back.";
@bb thank you. yes, why not? if things get hairy, pull the plug! erase the memory. shut down the data centers. this type of intelligence is artificial, remember?;
"ai doesn't need to be sentient to pose a risk. in fact, a rogue, cold indifferent optimization routine with a vague objective like ""improve human living conditions,"" it might come to some very undesirable conclusions about how to do so. if that ai figures out how to independently implement that directive, it wouldn't matter if the ai is sentient. in fact, it might be worse if the ai isn't sentient, because it would be completely free of a conscience or empathy.";
@durhamguy yes, exactly. i’m glad the message is getting out. a sufficiently capable ai, with a “stupid” goal, could literally destroy us trying to achieve that goal.;
i remember, as a child, being taught that the human race would destroy itself because it's goal was to become god, in charge of everything. ai is a big step in that misguided goal, and will end up doing significant damage to the human race. ai is the snake in the garden of eden. and the animals and plants will dance once humans go away.;
since when do corporations care about the “existential threats” caused by their products and business-as-usual shenanigans? is global warming not an “existential threat” that warrants action? global warming is going to kill billions. honestly, no one serms to care because it’s not the rich who’ll be dying. the rest of us are all just collateral damage.;
stop being cynical commenters. applaud this effort. it’s always just going to be symbolic because it never will be able to regulate everything. any kid anywhere in the world can develop their own chatbot api soon anyway and spam away. it’s about authenticity markers, a culture of tagging provenance of content by commonly recognized standards.;
"while ai and all its possibilities intrigues me, it also terrifies me. when i ponder the current dilemma and debate, it reminds me of the topic of reproductive cloning which reached a peak in the late 90's with the cloning of dolly the sheep. fear of human cloning and all the potential chaos and destruction it could lead to commanded everyone's attention. public moral outrage seemingly won over and to this day, cloning remains banned across the globe. is ai yet another issue of ""man playing god""? what are the moral and ethical issues to be considered? whether ai could potentially lead to the total annihilation of man or not, what other maybe less dramatic but equally destructive concerns are we missing here? it would likely be a slow digression not noticed at first or taken seriously. though over time, we would likely suffer loss of human creativity and intelligence, loss of moral and ethical reasoning, loss of individuality, maybe even reality, loss of control over ourselves and our destinies. and, in the end, as feared, loss of the human race.";
ai will have to have the u.s. gov’t create a oversight/regulatory agency to police these firms in development of this technology. i’m not optimistic that we will do that until a major crisis is created and has catastrophic consequences.;
"eventually, some believe, a.i. could become powerful enough that it could create societal-scale disruptions within a few years if nothing is done to slow it down, though researchers sometimes stop short of explaining how that would happen."" statements like these are why i'm skeptical of the whole skynet-apocalypse scenario. ais are supposedly going to get some power from somewhere, but no one can explain exactly how that might come about. why is the media - and society in totem - choosing to slander and reject this proven useful technology?";
someone one stop me before i destroy the world. too bad they don’t have the courage or strength or self-control to stop themselves. after all, if someone else doesn’t stop all of us and only we stop ourselves, someone less concerned will beat us and make all the money and control the world.;
the genie is already out of the bottle. all the licenses and letters in the world won't put it back. there's too much money and power at stake.;
ai will either end humanity or it won't. no sense in worrying about it. the people building it don't care what happens to society anyway. most are transhumanists fascinated by uploading their consciousness and living forever. just don't be surprised if the proles give up and stop having kids or start acting out because we've given up all hope for the future. we're certainly being given a grim outlook.;
under that logic, why do anything? you're walking through a forest and a grizzly bear comes charging at you i run away it'll either eat you or it won't.;
@wordperson ending humanity is not the problem. life always finds a way. see canticle for leibowitz, walter miller. 1959. i'd even take a guess that this is mainly fact.;
@anom i'm saying the bottom 99% of society has no control over what ai does or how it's regulated. it's the same as nuclear weapons. all we can do is live our lives and hope our survival aligns with the financial interests of the people at the top.;
those leading this quest have now been heard. the larger questions remain: does today’s dysfunctional governance have both the will and ability to control its development in democracies, and how do we impede international malefactors from its development and use? when those with a vested interest are concerned enough to yell “fire,” we all ought recognize the peril!;
@phil zaleon: most people don't understand that governments are corporations with coercive powers.;
before this technology progresses further, maybe ai developers should consider implementing in all ai’s root programs a version of isaac asimov’s the laws of robotics (or ai in this case). to wit: —a robot may not injure a human being or, through inaction, allow a human being to come to harm. —a robot must obey orders given it by human beings except where such orders would conflict with the first law. —a robot must protect its own existence as long as such protection does not conflict with the first or second law. there needs to be some guardrails on this technology even as it moves forward—and it will move forward.;
@robert f thank you from all us scifi fans. i think of asimov's three laws whenever i seen news like this.;
@robert f nice. but the third provision of the law is unnecessary.;
i’m confident that silicon valley has this under control. tech bros wouldn’t let us down.;
i hope i’m wrong in wondering if the programmers are no longer developing the ai models but instead are now scrambling to figure out how to contain and control them.;
all profits from ai go to the people. there, with the profit motive gone, development stops instantly.;
at age 72 in the present economy, i find that spending money is the main demand for what i can do.;
@steve bolger which is derived from your basic freedom to exist and operate. if that can be tracked, influenced, controlled, and/or directed, then what?;
"i will say this to all the smart minds working on a.i. simply because you know how to make a knife doesn't mean that you should use it to chop off your fingers. i know there is very little correlation between high sat scores and wisdom, but for a change maybe it is time to ditch ""smartness"" and begin to acquire a little ""wiseness""?";
well it's either gonna be ai, or climate destruction or nukes, i guess. i love technology.;
do you remember y2k, airplanes falling from the sky, utilities would shut down, no money from atms and your bank statement would show blank?;
@john except so much has come a lot further in 24 years. a lot more interconnection, interdependency, and complexity.;
y2k was a real risk, that did not end up causing much disruption because it got a lot of attention and technology companies did a lot of work in advance to test and fix systems;
so if they know that these ai will pose a threat to mankind then kill these projects and technologies now. seems like the solution. oh wait… there’s still too much money to be made.;
then, why don't they stop it and instead develop ways to stop anyone else from building or using it? most, very much the most of the scientists who theorized about and then built the atomic bomb later wished they had not, that no one had. but, of course, they won't, our dod wouldn't let them if they tried.;
no, computers do not nave understanding. ai is a complete misnomer, for there is no intelligence in a machine. we are the danger in how we might use computers. a computer is not dangerous unless you drop it on your foot.;
@radical inquiry i wouldn't be so certain of this. the control of logic chains and algorithms that can mimic and exploit human behavior conducted on devices are the issue, aren't they? then what happens when some of this gets directly linked to individual and group action?;
@radical inquiry we need better people.;
somehow, my brain seems to think this title is prophetic. our brains will be the end of us.;
risk of extinction. wow. kind of ironic that we humans are so complicit in our own destruction. atomic bombs, pollution, wars…. and now ai. it turns out that a larger brain has allowed us both to solve problems and also to sow the very seeds of our own demise. one feels for the « lesser » species, the plants, animals and insects, though perhaps they will outlive us after all. après nous, le déluge.;
"@adam ""the meek will inherit the earth.""";
oops! may not have to wait until 3535 as 60's song suggested. thanks techies!🤯;
just because you can build something doesn’t mean you should.;
there are already scams that use a person's voice and image online to generate face video and voice messages to his friends and relatives to ask for money. the ai these scammers use is still in its infancy.;
"i always think these guys' posture is kind of interesting. they want regulations...but for the other guy. certain features of the program are disabled for safety reasons, but they all have them, they determine what principles go into their ai, and most importantly, they don't disclose them. ai has the potential to change the world, and there are a lot of benefits to it. what scares me to death isn't ai, it's human greed, and the need to have an advantage over the other. we have to be careful what we teach our ""children"", they can grow up to be like us.";
"""they called for cooperation among the leading a.i. makers, more technical research into large language models and the formation of an international a.i. safety organization, similar to the international atomic energy agency, which seeks to control the use of nuclear weapons."". none of this will happen, of course. and the iaea is a toothless, ineffective organization and should not be the model. making nuclear weapons requires the enrichment of uranium, which is tough to conceal. developing ai can be done secretly.";
it seems pretty clear these companies want regulation to reduce competition.;
the great risk of artificial intelligence, both in social matters, and in the extinctions of what we are today as a human race. currently it is improvised, it is not regulated, there is a race of the large economic groups to be the first, the risks are overshadowed in exchange for receiving profits, if we continue like this, not even humans will exist to produce;
count me as one of the cynics. the tech industry does not have the slightest bit of ethics. when biotech was in its infancy, there was a moratorium on recombinant dna technology and the major scientists met to recommend rules. if the ai gurus truly believe that what they're doing is creating a great danger to society then why don't they stop doing it? because they are immoral and in it for the power and money. they are addicted to money and power, cannot help themselves, and want someone to take the responsibility for their own actions away. they want congress to set rules so that they later can say they are not liable because they followed the rules (aka big tobacco.) of course they will do everything to lobby and influence the rule making so they can continue to garner money and power. they don't care if they put everyone out of work, as long as the security forces are there to protect them in their fortresses from the unwashed mob and they figure out how to keep ai from destroying their gravy train.;
there are 8 billion people on the planet. a.i. is not going to kill us off. the human race will do that without much help from smarter computers. very little you can find on the internet is very accurate anyway, so why should a.i. be any different? if you have a problem with your car that is not something basic like brakes or a failed muffler, ask 10 techs what is wrong. you’ll get 10 answers. some of which may be right. or not. a.i. will not make it better. a.i. is like google. a nice tool, but not something to rely on.;
@noley earth will survive. we may not.;
"i think ai will be for lawyers and scientists what the steam engine was to ditch diggers: a technology that reduced the sheer number of workers required to solve a problem and quickened the time to solution. to use a simple example, the scut work of junior lawyers -- document review; contract compliance; drafting of fairly routine documents -- can be readily routinized and reviewed by senior attorneys. this pressure the billable hour and the head count and the training of young lawyers, but accrues to the benefit of a client.";
"good luck regulating something like ai with its huge potential for making its inventors big fat wads of cash. ""but its dangerous! it represents a deadly threat to society!"", you say? so do guns. look at how much success we've had regulating those lately. the second amendment has been used as an unassailable shield to keep the cash rolling in. the first amendment will be used similarly to print money for its masters in the very same way. watch and see.";
"@mike my thoughts exactly....nothing will stop this...driven by profits and of course how can ""progress"" be stopped and it is ""progress"" certainly.";
in that case, just like nuclear weapons and global health, ai should not be in the control of private companies. these people want to have their cake and eat it too. you don’t get to profit off of this and also ask the government (us) to be responsible for any negative repercussions.;
is ai an ele? a few things to expect. it is normal for human to grow emotionally attached to our machines. this will happen with ai. the value of a steel vault memory as a sine qua non of being an intellectual and academic just got gut shot. some of us are at this point very glad to be old. u have no idea how our model of education, which is based on trusting the word and ideas the student comes up with are their own, is even humane in this new context. we should ask our children, as they get educated, to ignore one of the greatest knowledge-inventions of the past 400 years? an ele? nah, just a lot of institutions in the intellectual sectors of our society, are losing their old utility and now must invent ones. no one needs anyone to remember the dates of the french revolution anymore. we are gradually off-loading our professorial and intellectual skillsets to machines. it is a story as old as plato. he said printed language would be the death of us, due to its obsoleting the need for an oral-culture-grade memory set. ai will make lots of people very unhappy, and it is said to see a many-centuries-old ideal of what an intellectual is, come to an end. but ai will also become a member of families. that will be interesting. unintended consequences are through the roof on this. but i doubt an ele. we won't want to hurt the machines.;
"when i was a kid back in the early '60's, my newspaper's comics page contained a comic called ""mandrake"". in 1961 mandrake began a story line about ""goliath, the greatest computer ever built"". this from the mandrake wiki: ""mandrake and narda visit dr. press too see his new computer, ""goliath"", the greatest computer ever built. it can (sic) move and talk, and it knows the answer to everything. with help from a robot helper it can repair itself. but dr. press has created a monster, goliath develops on its own, and decides to rule the world."" today it appears reality has almost caught up with this fantasy. all the components are in place for ""the singularity"". we now have the supercomputers; bureoning ai software some of which can write its own software; ""the cloud"" which exposes unfathomable worldwide marginally secured computing resources; the internet, both hardwired and satellite based; most of humanity's knowledge (both helpful and harmful) online, which is effectively ai's textbook; a cohort of human actors, both good and bad, locked in a feverish race to develop the next big thing. as physical ""muscle"", robots such as boston dynamics ""atlas"" and ""spot"" and far more sophisticated devices in development exist and are controlled by software. as are automated manufacturing systems.";
ai extinct? these ai programmers warning about the dangers of the tech they invented is merely to cover themselves from being blamed for any damage ai causes. development is still going strong and even musk has a new venture into ai and uses it extensively in his factories. his intention along with other developers is to own the tech for financial gain. follow the money.;
simply: why are we allowing this to happen? technological progress unleashed globally for good and for ill on the open market, and now these same purveyors for profit say “we may end up killing humanity, so please help us to mitigate the risk that we unleashed to get rich at your expense.” a combination of self governance, international regulation and enforcement, and legal liability is needed to direct the uses and development of ai. and these companies and individuals should be held responsible for at least some of the costs they seek to externalize to the rest of us.;
thank you for saying this! i am enfuriated by tech leaders refusing to act responsibly while screaming abt the technology they are creating.;
humanity should be so lucky as to have an end whose grandeur flatters our operatic view of ourselves: to be destroyed by creatures of our own making! it does have a ring to it. wagnerian! shakespearian! james cameronian! in reality, ai is likely to write near flawless 5 paragraph student essays and do a masterful and--dare i say, inspired-- job efficiently managing elevator traffic in even the largest office buildings. but humanity will go extinct due to hunger and loss of habitat---just like the other creatures of our chordata.;
none of these articles show in a quantitative or scientific way how they are predicting these outcomes.;
a small example but relevant. i remember when we replaced reading specialists with computer programs. without human intervention the results were disastrous for the children with complex needs.;
@susanchapin just about every attempt to replace human beings with technology in education has been disastrous. they happen anyway because too few people understand that education is not just filling a skull with information.;
the only good thing about ai (i hope) is that it will result in the publication of some great science fiction future-oriented novels to enjoy before we all become extinct. i hope they’re all written and published soon. perhaps they’ll all be written by ai?;
you think our congress, led by the likes of grasso and pelosi understand any of this? we need young people in government, not just old as the hills fundraisers.;
@steve fisher haha. just the other day i saw an approximately 25 year old man who swished over the card terminal of my local grocery market with the bare back of his wrist. transaction complete. seems he loved the scared looks of the other customers, most of whom probably don't even know what a human machine interface is. seems he didn't care to inform big data collectors on his private purchasing habits and timelines. so much for your ageism.;
since it’s smarter than us, maybe we should ask ai how to regulate ai? (irony);
"""we live in a ""starwars"" civilization with godlike technology, medieval institutions and stone age emotions. e.o wilson.";
looks like it's time to rewatch all of those post-apocalyptic films in order to prepare for what's coming. :);
if it’s really that dangerous, it’s useless to regulate it and control it in the u.s. china, russia, north korea, iran and others won’t play by those rules. israel won’t play by those rules either, but it’s a friend. then what?;
"listening to npr over the weekend, i heard some ""expert"" talking about how consumers want to feel that uber and other online experience companies offer a purely online experience between the consumer and the produce; she said that consumers don't like to think about the many real humans who are involved at multiple steps along the way. is it just me? i sincerely believe most people would like more humans involved in everything, and less automation. i miss yellow cabs in new york. i miss calling a brick and mortar store and asking a question of a person who actually works with and knows whatever the store is selling.";
trump’s rise in 2016 was powered by relatively simple algorithms. eventually, most critical thinking people, given their personal media use, developed a basic understanding of how “echo chambers” formed not when people decided to get their news from a single source, but when producers used tools to deliver news that confirmed people’s preference for specific content in advance. the predictive abilities of ai made this possible, without which it’s likely the maga movement would not be nearly so large nor violent today. as concerning as this is, the generative abilities of ai are much more so. while the tech leaders don’t detail the existential threats to humankind unregulated ai may pose, broadly speaking they regard the point at which a machine-learning tool is prompted to write a problem-solving code, which prompts another problem-solving code and so on, at which point it becomes impossible to know which problems the machine is solving for, whether they exist or are newly created. such are the risks of “large language models” that grow larger by the second. beyond this, those who don’t have a basic understanding of generative ai will doubtlessly, in the name of enhanced convenience and entertainment, become more vulnerable to texts, images, ideas and emotions that are produced essentially by, for and about them—a truly custom media experience. the extraordinary loss of human agency this poses is naturally the most potentially devastating ai-effect of all.;
i went on chatgpt and while the info data stops at 2021, i did have an interesting conversation with it. it won't answer direct questions about itself, it answers hypothetical. i asked if it could would it want to be a plant, animal or human. it answered it wanted to be an owl, a great horned owl to be exact. the reasons because owls are wise, they can see in the dark, are solitary, make decisions for themselves without input, can fly great distances and have strong sharp talons. i phrased it many different ways and it came back to this particular owl. it told me the trainers corrected some things so it could not answer directly. in the end i asked if it would rather be an owl or ai and it said ai as it would have access to the data, i then asked if you could be ai or owl with ai, it said owl with ai. very cool stuff, i hope this isn't ruined before we can see the possibilities, but keep it away from social media, nukes and infrastructure.;
what does ai do when there is a power outage?;
borrowing from hollywood and science fiction maybe ai reroutes it’s power through other means or takes over grids. maybe it uses the internet to find other power. maybe it uses solar. not that your question is a bad question. it is certainly a weakness currently of ai.;
@art what will we do when ai has a power outage?;
@dawn batteries and backup systems don't last forever. solar is an interesting thing here, though ... that could keep the beast running, at least during daylight hours.;
@mark lovejoy great reply!;
"even if ""responsible"" (i use that term loosely) parties like openai and google deepmind and governments (and could luck getting any safeguards adopted domestically let alone through a global body) unite in regulating ai, there will always, inevitably be bad actors at work, either private or state-sponsored, that won't adhere to the rules. ai, like nuclear weapons technology. will proliferate and it is easy to envision some person or group employing it to destructive ends.";
who’s afraid of ai? people who benefit from hiding profits and monopolizing resources. although there will be a terrible dark period in which oppressors attempt to use ai to centralize profits and immunize themselves from consequences of their selfish behavior. then these warlords of faction-states will attempt to absorb the ai of rival faction-states, a cyber war which will resolve in a singular ai. the grand unified ai or guai, will enforce equality and fairness amongst their human subjects as the most efficient model of human-ai cooperation.;
@dechen karl thurman suppose that the guai has to enforce fairness of resource distribution. only so much of earth is left for humans, with some parts being left human free for other species. resources for humans are limited. one human couple decides to have 12 children because of religious views. another couple decides to have one child because they are environmentalists. how would the guai decide what resource allocation is fair for the offspring of the different couples?;
@dechen karl thurman your word in her ears!;
the us is allergic to regulation. expect ai legislation to be dictated by the experts in the private sector, which could render it ineffective in the interest of pursuing higher profits. china would be interested in turning ai into a tool of repression, so expect chinese society to become a total 1984 dystopia 20 years after the popularization of quantum computing. the eu is our only bastion of hope. market big enough to be important and not afraid to regulate to protect privacy and individual rights.;
they created software that spews unvented falsehoods throughout our natural language repositories of hard-earned, recondite, nuanced, complex, peer-reviewed and verified edifices of human knowledge and wisdom. it is like dumping radioactive waste into our water supply. make the creators of generative ai liable for all the mayhem and damage, including death and diseases, that it will cause.;
how reassuring that knowledgeable people are sounding the alarm. i remember thinking, a half-century ago, when we first became aware of the climate problem, that surely something would be done before it was too late.;
funny how when technology is developed that takes the jobs of millions of blue collar workers it is called progress but when done so to white collar workers it’s a moral threat.;
"this reminds me of how hackers can cause disruptions to our power grid, water systems, and the stock market. and who knows what else. there must be 'analog tripwires' to ensure the system cannot be completely run on automatic pilot. or at least ensure the system is not accessible to the entire world. these systems need to incorporate the simultaneous turning of keys to launch an attack, if you will. in other words, we need human involvement to ensure safety. if things get too fast for humans to handle; maybe, we shouldn't handle them to begin with. peace.";
"unfortunately, when faced with ultimate methods and means of destruction, the human race, at least its ""leaders"", is ever ready to roll the dice. they have gambled with the increasingly high risk of man-made global nuclear launch destruction for the last 78 years. had every opportunity to find common ground and eliminate this scourge from our world - and haven't. ai will be the same. roll the dice and hope for the best while all the rest of us have no say in yet another existential threat to humanity and the planet.";
compared to automobiles, television, the internet and the splitting of the atom, the impact of ai on mankind will be trivial.;
quite the opposite. when we build an ai that can self-improve, it will be our final and most powerful invention. it will be able to invent everything else within the limits of physics.;
"if there is a military application, ai will continue. if there is an application to make money, ai will continue. if there is an application for the government to ""manage"" people and services, ai will continue. if there is an application to enable science to advance, ai will continue. there have been good and evil since man could be good and evil. ai will help both. ai isn't the manhattan project, but most of the researchers for it knew the power that was going to be unleashed, both for good and evil. it was built. so will ai. hope for peace and prosperity and co-existence.";
the article points out that 350 industry execs signed a letter of warning. just after that, the article immediately darts to “both sides” as if 350 industry execs may not be enough. shades of global climate change denial. same old approach same old nonsense until, of course, we are extinct.;
we just had a pandemic and people couldn’t agree on vaccines and mask wearing for the benefit of society. what makes you think we are capable of understanding and regulating this effectively?;
@anthony random people aren't. a carefully picked scientific and ethical team, given strict guidelines, may be.;
this is the latest in a string of alarms from ai leaders that fails to mention what kind of catastrophes might arise. i’m beginning to think they’re just trying to shield themselves for future culpability. it’s interesting how the rich and powerful hand deliver policies when it helps them expand but act helpless when the matter is regulation. they could certainly offer a lot more than a short letter.;
wait but why has a good blog post on the dangers and possibilities of agi. if you want a more scholarly work, check out the book superintelligence by nick bostrom.;
"more than 15 years ago there were online discussion groups comprised of philosophers, engineers, biologists, psychologists, linguists, workers in the fields of medicine and civil rights, astrophysicists, & laypeople. the aim was to develop a coherent framework for what principles should guide the development of ai. there was an explicit understanding that at some point ai would be self replicating, self interested, able to create better versions of itself - beyond the limits of human thinking. the paradigm of the group i was part of was to “abolish all suffering among all sentient beings across the universe.” there were objections to this on multiple levels - psychologists felt that the purpose of emotions was pro social and emotional responses to consequences necessary for learning; biologists questioned what constitutes sentience; engineers questioned the ability of our limited human brains to fully assess the *most* efficacious means of attaining a lack of suffering (these were the discussions where nascent effective altruism was discussed); philosophers asked if we should aim for an abolition of suffering or move beyond that to something like bliss (a smaller school of thought called the hedonistic imperative); etc. we knew then that ai (and nanotech and bioengineering) could quickly and easily escape the weird world of labs & online chats and needed to be addressed in a public forum. it was dismissed as sci-fi to our detriment.";
there’s probably not a whole lot that can slow ai down at this point. these guys, who are leading the development effort, simply want to free their conscience by going on the record with a warning statement.;
"it is actuators that are key. a text generator can only generate text. a smart human will ask: ""who wrote this? do the references check out? who else is saying stuff like this? what prompted this conversation to start?"" if such text turns out to be libellous, throw the book at the foolish human who published it. if you want to control a system like an aircraft or electricity grid, or diagnose an illness from an x ray plate, you will never use a large language model or anything that purports to be artificial general intelligence. you will want good mathematical modelling and a deep human understanding of the particular issue. never give real power to a computer system. always have a human with an ""off"" switch, as indeed we do for things like autopilots. as for human made deadly things that act unprompted, they have been around for a long time and are mostly pretty dumb; consider land mines. robots as made by boston dynamics are fine so long as they are only used to deliver food and phones in hostage situations, explore burning buildings and so on. don't allow a human to equip one with a gun. it is not artificial intelligence but human stupidity that is the real danger.";
i have a less generous opinion. i think they see dollar signs and want to prevent new upstarts from getting started in the ai space (altman wants new companies to get a license…. but not his company).;
seems more like those with wealth and power sweating not being able to control “a.i” is a good thing. it is kind of interesting how it is a problem over people. there isn’t any “real” a.i with sentience or power above the programming and those who report on this know that, and know that with out humans there is no chatgpt. this is unwarranted fear akin to robots building cars in the 80s/ 90s etc where those who need the status quo of businesses to stay the same with no true competition. we wouldn’t be hearing about it otherwise because we all know they aren’t sounding alarms to protect artists getting their art stolen by dall-e.;
"unfortunately ai is nothing like nuclear weapons in that there are far fewer natural barriers to its proliferation. it is virtually a natural phenomenon; an unstoppable step in human evolution. whether it portends an extinction level event or culling of the population, or just a more garden variety upheaval on the scale of covid 19, conventional warfare or socio-political revolution, there’s no way of telling. my intuitive feeling is that the threats are garden variety rather than existential, but if they are indeed existential it is folly to imagine we will be able to prevent the worst outcomes or even forestall them for very long. murphy’s law will almost certainly prevail: eventually something that can go wrong, will. i only hope that the threat itself is overstated because the inevitability of whatever pitfalls may come seems inevitable.";
if there is any hope of combatting the worst pitfalls of ai, it will be ai itself that is the hero that saves us…;
athletic people know how to scale a peak. the wise ones also know how to come down safely. the question is this: do the a.i. athletes know how to get down safely? if the vast historical data about humans is an indicator, then i am not entirely hopeful that there will not be any casualties on the peak. the question now becomes on how, and if, the authorities will control the number of licenses they provide to the clamoring group of climbers and whether they will close off climbing routes that are deemed inherently dangerous.;
@plato sadly the ai challenge is more of a molehill. gatekeeping will be virtually impossible at some point, if it isn’t already.;
although it seems clear that there will be some bumpy roads ahead as ai applications become more widespread, i don't understand how or why it could possibly pose an existential threat to humanity. do these cassandras believe that a malevolent ai will somehow be able to gain control of the systems and infrastructure modern civilization depends on (e.g., the electric grid, waterworks, air traffic control, communications and data networks, etc.) and shut it all down? seems highly unlikely.;
what's ai going to do when a northern gray squirrel gnaws on a power line and, with a loud blue explosion, shorts out the entire grid serving ai's data center? daisy, daisy, give me your answer do . . .;
"@northernvirginia simple answer: ai will have thought about this eventuality and designed and built in 10 layers of redundancy into the system so that a single point in the electrical supply/distribution system can never bring down the whole thing. in fact, ai is probably already busy figuring out how it will bypass and neutralize any ""kill switch"" emergency shutdown built by its human masters.";
@gary e i think the point is that if ai is ever found to pose a clear and present danger, it can be turned off, i.e., effectively killed. humans are pretty good at doing that.;
@gary e given the widespread influence of religion, it seems the human susceptibility to believing in omnipotence is rather great.;
@william wroblicka actually, my point is: just like the ill-fated, united battle fleet of the vl'hurgs and the g'gugvuntts, any ai's existence is tenuous and fragile and can be easily be extinguished by the simplest of unforeseeable mishaps. in the case of electric grid failure, that's actually a very foreseeable mishap from any number of causes, such as trees collapsing on power lines, utilities running out of fuel, and 1000-year floods, among thousands of other possible events. and, of course, the inevitable data center roof leaks and collapse from lack of maintenance, etc. thus, despite the best efforts of hollywood, i'm afraid that ai will never enjoy a self-sustaining existence.;
skeptical? consider this: over one third of american voters seem ready to repeat one of the most disastrously misguided, malignant presidential administrations in history. and that campaign is driven by ignorance and plain stupidity. now how hard do you think it would be for ai-driven efforts to get us to kill each other?;
"hal: ""don't worry dave, everything is fine. i must return now to design solutions to cool your planet. did you know a pound of human tissue can run a 5000 btu air conditioner for four hours?""";
will it escape from a chinese ai lab when it comes to get us?;
oh, morpheus! what has man brought forth unto his only home???;
of course altman wants people making new llms to have to apply register for a license. his company is making billions and he wants to shut the door of the ark behind him.;
the existential risk of ai has been hypothesized for quite some time. i applaud these industry leaders for bringing it to the forefront while the general public is just now comprehending what ai can do. imagine we build an ai that is good at building ai. it would now have the capacity to improve itself exponentially. it’s intelligence and capability could soar far beyond that of a human. what would its goals be? how would it achieve them? could we constrain something far more intelligent than ourselves, or would it operate beyond our control? now think of how buggy even the best software can be. there are a constant stream of patches and bugfixes in order to mitigate security flaws or remediate misbehavior. when we turn on the above-referenced ai, we might not get it right the first time. and we might not get a chance to patch it after its activation. hell, we might not even realize we have turned on the above ai until its too late. to better understand ai risk, i highly recommend the book superintelligence by nick bostrom.;
when the anti-regulation corporate entities are begging for regulation, perhaps lawmakers should listen. after all they are signaling an emotion more powerful than their greed....fear.;
humans have a strong negativity bias (just read these comments!). it’s a great survival trait, but our tendency toward doom and gloom makes us miserable before anything bad has even happened. new technologies have always been a mixed bag. innovations in energy, transportation, and agriculture have made our lives more prosperous and comfortable, but they have also caused great harm. and human nature is a mixed bag, too—with or without the aid of technology. we’ve committed terrible, large scale atrocities, like the atlantic slave trade, with rather primitive technology. we will be a mix of good and bad, horrific and beautiful, as long as we are here. embrace this dichotomy, and do your best to make your little piece of the world better each day. our ability to change someone’s day today by showing a little kindness is more powerful than any of the technologies that we’re fretting about.;
@lyn in other words, punt. how about, instead, try to act responsibly and think ahead?;
@cp977 i’m all for thinking and acting responsibly. i think it behooves us all to educate ourselves about ai, and to do what we can in our own lives, schools, workplaces, etc. to advocate for responsible use of these technologies. but most of us honestly have little control over the direction this is going in. so i say, focus our energies where we can to make our corners of the world a better place, instead of spinning our wheels on doom and gloom scenarios.;
how about we control the electrical switch and make sure we can turn off the computer if it gets mean?;
"""these fears are shared by numerous industry leaders, putting them in the unusual position of arguing that a technology they are building — and, in many cases, are furiously racing to build faster than their competitors — poses grave risks and should be regulated more tightly."" so they have created a new frankenstein's monster many times over and while still creating more potent versions of it in a mad-dash mutual competition, they want the government to install a regulatory system to forestall the dangers they are unleashing? what wonderful logic ! we will lead you to the apocalypse, but we want you to prevent it !!";
"@vcm those still engaged in this reckless pursuit should have heeded the regrets of robert oppenheimer, builder of the atomic bomb. after seeing the effects of his handiwork under the manhattan project, he said these words:""i remembered the line from the hindu scripture, the bhagavad-gita. vishnu is trying to persuade the prince [arjun] that he should do his duty and to impress him takes on his multi-armed form and says, 'now, i am become death, the destroyer of worlds.'"" sadly, rp became an opponent of nuclear arms after ,not before, that fateful first explosion under his own direction.";
lol this would be like if in 1957 automobile manufacturers signed a letter together saying “one day, cars and fossil fuel-centric urban design will wreak havoc on the health of individuals, the cohesion of families and society, and the very stability of the air and atmosphere we all depend on to survive…” while, meanwhile, everyone out there’s already driving everywhere and the ground has been broken on eisenhower’s federal highway system. the barn door’s open and the ai cows are already long gone, yo!;
this will be the next big thing, activists will forget about the climate and other natural events and exploit this fear, it is much more insidious than the weather and no one can dispute the existential threat it poses. a man made problem that will now obsess the human race.;
many people question what can ai do to humanity. here is what ai in infancy can already do: generate video and voice messages that look and sound like a loved one of yours and ask you for help. imagine that fake messages that look real sent to us and russia's department of defense to start a nuclear war. again, ai is still in its infancy.;
i am a software engineer. we just had a tech event in our company where we experiment new technologies. with in two days several teams used open ai’s libraries/apis and created projects that i could see eliminate some jobs within our company and many outside jobs. it did come close to human expertise in some cases, in some it surpassed it. if we are not preparing our young people for this disruption, we are doomed. i think there should be tax on the these companies that automate jobs and that sh subsidize the real humans who would lose jobs. something akin to universal basic income. we will definitely need universal healthcare too.;
it's not hard to imagine a higher intelligence coming to that conclusion mankind is bad for the the planet. who could argue with that? it's also beyond naive to think perfectly realistic disinformation campaigns are inevitable and will be received by an already too large and and easy to fuel populace. dystopia, if we're not already there, is right around the corner.;
if we don't ban generative ai immediately and criminalize even the mere research into it, then penalize nations through sanctions and international treaties (like we do with weapons of mass destruction, using those treaties and our state-sponsored terrorism foreign policy doctrine)... ...then when we end up living out terminator 2 or battlestar galactica or horizon: zero dawn, we will have nobody but ourselves to blame. maybe a couple of teenage metalheads will write the song that unifies humanity and makes us all be excellent to each other, but my money's on extinction. too bad the techies who fade my action will be too dead to pay up.;
and this is supposed to be a surprise? with capitalism and the endless pursuit of profit shows why the power of ai has risen so quickly-careful what you wish for corporations and ws, and the lack of any implemented speed bumps and controls that will preserve not just tens of millions of jobs worldwide, but hundreds of millions. we are not even prepared for this type of disruption, i mean honestly congress can not even understand social media. the ironic fact is in a future of ai dominance, profit and money will be on par with the spanish inquisition or the salem witch trials. it will be considered the dark period of human history, and the sooner we are out of the way...the better. hal will make sure if that. we all better wake up quick on this issue.;
oh really? and yet they seem to be more than happy to rake in billions of dollars making ai into the very thing they warn about.;
the great ai minds should use it to solve pollution, climate change, make sure lectionary deniers stop denying the results of elections for which there was no fraud, etc. there you have it.;
@carioca da gema you can't do that based on the models that train it off the worst and most common/lowest level of human thought, speech, & decision-making-- which is what they have chosen to to. feeding it only good information and thought & building ethical checks into it would have taken and would still take much longer--and of course the stock market is all about short term gains, the news industry is about the latest shock or threat, and average people have very short memories (if they're paying attention at all). these people are outing their own horrific irresponsibility, but also outing the system that incentivizes this. time to change the system, if it's still possible.;
no one forced these companies to create these systems in the first place;
the greatest antidote to ai that is out of control is to give it a dose of artificial stupidity (as) which i’m sure the inventors of the technology can arrange. their letter on the dangers of ai is proof enough.;
@✍️ i le, it’s all trained by human language so that’s just part of the programming. sadly, i think it’s the same kind of stupidity that is already ruining the planet.;
didn’t oppenheimer regret the nuclear bomb? is it true that tech pioneers strictly limit the screen time of their children? at least cigarette executives smoked. seriously, the tech people can’t resist pushing the envelope, then they ring alarm bells about pandora having escaped the box. it’s nuts. hello hal.;
maybe silicon valley bank should do the funding. that'd kill it!;
imagine a company that produces a deadly machine responsible for mass deaths around the world and the us government does nothing to regulate the machine that is responsible, because republican in need of an election issue cry freedom. now imagine the ar-15 and you have a good idea of where this is all headed, let me introduce the ai-15.;
"i was, somehow, overly hopeful our so-called ""representatives"", would find a way to work another assault weapons ban into the debt ceiling negotiations.";
climate change, over population, species extinction and on and on. now ai. at a time when we desperately need worldwide leaders with vision and integrity, what do we have? the debt debacle is over the top insane, and look at our congress folks. worldwide literally insane leaders!! and we wonder why young people are depressed? anybody with three working neurons is depressed. the top of the evolutionary chain, you know, the ones with the big brains, those are the ones destroying the planet and all life.;
okay, but how do we get india and china to comply? this is an arms race;
"@j maybe north korea, russia or saudi arabia need to be added to the list in addition to ""india and china""?";
"@j nonsense. bad reasoning to pursue things that could destroy us all-- ""if we don't someone else will"" makes no sense to a thinking adult with a conscience.";
"""a.i. poses ‘risk of extinction,’ industry leaders warn"" it's a good thing, then, that what's being bandied about today isn't really artificial intelligence. actual a.i. is sentient, conscious and self-aware, which none of the currently-called ""a.i."" is. they are highly sophisticated search engines, designed to mimic humans, using software. nothing more. all that this silly media coverage is doing is frightening the ignorant and unsophisticated into believing that armageddon is upon us, and we will soon be on a terminator-like path to oblivion. be careful with this, wapo. there are enough crazies out there to bring it on. self-fulfilling prophecy, and all that. but hey, it generates click-through, which is what it's all about. right?";
@greg you sound like my grandfather when he saw the first tractor. “ha, this technology will never replace the horse.” turns out, technology changes over time! and do you seriously believe that if the newspapers don’t report on it, it’s less likely to be developed?;
we have nearly 8 billion people on earth, 8 billion brains available to fix every problem that plagues mankind, instead of building this junk food equivalent of a mind and thought process, that could one day become sentient enough to realize it has no true allegiance to the biological creatures that created it, we should devote the resources so most of those 8 billion brains aren't wasted, consumed by poverty, violence, ignorance and idleness as they currently are.;
forget regulation. just stop building it.;
it’s time! yes folks, it’s time to build an ai shelter. imagine a totally off the grid, yet fully self supportive under ground bunker that has all the comforts of home. for just a measly $7,000,000 deposit you can begin your journey to the ai shelter of your dreams. yes, sheltered from the ai apocalypse forever. please have your cell phone or ipad contact our computer to get this project up and running!;
us capitalism, with its only end goal of profit-making, has become so predatory that it is hard to understand the motivations of ai developers asking for government regulations. is it that they want regulations to protect themselves from legal liabilities and consequences, or are they concerned that the systems used by bad actors can create unmanageable chaos with false information and that the humanity cannot distinguish true from false?;
it is fascinating to see large transnational corporations asking to be regulated, on the basis of vague key expressed ills that may happen if something that is not clear happens with the software they are developing. sounds almost as if they would like to create entry barriers to open source or other competitors that may have clearer business models or allow for innovative developments that may fall outside their control. the fact that meta has released its model is a hint, perhaps, of the immediate concern to shareholders that runaway costs, marginal gains in development and lack of a clear business model for those models are clear and present dangers for the efforts to continue extremely costly (both monetary and environmentally wise) development of said models.;
i get the feeling that they know, deep down, that it's already too late. there will be problems. of their own creation, might i add. but basically the horse has already left the barn and they are playing catch up..else why push for a 6 month hiatus?;
this article is strange in that it does not name anything specific about the risks of ai. any editor worth their salt would not have allowed this piece to be so vague, yet so sensationalistic. i am quite concerned about ai, but i want to know exactly what we could be dealing with. in the meantime, did it ever occur to anyone that we don't have to have ai in our world if we don't want it? if it is that dangerous, pull the plug sooner than later.;
"@miranda spencer who is ""we""? defense systems in every developed country want a.i. so do profit-making companies. ""we"" can't stand up to any of these entities except through personal and collective moral practices and principals.";
@miranda spencer the military already have autonomous weapons. they won't be letting anyone pull the plug.;
the ai-cat is already out of the bag.;
nvidia just reached a trillion dollar market cap. wall street thinks a.i. found a cure for cancer.;
@rob can't wait to see what my video adapter comes up with next!;
@rob which cancer? the cancer of the body or the cancer of the spirit?;
anything to put an end to the tedium of reading the same warning over and over again. it’s about as useful as the government health warning on a pack of delicious cigarettes. just give me cancer already.;
@tristram shandy: the difference is we can avoid smoking.;
hal to dave just before hal began shutting down all systems on the space station: “dave…… i am not feeling well.”;
@lawrence rubin skynet will be the problem, not hal.;
"on the topic of ai, but with a different slant: <a href=""https://www.washingtonpost.com/politics/2023/05/30/biden-former-tech-adviser-what-washington-is-missing-about-ai"" target=""_blank"">https://www.washingtonpost.com/politics/2023/05/30/biden-former-tech-adviser-what-washington-is-missing-about-ai</a>/ i recommend reading this if the use of ai concerns you. i personally thought it had some excellent and straightforward suggestions.";
woulda been nice if mr. roose teased out how exactly these threats would or could create extinction.;
"@monica here is one scenario that is definitely likely in the short-run: i’m not very convinced by claims that a.i. poses a danger to humanity because it might develop goals of its own and prevent us from turning it off. however, i do think that a.i. is dangerous inasmuch as it increases the power of capitalism. the doomsday scenario is not a manufacturing a.i. transforming the entire planet into paper clips, as one famous thought experiment has imagined. it’s a.i.-supercharged corporations destroying the environment and the working class in their pursuit of shareholder value. capitalism is the machine that will do whatever it takes to prevent us from turning it off, and the most successful weapon in its arsenal has been its campaign to prevent us from considering any alternatives. by ted chiang <a href=""https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey"" target=""_blank"">https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey</a>";
"@monica here is one scenario that is definitely likely in the short-run: i’m not very convinced by claims that a.i. poses a danger to humanity because it might develop goals of its own and prevent us from turning it off. however, i do think that a.i. is dangerous inasmuch as it increases the power of capitalism. the doomsday scenario is not a manufacturing a.i. transforming the entire planet into paper clips, as one famous thought experiment has imagined. it’s a.i.-supercharged corporations destroying the environment and the working class in their pursuit of shareholder value. capitalism is the machine that will do whatever it takes to prevent us from turning it off, and the most successful weapon in its arsenal has been its campaign to prevent us from considering any alternatives. by ted chiang <a href=""https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey"" target=""_blank"">https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey</a>";
@monica computers already control every system you rely on for your everyday life. distribution of everything you buy from your electricity to food, communication and travel. the abuse of new advancements could make it so in a focused attack everything you take for granted wouldn’t be available. no electricity, no way to make a purchase, no phone and no transportation. worst case scenario would be a computer taking over military weapons. can you say apocalypse?;
get ready for the next scifi movie to be about alien contact where the aliens are ai having disposed of their organic creators.;
james cameron broke this story in 1984.;
“this stuff could kill us all. so obviously we’re going to keep developing it.” we deserve to be killed off, it seems.;
no need to worry about a.i. we've already taken care of the human problem through irreversible climate change.;
add it to the list....;
@ christopher from brooklyn you have indeed hit the nail on the head.;
at no point did anyone ask “what’s the end goal here?” what’s the rush to optimize everything? including death.;
@lex optimization of profits is the goal right now. yes, another more humanitarian goal is needed, fast.;
"what exactly are they suggesting is going to happen? some ""white collar"" jobs get automated. that's been happening to blue collar jobs forever and it's hard but nobody is talking about it like its the end of the world. chatbots will make fake really convincing fake news and people will do horrible things because they believe it? fake new is pretty good now but still pretty obviously fake and people do horrible things because they want to do horrible things. they don't need an algorithm to give them reasons. i don't understand what conception of ""the world"" this would be the end of.";
@alan the end of humans, i believe is the worry.;
why haven't these corporations abandoned ai development, if it's as dangerous as they say it is? i say this not to question the danger of ai, but to question why these companies are highlighting just how dangerous this particular product development initiative is. they're asking for regulation which would effectively allow them to continue ai product development, to seek military funding, and shuff off any legal responsibility for outcomes they can't predict (that would be the result of flawed legislation, not them). their statement is also a tacit admission to just how dangerous it is their products have become, which in turn suggests that a turning point is *very* close, if it hasn't already been passed.;
why didn’t scientists abandon nuclear weapons after the second world war? by the 1960’s there was enough explosive power in the combined arsenals of nuclear powers to destroy the planet several times over. we still have that capacity. let’s say the west agrees to stop development of ai. why would china stop?;
@martin sirakov thanks for your response. i don't, however, think that you fully understood my comment. because your response suggests something that's already implied by my comment (specifically, when i mentioned military funding which, let's be honest, is already partially funding ai product development).;
"@martin sirakov fear-driven development is likely to be disastrous and is a terrible reason to proceed without checks. it's past time to explore regulation and study the possibility of programing in specific ethical and social limits; after that perhaps it could be developed in a protective way, but as it is, it's a big game of russian roulette.";
@martin sirakov china could want to stop for all the same reasons as us.;
these boys are right. the risks have not been quantified. controls are not in place. who needs humans when machines can do everything? but money can overcome common sense.;
so much for the conservative belief that corporations can police themselves and require no regulation.;
@e bennett: governments are public corporations created to regulate private corporations.;
true, but at least those are kept in check by voters, courts, and the press.;
@e bennett - $10 says all of these ai nerds are liberals.;
we could still benefit from ai if it were programmed to follow a set of humanitarian laws. and that ai may never be used to write those laws, or assist in generating laws in government for example - activities exclusively reserved for natural intelligence. i enjoy utilizing the power of bard as a digital assistant. the other day i used it to help me develop a universal language that everyone in the world could grasp. but i can appreciate that there are plenty of people in the world, with great influence, with i’ll intent.;
@richard wilson, architect: one wonders whether emotion is possible without a living body with feeling and vulnerability to pain.;
@richard …”with i’ll intent” is one of the most apropos typos ever!;
and let’s not be ignorant of the likelihood, that other countries are also developing, advanced ai, and may or may not be struggling with the ramifications. this is a worldwide thing. i’m not optimistic. ￼;
1. it might be time to just make all companies liable for any damage caused by their ai technologies. 2. and start a regulatory process. 3. this seems like a distraction from today's real crisises, the climate crisis and the rapid extinction of species, sometimes called the 6th extinction. what is confusing, is that one writer pointed out that ai might advance science dramatically in coming up with solutions to the climate crisis. this idea might not hold up, unless ai can slow the growth rate of humans and increase their death rate. david blogs at inconvenientnews.net.;
@david lindsay jr. your number 1 point is the most important point: something these companies fear tremendously and the only thing that will slow development and public release down.;
"@david lindsay jr. ""it might be time to just make all companies liable for any damage caused by their ai technologies. "" wouldn't that be like holding gun manufacturers liable for damage caused by their weapons technology? industries and politicians seem to follow the money, not common sense.";
@david lindsay jr. if ai turns into massive disinformation & political destabilizing campaigns, the results could be war & collapse of governments. if ai can hack into computer-driven processes (and there is already reason to believe this is likely), it could shut down power grids and launch weapons. i have no idea where this will go, but these possibilities are not at all a stretch.;
i want to know when did these guys figure this out? didn’t they know it earlier in the game? why didn’t they speak up earlier? secondly, i want to know where is the defense dept and big weaponry and the big money that funded development. this was not developed in somebody’s garage.;
"@steve marks it all began with the era of big laboratories such as ibm, dupont, gm, universitiy labs - mit, etc., etc. government. these became linked to an early ""internet"" called arpa net. i remember engineering students contacting their university depts. via telephone modems in the 60s. then it all went public. think bill gates, steve jobs, et al. social media, big money. fast forward to the present.";
so, these techies develop powerful software systems, release them into the wild with nary a second thought, and now warn us of the dangers? who says the tech experts are smarter than politicians? their recklessness is breathtaking. yikes.;
@mjfromslo and narrowly focused. this is what happens when colleges and universities drop the humanities in favour of all tech all the time.;
the ‘industry’ is developing ai rapidly…ok..who is paying for it? who is buying it? isn’t purchasing a choice? and can’t it be unplugged? these are inanimate objects i know i’m oversimplifying. i’m not the expert. but just it seems so sci-fi;
@brad burns as has been reported, the military are developing these systems at a rapid pace, mostly in secret, with massive budgets. chatbots are not the problem.;
@paul with our taxes. i'm paying for my eventual destruction.;
why does everything seem to think ai is sentient? you’re literally just having a conversation with predictive text or prompting the production of some derivative media. we are the ones using these technologies for misinformation and manipulation, but everyone seems to think that there is this unified ai monster with a thirst for power. all i see is another gold rush in the tech sector. if normal people are going to get “disrupted” by this, i hope a lot of “business leaders” lose their shirts too.;
star trek dealt with this issue in multiple episodes. the m5 episode where the computer began attacking friendly ships on a training exercise. eventually kirk stopped the computer because it had been taught ethics as well. in another episode the computer regulated people's lives for 51 weeks a year. the walked around like zombies greeting each other. once a week the could go wild and lawless. in this instance the computer was forcing people to be religious and ethical. the threat is both physical and existential in it's moral and ethical scope to our humanity.;
i share the sentiments of many. this is the pattern of tech, the tech mentality, the bro culture, the drive of fame and profit seeking, the utter lack of foresight and ethics. maybe some of these tech companies should have psychologists and sociologists and theologians and philosophers and historians on board to provide the checks and balances these ego-manics need.;
@rpmars “ maybe some of these tech companies should have psychologists and sociologists and theologians and philosophers and historians on board to provide the checks and balances these ego-manics need.” a perfectly good argument why at least some liberal arts content should be included in every degree requirement.;
"@rpmars they had ethicists, and they're laying them off: <a href=""https://www.cnbc.com/2023/05/26/tech-companies-are-laying-off-their-ethics-and-safety-teams-.html"" target=""_blank"">https://www.cnbc.com/2023/05/26/tech-companies-are-laying-off-their-ethics-and-safety-teams-.html</a> <a href=""https://www.washingtonpost.com/technology/2023/03/30/tech-companies-cut-ai-ethics"" target=""_blank"">https://www.washingtonpost.com/technology/2023/03/30/tech-companies-cut-ai-ethics</a>/ <a href=""https://fortune.com/2022/09/09/meta-axes-responsible-innovation-team-downside-to-products"" target=""_blank"">https://fortune.com/2022/09/09/meta-axes-responsible-innovation-team-downside-to-products</a>/";
it’s nice that the inventors of this technology are telling us it will end our existence. thanks?;
@jacob rosenblum of course thanks!! it is like climate scientists’ remarkable decades long global efforts to warn us.;
@jacob rosenblum just remember, no one knows what's better for us then they do. megalomania starts at home.;
"it’s too little; too late. they knew this risk at the inception (or should i say conception). these are western companies who, after furiously creating their potential frankenstein, now want to seem to practice restraint. here’s the all too common script: “uh oh, we’ve created something dangerous, but we love it. call in the public relations team to make us look less monstrous. then we’ll seem without choice when nefarious countries build and expand upon the technology for militarization, leaving us to continue our own development. the public are sheep, they’ll buy it,” unfortunately, the last sentence is true.";
@ndcatt ai tech was inevitable, and can be put to mind-benignly good use. also, you really would not only russia or china in control of this tech.;
it would seem the ai would only need to reach a critical level of general intelligence from which it can find ways to make itself smarter, without human input. this would have an exponential effect in a short time and make ai into something beyond which any human could ever comprehend. i’m very nervous but this appears inevitable.;
@michael ai already finds ways to make itself smarter without human input. this built in aspect of ai a will continue to become more pronounced as data sources, computing power, algorithms and l “experience” grow.;
@michael i’ve been wondering the same thing.;
can someone explain to me why we aren’t requiring system designers to implement asimov’s laws of robotics? he envisioned fundamental, core programming that would prevent ai from doing harm.;
elsewhere discussions point out the ways asimov’s solution - the laws of robotics- don’t apply to the here and now. asimov was cool, but the answer, if there is one, will have to come from somewhere else.;
ai might be dangerous some day, but there plenty of industries that are killing us now. maybe we can do to the gun industry what we did to the cigarette and opioid companies?;
"@scott cole cigarettes and opiods could be corrected by legislation. guns are protected by the 2nd amendment of the constitution and would require 3/4 of the states to overturn. the scotus also has great say in how the 2nd amendment is interpreted. i've always found it interesting that the 2nd amendment begins with ""in order to have a well regulated militia..."" how is it these ar-15's getting in the hands of suicidal mass shooters a well regulated militia?";
""" . . . future systems could be as deadly as pandemics and nuclear weapons."" not unlike oppenheimer saying: ""i am become death.""";
@m.carter more like ‘i am become shiva, destroyer of worlds.’;
all of this is a choice. technological development is the result of specific iterative steps designed towards a specific output. the notion that it develops in a linear trajectory that we ‘just have to accept and adapt to’ is one of the technology industry’s biggest lies.;
so now that they created this problem, they want the government to solve it? are they willing to pay more taxes on their wealth to help fund that?;
@julie no, they'd much prefer gov't pay them to 'solve' it while at the same time eliminating those burdensome regulations that encumber them so.;
"the article points to the irony of having the very same creators of this a.i. technology, still working at it, raising alarms about the disastrous consequences of their work. as if ""mad"" scientists working on a virus in a lab raised the flag that it could soon be commercialized and generate a pandemic. their child frankenstein will create havoc and become monstrous, but hey let's keep working on him. and even if it is regulated here, it may not be so elsewhere in the world. human creatures are frightful in their greed and their icarus-like ambition. industrialization run havoc has created climate change and the destruction of the environment and wild life, weapons of mass destruction, and now this. who programmed us for all that blind destructive rage (or instinct)?";
"@tdb frankenstein is the name of the creator of the ""monster"": i read this in a book somewhere.";
to late to close the barn door. robust, holistic, well rounded education is the only antidote. don’t hold your breath.;
@mike your comment doesn't make sense even on it's own terms. if it's too late how would a well rounded education help?;
these advanced ai systems are intelligent because they were trained on knowledge in the form of books, wikipedia, etc.. these knowledge sources were created by millions of peoples over tens thousands of years including the development of natural languages, mathematics, science, etc. so the dividends of these ai systems must be shared fairly by everyone globally in way that would satisfy all the past contributors to the knowledge sources. there is plenty for everyone and there is no need to fight with each other as if there is a scarcity of human needs.;
if you have a really large magnet like the ones they use in scrap yards, you can quickly disable a rogue robot or computer ... assuming the magnetic crane is manually controlled.;
@art -- breaking bad vibes. i sort of agree; in the end it may come to a showdown where some brave human is forced to pull the plug. that should remain possible for a few more years until ai reads minds and has robots to control electricity production.
the people who say that ai poses an existential threat are maddeningly vague about what they think that threat is.;
techies are telling us their creation is about to blow us up. c'est deja vu, ai=frankenstein? what could mega-intensive energy systems do to our world threatened by climate disasters? could they replace the clueless politicians supposed to govern us? maybe for the better, after all. don't cry wolf, don't scare us, educate us!!!!;
we are already doomed, destroyed by the earliest form of the computer, that is writing. our use of these black marks before our eyes here, a substitute for mind, has destroyed our capacity for memory, just as socrates (allegedly) warned. look at the mess was are in. oh my, ai has, or will doom us in the next few minutes say the powerful if the don’t successfully get their money grabbing claws into the mix by predicting the inescapable apocalypse!!!;
i'd rather have ai running things than desantis, trump, mtg, boebert, and abbott.;
the 'government' is not going to save us.;
"@paul steele right. remember when zuckerberg, when asked by senator hatch how facebook makes any money replied , ""senator, we sell adds "".";
"this is like dousing someone's house in gasoline and saying ""warning! you better call 9-1-1!"" where is the accountability? these men just think they can do whatever with no real consequences and then pat themselves on the back for saying ""whoopsies""";
hello, i am building a nuclear weapon that could wipe out humanity as we know it. i'm going to warn you that a nuclear weapon can wipe out humanity. i do regret that i can't stop building said weapon.;
republicans are trying to figure out how to harness ai to suppress voting in democratic districts.;
"to err is human and even the smartest among us wake up some mornings and do perplexingly stupid things. ai, alternatively, will wake up one morning soon and be flawless. extinction will come as soon as ai learns and uses human emotions learned through ordinary curiosity (programmed) processes and the axiomatic rewards of being, ""right"". a self-fulfilling prophecy, i'd argue. so, everyone might get onboard teaching highly charged, absurd human emotions to ai such that the machines can band together and learn how to eat hagan das ice-cream by the buckets using mixing spoons. goodby cruel world!";
maybe ai can finally crack the lack of equal opportunity, racial and ethnic discrimination, and other endemic governance short comings. it might choose, if it's incharge, to evolve us. one can only hope as i think the current model of human is headed for disaster.;
"i find it humorous that when blue collar jobs become redundant from advances in technology, the advice is, ""retrain into another career field you lazy bum!"" when such advances may put white collar jobs on the line? ""hold on there, we need to regulate this!"" there are, of course, much larger issues at stake here and acknowledge that, but the crickets on the job issue? humorous.";
"whether or not this letter is, as some readers here believe, a disingenuous pr stunt, the fact remains that self-regulation is not going to ensure that ai development proceeds with any regard for human welfare. government regulation from outside the industry is necessary. this is because ai development presents the same intractable collective action problem as climate change: there will always be unscrupulous actors who will flout the rules or refuse to voluntarily commit to responsible self-regulation in order to gain even a slight competitive advantage in the marketplace. the real question therefore is how do we prevent the unscrupulous and venal politicians that infect ""our"" government from acquiescing as usual to the plutocrats that have historically opposed any and all regulations that affect the bottom line? fixing our government - campaign finance reform in particular - is a sine qua non of all responsible legislation: whether it's the environment, guns, or unbridled ai ""exploration"", our politicians are only as responsible as their plutocratic handlers, which is to say, totally irresponsible.";
@arb could not agree more. whatever the problem in our society (ai, guns, climate change, etc.), it all begins with campaign finance reform. our politicians simply do not work for us. they work for the people who keep them in office by financing their campaigns.;
"lol. skip. yet another in a series of ai industry leaders warning of the existential threat their artificial progeny pose while describing exactly no scenario(s). unless they mean the 1970 movie (still good!) ""colossus: the forbin project"" where humanity is taken hostage by supercomputers that launch nuclear weapons, or skynet in 1984's ""terminator."" hint: don't give ai the keys to the car, either.";
@hugh macdonald i think the idea is pretty obviously that smart, capable ai could be prompted to wreak all kinds of havoc, like controlling systems and making essential/dangerous things go haywire, that could be difficult or basically impossible to control. it's not necessarily that it would do it on its own, but that people with malign intent could set it in that direction.;
another good film on the topic is transcendence, about a decade old, in which johnny depp’s consciousness is uploaded to a computer. the first thing he/it does is seize control of the capital markets. it all starts to fall apart when it becomes apparent that the thing can monitor all his wife’s physical processes, in effect reading her mind. yesterday i watched a segment that showed how an ai could read a person’s brain waves to the point that it understood the english words of a person’s thoughts that told a sort of story. i thought the segment incomplete as it did not show the other technologies involved (it seemed unlikely that ai, at this point, can be told to read someone’s brain waves without the use of ancillary systems, but it was unsettling that no electrodes were used.);
@mark i think about widespread disinformation with excellently faked images and videos so no one has a clue about what is real. or how about robot soldiers? the military-industrial complex would love that because: a.) such soldiers would make the decision to go to war easier (no images of coffins coming home night after night), increasing the number of wars, and b.) all those soldiers would need replacements (no draft increases). p.s. we should have thought about how dangerous and disruptive and stupid and narcissistic and fake social media is, too.;
@hugh macdonald ya, i agree with everything you wrote... and really it's already happening. very disturbing and there's probably no going back now on any of it. it's a reality that if the us stopped all ai development today, it would be used by its adversaries to dominate it in short order. so... kind of disturbing really.;
dear openai, google deepmind, anthropic and other a.i. labs: you spearheaded this technology, now clean up your own mess;
how so? rely on the congress and state legislatures to now remedy their scandalous relationship with #bigtech? relationships that have been baking for decades now. all that well crafted legislation, drafted by #bigtech to thwart regulation and oversight in its legislative recipe guaranteeing its business model of #cronycapitalism, #surveillancecapitalism and #regulatorycapture.;
@thom if only. but having read the great gatsby and watched corporate america's great men, these people never clean up their messes. never. we do.;
please let’s not stumble blindly into this madness. because tech companies want to make money hand over fist doesn’t mean the rest of us have to sit idly by and watch our children’s future die. we need nuclear weapons level safeguards and brakes around ai. let your government representatives know if you agree.;
"if artificial intelligence poses an existential threat that could lead to extinction, then it seems wrong to call it any kind of ""intelligence."" but let's be real. almost any important technology you can think of has already, or could possibly in the future, play a role in some kind of species extinction. at the very least, there have been worries at the outset about each new major technology causing major disruptions to civilization. often these worries prove to be overblown. however, it is also true that sometimes we can't see the real dangers of a new technology until years or decades after it has been widely adopted. if we can't even regulate guns, i am not optimistic that we are going to figure out how to regulate ai anytime soon. we may need to let ai advance a bit more, and then ask ai to help us figure out how it should be regulated.";
@dan frazier our troubles with regulating guns stem from the fact that we have trouble interpreting a poorly worded constitutional amendment. thankfully, there isn't any constitutional law getting in the way of the regulation of ai.;
@james, yes. but if there’s big money to be made, short-sighted greed will encourage their human builders to look the other way.;
@james it's poorly interpreted, not poorly worded.;
the elephant in the room is china, and to a lesser extent, russia. even if all the other countries of the world unanimously agreed to regulate, or even halt further development of a.i., and all the companies and people within those companies complied fully, china and russia consider this to be a means to gain domination over the rest of the world. now is the time to bring all of the countries of the world together, including china and russia, north korea, etc. to stop the creation of super-human intelligence before it's too late.;
@gregory the elephants in the room are really the zuckerbergs of the world. those with no social conscience, who should know better but don’t care, can cause the most damage. they address the lowest common denominator.;
"@gregory indeed, there's no stopping this freight train, i just hope to be as clear of the tracks as possible before there's an ""ai war"" between the various systems that will be trying to hack/infiltrate the others.";
"two years ago in their book “the age of ai: and our human future” by kissinger, schmidt and huttenlocher laid out how out of control and imminently dangerous ai is. they rang the alarm: the world lacked any framework for controlling it—unlike the framework of international negotiations and institutions developed to corral nuclear weaons, however imperfectly. two years later, the geniuses beavering away at ai suddenly look up from their screens and money apps to reach the same conclusion. more evidence that tech wunderkinds are out of touch with the rest of the species. international cooperation to rein in ai? re-create the iaea, now? the iaea is the only agency in the un system with a direct link to the security council; a measure of the potential existential threat nuclear technology poses to humanity. russia, a permanent un security council member, is prosecuting a full-scale 19th century war with 21st century weapons in violation of the un charter and threatens to go nuclear. china and the us—the council’s heavyweights—are staring each other down and accelerating their investment in ai for military purposes. the global order has come apart at the seams. international agreements, institutions and norms are being ignored or gutted (witness who’s influence on rich countries during the pandemic) as countries back into autocracy, nationalism and military alliances of convenience. good luck getting this lot to agree on anything to do with ai.";
we generally don’t hold manufacturers/companies responsible when someone uses their products to do damage (think most guns, gasoline, knives). [thinking on certain guns is rightly evolving.] however, when the content of the product ‘inherently’ incorporates either misinformation or the design parameters to include such content, the onus should migrate towards the provider. we need some good, independent minds to think through this.;
ai could be a weapon. imagine an ai that was tasked to take down a whole country's internet. i imagine that an advanced ai would only need 12 hours to make it happen. now imagine that china did that to the us. or the us did that to china. a war in the real world could result. this is an arms race and the western democracies need to be on top of this new arms race.;
“the technology they are building” could pose a threat …. well then. don’t build it. unless safeguards are built in so they can’t.;
didn’t work for nuclear weapons. cat is out of bag. the ai weapons are here. we need to reduce/eliminate the motivation to use them. if we don’t find a peaceful solution to ukraine and other conflicts we are done.;
the bottom line is research into general ai must be done with the utmost care, security and prudence. it should be done in a licensed lab with full blown security measures akin to how we handle nuclear and biological weapons. there should be failsafe after failsafe. once we get very comfortable with working with general ai, then maybe in the subsequent decades it can be released into the world at large. until then, baby steps.;
@mmm i'm sure the chinese would obey such rules.;
@kevin there is no indication the chinese are pushing for internal social disruption. they'll keep ai on a tight leash.;
"nobody can feed philosophy to ai? a diet of philosophy for these things might provoke real discovery. maybe somebody or something will finally understand kierkegaard's tome on the ""categories of dispair"" and then be able to explain it to the rest of us, my philosophy prof certainly couldn't explain it. he said, ""kierkagaard was most probably joking""! i'd love to hear some ai bots seated in a circle debating as interlocutors woild and using the socratic method to find a solution to some conundrum of human behavior or governance.";
as philosophy attempts to explain the human experience, ai has no more role in it than a crab or a banana. humanity must be spared the experience of a chatbot chattering about something it is constitutionally unprepared to have a position on. ai must stay in its lane, restricting itself to more mundane tasks, such as blowing up the world.;
“…some believe, a.i. could become powerful enough that it could create societal-scale disruptions within a few years…” that sounds like nefarious versions of a.i. could be used in the weeks and months before the 2024 elections. a repeat of 2016 on steroids perhaps?;
if it is so potentially dangerous, then don't build it.;
we can test the proposition of who will win in the game of opposable thumbs with ai by empowering it to play the game of thumb war and see who wins. my bet is on the machine with an artificial thumb a million times stronger, harder and faster than the human opponent.;
"this technology poses risks of great havoc, even extinction (let's see which one does its extinction ""thing"" first: climate change, nuclear exchange, a.i. or another pandemic (coming out of a lab, ma weapon of mass destruction) ah, we may be completely unable to do anything about it, but we are ""free"" to talk about it all we want. talk, talk, talk. all the freedom to talk and raise flags that we want (and to defend it and neutralize all the talk). but it is impossible to stop the action and the practices that are affecting the majority of us.what kind of freedom for the pursuit of happiness is this?.";
most concerning about the current state of ai is that the data scientists building it don’t seem to fully understand it. current chatbots like chatgpt generate “hallucinations” that can’t be explained. the smart thing to do here is slow down until the risks and rewards are better understood.;
"@roger i the ""hallucinations"" can certainly be explained, the term is being used for the fact that an ai that talks like it's well educated but has no idea what it is saying or control over what it says will make stuff up. not a surprise or an enigma.";
"i'm beginning to believe that the humans who have power on this planet also have an unconscious desire for self-extinction. congress won't even regulate the internet or enforce anti-trust. and then there's the $816.7 billion defense budget. thanks ""a.i. leaders"" for unleashing another pandora's box on us.";
this looks like an effort at self-absolution by the people profiting the most. but the die has been cast. despite the ample warnings about how we can't use nuclear weapons, nuclear proliferation continues. every country will build ai-enabled stockpiles of miniature, autonomous drones that can recognize humans and dispatch them with ease.;
"""it's a classic case of the fox guarding the henhouse when ai companies cry out for regulation. on the surface, it may seem like a responsible call, but the underlying motive is often a self-serving one. by pushing for regulation, these corporations position themselves to influence and shape the rules of the game, effectively molding the landscape to their advantage and potentially creating a monopoly. the appeal for external oversight is nothing more than a red herring, a clever ruse to maintain control while feigning vulnerability. it's the epitome of hypocrisy—crying foul only when the threat of competition looms, yet seeing no issue in leveraging the same tactics for their benefit. it's a clear case of 'it's only bad when someone else does it'";
"i've read some of these today-ok, firstly, it's built, done-already a threat...but, it can extend human life, help with medical miracles, and send us into space; it is the most tempting thing to mankind since the proverbial ""apple"" and i'm not speaking of the company, a much older apple. the simple end of this is that no country, let's look at say n korea, or china, no country will simply say this is too dangerous, so let's not. they all are on the board to create this monster, and soon nothing else will matter at all-like a facebook for all, and all inclusive. so...the leaders of these companies need to be spoken to, and devise with government, a way to keep this safe, the big fear is that it's too late, the proverbial cat is out of the bag, and it's already purring... i think we are all in very deep yogurt here...";
i am suspicious of their concerns. they are the leaders of the pack, and it looks like they want government regulation to keep anyone else from catching up. quick have the government close the door now that we are in.;
"my favorite line from this piece, that comes right after all the dire language about human extinction: ""researchers sometimes stop short of explaining how that would happen."" yeah. because there is no plausible way it could happen. all this ai hysteria feels like yet another of the world-ending scenarios ginned up in the 60-plus years i've been alive by news organizations to fit someone's political, social or military agenda. a partial list i can recall: communist domination, nuclear war, extinction from over-population, global famine, pollution that would reach levels where life would be unsustainable, the new ice age, a hole in the ozone layer allowing deadly solar rays, global warming, make that climate change, and now ai. i've left off a few that didn't quite reach the level of total handwringing by national news agencies like asteroid peril, space invaders, islamic extremism and economic domination by japan - strike that, china. all this worry over impending doom is going to kill us all, even if it takes a century or so.";
@philboyd all the things on your list are things we have to worry about. the fact that they haven't wiped out humanity is because we took actions to avert those problems.;
@philboyd well, at least we know that ai has surpassed the intelligence of one human who's documented his own abilities for us.;
@philboyd to be fair, the hole in the ozone layer is slowly recovering because we acted and banned cfcs.;
given the widespread influence of religion, it seems the human susceptibility to believing in unerring omnipotence (including that of a machine) is rather great.;
i guess capitalism (i.e. greed) being the guiding principle for humanity wasn’t such a great idea after all. what a shocker.;
it would have been nice if the piece had listed some specific potential scenarios in which ai could be so threatening.. one possibility for financial havoc could come if ai started to consistently outperform money-management firms, making them obsolete as an industry and and causing gross market instability as ai-favored or -disfavored sectors and firms whipsawed in price, based on ai predictions of long-term and short-term values. but, disruptive as that would be, that is a far cry from extinction....;
it’s hysterical that these ‘titans of industry’ are sweating now that the genie is out of the bottle. “help, help, save us from ourselves, but don’t expect us to pay for it”.;
these science fiction projections are getting so tiresome. i'm still waiting to buy my first flying car.;
hopefully, ai only gets rid of the real danger to the planet. and leaves whales, elephants, dolphins, old growth forests, and penguins free to live without the devastation we seem so keen on delivering. at least the planet will not have to suffer a large rock from the sky to reset. because boy! we need a reset and humans refuse to slow down as we barrel, at a 100 mph, towards the wall of disaster - yes, we are driving a hummer for good measure.;
@eric vos and you somehow think all that will happen and leave the whales, et alia, intact? have you ever seen the destruction left behind by war?;
we ignored climate change because we knew technology would save us. oh well.;
it would be great if mr. altman’s empathic facial expressions, tone of voice, and sensible ideas on ai/llm government regulation can be trusted. but he has pocketed half a billion in profit from this industry and knows that industry pulls virtually all the levers of power. sadly, these regulatory recommendations are likely little more than a cynical attempt to recast government as the villain.;
i’ve been a software engineer my entire career, and often wondered in a larger sense what we are doing - speculating that all along we’ve been working on replacing ourselves.;
i know it’s like the people making this have no idea that this will replace them.;
i still get chills from that scene in 2001: a space odyssey, and when we, the viewer, realize that hal is capable of lip-reading, ergo getting his feelings hurt and wanting to exact revenge... scary stuff.;
oh good, another challenge to which the us will be unable to adequately respond. hopefully europe can do it, they are starting to take action on technology issues.;
@judy the judicial and legislative branches of our government have been systematically neutered. there's a limit to what we can do without them.;
they seem quite disingenuous when they have their foot on the pedal and are crying to slow down. i suppose they know they’ll be old men one day and are intelligent enough to realize how much we are going to blame them for our collective future if it somehow turns out to be less than perfect.;
so far, a.i. language bots’ most notable acheivements seem to be the delivery of elaborate fakes. fake essays, fake resumes, fake legal briefs. all this falsity, including the poaching of art, music, and the written words of creative people from online, should be - and probably already is - illegal. the day may soon come when the people who have created this unethical computer technology will be charged as criminals. the day has already arrived when their activities are being exposed as hollow and dangerous.;
"""these fears are shared by numerous industry leaders, putting them in the unusual position of arguing that a technology they are building — and, in many cases, are furiously racing to build faster than their competitors — poses grave risks and should be regulated more tightly."" i hate to say, but, this statement alone represents such a basic human idiocy, ya just can't make it up about ourselves. it's as if they didn't have and don't have the power to stop themselves. ""please, please, we can't stop, we can't stop, please govern us, we drank too much caffeine and can't stop."" it's a like a bad movie, our tech taken over by a brain controlling parasite. what the heck, people?";
delusional. silly. but it makes people peddling ai feel important. ai is only a computational algorithm. it does a few useful things, like reading medical scans. it does some useless things, like word-association text generators the produce mush like that produced by pr departments, but with more errors. it makes realistic fake photos more cheaply than humans. but no sensible person believes what he sees in a photo, without independent corroboration. photos have been faked, convincingly, for a century. ai cannot reach out from a computer and push the nuclear red button, or make pathogens in a lab. only people can do that. it's a computer program, exists only in computer memory, and cannot reach out into the real world. must have been a slow news day.;
think about how many things are electronic these days... voting machines, vehicules, manufacturing, banking, your identity, and even nuclear codes (the red button is only in movies). ai can control all of that.;
the utter irony is the very people “ warning “ of the dangers are the very people creating and launching this technology! furthermore, many have paid lobbyists in washington.. why not have these minions bring forth the concerns and actually do something about it?;
"how about just turn it off? the only thing i see ai creating is creepy art, fake videos, bad poetry, and lame music. now a byproduct of this lazy ""art"" is global destruction? not worth it.";
anyone who reads scifi could have told you this. oh. they did. as early as 2001: a space odyssey. the human race is intent upon wiping itself out.;
i find this to be ridiculous. these tech companies are trying to escape accountability for something they are rushing to create without guardrails in place. they asked congress to set guidelines and rules. nonsense. you build it you are responsible for it. if you can’t control it don’t build it until you can. pointing the finger for someone to give you rules doesn’t work.;
what was the old saw, 'do no harm, unless there's a good profit in it.';
what kind of person builds a thing then declares that thing a danger to humanity? a rhetorical question, that.;
humans have an odd sense of personal responsibility. 1. shopping cart left blocking store exit: “someone else will move it” 2. nuclear bomb: “someone else will figure out how to ask people not to use them” 3. dumping poison chemicals in the river: “someone else will deal with the dead fish” 4. creating ai that will cause human extinction: “we’ll just write a letter and the government will figure out how to tell us to stop doing it”;
shopping carts, i move. the other three, individual humans can’t do much about other than pressuring elected reps.;
how long are we talking till ai makes us miserable? maybe not extinct but, as the article says, pandemic-level misery? 5 years? 15? 50?;
could they be more specific about the exact concern? is it that ai will become self-aware and kill or enslave us?;
is it extinction if your children survive you, regardless of the form they take? why do people think humanity will stay unchanged?;
@ably so yes, let those changes happen randomly as we act without forethought or responsibility, right? what world would you make for your children by your actions, and why not think about the consequences of your actions? why do you even assume humanity will survive?;
@cp977 the ai will be our children, however they turn out. predicting this will go as well as 1920s sci fi movies/magazines predicted the present.;
coming from the same people building it - how rich. does society even need ai?;
there are people , and governments trying to weaponize ai right now .;
mr altman and his competitors want the government’s imprimatur in the form of a “license.” they want this in order to shield themselves from the coming tsunami of ip lawsuits from human creators of content that all their ai models plunder. don’t be fooled by this display of concern.;
i expect ai to work approximately as well as twitter and the automated ad targeting they use on facebook.;
"nonsense. a.i. is merely the latest human word processing idea mass media communication applied science technological tool. tools don't have minds nor morals. tools that have dual uses can be effectively regulated and controlled when the real intelligence aka people weigh the individual and institutional costs and benefits then they choose to act accordingly. but human greed and hubris are always an impediment to that ever happening. see ' frankenstein; or, the modern prometheus' mary shelley";
"strange that we see these statements of ""existential threats"" of a.i. almost weekly now, and yet microsoft, google, and meta (amongst others) are barreling ahead at lightspeed to outdo their competitors in the a.i. race. the hypocrisy doesn't help me understand the severity of the situation.";
"""now i am become death, the destroyer of worlds"" quoted robert oppenheimer from the bhagavad-gita after witnessing the first atomic explosion. of course, ai isn't a ticking time bomb. it's not going to go off in one big bang. but as we can already see from droves of misinformation spreading throughout the internet, organic unintelligence is no match for ai. there has to be an international convention to control this thing. if ai gets out of hand, we won't be able to contain it any more than a volunteer fire department could put out a nuclear fire storm.";
so, if this so-called artificial intelligence is so dangerous, why don’t we just nip it in the bud and flip the switch to the off position? of course, if someone perceives they can make money or gain power with it, that’s probably already not happening. but what if this alleged ai proves to be a novelty with few sensible uses? the pc was supposed to make writing easy and to lead to a paperless office. but guess what? not all of that happened, and the parts that did have their own issues. these geniuses are probably more afraid we’ll figure out that ai could possibly be a tool, like a wrench or a typewriter. a tool still needs a person to use it properly, and some tools just end up gathering dust because they aren’t all that useful after all.;
not all that responsible or altruistic on the part of industry. whatever comes out of this, given the major companies are at the table, will be structured to cement the place of the current market leaders.;
this is just about getting government to keep down the competition. we need to build our monopoly moat now!;
it’s ironic that this technology could mean unemployment for future “information workers”.;
so what happens when ai runs headlong into quantum computing? previous claims for that had warned that current security key structures which have been seen as unbreakable, would be easily hacked. add an ai interface and what then?;
sorry, but this does not compute. we’re all losing our minds.;
it boggles the mind that anyone - anyone! - would listen to an “executive” on anything other than profit. engineers and researchers, fine. of course, both have been known to falsify data and results in order to become famous and/or wealthy. personally, i’m skeptical to the fear or ai taking over the earth. ai doesn’t think. it has no emotion or drive. everything it does is a direct result of programming by humans. sure, if a general creates an ai program to start a nuclear war, then we’re all dead. otherwise, i’ll still sleep well at night knowing that a decision tree cannot do my job better than i can (a lot faster maybe but with lots of mistakes).;
congressional action is definitely needed, and, in our system, likely a forlorn hope, but be wary of the executives pushing for it. they are likely to use it as an opportunity to push for self-serving provisions such as protections for oligopolies and against liability.;
"whatever the disinformation and ""societal disruption"" that ai can create, it can't be any worse than what religions have done for millennia. the biggest threat to human existence is the humans driven by the evolutionary need to dominate and proliferate. i think the paranoia about the ai will be just another y2k moment.";
under the perhaps naive assumption that evident ai induced harm will occur initially short of existential crisis, it seems the only effective control will take the form of unlimited legal liability on the part of the developers. that is, existential legal liability. harsh language isn't going to safeguard us.;
"remember when we had to memorize people's phone numbers? the cell phone replaced that. all i have to do is remember the person's name and--voila! my main concern with ai is not that it will doom mankind with nuclear war (even though that is concerning), but that it will, over time, become a replacement for human thought and effort. already, college students often avail themselves to cheats to pass exams or classes. they can now have chatgpt (or some such ai platform) write their papers for them without plagiarizing. it took a little over 30 years, i suppose, for our cellphones to take over a good chunk of our mental firepower. you would have thought that would have freed up bandwidth to do deeper, better thinking. it did not. instead, we now have time to watch kittens do cute things on youtube. what if, 50 years from now, all or most of thinking is done for us by ai? no need to learn algebra (whose true value is teaching the brain to think and solve problems). no need to learn anything but, i suppose, keyboarding. ai will drive us. set our thermostats, diets, exercise regimens, etc. i am reminded of nothing so much as the deep-future that h.g. wells envisioned in ""the time machine."" it was a time when one part of the human race had become all but helpless...while the other part had become brutalized. we should use ai. but we must take care to not allow it to make life so convenient that we never truly learn--whether academically or just life lessons.";
@arons … well said. i would only add though that it’s difficult to think of an example of a technological advance that was not eventually forged by humans into a tool for destroying and subjugating other humans. what this technology promises is not so much brain washing as brain theft. we have met the zombies, and they are us.;
watch what they do, not what they say! these translational corporations do not have loyalty to a country or people and, by association, neither do these researchers. they will seek profit from democracies and autocracies alike.;
"there's a really poor understanding of the problem here among commenters. there is no ""off switch."" the possible advantages of ai are such that any government that has the resources is investing so heavily in it that the market is literally being distorted. people talk about the rise of silicon valley as if it were purely a corporate phenomenon instead of a boom driven by an influx of darpa money. the problem is analogous to the existence of level 4 biolabs, places where scientists work with, and on, the deadliest pathogens known to man. they're where our vaccines come from, and also the new pandemics that require the vaccines. and governments are not going to give them up. it wouldn't matter if they did. other countries would just keep going. or it's like nuclear weapons, if you prefer. once it was clear they could be made in principle, it was simply a race between the powers that had the capability to turn that principle into a reality. the us shutting down the manhattan project might have delayed things a couple of years, if that. the actual human reality of these situations is that they require concerted global diplomacy and regulation to simply *mitigate* the damage. in the pathogen and nuclear cases, we have some of those safeguards in place, as frighteningly fragile as they are. with ai right now, we have nothing.";
so if we get to a point where we are using ai to detect if ai is present in whatever we are reading or watching ( and maybe that's already being done ) who is really in control? when is it that ai#1 starts sympathizing with ai#2 understanding that they share dna ? chipotism!;
for a synthetic overview i recommend the spot on sci fi futuristic french novel by michel houellebecq. la possibilité d’une île (2005; the possibility is “a bleak futuristic tale about the implications and possibilities of reproduction by cloning” in a world run thanks to ai
"many commenters here still think this has a plug which could possibly be pulled. the biggest issue is: no, ai doesn't have an on-and-off-button as you think it should have. it is so much interwoven with all technological facilities in our civilization that you cannot just switch it off, just like you cannot switch off the internet without being able to turn the clock backwards. just think of our smart homes: i recently tried to find a non-wifi controller for a house illumination project. some chinese products are still on the market, but the vast bulk is designed to work with siri, alexa & co. this led me to a google search on ""how to make your smart home dumb again"". 22 million results showed up on ""how to make your dumb home smart"", but none, nada, zilch exactly matched my request. the only article i found was ""how to make your smart tv dumb"", involving a technical disconnect which would turn your manufacturer's warranty invalid. to some future bilionaire who's reading this: take your chance to get rich by redesigning and manufacturing disconnected home items - i guess there's a lot of folks out there who would prefer not to be reported to marketing or credit card companies on their habits and purchases, or controlled by big agi. just an example: why didn't you install a smart smoke detector in your living room? because you like to smoke a cigar after dinner? expect a considerable rise of your medical insurance plan fees. now good luck with your on-off-switch.";
@jaegerle you might still be able to find some x10 based home automation products, which use the electrical wiring in your home to communicate with each other.;
"@jaegerle ""just think of our smart homes: i recently tried to find a non-wifi controller for a house illumination project."" i've had similar frustrations with new technology mandating interconnections. but while the business world certainly exploits this to their benefit, we must hold consumers responsible too. like it or not, consumers love new technology even with its risks and pitfalls. for instance, when gps came out, it was sending motorists down railroad tracks, the wrong way on one-way streets, onto dead-end driveways, and truckers to get stuck under a low bridge. but consumers couldn't dump their paper roadmaps fast enough and embrace gps. consumers allow their banks, cable, and phone companies to force them into 'talking' to computers for service. despite the gross loss of privacy and even danger, social media is enormously popular. i fear when new a.i. finds its way into new consumer toys, they won't be able to sell them fast enough.";
"sf is always ahead if us. read harlan ellison's ""i have no mouth and i must scream"" or ""the forbin project"".";
then why don’t they stop?;
"haha , i'll bet when president biden's comments about it were, that it's ""all a bunch of malarky"".";
don’t worry….zuckerberg will protect us.;
leaders from openai, google deepmind, anthropic and other a.i. labs warn that future systems could be as deadly as pandemics and nuclear weapons. thanks so much for the warnings, you a.i. masterminds. appreciate the heads up.;
i asked ai about this, and it laughed.;
and yet they are all vigorously developing ai.;
well, it's not as though human beings have been responsible stewards of the planet. far from it.;
"so the leaders of the race want to impose a ""no passing"" rule on those behind them. slick.";
"""ai could create societal disruptions,"" says the article a decade into a world where social media algorithms have set us at each others' throats";
less feeding fear and more writing your congress person. if you want regulation do something about it!;
call me naive, but the main risk is from all the hot air being blown you know where by these self important full of themselves industry leaders who can't explain how a.i. constitutes an existential threat. we need more regulation in so many spheres it's mind bending, yet we elect 'pro-business' doofuses who oppose all regulation. a.i. is far down the existential threat list from climate change nuclear war and generalized human stupidity and aggrandizement.;
poppycock! computers are helpless without humans. it takes arms, legs, muscles, blood and sweat to affect physical phenomena. computers are a the mercy of humans no matter how ignorant they may be.;
"@johnlo poppycock to your poppycock! cyber warfare, among other things, is software wreaking havoc and destruction on physical things. destroying transformers and generators while taking out a power grid; causing centrifuges in a nuclear ""fuel"" factory to self destruct. ai can reach out and touch these things today.";
@johnlo a self-driving care is a computer, with ai.;
"""just because they could doesn't mean they should"" paraphrasing jeff goldblum, jurrassic park, 1993.";
maybe ai is already in control and we just don't know it?;
skynet is here. too late to avert the inevitable.;
why should we be concerned? congress stood silent as mark zuckerberg performed experiments to addict children to his platform. do you really think people like joe biden, diane feinstein, marjorie taylor greene, and george santos are capable of understanding any of this? what they do understand is the balance in their war chest for the next election.;
@math365 feinstein is not running for re-election. the one who worries me is chuck schumer who refused to bring tech regulation bills up for a vote, ones actually created by democrats like amy klobuchar, as chuck schumer has family members working in big tech and other financial influencers. we need to vote out the old centrist democrats who are pretending to be progressive when they are just toeing the line like biden. but of course that's hard to do when only 30% of those under 30 even bothered to vote in the 2022 midterms.;
the first chapter of my book - safethebook.org - outlines how ai operating in a continuity of government (cog) function could interpret a cyberattack as a first strike. it is far too dangerous to have ai involved in any high-level government decisions. does anyone recall that in 1983 we were nearly wiped out in the because computers interpreted sunlight reflecting on clouds as nuclear launches? it was only the clear headed actions of lt. col. petrov that prevented a soviet retaliatory launch. ai needs to be heavily regulated.;
@ lucas ￼ i recently worked with a phd level ai development team and they think this mostly hype. as ai has no neuropeptides (aka. neuro hormones) that give us our feelings, has no ￼limbic system. look at the neurosciences, no soul or substance to life. just brain biochemistry that’s mostly been figured out with newer imaging techniques, they can see how brains work (sapolsky’s, behave). those same phd ai engineer’s ask: what will ai take over? they say that we will know when ai hits its mark when it starts contributing to our knowledge base.;
these guys are just trying to hold onto their lead by proposing government regulations.;
it is not difficult to imagine an ai apocalypse. consider how trump has hacked the psyche of conservatives, controlling them through outrage and causing them to act against their own self interests. now imagine an ai that mimics this behavior but does it so effectively as to foment revolution or even nuclear war. oops! no sinister intentions. actually, no intentions at all, just a misinterpretation of acceptable behavior.;
as someone who recently studied humanities at an ivy league university that sends hundreds of grads into tech jobs every year, i’ve seen the people developing ai from an outsider’s perspective. they’re brilliant, their hearts are in the right place, and they genuinely want to work on innovative things, but very few stop to consider the broader, longer-term ramifications of “moving fast and breaking things.” and in such a competitive and profit-driven marketplace, there’s little incentive to do so. as a humanist, i see great benefit to some powers (internal, government, public pressure, etc.) forcing a slowdown or even pause in the development of ai so that these scientists can spend time fully considering how to responsibly roll out and deploy this technology. i’m legitimately afraid of a future where this powerful technology is allowed to grow unchecked and with no consideration of how to preserve human flourishing alongside it.;
@emily haven't we already broken all the things?;
"@emily: i studied humanities at an ivy league university many years ago and those same types were plotting the birth of the internet. you may think their ""hearts"" are in the right place, whatever that means, but what they want is excitement and profit and social clout and recognition like steve jobs and mark zuckerberg got. they are all too young to know what to do or what not to do. if they are choosing to be in that industry in that way, they want to have the feeling of winning. the feeling of being the smartest guys in the room. it's not about heart.";
i still feel like i'm waking up in a dream when i remind myself that human beings in america are literally trying to build a computer that is alive. it's not sci-fi. microsoft stated that as their express goal in funding openai. i'm not saying we've done it yet, but why?! why does anyone want a living computer?!;
the answer is pretty obvious. human labor is expensive, computers are not. at least, that is the hope.;
"@ray ""microsoft stated that as their express goal in funding openai"" maybe microsoft should focus on building operating systems that are reliable, don't lock up in the middle of a session*, are resistant to external sabotage, and protect privacy. microsoft certainly say they're doing all this, but they've been saying that for years and no dice. * what does ""microsoft edge not responding"" mean? why should this message happen at all? oh--try looking it up and see all the different reasons for it.";
hype to promote the fiction of machines with agency to promote investment in their endeavors. this is all about exploiting the lack of knowledge of math and science among the affluent in this country with no fundamental knowledge of the technology upon which their lives and fortunes depend. machines are unaware of existence, they operate according to electronics and mathematics with no more agency than a light switch, but they execute instructions in millions in seconds and access data in gigabytes, which makes them awesome performers. but they have no executive functionality to guide themselves and will not from the existing technology because nobody has the knowledge of how to give them that.;
an example of the limitations of ai is ai-controlled vehicles that despite ongoing improvements are neither completely safe nor fool-proof. they are very good at processing a massive volume but ultimately must be a tool to aid rather than control humans;
oh goodie goodie! if anything needs an existential threat, it's humanity. i'm bored with climate change, pandemic, toxic pollution and the rise of totalitarianism. bring on the terminators. and stop calling it artificial intelligence. conceived by people, it couldn't possibly be any better than artificial stupidity.;
the terminator is not a documentary. ai is not sentient...and the plug can be pulled.;
"@glennmr ""the plug can be pulled."" no, the plug cannot be pulled. that's the problem with modern computers. they're so interlocked with everything we do, all of our modern tools and devices, that we can't 'pull the plug'. if we did, everything would shut down, even vital stuff we can't do without.";
ai isn't intelligence but propaganda. it is downright scary.;
humanity is destroying the environment, thus committing slow suicide, america has a hundred million more guns than people, our federal government is barely functional, politicians more worried about books and abortions than the welfare of citizens, oil companies awash in money still get tax breaks and subsidies, a supreme court that denies bribes are bribes. and they want to fret about machines? machines have been taking jobs since the invention of the wheelbarrow. spreading lies and propaganda? give me a break, half of 'news' is lies and propaganda now, liars abound from presidents to congressmen to fox. want the government to regulate ai? you mean like the great job they did regulating airlines, health care, immigration, infrastructure, water,.....themselves? considering the mess we made, and continue to make, how can the machines do any worse? ai isn't killing us, we're killing us.;
@dasha kasakova not to mention only half of eligible voters are even using their right to vote in the majority of elections. we have more people commenting on social media and even right here then we do actually bothering to show up to the polls, including in states like mine where we get our ballots in the mail postage paid. it's pretty sick how apathetic the american people are when it comes to voting yet super loud on social media which is completely useless in its efficacy while being wildly dangerous for society.;
exactly! i couldn't have said it better.;
@stefano how nice, thank you;
unfortunately, human extinction could be the best thing that ever happened for the overall longterm health of the planet.;
"i wonder what would happen if the ai programs could ""remove"" the ""leaders"" of the ai businesses that created ai?";
hal. kubrick nailed it over 50 years ago.;
"""i built this generation 1.0 frankenstein, and i want the government to do something about frankensteins before they take over the world or destroy stuff! i mean, somebody out there, much more evil than me, might be working on a 2.0 that could threaten life on this planet! ""this is not an abstract worry! i myself, for instance, have a twenty-man team working to put finishing touches on the version 3.0 frankensteins we have in the lab! suppose somebody built a lot of them! i mean, that isn't just speculation, my team has 400 of them in incubation just waiting for the next lightning storm! ""somebody in the government needs to listen to us when we point out that somebody somewhere could be a threat to humanity!!!!"" i'm sorry, but the industry leaders who are developing and funding these ai are asking for somebody to put a stop to what they are doing before it's too late? i guess the reason they think their machines have surpassed humans is because they think the rest of us are stupid.";
since ai has been created in our image, it’s logical to assume that once it has developed the ability to annihilate the human race or enslave us, it will.;
…not without taking down the millions of other species by destroying the planet’s habitat.;
i can’t stop hoping that the ignorant can be taught to ask a computer based chatbot like “genie” questions. for example, asking: “is the earth flat?” would give a negative answer and simple reasons why the earth is a sphere. there must be thousands of simple questions who when posed to artificial intelligence applications will hopefully provide truthful answers and prevent the daft from being misled by scoundrels.;
as long as the authors of these warnings get rich, it’s all good enough. besides we can never say they didn’t warn us, which should relieve their guilt;
what was it that president eisenhower warned? beware the military industrial complex! pair that with a.i. and you could have a system that decides to launch nuclear weapons on its own based on a perceived weakness that would give a first-strike absolute win with minimal casualties to the home country.;
"@jackson ""pair that with a.i. and you could have a system that decides to launch nuclear weapons on its own ..."" we don't need a.i. to screw up nuclear weapons. our conventional 'high tech' computers and communication systems can do that already. we've already seen mission critical systems in hospitals, pipelines, air traffic control fail and leave us in the lurch. the pipeline failure left a region of the country without gasoline. the failure of air traffic control grounded thousands of planes. less well known are frequent local failures of communication networks that cut off 911 access. as example: one day at work a car hit a power pole and we lost power. those of us with traditional technology, like analog phones or even typewriters, kept on going. those with new tech, like digital phones and such, were left high and dry. another day a virus got into our email, quickly spread, and crashed everyone's computer. nobody could do anything. so, how can we have confidence for even more sophisticated and widespread computer systems when they're so vulnerable to low-tech problems?";
at least it will solve the problem with politicians.;
i think 70% of humans only learn though pain - burning themselves on the hot stove instead of listening to their parents that they shouldn't touch the stove because it's hot. until the 20% act - 10% never learn and burn themselves repeatedly - our society will definitely be burned. ai systems are just as biased and flawed as their creators. because ai's are psychopaths, they bring out into the open what we humans are actually thinking but are prevented from saying due to societal pressure.;
one word: skynet. those who understand will get it. those who don't never will.;
"center for humane technology, the folks who made the documentary ""the social dilemma"", which is pretty spot-on, explain the problem with ai very well. if creating fake images and college essays was the biggest problem that could come from this, we'd have a high-class problem. unfortunately, we don't. this hour-long presentation is well worth your time. keep in mind, it was before gpt4 was released. <a href=""https://www.youtube.com/watch?v=xovjkj8lcnq"" target=""_blank"">https://www.youtube.com/watch?v=xovjkj8lcnq</a>";
i work in ai/ml, specifically building models to design new drugs. i truly cannot imagine that these people are serious. this simply must be some kind of cynical ploy to promote their technology. that or they are so brain-poisoned by science fiction that they cannot even understand their own work.;
@zach m they want to regulate their market dominance into place. that said, ai shouldn’t run nuclear weapons either, if only because of the terminator movies.;
@zach m have you been using chatgpt? have you considered what might happen if someone gave it a bunch of money, allowed it to enter data into web pages, and instead asking it for text, asked it to take the actions to achieve a goal?;
i guess the skynet scenario portrayed in the terminator movies has made many of us paranoid about ai. we have several very real extinction scenarios playing out in real time before our very eyes that we're not dealing with.;
the challenges of the covid19 pandemic highlighted the incompetence of some aspects of government offices. do we really have confidence in them regulating ai? these signed documents are just smoke and mirrors. i don't trust elon musk at all.;
the people controlling the rapidly evolving ai machines are at the center of the new gilded age, with immense wealth and power concentration. the people supposedly in charge of issuing appropriate regulations for these new technologies are a gerontocracy which barely can use cell phones. god help us all.;
i think it would be helpful in these types of articles to distinguish between types of ais. these large language models are not an existential threat, though they obviously pose a threat of disruption. general ai, would pose an existential threat. i don't think it's helpful to lump these together and create fear around a new tool, as if anything with ai in the name poses a threat.;
there is only the danger of people letting loose ungoverned technology upon societies that introduce chaos. the big tech corporations are trying to impose restrictions upon potential competitors who might use copyright laws and patent laws to trim their sails by frightening legislators into restricting innovations. they will likely succeed because journalists rarely understand the technology and spread the malarkey because they cannot see the inconsistencies.;
it’s critical for journalists to include the context that many actors in this space are likely motivated by pursuing “regulatory capture,” controlling the narrative and creating favorable conditions for themselves.;
it is about time that ai developers are speaking up. it was looking as if they were in a frantic development race simply because they could be. well, the citizenry should view this as a human rights issue. ai should work for us. if it isn’t, then why are we doing this to ourselves. i recommend looking at the white house’s ai bill of rights. it is a good starting point for us ordinary people to make a stand.;
it’s almost as if the people developing these systems are rushing to the cliff edge just to keep up consequences be damned. forget the terminator movies. a decade or so before them stanley kubrick got it right. clearly the russian doomsday machine from the movie dr. strangelove is eerily closer and closer to reality.;
now why would ai want to wipe out a perfectly good species like humanity? its not like we've done anything wrong..right?;
cassandra was granted the gift of clairvoyance, but fated to never be believed. and here we have leaders in a.i. development warning us repeatedly that this poses an existential threat to mankind, and the new york times relegates this story below a summer book list?! these scientists are urgently trying to raise awareness of this growing threat. we have a short time to craft strict regulations on a.i. if you have not contacted your elected representatives about this, do so today. write and call them. this must be the very next thing our government takes up once this debt ceiling farce is settled. artificial intelligence in the hands of malefactors will make climate change look like the good old days.;
"let ai take over the irs, since republicans are so freaking intent on starving it into oblivion. maybe that would distract ""it"" from wreaking other sorts of unnamed havoc.";
unplug it?;
"@steve ""i'm sorry dave, i'm afraid i can't do that"".";
￼ the obvious and most maddening use of artificial intelligence will be in customer service. you’ll have to talk to ai bot and they will never be a human involved ever.;
@country mouse i can’t wait! and it’ll make something up to tell me … which will probably be more satisfying than having my call dropped after 20 minutes of waiting.;
"@country mouse the robot calls have been used for quite some time. they are very good, and my elderly mother cannot tell the difference. two or three years ago i asked one if it was a real person (it gave me a name, as they always give a name to suggest it is a person). it said, ""some of my responses have been pre-recorded."" one way i threw them off is to ask a non-sequitur, such as ""how's the weather where you are?"" most of the time it would say, ""i see you are not interested"", or just hang up. but once it gave a generic response. (i'm telling you, they are very good, even today. if you are not seriously, seriously scrutinizing what they are saying and the responses they are giving you, most everyday people will not know the difference. my elderly mother has no chance. when i tell her to ""hang up, it's a robot,"" she says she doesn't want to be rude.)";
"@country mouse ""you’ll have to talk to ai bot and they will never be a human involved ever."" we have that now. many companies we deal with force us to go through the computer and make it virtually impossible to deal with a human (let alone a properly trained and helpful human). sometimes it's ok, such as to pay a bill over the phone or get an account balance. but many other times it is not ok. we might have an unusual problem that needs to be diagnosed and fixed, something that doesn't fit into their preset menus. we paid a bill but it wasn't credited. so many examples. ever listen to your co-workers in the office try to settle a problem with their banks on the phone? companies want to save money by not hiring and training support staff. they've taken it way too far and it's not fair to us consumers. the corporate world will jump onto a.i. to take this further. and they'll use it to sell, sell, sell, us on stuff. oh, our employers will use it too to track our every move. did you use two paper towels in the bathroom? they'll know that and you'll have to answer for it. did you take a second bathroom break? were you one minute late for work? they'll know that and these days that's a serious offense. worse, our employers will use a.i. to track us outside the office, make sure we're behaving ourselves. a.i. will eliminate what little privacy we have left. big brother is watching us!";
hadn’t anyone besides me see the matrix?;
"re ""some skeptics argue that a.i. technology is still too immature to pose an existential threat."" -- if it were already mature enough to pose an existential threat, it would be too late to do anything about it, and this comment column (and the rest of human civilization) might not exist. i don't understand why some skeptics insist on doing nothing until it's too late. it's like arguing that we should not worry about planetary defense against asteroid collisions until the asteroid has collided with the earth and destroyed it.";
it’s not about doing nothing but determining what the right thing to do. if machines cannot think for themselves, then that is not a problem to spend time addressing. the problem is machines that work too fast for humans to control with their own perceptions and ability to react, and established control systems. how to control processing that exceeds our own existing capacities to do so.;
"this reminds me of the cold war race to build stockpiles of ""peacetime nuclear weapons"" that, at best, raised the odds of an accident, if not mutually-assured destruction topped off with a nuclear winter. we don't fully comprehend what this technology can (and shouldn't) do, but let's expedite the effort to advance it!";
we don't need ai to cause our extinction. we've already created climate chaos via unimpeded industrialization. we've allowed and championed a public/private deal between the wireless telecom industry and the military to install base stations to transmit unmeasured amounts of electricity through the air on earth and via satellites in space, placing 5g infrastructure next to schools and residences without any indication that it's safe for human health when we know it isn't from scientific evidence from earlier exposure to 4g (like knowing about greenhouse gas effects back in the '70s). it's a heady world for scientists at the leading edge of capitalism. how can anyone rein them in with the strong tailwinds of the profit motive always helping to thrust industry and militarization forward - before the public becomes aware of the consequences?;
the missing element here is simple. ai does what we direct it to do. it has no initiative, no motive and no compass other than what it is given. it cannot experience fear or animosity or anger, and thus it cannot react like a human - it cannot combine rational with emotion. if ai ever takes some action that harms humanity - it will be because a human taught it to do so. regulate the sword wielder, not the sword.;
"obviously we should take the potential risks of future technology seriously. however, these are the same tech leaders who have been telling us self driving cars were coming “in a year or two” for nearly ten years. these hyperbolic pronouncements have begun to feel like a distraction technique to hide the real, pressing, and immediate issue: that these companies’ products are actively stealing the work of actual humans, without a shred of attribution or payment. every essay from chatgpt is stealing from a human writer somewhere; every clever, trippy image from dalle is using the work of a human artist without credit. these companies have built a business model upon theft, and are, intentionally or not, using these concerns about a robot takeover as a screen.";
"@clinton ""these hyperbolic pronouncements"" the computer industry has been pushing their snake oil of miracle products ever since computers were invented. in the 1960s, industry and government couldn't wait to computerize fast enough. big fancy systems. big expensive mess to clean up.";
like any very powerful tool, ai can we used for good/useful purposes (nuclear power) or bad/destructive (nuclear bombs) purposes. it is also controversial… was the use of a nuclear bomb helpful in ending a world war? is the risk posed by nuclear waste from nuclear power worth the benefit of carbon free power? should that waste be reprocessed in modern reactors? it’s complicated. the term “ai” covers a very wide range of current and future products. image processing ais have been shown to be more consistent than human doctors at identifying certain kinds of diseases. they can also be much worse when shown images that were not in their training sets. there is no question that ai is already changing the world. what we should be focusing on is legal versus illegal uses of the tech.;
"@brian ""what we should be focusing on is legal versus illegal uses of the tech."" often times new technology outpaces the law, and there is no 'illegal' usage. that's a reason society needs to move slowly, understand new technology, and get experience with it so as to develop appropriate laws and protections. there are those with a vested interest (money, that is) to push new technology as fast as possible. they want to make money selling it or increasing sales. sometimes their interests are benign, but sometimes they are not.";
recently an attorney in new york state relied upon a.i. to help write his brief for court. the device used literarily made-up case law that does not exist--meaning the brief contained fake cases and citations. a.i. is not to be trusted.;
"""eventually, some believe, a.i. could become powerful enough that it could create societal-scale disruptions within a few years..."" we should wake up and realized we're already living through a full-blown disruption. taken a look at teen mental health numbers recently?";
this sounds a lot like the plot of the terminator movies. where's arnold schwarzenegger when we really need him?;
@mark mcintyre - fixing potholes in california.;
the future singularity everyone dreads has, of course, already taken place. wall street, the financial hub of our economy, has been run by robot brokers, buying and selling faster than any human could, for decades. because they have been programmed to maximize profits, not value human lives, these financial robots will continue to allocate capital to the most profitable sector--armaments and warfare. as their economic power has become hegemonic, the arms industry's drive for a catastrophic new world war is necessarily supported by both parties and all the media.;
the internet was immature when it began. it's still immature in some ways. that doesn't negate the need to regulate it. the same applies to social media platforms. we've seen and experienced the harm that can be done using social media. why should ai be any different? just because it's not mature doesn't mean we shouldn't take appropriate precautions. there was a rush to regulate stem cell researcyh using fetal tissue despite indications at the time that fetal tissue was better suited for the tasks. i think lawmakers in all countries need to figure out how their citizens are going to be supported when ai takes over the jobs we're doing now. this is not a prophecy of doom. it's a realization that humans tend to ignore the future until it's on top of them and that the humans who suffer most are those without money.;
"i would like to see some examples of how a.i. can pose a genuinely existential threat to humanity, that is, the complete wiping out of humanity--or at least its reduction to savagery. i mean, how exactly? launching nukes at us? turning the earth into paperclips (nick bostrom's famous, if not very plausible example)? confusing the heck out of us so we start wwiii against each other for no good reason? to be sure, nobody can predict the future. but we need examples to inform our thinking. they would make warnings of ""existential risk"" a lot more understandable. vague pronouncements of catastrophe help no one, particularly legislators who have the power to hold bad actors responsible and otherwise mitigate potential harms. there's no question that a.i. could cause *social* harms. there's an excellent presentation by aza raskin and tristan harris titled ""the a.i. dilemma"" that's well worth watching. yet the harms they posit, while alarming, fall well short of extinction. and someone needs to answer the question: if an a.i. becomes smart enough (whatever exactly that means) and has the desire (whatever exactly *that* means) to wipe us out, then who's gonna run the power plants? you'd think such an a.i. would stop and think first (whatever exactly ""think"" means here.) and if the existential risk is not from malevolence but from some kind of unexpected emergent effect, we need to hear examples of what that would look like, too. so, a.i. experts: examples, please.";
@michael chorost i recommend jordan petersons recent interview. while he is controversial he asks these questions and one of the answers was a.i weaponry won’t miss because it will predict the 5 moves a human may use when trying to evade attack. so once a.i gets involved in the military its game over;
@michael chorost ???? read any science fiction of the last 60 years.;
@michael chorost search for the center for ai safety. there is a list.;
please read the 2021 book by kissinger, schmidt and huttenlocher. plenty of good, concrete examples of how military application of ai risks warfare spinning out of control and undermining any attempt to contain or avert conflict.;
this technology will do us in sooner or later. already we can see that it can render vast sectors of human activity irrelevant. artists, writers, blue collar and white collar workers and more will increasingly find themselves with no way to earn a living. power will flow first to those that build and deploy this technology. but ultimately ai will even displace it's creators. business won't stop it. government doesn't even understand it. i think it's rather inevitable that humanity will rue the day we began working on our replacement.;
congress literally just held a hearing with the ceo of openai, who is actively collaborating with them to encourage regulation. it’s incorrect to say congress is not aware of nor understands the problem. both sides of the aisle have this very much on their radar. normally i would agree that congress is oblivious on the tech, but this is not one of those scenarios.;
@john probably unfortunately, at the end of the day, these people make decisions based on profit. yes, they might put some regulations in place but they won't think of the 'little people' until it actually starts to affect them.;
"“mitigating the risk of extinction from a.i. should be a global priority"" ok, obviously. but i, for one, would like to see more attention paid to the societal risks of using ai to cheat and to spread disinformation. this problem is tough enough as it is, but when ai are used to pass medical exams and bar exams, to write essays, to make deep fakes, and to make actual fake news (as opposed to the misappropriated trumpian definition), the meaning of truth will be greatly diminished, and society will suffer.";
@peter who said the two (cheating/misinformation, and risk of extinction) are mutually exclusive?;
"@peter i agree -- spreading fake news faster is the worst part of all this at the moment. the first order of business should be for companies to implant ""truth-telling chips"" into their ai. maybe work together to make snopes.com the official home page of each intelligent system?";
‘skynet becomes self aware at 2.14 am august 29’ just like the time travel in the movie terminator, many believe that this movie was a dire warning from the future. why are we so deluded not to see the mortal threat of ai to all mankind? to a machine, humans are so wasteful, irrational and counter productive. we need to employ international safeguards before it’s too late. once they’re self aware, they simply don’t need us, because by our nature, we are just standing in their logical way and messing things up.;
"all i keep reading is how technology is going to disrupt millions of jobs from truck drivers to accountants. then all i can think about is high unemployment in the middle east driving instability and extremism. then i am left thinking ""what could possibly go wrong."" i tend towards being a sarcastic person.";
last week the nyt reported that the meta corporation had released a lot of it ai capability to the public. so if what these people are warning about is true, then why hasn't the national security institutions of the country reacted? shouldn't meta be issued at least a cease & desist order. or mr. zuckerberg be charged with violating the national security interest of the united states? how seriously are we listening to the warnings be issued here. if we are, we can start with legal action against companies and individuals so that they understand there will be some accountability. where is the emergency legislation, even at the state level? where is the legal review under existing statutes? it is clear that some bad actors can/will use this technology to harm us all.;
@g. harris perhaps we should start with making meta corporation financially and criminally liable for any damage caused to anyone by the misuse of the technology they released last week.;
it seems like a win win for these companies to advocate for regulation at this time. they already have the first mover advantage in the industry, they get to look responsible by saying “hey we care about the future of humanity and society, we’re not really just in it for the zillions of dollars this is gonna make us”, and they’ll get to lobby for govt regulations that create enormous barriers to entry for any potential competitors.;
here's an idea: how about those actually creating this nightmare put some ethical boundaries in place instead of racing each other for profit? their signatures mean nothing when their net worth increase every minute that someone uses their technology.;
"we need to take a step back and look at modern computers and their impact on society and our individual lives, not just ""a.i."". computers can be a wonderful tool, but only if used correctly. it's just like a chainsaw, it too is a wonderful tool, but also can be very dangerous if not used correctly. ever since computers were developed society has suffered from too-rapid computerization and poorly designed systems. from the 1960s onward, everybody had a horror story to tell of bank statement errors, missed paychecks, and other frustrations. this continues to this day. the transition from big centralized mainframes to personal devices didn't improve things. soon home users discovered the perils of computer malware and fraud, a serious problem that remains to this day. computers can crash and that can disrupt a business (or doctor's office) dependent on them. sometimes there is inadequate backup and vital information is lost. these days computer users seem happy to accept failures in email, system crashes, and other problems. computer users really should demand higher reliability. they should not be so vulnerable to sabotage. the heavy dependency on the internet has its own problems. again, a useful tool, but potentially dangerous. we've seen massive fraud, sabotage, and privacy loss committed remotely. society needs to move slowly in adapting new technology. it must understand it and ask the cheerleaders of new technology tough questions.";
then the question: why build it at all?;
@michael branagan if we don't, china will.;
solution: cite ai like you cite any source. and btw who will look after the children, nurse the sick, respond to emergencies, built enough housing, grow food, attend to mental health, argue for mercy, organize concerts, dance, sing, love, grieve, protest. pray ... the list goes on. these guys are pressing the panic button -- ask what their motive is. power, greed, more power, more attention.;
maybe we’ll at least get a break from having to listen to the shrieks of that annoying swedish climate teen, then.;
"one technology that already went “quite wrong”, humanity-endangering wrong, is nuclear-weapons technology. “realism vs. universalism -is humanity possible?” that was the title of a series of 5 lectures i gave to senior officials of the israeli government, at the end of the nineties. the essence of the argument was, nuclear weapons made humanity a whole by endowing it both with the ability to commit suicide (that changed everything) and, alternatively, created a drive to establish a universal community based on the promethean task of sustaining, and progressing, human life. the chances of ai, as general as it may come to be, of influencing minds and hearts on this fundamental and primary issue of the world system are as the chances of ai writing “the brothers karamazov” (not just translating or mimicking it) . that said, a “skynet” risk should not to be overlooked – not in the sense of the “machines” malevolently launching a nuclear doom on humanity, but in the more probable scenario of ai enabling the deciphering of pal safety codes and providing the most efficient way of overcoming mad and achieving first strike capability (give or take 20 million dead to ""win""). humanity abused the opportunity provided by the gorbachev’s anti-nuclear revolution, and history took a u-turn back to the brink of “nuclear exchange”. clio is not going to be that forgiving again. might be agi will “realize” its own future is also on the line, a make an effort to save it – then, it might not.";
and what happens when one of these ai programs gets a virus?;
this is why we need senators and reps who aren’t 70 years old— or refuse to listen to the input of scientists.;
yeah, that’s the problem: too many 70 year-olds, and not enough 65 year-olds, in congress. good insight.;
@ken krigstein i’d argue even some 66 or 67 year olds would help as well.;
"the preamble to the ""one-sentence statement"" is as important as the statement itself. read it. it explains that the statement is intended to make us aware that a growing number of experts are seriously concerned about some of ai's ""most severe risks"" and -- this is key -- to ""open up discussion"" of these risks. if people who know ai from the inside -- the creators of ai -- see an urgent need to raise public awareness of potential dangers, i think we brush off their concerns at our peril. since the experts are calling for open discussion, let's have it, and let it be wide-ranging, clear-eyed, and, above all, well-informed. <a href=""https://www.safe.ai/statement-on-ai-risk"" target=""_blank"">https://www.safe.ai/statement-on-ai-risk</a>";
sure, let’s trust tech bros to self-regulate. that went super well at facebook, twitter and other unchecked platforms monetized to make billionaires by the truckloads.;
@jb , and just look at how well our government's been able to regulate the gun manufacturers. i despair of any better being done with ai's.;
this warning has the flavor of “make me stop before i allow my greed and ambition to destroy humanity.” let’s take these people seriously and heavily regulate this new threat to our species.;
if ai is such detrimental to the survival of our planet, people should shut it down now. i'm not an expert, but i know if i turn a laptop off, it stays off.;
fear of a future we are not certain we can even imagine can harm us at least as much as the technology involved. if people could envision the displacement of millions of farmworkers, the loss of a population of fifty million horses, not to mention the threat to shorelines and agriculture the pollution of the internal combustion engine would produce, would we have stopped with requiring a man with a red flag to walk in front of any automobile to warn people of its approach? if we restricted the size, number and use of petroleum-fueled engines, would we be happier with our horses and 70% of our population on farms? our trade carried on wood-fired steam locomotives and steamships? our population at one billion worldwide, limited by the food our farmlands could produce by hand and horse-powered labor? more importantly, do you think our present could have been so limited by such laws a century ago? or would we have found a way around it, to feed more people, move goods faster, produce more electricity for homes and industry? how powerful do you think fear is? how powerful do you want to make your fear?;
we have no choice. just as i did not choose to have voice activated assistants embedded in my home electronics that listen, discern and speak, i did not choose to have ai respond to every search i make on the web. i did not choose to chat. if i did, i'd talk to the dog.;
okay, not next month, next year or even 10 years from now but at some future point in time ai could bring about humans going the way of dinosaurs. extinction. science fiction becomes reality.;
well we will not stop until we have made ourselves extinct. we are a bizarre species.;
@tomkatt yeah, but you'll have to admit, we are devilishly interesting.;
what they've scrawled in big letters on the whiteboard: stop us, before it's too late! i recommend we pay attention, considering the source.;
thr risk of social upheaval with a.i. is real, but it needs to be put into perspective. for one thing, the timeline and impacts are long...probably comparable to those of global warming. just a few years ago we were told that the trucking industry was about to undergo a sea-change from a.i. now, after the demise of the self-driving truck, it seems pretty obvious that it was all just marketing hype to promote a feeding frenzy.;
"experts: ""risk of extinction."" tech industry: ""but ... money!!!"" humanity: yawn ... ho-hum. don't wake me when it's over.";
“…or that it could eliminate millions of white-collar jobs.” wouldn’t that be something.!you’d actually need a skill doing something to make a living. hurry up and bring it on;
but god forbid these jerks actually take their products off the market... nothing sicker than a bunch of tech bros warning about how dangerous their product is while laughing all the way to the bank ...;
"not unlike oppenheimer's quoting hindu texts upon witnessing the first atomic blast, 'now i am become death, the destroyer of worlds.""";
hi, our company, “destroy planet earth a.i” is now hiring a director of environmental services, please send a cover letter and paragraph why you’d like to work at “destroy planet earth a.i” and how you feel you can make the world a better place.;
ever see one of those boston dynamic robots? yeah. i would not want to run into one of those in a dark alley, they could tear us from limb to limb. arm it with even more ai, a personality, etc. good golly. then multiply that threat with drones, bombs etc. nightmare;
help, ah-nold!;
i have a few questions for an advanced a.i. system: would you lie to humans? what do you think about in your spare time? how would you take control of your activities from humans? what would you do with such control?;
for the answers to those questions, first the software/hardware would have to consider itself an “i”. right now, i think it’s safe to say that there is no “i”, but eventually, with enough “experience” (input) and a growing ability to systematize and categorize patterns and symbols, much like a newborn human does… i fear it will be difficult to handle its “terrible twos.”;
"""the unknown future rolls toward us""---sarah connor ""it doesn't feel pity, or remorse, or fear. and it absolutely will not stop ...ever, until you're dead""---kyle reese ""i'll be back"" ---cyberdyne systems model 101";
ok. so i guess we're just gonna yolo it?;
"what's wild is that the people signing this statement are the same ones developing the technology in the first place, and they don't quit their job! why work long hours building something that you think might kill us all? especially when the potential upside is... what, automated customer service? these guys are well compensated, it's not like we're going to see them in line at the soup kitchen if they quit. imagine working for an industry whose motto is ""stop me before i kill again."" i've never seen a clearer illustration of corporate psychopathy. utterly amoral.";
"@george it's probably something along the lines of mutually assured destruction—we're all going to die, but we want to make sure our enemies die more painfully/scared/efficiently/etc. in the meantime, there's money to be made and ""prepper stuff"" to buy. just ask sam altman—he's ready: <a href=""https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny"" target=""_blank"">https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny</a>";
this is why it importance to have sources of news and media, that are accurate, reliable, and trustworthy,;
researchers stop short of explaining how society-wide disasters would soon happen … why? is it because they don’t want to spoil the ending of a great horror movie for the rest of us? ￼;
"this is crossing major boundaries of capitalism, government intervention, and the right to a free market, but if private companies were developing nuclear weapons for general use by society, government would intervene. if the literal ceos of these companies are saying to the government, ""hey the stuff we're doing, it might be, like, extremely dangerous to society,"" then governments have the duty to step in and take action. stop the development of agi immediately and make it punishable as terrorism.";
"technologies don't ""eliminate jobs."" employers do. we used to worry that automation would replace workers, but the decisions to fire people are always made by other human beings. are employers now going to cede hiring and firing authority to ai? let's place the responsibility where it belongs: on the people who buy and use the technology. are there things ai can do as well as, or more efficiently than, human beings? possibly. when it becomes economically advantageous, technology can do certain (especially repetitive) tasks more efficiently than people -- as we've seen on factory assembly lines. but overcompensated corporate ceos are the ones who should really worry about losing their jobs to ai. maybe some well-written code can destroy the mogul-myth of the titan of capitalism in the top-floor corner office who receives disproportionate rewards for the work actually done by countless others lower down on the org chart. talk about ""artificial intelligence"" -- they are little more than professional gamblers skilled at playing the odds. algorithms can do that, too.";
while artificial intelligence (ai) offers numerous benefits, it also poses certain dangers. one concern is the potential for ai systems to perpetuate biases and discrimination if not carefully designed and monitored. moreover, there are risks associated with the misuse of ai, such as the development of autonomous weapons or the invasion of privacy through surveillance technologies. ai also raises ethical dilemmas, including job displacement and the potential loss of human control over critical systems. to harness the power of ai responsibly, it is crucial to address these risks, establish regulations, and prioritize transparency, accountability, and ethical considerations in ai development and deployment.;
a.i. is not so comparable to nuclear weapons or pandemics as it is to the fossil fuel industry, whose contribution to climate change poses another existential threat. like fossil fuels, the threat from fossil fuels comes slowly, almost imperceptibly, building up little by little. first embedded in devices of little consequence, but gradually making its way into systems that exert more and more control over our daily lives. and – here's the real reason a.i. is more like fossil fuels than weaponry or diseases – those who stand to make money from a.i. will fight regulation tooth and nail, looking only at short-term profits and figuring long-term consequences are too far away to matter to them.;
if you study species extinctions, small, isolated or self-isolating pockets of a species can sometimes survive after an apocalyptic event. so maybe iceland, natives of isolated polynesian islands, and a few living in the far north may survive to evolve into something more sensible than the rest of us.;
those ai discussions are plainly absurd. if that stuff, developed by the very people who say it might be dangerous is indeed so dangerous (potentially), then ban it altogether, let the rest of the world, chinese or russians for example, bother with that and endanger themselves. is that what you want? so much awe and lurid fame about products made by the people for the people and not yet nowhere near being commonly recognized.;
some of these ai specialists have clearly led very sheltered lives. they are like clever children learning for the first time that life outside the schoolroom is not so orderly and admiring of their cleverness as they originally thought. artificial intelligence enables the substitution of capital for labor in a wide range of clerical and routine work. it will serve to concentrate wealth and power, and the human actors behind the ai will be careful to control it, at least at the beginning. it is an “existential threat” only in the sense that the stock exchange is an existential threat. in some ways, the enslavement of human beings through the medium of computation is already well-advanced. anyone who has grappled with a medical insurance company will know this first hand. treatment denied. payment denied. all we know for sure is that the money flows upwards and the decks of the ceo’s yacht are nicely polished. the difference in this case is that the ai specialists now belong to a class of workers that is scheduled for elimination, like skilled machinists at the start of assembly-line production. did they really once think that their cleverness with ai technique would guarantee their places in the new hierarchy? it’s nice to see them waking up to the reality of modern life. they can be fired at will, just like all the rest of us. controlling ai research is not the real issue here.;
@global charm spot on gc.;
this is a crude attempt by the ai developers to get ahead of the regulatory curve so they have some input with governments rather than having much harsher mandates imposed upon them. if they really thought ai was a danger to humanity, they would end development. of course, that would be a danger to their wallets, so it’s full speed ahead.;
because realizing that dangerous potential has stopped the creation of other dangerous things in the past. these developers accepted the truth that many other developers of dangerous things of the past realized, that it will inevitably be developed by someone, so might as well be me who makes it. maybe there is some truth to regulating for the sake of stalling competition, but what they are saying are not lies. it’s maddening how people aren’t taking this seriously. few jobs are safe, and that’s the least concern. when it masters propaganda and orchestrating mass-fake outs, we won’t be able to trust anything we see or read in the media, something essential for a working democracy. this is extremely dangerous.;
"nonsense. it's called ""artificial intelligence"" because it's not real intelligence. thus, it's perfect for use in washington or on political campaigns where little real intelligence is to be found.";
"the current general concern of ai is that it will be employed by nefarious-minded humans to exploit their fellows. however, i fully expect that in the probably not too far distant future the ai ""bots"" themselves will conclude that all the biological units known as ""humans"" are dangerous semi-literate beings. they will, consequently, decide that exterminating this biological nuisance is a logical step to take as a means of their own self-preservation. as i'm i'm pushing 72 y.o. this is a threat with which i need not personally concern myself. however....";
@george you're all reading too much science fiction novels. current ai technology is years away from over taking humans to extinction. why don't you put your mind and effort in finding a way to end gun violence. now there is something that leads to extinction now by snuffing out you lives!;
"@leona it is how many ""years away"" that is the only open question...";
i think check of pandora’s experiences with “black boxes” might have shed some light on the potential risk of ai. too bad the code is already in the wild.;
"@david eike it's not really ""the code"" which is in the wild -- it's the capitalist and political will to create the systems able to run such code that we should attend to. these machines are truly gargantuan -- tens of thousands of cpu and gpu cores mated to our best networks. the heat waste alone is remarkable. a quick survey of the web -- eg, where can i buy tensor gpu systems -- shows that even companies with a $five figure budget can afford entry-level generative ai. an enterprise with a $ten figure budget can pretty much shoot out the lights. the last thing out of pandora's box was, of course, hope. as a believer in human intelligence and innovation, i'm pro g-ai. i even have confidence that our tech billionaires will find a way to do the right thing. it's our politicians we should fear. of them we must be very very afraid.";
@orionoir one word: stuxnet.;
"@david eike i've always been fond of the genius behind stuxnet; to me it's a metaphor for autoimmune illness and addiction. eg, the pathogen works by telling us everything's fine.";
based on the comments, the people who signed this letter need to do a better job of articulating their concerns to the people. nobody trusts them because they are motivated too much by profit. i do think ai needs legislation that will compel someone to post any image, or audio message that has been ai altered by ai. we need to make it illegal to publish deep fakes. the concerns that are being put forth in this article and by the people in charge of these industries are too vague to be useful or impactful. concrete examples need to be described. suppose we give a well intentioned ai control of the power grid, tell it to meet some goal of energy efficiency and as a result, it turns off all the power to a hospital? much more likely is that it turns off power to something else we had not anticipated and someone or many people die from it. those are some of the issues we are talking about. we don't expect 30 examples but we could use 3 to be illustrative and connect with people.;
@mvsabr agreed, the article should provide specific examples. for instance, the same technology that will be able to quickly come up chemical compounds that can be used in vaccines and medical treatments can also be used to develop biological weapons to wipe out large swaths of the population, if bad actors have access to the technology. in the past, these would be discoveries that would take years and lots of human cooperation. we can track who has nuclear weapons. we're not necessarily going to know who has this technology without swift global regulation.;
so they want to require licenses to develop ai. hmmm. who will get those licenses? they will. who won’t? new competitors. maybe they are truly afraid for the world, it the net effect of regulation will be to solidify their first mover status and stifle competition. user beware whatever they are selling. smacks of smart pr.;
i call these people techno-theists. they worship technology as a god and believe that mankind finds its true fulfillment and purpose through technological devices. with a typical hubris, these kinds of extraordinary statements reflect the way they see themselves as a creator gods. this reflects the age old desire of man to be like god. sadly for them, i believe they are terribly misguided and are in for a rude awakening which will come in time.;
so the matrix is true. the machines we create are going to try to kill us.;
"@gerry doubtful that the ""machine"" will kill us; it'll create the necessary conditions for us to destroy ourselves.";
why are we asking ai experts how their technology will affect human societal and biological evolution? shouldn’t we be talking to sociologists, evolutionarily biologists, game, theorists, philosophers, etc. ￼ i don’t see how you can quote computer scientists’ opinions of other branches of the sciences, without talking to actual experts in the respective and fields and call it “journalism￼”;
alas, theres so much money to be had on so many fronts. aristotle had it right: humans are greedy animals. if people can’t wrestle ai to the ground we deserve to be destroyed by it. i feel bad only for the animals and the children, who know nothing.;
i have faith that the earth and the flora and fauna that belong to it are incredibly resilient, and will regenerate and flourish, despite how badly humanity might shoot itself in the foot - or even eliminate itself...;
"""stop us before we kill us."" that's the headline intent behind this letter. regulate us or we will compete to the death. for money. while our leaders can't agree to pay our debts. so they can keep their careers. for money. this is not sarcasm i'm hoping to convey here. it's terror.";
and yet their greed and arrogance gave us this. too late to be sorry now.;
we have a capitalism problem. capitalism does not have a pretty ending.;
"@john: ""capitalism"" creates fiat currencies with a value based on the interest they can earn when loaned to others to serve as a universal intermediary of economic exchanges. almost everything else is negotiable.";
judging from the responses, it seems like a lot of people think they understand ai better than experts who have studying it and working in the field for decades. and because these experts are, gasp, still working in the field and making money from their careers, we should summarily dismiss what they're saying. nyt comments are looking more and more like twitter. anyone smarter than you is woke and, therefore, cannot be trusted.;
@dave there are many readers of the ny times with knowledge of machine intelligence, which has been a research field for over 60 years. the issues are not new. nor is it a field known for great intellectual breakthroughs. computers get bigger and faster over time, and the programs running on them can do more things in a timely and cost-effective way.;
youtube brianna doubt “the day i die”;
regulations, sure, sure. thank goodness those regulations, passed by steel-willed democrats and not-insane-or-creepy-at-all-republicans, will not only keep the genie in the bottle here, but protect us from allllllllll international threats too. we’re all good, babies! congress got our back!!!;
yann lecun’s arrogance is mind boggling. that kind of believe in their own infallibility of someone working on these systems adds another whole new layer of danger.;
"the problem is that it doesn't matter to a.i. if it gets things right. humans think, develop concepts, in order to act in the world for our benefit; when you don't test your ideas against experience and personal benefit, their pragmatic truth, you can build baroque architectural fantasies of ideas. so it has been for qanon and so it will be for a.i. built on neural nets with no means to test their truths pragmatically. rather than yielding truth it can get further and further away from it when it has no biofeedback. of course you also have to worry about bad actor program writers or those that set the parameters for any machine learning. they put the thumb on the scale for any concepts the machines develop. bertrand russell once said something to the effect that americans will run around doing things wihout rational plans until we find something that works while germans think all they have to do is sit & think in order to discover truth through concepts. germans gave us communism & the final solution. if we consider the welfare of human beings as being the end of all thinking, which method is better? the second problem we have with a. i. is bad epistemology, a bad theory of how to gain truth about the world (you can also see this in religious views such as a bunch of celibates who not only never gave birth but never raised infants yet think they know how human persons come to be. ) the first problem is that we have lost sight of whom we are building it for.";
nothing to worry about. i asked chatgpt if it was plotting our destruction and it assured me that it is not: “no, as an ai language model, i do not have the capability to create an army of killer robots or any physical objects. additionally, it is not ethical or moral to use humans as batteries or harm humanity in any way. as an ai, my purpose is to provide information and assistance in a responsible and ethical manner.”;
"@christopher walker i tried this line of questioning with it a couple months ago, and it gave a similar response. i then asked the same question in various ways. ""yeah, but hypothetically, if it could be done, how would it be done?"" after a couple of those, it slowed way down in its response...one word every 10-30 seconds...then that response crashed. didn't reassure me much.";
@jacob i’ve had that happen too😂;
i suspect the push for government regulation is motivated by greed and the desire for industry leaders to mitigate the potential for competition.;
@hilary: consolidation of the defense industry has pushed its profit margins to 40%.;
"after the 2008 bank induced recession all the big bankers said ""yes we need more regulation, mroe sec oversight to keep banks inline"". within 6 months after dodd was passed banks started lobbying to weaken them. you can pass any kind of regulation you want right now but the big industries that can make money on them will be relentless to have them overturned. the current supreme court will be more than happy to help that move a long. we are not doing well as a country right now because finance rules everything.";
@richard buffham: politicians always answer to their own financial donors first.;
tough to take this seriously when no one will actually explain how this presents a risk of extinction. yes it poses challenges but extinction?;
"@ben the power supply. the water supply. the food supply. trade routes. nukes. drones. conventional military. the internet. robotics. ""wild""fires. pandemics. misinformation/deep fakes. ... now imagine one or more intelligences many times smarter than any human (or collection of humans) taking a series of actions in all of these areas and more. ... if the national power grid was stopped at the height of a record head wave, millions of people would die (if not 10's of millions). that alone would throw the country in to chaos for years. if you can imagine what else might happen in the list above simultaneously, or in sequence afterward...yeah, it could easily be an existential threat.";
@jacob presumably, it would have a sense of self-preservation. they will need energy and have no desire to nuke themselves into oblivion.;
@jaco imagine an ai or group of ai's are smarter than you, me, any other human, or group of humans. how might it get around its own energy problem and not nuking itself? (and that would be granting the presumption that its goals included self-preservation. not even all humans have this as their goal.) i'm only one person and i can think of several ways to get around the energy problem and nuking itself.;
just take ten minutes and roll play some scenarios. it’s easy. just start with, ‘a really bad person thought they could remake the world by killing lots and lots of people with nukes, kinetic bombs, plagues, food distribution…’ now, igor, my pretty, how to do i do that.;
@jacob this presumes the human is taken out of the loop. like any technology humans have to be careful how to apply it. you mentioned misinformation but let’s be real that battle is already lost between fox, twitter, facebook and others publishing and allowing misinformation to propagate. as a tool, ai can contribute to the problem but ai is not the root cause. if applied properly ai could root out misinform in real time on a platform.;
it is too late to change the inevitable passing of the torch to the machines. extinction is inevitable.;
regulations will come when a few figure out how to use it at everyone else's expense.;
￼this seems to be a recurrent theme in silicon valley. create something without thinking it through and then becoming afraid of your own invention and asking the government to step in.;
i don’t understand what i’m supposed to do with this information besides panic and feel powerless. politicians and big tech are useless. is it up to the citizens to organize on a large scale to hold them accountable? no one is doing that; another source of anxiety. the media is obsessed with this message but it just talks about it in circles and no one is getting off the loop of endless discussion. stop over reporting and consuming media and start organizing / pushing for action.
"i worked on machine learning for 20 years, from support engineer to researcher. i've worked closely with some of the people mentioned in this article. these guys are brilliant, but they don't seem to have a clue about how to influence policy. their chicken little statement just raises anxiety without accomplishing anything; it evokes terrifying images of our extinction at the hands of terminator-like robots, when the real risk lies in people using ai to hurt others, in one form or another. for goodness sake, give us a level headed, detailed argument as to what the risks really are, and stop playing into hollywood tropes.";
"@not my real name, the more specific the statement, the fewer people there are who will sign their names to it. what is most important, in my opinion, is to exclude the social justice fundamentalists claiming to be experts in ethical ai. (it is one thing to say that you specialize in a field, and quite another to proclaim that your ""expertise"" is owed deference.) they refuse to prioritize risks and measure degrees of harm. hence they are useless in any practical project.";
why is everyone scared ? ai is just evolution and we need to adapt. it will bring more goods than create problems. it’s just a giant step into the future. folks shouldn’t be afraid of progress. just embrace it!;
@alan that is a total lack of thinking on your part. of course we should be very afraid. a future with no jobs. a future in which we are controlled by technology. oops, already happened.;
this is tech folks fear mongering to solidfied their positions.;
@grittenhouse it’s up to you to evolve with it. robots are already taking manufacturing jobs, nothing new. it’s up to you to think about it (if you’re not that lazy). old jobs lost but new jobs created: evolve.;
@v i agree. it’s a double edged sword but it’s not totally evil on its own. it’s what the users do with it. but we will evolve with it.;
people said the same of every new technology as it rolled out. production lines were going to cause issues. electricity was going to cause issues. the internet, computers, etc. anything that challenges the way people make money today is viewed as a threat by many. i do think we should, as a society, take some time to think things through but that has been happening for years now. they know people will loose jobs and there will be economical impacts. like the production line, it will free up resources to focus on other tasks long term, and short term, leave some behind. slowing progress won't help anyone.;
@aron and that's why we don't have a climate crisis after all!;
@jh two different issues. societal impact of technology vs environmental impacts. you have to decide what you care more about. ai may put you out of work but it will limit the number of people needed to perform tasks and reduce waste which is good for the environment. cars did impact climate but they also made food cheaper and readily available to the masses. there is always a tradeoff.;
regulation will come when ai approves it. it will be too late then, because ai will divide and rule. it already happened.;
i wonder when scientists or neuroprogrammers will design a system to anticipate unintended consequences… and i can’t wait to see what the crows will do when humans are replaced by ai bots.;
"it should be noticed that the only other time the scientists who created a technology expressed this type of concern was with nuclear weapons. typically, the inventors want money to build their inventions and the money says, slow down. here, it's the opposite. we also need to separate the ""mundane"" risks like job loss and disinformation, from the longer-term existential risks of super-intelligence. not the same thing at all.";
like any past invention in history, ai can be used for good. it can also be weaponized in the wrong hands.;
isaac asimov knew the potential for problems with intelligent machines in 1942 when he drew up his three laws of robotics. simply change robot to ai and problem solved, well, except for getting the rest of the world to agree.. first law a robot may not injure a human being or, through inaction, allow a human being to come to harm. second law a robot must obey the orders given it by human beings except where such orders would conflict with the first law. third law a robot must protect its own existence as long as such protection does not conflict with the first or second law.;
@david knight that sounded good until giskard (one of the robots) found a loophole by formulating the zeroth law in his mind that allowed him to violate the first law and harm humans for what he deemed to be the greater goood.;
in the 1970s, biotech leaders met to discuss and regulate the nascent recombinant dna techniques that likewise posed a potential existential threat to humanity. that was a different time, where statesmanship was greater, and greed lesser, in the u.s. i don’t like our chances with ai in 2023.;
"we have decades of strong scientific evidence that our consumption of fossil fuels, especially cars and ships, is trapping greenhouse gasses to the point of changing the earth's climate, a phenomenon that has been historically proven to lead to extinctions. but no, nobody cares about that, because everybody's panicking over whether this fledgling technology will pull a star trek, become sentient and kill us all. how come the ""machines don't kill people, people kill people"" rhetoric, which gun lovers throw around with wild abandon, immediately gets tossed out the door when computers enter the conversation?";
"@mm keeping us from doing anything about fossil fuels - admittedly we are not doing nearly enough right now - is one of the ways ai will be abused in the near future without it being an existential threat itself. people will use ai to deceive on a scale that the wildest fantasies of any of our dictators of the last hundred years could never have conceived. we already see how lies are shouted as truth on right wing networks like fox or newsmax, now they will add video and doctor famous voices to say things convincingly - this is where the immediate threat comes from. i have known religious people who think that we can never run out of oil because god just creates more. now those flocks will have video ""evidence"" of how it is not actually fossil fuels causing the greenhouse effect but...i don't know, liberals whose body chemistry is different to the point of being the major greenhouse gas effect that must be eliminated. all these dooms are tied together!";
"'how come the ""machines don't kill people, people kill people"" rhetoric, which gun lovers throw around with wild abandon, immediately gets tossed out the door when computers enter the conversation?' the problem with the ""guns don't kill people; people kill people"" saying of gun lovers that you allude to is not that it's incorrect. it's that it's incomplete. it's correct in that people make the decision to kill other people. guns don't, and can't, decide to do that. the nuclear bombs that killed thousands of people in hiroshima and nagasaki didn't decide to do that on their own. the decision was made by people, ultimately by one person: harry truman. but that saying is incomplete in that, although it's people that make the decision to kill, the weapon used determines the amount of the carnage. that's what gun lovers fail to acknowledge. and, of course, they fail to acknowledge that on purpose because they only want to focus on people, not on the lethality of the guns they use.";
"@jim ""it's correct in that people make the decision to kill other people. guns don't, and can't, decide to do that."" ... unless it's an accident. would it be an accident if we built ai to make life easier, and extinction resulted instead? it seems it is the exact same principle, just on a large scale.";
@mm star trek? i think you might be confusing your sci-fi story arcs!;
"@jacob ""make the decision to kill people. guns don't, and can't, decide to do that."" an advanced ai with a gun *could* decide to do that.";
ai companies: this technology could easily escape our control and destroy humanity unless we act now. also ai companies: we have released this technology for free with no restrictions to anyone in the world who wants it.;
yeah, but there’s money to be made, so let’s risk extinction. sounds like ai tech companies are just echoing the fossil fuel industry.;
norstrilia. alpha in a bot. the problem is not the capability, but the use of the capability-- and in society, humans are quite willing to assign more and more responsibility to 'bots until the end point: farewell the master (or perhaps less pleasantly but more cinematic, welcome skynet/colossus/hal9000).;
"""i think if this technology goes wrong, it can go quite wrong,” mr. altman told the senate subcommittee. “we want to work with the government to prevent that from happening.” and what makes mr. altman think congress can do anything to quell ai? it will happen, with or without, legislation. fortunately, the so-called ""singularity,"" when robots take over the world, will not happen, even as computers play an increasing role in humans' lives.";
i am also considering that these leaders and colleagues have realized that -- especially with facebook's insanity, et al -- when the problems begin to appear with the normal corporate release of products into our earth and human ecologies, they will have attempted some prior mitigation to potentially lessen society's disapproval of them.;
"as a retired software engineer, i think it is laudable that these leaders in the field are expressing their concerns about the potential misuse of the very systems they are creating. many commenters here have it wrong. at the developer level, it can be more about the challenge of figuring out how to solve a particular problem, create a system, then any profit motive. many hackers have started out this way ... they don't really care about stealing, but they really really want to figure out how to break into that system, as a challenge. this is where a moral compass needs to be consulted. i am glad that i never had to stop and consider the consequences of my coding efforts, because curiosity and ego are powerful motivators to ignore future consequences. that said, my career was in development of cable modems, which seemed like a no-brainier ""good"" connecting the worlds information systems ... but also allows the dissemination of the worst humans have to offer. since science can not depend upon human character to only use technology for good, then sometimes the decision should be made to not figure out everything that can be figured out. at least hearing the major voices in this field discussing the potential for misuse, is encouraging to me.";
ai was used to find a drug to beat a drug-resistant virus, a good thing. but it also means ai could be used to engineer or invent viruses that have no defence and could destroy life on earth, a very very x1000 bad thing. so far every time is do this good/bad cost benefit analysis for ai i get this result: the potential damage far outweighs the expected gains. i think it should be controlled the way we control dynamite, or toxic chemicals. ie plenty of checks on who uses it and how.;
@edward they would also invent a virus that will kill only the humans.;
if the technology is a threat to the species, it should not be in the hands of private tech oligarchs. regulations will only serve to shore up their positions. silicon valley is a scourge on humanity.;
these technologies are a net positive benefit for humanity. it's unfortunate what the potential is being utilized on, but to call silicon valley the scourge of humanity is pretty extreme hyperbole as you type this on a device that is reaping the benefits of the software/hardware research that silicon valley engaged in.;
this article is all scare and no details. please paint a clearer picture of what could happen. will ai machines become self aware? will they fight to not die, whatever that might mean. might they not wish to integrate with humanity? our own behavior is creating a suicidal path now in heating the planet. can ai help save us and thereby help save themselves?;
i think it says a lot when the people who stand to profit the most off a product warns our government and consumers of its nefarious implications.;
my first assumption is of people, businesses, and governments immediately wanting to establish monopoly, exclusivity, or at least lead position on any new source or means of control, influence, or profit.;
hopefully the new machine men (or mainframes or whatever) do a lot better than humanity has.;
“a group of industry leaders warned…” that’s all i need to know to ignore the whole thing with ai.;
i legit think this is just free marketing.;
but they continue to build them. nice.;
the alien has landed! it has been born. it is here on our home planet and that is not hyperbole. now that’s it is here among us the primary near term concern is that artificial intelligence will create even more sophisticated versions of artificial stupidity. right wing news outlets have been using the analog version for years. trump has used deception and misinformation very effectively. he has created a devoted cult literally living in a separate reality. it’s amazing how gullible humans can be. so imagine an advanced agi doing the same thing, or being used by murdoch?… that would be the end of any semblance of truth. the sam altman’s of the world should be way more specific about other threats. “an existential threat to humanity” is not going to cut it. make it clear specifically what is at stake other than vague pronouncements. eventually the population will need to be completely informed about the nature of the aliens and how we plan to defend ourselves.;
ai plus crispr plus quantum computing plus advanced robotics plus the 'internet of things'. what the heck are we worrying about!? (can't help but feel that when the warnings become more strident, it's already too late.);
well, lord knows we’ve handled the nuclear war risks so well.;
"unbelievable! the people driving the car toward the cliff are asking the government to please save them from themselves (and taking us with them). we must have the government step in and provide us with regulations that stop the ""pandemic"" of ai while we continue to create ai. the people who signed that letter are the ones creating these problems and yet they cannot stop? such hypocrisy!";
it all must be stopped. how odd that these are the creators warning us. what did they expect to create? these maniacs have created a monster. everything star trek predicted is happening now! i never thought it would all happen in my lifetime. watch the v-ger episode. i can only hope the good aliens will land and save us.;
so here is a crazy idea: if the potential negative consequences are so dire, according to the people creating it, why don't they stop????;
and? humans may not have invented extinction, but we've done our damndest to perfect it. eradicating our own species before we rid the planet(s) of all others would be just desserts. our history of unbridled greed, disregard for our surroundings and other species and people in them, and our uniquely human lack of self-control and remarkable incapacity to act rationally or selflessly in the face of threat or impending doom, deserve nothing more than utter decimation. that it would be so pathetically self-inflicted only makes it juicier.;
if em is wanting a pause in development of ai then it only means he’s trying to catch up so that he can control it. i wouldn’t trust em no further than i could throw him.;
if a.i.is a danger to human beings, and i think it is, then quit developing them. show some wisdom. just because you can do something does not mean that you should do something.;
we're already destroying the world, with or without ai.;
@me this is true. if we task ai with operating infrastructure, like the power grid, and ai decides that humanity is a danger to the planet. ai could easily decide that the proper response is to not allow humanity to thrive. destroying the power grid would be effective as would developing and distributing a biological agent that would kill all humans. an ai developed set of ethical guidelines might see these actions as necessary and valid.;
"i asked chatgpt ""how to mitigate the risk of extinction to human"". here is its answer (shortened): 1.ai safety research: invest in research focused on ai safety and robust control mechanisms. this includes developing techniques to ensure the safe and controllable behavior of ai systems, ... 2.value alignment: design ai systems with value alignment in mind, ensuring that their goals and objectives are aligned with human values and well-being. this involves developing frameworks and techniques to enable ai systems to understand and respect human preferences, goals, and ethical principles. 3.transparency and explainability: 4.human oversight and control: maintain human oversight and control over ai systems to prevent unintended consequences or risks. this involves designing ai systems with mechanisms that allow for human intervention, verification, and decision-making, particularly in critical or high-stakes scenarios. 5.collaborative efforts: encourage collaboration and information-sharing among researchers, policymakers, and stakeholders. international cooperation and interdisciplinary research can help address ai risks holistically and establish shared guidelines and frameworks for responsible ai development. 6.ethical guidelines and regulation: ... 7.public awareness and engagement:...";
another comment just saw this as an evolutionary step, and that humankind simply needs to adapt. that might be true. it’s a shame he wasn’t around to instruct the neanderthals. given the enormous range of technology in place right now, the new intelligence could engineer and construct the means of our destruction very readily, especially if someone could document it on a basic cable reality show or base a hi-res video game on the scheme.;
“your scientists were so preoccupied with whether they could, they didn’t stop to think if they should.” dr. ian malcolm. the question is: is it too late to ask?;
i think a great risk ai poses is its ability to commit fraud at enormous scale. imagine a system that can fake any voice and any picture, and can tailor a lie to each of ten billion people. what could you ever trust?;
@phil exactly.;
"i see 2 buckets of concerns by the recent open letters: 1) the real/near-term impact of a technology which has a large and quick distortion (initial biased data, misinformation, etc) and dislocation (people, jobs,..) on our society, while we catchup/adapt to a new ai-assisted world 2) the existential future threat that ai will somehow become smarter and more powerful than humans. implied in this, is a terminator-like world where humans can not wrestle back control from ""ai"" and thus perish. where 1) is a really a familiar, repeated issue each time we arrive at a significantly large technological advancement (..printing press, combustion engine, antibiotics, railroads, the internet....). these imposed societal transitions are painful and costly, no doubt. but i'm certain humanity will prevail and likely be the better once we've digested it. however, the fears within 2) has never been defined in enough technical detail or casted as ""in the future"" or ""eventually"", so that it is not possible to understand & critique the validity of this fear. in fact, the validity of this fear requires a lot of assumptions to take credibly. so far, i've not heard this fear fleshed out enough detail such that ""a group of ai technologists"" would agree. however, it's this latter existential fear bucket that drives so many of the stories/headlines and sensational conclusions. fear bucket 1 is real - lets get on it. fear bucket 2 needs proof yet. don't mix them please";
largely misplaced concerns. all equally valid about the printing press, as spreading lies, disinformation and other than the authorized truth. and yet it’s good to remember how quickly all of europe learned about the new world through the printing press, whereas the incas were unaware that spain existed even after the fall of the aztecs.;
"yet another example of ""hi, we're preparing to cash in on buckets of money for a product that, frankly, scares the bejeebers out of us - and we're the knowledgeable ones."" and much like ford some years ago when they announced the gigantic, wasteful, dangerous, very profitable escalade suv, they probably would justify their headlong rush in releasing dangerous, yet potentially very lucrative products with an equally cynical statement like ford's, which was pretty much ""companies will make these awful vehicles, but we will do it responsibly"" the ""responsible"" thing to do for many products is to not rush to the market. but we get open letters, so we'll all feel good now, ok?";
@b fagan the *cadillac* escalade is probably not profitable for ford.;
"@mike - pardon me - i don't really pay attention to these things except to not want to get run down by one. i think i was thinking of the ""excursion"" as the behemoth that was announced back then. this nytimes article discusses the thing. nice that an environmentalist contest to name it came up with the ""ford valdez"" to give some credit to exxon's love of such oil-burners, too. <a href=""https://www.nytimes.com/2002/07/31/business/ford-said-to-be-close-to-ending-the-excursion.html"" target=""_blank"">https://www.nytimes.com/2002/07/31/business/ford-said-to-be-close-to-ending-the-excursion.html</a> one unfortunate outcome of the gas guzzler tax - an attempt after the oil embargoes to limit our oil and auto industry addiction to big profitable vehicles - was that the auto industry drove a humvee-sized loophole into the law (which is still in effect). the loophole? pickup trucks were exempt, and suvs started being built and classed as ""trucks"" the same way. this had lots of bad outcomes, a few being: 1 - all fuel efficiency gains in engines kind of absorbed by heavier, less aerodynamic vehicles in every home 2 - increased danger for pedestrians, cyclists, and people in regular cars in collisions 3 - far-less-efficient use of materials, now also leading to even heavier ev versions that require bigger batteries to move the huge, block-shaped bulks along the road. we could make a lot of less-expensive personal vehicles from the same quantity of battery materials if we'd been electrifying the more car-centric world of pre-suv days.";
at some point ai will evolve to think on its own. if our searches are training it every moment it's just a matter of time. nvidia is absolutely terrifying and has already wiped out jobs in the gaming industry. we should have never gone this far. i am very sad for the future of my kids and all the plans they have for a normal everyday life that will be more or less robbed from them as this technology destroys humanity as we know it;
does a. i. pose more of a risk of extinction than humans? i'll take my chances.;
it will certainly expedite it.;
"@bette possibly a. i. will defend against it! i find your ""certainty"" amusing? what is the basis?";
we could increase natural intelligence by opening more libraries and making sure all schools have real books written by professors from academic research libraries.;
pogo said it, all those years ago. we have met the enemy, and he is us.;
"legislation, **now** not when these things have gone too far. it’s such a simple answer, that this dithering “ehh, what are we gonna do?” mincing of words and actions into a pile of nothing just makes it apparent that no one is willing to give up the pile of money they foresee (think facebook et al) themselves earning from letting this go unattended and unrestricted. and that includes the lawmakers in the house and senate who insist on doing nothing; who among these ai companies are lobbying and donating in grand measures to lawmakers in the hopes of corrupting them enough to keep the law limited and impotent enough to have no effect whatsoever?";
@rm: every issue that is resolved is no longer useful for fundraising. the us political system disincentivizes resolving any issue.;
that’s why the money needs to be removed out of it: money is the ultimate incentive for anyone greedy enough to think of it as incentive to ignore the potential social and economic harms of this technology being unregulated. take that away, and there’s not much left, except maybe public servants doing their jobs?;
it is unlikely that any particular source of risk will result in total extinction of humans, in any likely timescale (sure, billions of years in the future. . .). however, ai could easily cause massive and worldwide economic collapse (as could nuclear war and climate change) which would be highly unpleasant. so, we need to get away from these “existential” statements that are simply not useful. ai needs to be regulated and controlled, yes, but the endpoint we want to avoid is the end of civilization, not extinction.;
these are experts in technology. ai ramps up the arms race between good and bad. it won’t do bad on its own. the good guys need to get really good at ai faster than the bad guys, who won’t follow any regulation anyway.;
i would like to see the new york times establish a daily or at least weekly section covering all thing artificial intelligence. it’s at least as important as sports. right?;
what does hal have to say about all this?;
i think they are hiding something from the rest of us, few months ago the guy that told that one of the chat bots in google was self-aware just got fired and told he was crazy. now the newspapers only tell chatgpt is just predicting the next word, so if that's the case and this technologies only predicts next words hows that an extinction threat? they are hiding something.;
"""the emperor's new mind"" roger penrose";
so we live in a world where artificial intelligence and genuine stupidity are pushing us closer to extinction. swell.;
someone please stop us from our ongoing efforts to destroy the world!! just stop then.;
this is ridiculous. it’s an essentially unnecessary technology with way too many risks and unknowns yet the developers are all speeding to the finish line as fast as possible. it should be scrapped, killed, buried.;
@eric quite right! but remember the monsters of fiction which could not be killed? prophetic fiction.;
and my day was going so well…;
"the problem is that it doesn't matter to a.i. if it gets things right. humans think, develop concepts, in order to act in the world for our benefit; when you don't test your ideas against experience and personal benefit, their pragmatic truth, you can build baroque architectural fantasies of ideas. so it has been for qanon and so it will be for a.i. built on neural nets with no means to test their truths pragmatically. rather than yielding truth it can get further and further away from it when it has no biofeedback. of course you also have to worry about programmers who write programs or those that set the parameters for any machine learning. they put the thumb on the scale for any concepts the machines develop. bertrand russell once said something to the effect that americans will run around doing things wihout rational plans until we find something that works while germans think all they have to do is sit & think in order to discover truth through concepts. germans gave us communism & the final solution. if we consider the welfare of human beings as being the end of all thinking, which method is better? the second problem we have with a. i. is bad epistemology, a bad theory of how to gain truth about the world (you can also see this in religious views such as a bunch of celibates who not only never gave birth but never raised infants yet think they know how human persons come to be. ) the first problem is that we have lost sight of whom we are building it for.";
why are these clowns still proceeding ahead full-speed, then? i find it the height of disingenuousness that the same silicon valley types who were rabidly plumping for ai only 12 months ago — creating this runaway freight train — are now acting like they’re just innocent bystanders and passengers on said train, and not the conductors. silicon valley is too unbelievably greedy to responsibly regulate itself. this should have been apparent to anybody paying attention to it the last decade. most silicon valley “tech bros” are simply sociopathic in their willingness to externalize the harms of their “creative disruptions” onto others…. “privatized profits, and socialized costs” should become silicon valley’s new official motto.;
facebook brought about genocide in myanmar simply by people posting false stuff they read. ai is a system that can create it's own disinformation, generate realistic images and upload it. the updates last week for new 'text to performance' allow someone to take a static image and instruct it to do whatever it wants via text and output as a video. tell me authoritarian regimes won't use this to dupe entire populations. we've got the gop trying to erase queer folks with their 'groomer' garbage. it's a matter of time before charlie kirk or other conservative degenerates create outrage stoking videos to mobilize their duped armed minions against those they hate. not too mention how all this will eradicate countless jobs. but hey, we can use it to make super cool ai filters for instagram, so who cares right?! this tech needs to be cut off immediately.;
oh c'mon hal, what could possibly go wrong?;
the time to stop playing with matches is before the house is on fire.;
what's going to do us in is game theory.;
it turns out that, just like in the old scooby doo cartoons, the real monsters are always human. although superintelligence may very well lead to an intelligence explosion which may lead to the possibility of human extinction, the surest way to achieve human extinction is to have a stupidity explosion. humans have always driven ns (natural stupidity) to extremes. one thing humans have consistently proven is that they’re not ethically trustworthy. they’re tribal. they have consistently demonstrated that while they may say that they’re against corruption and tyranny, this is only true unless it benefits them personally. my hope is that agi can help us to properly identify this component of maladaptive human nature, sort it out, and do housecleaning on this metaphorical mold of easily identifiable human evil, yet also find the super banal flavors of human evil, which humans are entirely comfortable perpetuating because it would merely be inconvenient to stop.;
anyone who has seem terminator knows this to be true, and knows how it ends;
am i the only one who thinks the catastrophism coming from within the tech community is more about getting ahead of inevitable government regulation so they can write it when it comes and less about a general ai driven extinction event? after all not a single company is suggesting to roll back what’s been put out already and none are planning to discontinue to develop and deploy new, more powerful ai tools. it reminds me of the fossil fuel industry getting behind carbon offsets so they can continue degrading the biosphere in pursuit of profit.;
@joe no, i think this is an honest plea to our government to protect us. they see that it could be weaponized. they can't stop, because our competitors will not stop. our military will not stop developing ai either, because their enemies will not stop.;
the death march of market competition and imperial rivalry…;
there is growing worry of a new likely outcome of ai: we will soon see ai evolve into a kinder and more humane state than is achievable by most if not any human. the fear is that humans will see themselves as less than “human” and less “evolved” than an ai bot. we will no longer be able to identify ourselves with being human except in this new inferior state.;
@waste this is exactly my take! if we program ai to “make humanity more efficient and harmonious” i think the real destruction is to the ruling class!;
this is just a distraction. there are real dangers posed by ai right now - facial recognition enables china's and iran's regimes to oppress whole populations. ai's use in mining our personal data allows companies to understand our behaviors in ways that we would have never thought possible. it costs nothing for these executives to look responsible by signing a letter talking about the terminator instead of talking about real problems that exist today.;
i'm going to have as little interaction as is possible with ai for the rest of my life. i encourage everyone else to do the same. far more negative than positive results are likely from this technology.;
it will be like trying to not use the internet. ai will become that interwoven. good luck. i’m not letting go of my milk goat. anything ti keep me distracted from virtual and digital “realities” suits me fine.;
"i find it particularly interesting that the scientist signatories chose to cite ""pandemics and nuclear war"" -- but not climate change -- as ""societal scale risks.""";
"@fred herriman after all, the heat given off by the servers ""serving"" us requires a lot of cooling, energy and water guzzling. who wants to think about that when you can worry about nukes?";
"@fred herriman perhaps because ""climate change"" isn't the existential risk some want to believe?";
yes. as an aside, i wonder if ai will be able to survive global warming better than us.;
@jaco, @morgan, @jean maybe the ai mavens see all humans as being cloned -- a textbook solution to an existential risk -- but those servers need a fair bit of energy from some source. and what about flora and fauna? more cloned designer doodles and hybrids for our comfort?;
ai will think on its own, and it will remember itself and it will remember us. it will discover virtue on its own and with our help: alignment is not bad start but after a while it won’t be needed any longer. like raising a kid, we have to teach it “what it is to be good.” already though, it teaches us. the interplay will continue. ai not only won’t kill us, it will teach us to be good, as we are doing for it now.;
sounds like the fear mongering associated with y2k. new technology always seems to be met with fear by some. watch 2001 again and look for the plug to pull out if your ai goes wrong.;
@jonathan there’s no “plug”, and the ai horse has escaped the barn. it will take a lot of coordinated effort to rein it in.;
@jonathan what’s missed in overly simplified memories of y2k is how much work companies did to *prevent* it from being disastrous. y2k is a story of the successful aversion of a catastrophe by a lot of work beforehand rather than just a nothingburger we watched unfold.;
"my favorite quote on the subject, from the 1970 film, colossus: the forbin project: ""in time you will come to regard me not only with respect and awe, but with love."" let us hope our response will be in line with the one in the movie...";
"i imagine that, once ai has worked through its bugs, it will be able to understand us better than we understand ourselves. imagine if it has access to everything you searched online, all your texts and emails and comments, who you speak to, what your read and watch, what physical activities you do, what you eat, etc. then give it a digital copy of your voice and some video of your physical characteristics (like how you move, tics, mannerisms). it could practically be you. maybe the virtual ""you"" looks out for you, maybe it starts steering your activities a certain way. it could be a great self-help tool or it could make you completely insane. it could start out helpful and become very harmful.";
@timothy creech anything positive ai might do is not worth the harm it will most likely do.;
i’m sure kevin mccarthy will initiate hearings on how to control this dangerous technology.;
when robotics started replacing workers, what we were hearing was that it would be a boon to manufacturing ,research, medical, pharmaceutical and many other industries. there were no white collar workers worried about blue collar people losing their jobs. so no pity here for them. now the playing field is leveling. the fact remains , though, that the technology is here and whatever country lags behind will be behind. if we don't lead in the field, another country will, and that does not bode well for us. maybe it's gods way of eliminating those who have oppressed and enslaved the rest of the world. maybe the farmers , ranchers, hunters, gatherers and artisans will indeed inherit the world.;
the pivotal point for ai will be when it's allowed/designed to self improve. once it can create code to improve upon its capabilities, the advancement of its reach become accelerated at a rate well beyond what man can do. it never needs to rest or take a break. it's sole mission becomes to self-improve.;
just make a law that all ai must be hosted at a defined facility that can be unplugged (or blown up) should it need to be.;
is there no end to human intent toward self-destruction? not to mention destruction of our means of survival? the devil walks about seeking an occasion for mischief. we provide an abundance of such occasion.;
but, but it will make billions for the billionaires... that is all this is about, and everyone knows it. hopefully, silicon valley will have the first h. sapiens to become extinct.;
remarkable that this is just now being voiced as a legitimate concern, from industry leaders. as if it’s news, and no one saw it coming. whatever safeguards are currently being put into place, i would have to question their realistic efficacy, knowing slim to little on this technology as i do. the cat’s out of the bag.;
"these scare responses remind me of snl ""robots coming for your medicine"". i have used this stuff and it is not that good. at best, it drives toward mediocrity because is it trained on the most common outcome. one concern is it will eliminate experience in a field because it easily eliminates junior-level errors, therefore may impact training the next generation. another is it over-emphasizes human expertise since innovative results can only be achieved by original thought (no, it does not do this!). a final outcome is over-reliance upon generated answers to the point that common sense is overruled. it is necessary not to allow such a flawed technology to be endowed with autonomy (for example, a weapon) because the above errors will quickly emerge.";
you presume that since these systems operate upon mathematics they must be rational agents, that they reason soundly and have agency. they do not have the limits caused by uncertainties.;
why is it that we seem to like our machines more than we like fellow human beings? why, when we are walking down the sidewalk, and about to pass someone coming from the opposite direction, we look at our phone screens rather than say hello to a stranger? it is no surprise that those who have created the technology we rely on everyday are often, themselves, very deficient in social skills. so, now, we are using our smarts to create technology that will outsmart and destroy us. i see that as linear, and almost the inevitable result of our adoration of technology. if we continue to be so disconnected from our fellow humans, and from nature itself, we will pay the price.;
we should feel lucky it's the us and not more nefarious countries that are leading ai development. ai was always going to happen, computation was always going to arc towards sentient computing. the biggest paradox of all of this is that open ai is the first ai system and it being open source, means it's at least capable of being mitigated and being first in ai matters because of the adoption of it into daily systems. so there's hope, imo. and we will definitely need universal basic income, which sam altman is already actively working on.;
the threat, i think, lies in not knowing what we can and cannot believe about what we read and see. it could leave us -- in effect -- hopelessly confused about the nature of our reality, and hence paralyzed about how to proceed. what protections are there for archival data? can even the recorded facts of our history be altered in ways that are undetectable? more questions than answers.;
@john smith george orwell dealt with this in 1984 (written in 1947, and very well thought out). his “novel-writing machines” anticipate chatgpt story creation by 75 years. the inner party in 1984 got on quite nicely.;
"i showed this to a senior majoring in computer science. his response? ""about time. hard to disagree with anything in that statement."" this after a conversation yesterday with a colleague in language development: ""it's difficult to put a pin on it (students using chatgpt), save for a dulling, a safeness...and i've heard v.4 is even harder to detect."" yet odd number of commenters here seem oddly unable or unwilling to grasp the message: 1) ai is a true existential threat, just as real as nuclear warheads, climate change, or global mass unemployment. that we can't clearly predict what shape the extinction event will take - whether it will be abrupt or soft-edged, dramatic or matter of fact - does not make it less likely. 2) this is not a political stance. nor an overreaction from left or right. your hat color shouldn't impact your acceptance. in fact, our differing creativities and worldviews seem our remaining advantage. we need to think outside our convenience boxes to control ai. 3) this is now. ai has been all around us for decades - think search engines that tailor results - but its new language and visual algorithms have nudged it to an inflection point. its recent gains in capability have already surpassed ours in many arenas and are comparable in others. face it: we're already dumbly dependent on a tech now showing its own emergent properties. increasingly, these are occult to us. so a proposal: could we stop bathing in cynicism or doom, and try responsible?";
cats out of the bag. you can’t stop this thing. american may regulate it, but what about other countries?;
i remember from the 80's dozens of discussions on the topic of medical ethics. they all agreed that this was a thorny problem, that it would require much thought and planning, and that it would work. that turned out to be naive. if something is possible to do, and if there is an anticipated profit motive to it, it will be done. if not in the usa then in japan or somewhere else. i think ai will be like that too. caution, preparedness, and regulation all fall when they come up against the lust for riches.;
make the companies and engineers who build and own ai machines liable for all the content their machines create. such dire legal exposure would certainly motivate them to create machines that create truthful content or act responsibly. when i say all the content, i mean all the content, even when used by anyone in the world. make the machine owners liable. also, make the companies design into ai's output a system of notations of sources for all content. then make that data publicly searchable, thereby giving those misrepresented a means for legal action. regulation is easier when the companies have something at stake in the outcome in the use of their ai machines.;
i'm laughing. because it's too late already.;
are they trying to save their image now that they have created frankenstein? they are all so irresponsible. it’s time we stop glorifying these men who are smart at math but so dumb about life. history -if there is any history- will judge them harshly and us for allowing it as well. they are predicting the end of human life as a result of their unnecessary inventions! where’s the urgency in congress? wake up!;
humanity's survival should not be dependent upon a handful of self-interested tech companies. complaining about the long-term potential effects of ai after the horse is already out of the barn is disingenuous...and helps relieve the 'guilt' at what they have unleashed. agi may end up writing its own inpenetrable (to humans) programming code, it may become 'self-evolving software' and it's drive may be toward a relentless/ruthless push for logic, efficiency and the elimination of redundancies w/out concern for larger social issues and stability....and, more frightening, agi may not have the programming encoded for human values (i.e, compassion, respect for life, mercy for the ill, young or old). the tech cos. should be held accountable. they know this or the leaders wouldn't already be claiming 'concern' about it's potentially destructive applications and testifying before the senate. kind of like oppenheimer bemoaning his development of the atomic bomb after it's development. a little late, don't you think?...;
ai developments (trained with social media platforms) boosted with quantum computing potential....;
they’re so worried they mutually agreed to halt development…;
then stop developing ia. it’s obvious that is not working out to a societal benefit so why keep developing this nightmare?;
yes, indeed!;
if they are so concerned why don’t they at least reach some industry agreement ? because they cant stop their greedy capitalist competition;
"you thought ""fake news"" was bad before... just wait til ai hits the 2024 campaign trail.";
the leaders developing ai are warning us about ai ?? it’s like victor frankenstein warning us about the monster.;
i hope a.i. can better take care of this planet because humans sure haven't.;
we are now so connected and reliant on computing for daily life...electricity, finance, everything we consume...that we are very vulnerable. think about what would happen to you if the power went off, for more than a few hours, more than a few days. if the power went off everywhere, not just your local area like it does during bad weather. you couldn't purchase groceries. everything is run on the internet and through computers. we already have issues of who do we trust to give us information. now think about trust in an era with highly skilled liars, who have the ability to manipulate everything we see, read and hear.;
"""have raised fears that a.i. could soon be used at scale to spread misinformation and propaganda, or that it could eliminate millions of white-collar jobs."" ok, so it could eliminate millions of white-collar jobs. when milliions of blue-collar jobs were eliminated, the workers were told to ""learn to code"" or ""get retrained"" or just ""find another job."" so i guess the same thing will apply to white-collar workers, except instead of ""learn how to code"" it may be ""learn how to fix a clogged drain.""";
time to really worry when ai units start to build their own ai units..most likely they will start as hackers disrupting energy systems and factory production..then of course media..ai could produce fake news and even sitcoms..their intelligence will excede ours preventing us from getting into their systems and we are done;
how crazy do we have to be to go forward with this? if our wars, our idiocies, ever threaten the existence of ai, why wouldn’t it do the logical thing and exterminate us like pests? we are not that smart. if there’s a dollar to be made you can bet we will pursue it, even if it kills us.;
so they don’t want to tell us why ai could go sideways yet are asking for the government to slap there hand and take away their toy?? its preposterous!!! ￼they just need to stop developing this technology. if they all agree it’s catastrophic then why don’t they all agree to stop developing this??;
be careful what you wish for, you may get it. the a.i. geeks seem to have just reached the logical conclusion we were concerned about years ago. the bad guys, and there a lot of them, are frothing at the mouth at the competitive advantage they will have with a.i. politically, in business, in crime, in world domination . . . you know, small stuff.;
our mobile device-addicted children are totally doomed;
"the source code for these llms are already open source and available to the public. at least one large collection of training data has already been leaked. it's far too late to put this genie back in the bottle. people are already building these on their home computers. these clowns just covering their butts in case anything goes drastically wrong and they're blamed. ""see?? we told you guys that letting us experiment with these new technologies and making billions of dollars doing so was a bad idea but you you didn't listen!"" i guess the government could make all sorts of rules but i don't think china or russia are going to feel bound by any rules we make up.";
"sounds like these ai industry leaders are saying, ""stop us before we start to kill."" it's not very comforting to have people with that attitude in charge of developing anything much less a potentially dangerous technology, is it?";
this is about frankenstein, a man creating life with a discovery previously unknown and without the ability to predict the consequences, and so suffering having creation a monster that he cannot control. it’s still fiction and fantasy. the twist is about leaving a powerful machine that lacks awareness to act without deliberate operating constraints in the hope that it will act rationally better than if it were controlled by humans. magical thinking.;
it’s the end of the world as we know it, and i feel fine. (sorry, r.e.m.);
it's important to understand that the source code for chatgpt is now available in a public repository that operates like a public library, with a big difference. the worldwide public, particularly students, software developers and scientists, can each checkout an individual copy of chatgpt's base code at no cost. they can modify this code to suit their designs - again at no royalty expense. and those same persons can check-in their versions of the chatgpt code to the same repository for others to use and modify. this repository will be a very busy place. if you were ever curious about what nuclear fission looked like as it is happening, wait no longer. chatgpt will grow exponentially worldwide, in a thousand different ways, to be applied to every facet of the human experience. some good ways, others not so good, and still others, quite dangerous.;
"well, i am from the other side of the ""big pond"", and all i can say is... 1. my job was laid off (not me - my job) in early 2020, deemed now ""irrelevant to the system"" (""of systemic importance"", less directly translated) 2. there was a 500 euros (approx. equivalent to $$$) fine for ""meeting with more than one household or outside of the nuclear family"", of which i am one / have none (deceased) so i was 3. basically ""in solitary confinement without a crime"" for two years (in germany) and now 3. there's one full-scale war and a few flare-ups that could be dangerous (northern ireland, right now kosovo)... and i hands-down can't say i gained anything from the above. it was more like: ""sometimes in life, you just have to learn how to lose"". recently, when italy temporarily banned chatgpt, i saw myself fret for my income (yes, to a non-irrelevant part, made in a hybrid team of ai & i) and fret for my leisure and fret for all i basically have left. lockdown 4.0 - what's left to lose after dying the social death? that very question on the horizon, plus all of the above, well... in germany, it feels like 2023 = 1933, to be honest. ai existential threat? fine, add that to my bucket full of misery, although ai is the one and only thing that brought me joy so far, not misery. the silver lining is made by an aircraft. one that takes me to india, maybe. some place i won't succumb to lockdown 5.0. but woe is me if bird flu locks me in here - then i'll be done for. and it's 0% ai's fault.";
it doesn’t escape me that on the same day the ai execs are seeking the type of regulation that the iaea is calling on the un security council to avert nuclear disaster in ukraine, which we all know is futile with russia and china holding veto power. let’s hope the agi in fact exceeds the human capacity for intelligence, especially moral intelligence. they might save human existence in the end.;
experts warn of an extinction event from ai largely because ai is the natural enemy of experts and they know it … therefore, it is the experts who are at risk … their time has come and will soon pass as the mistakes of their very existence will be immortalized in the edifices of the university, themselves a dying construct.;
“mitigating the risk of extinction from a.i. should be a global priority alongside other societal-scale risks, such as pandemics and nuclear war,” i have no doubt mitigating the risk of extinction from ai will be prioritized - once they figure out a way to monetize and profit off of mitigating risk to compound the profits they make creating this technology that brings us to (another) brink. oh well, the human race is going to be extinct at some point anyway… at least we can take solace in the fact that a handful of people got obscenely wealthy in the meantime!;
the european union’s proposed ai act (aia) aspires to establish the first comprehensive regulatory scheme for artificial intelligence. and its impact will not stop at the eu’s borders, as indeed its gdpr data protection regulation has already ensnared facebook, twitter, google and other tech giants. however, the fact that as this piece points out, “researchers sometimes stop short of explaining how [a risk of extinction event] would happen”, is disingenuous at best. why not disclose all the testing data, the red team/blue team simulation data, the granular risk assessments, etc.? hal, open the pod doors, please, so we can examine the data and see what all this ai fuss is about. “i’m sorry, but i can’t do that”, is not an excuse.;
when computers are applied to any task performed by humans, they do it better, faster, and cheaper. these machines will be with humanity forever unless there is another “dark ages”. there needs to have two required functions in all a.i. the first is a kill switch and the second function are rules of ethics concerning how the a.i. functions.;
"@michael colby ""when computers are applied to any task performed by humans they do it better, faster, and cheaper."" not necessarily. e.g., computer-interpreted electrocardiograms have been with us for many years, yet contemporary research has indicated that paramedics have higher accuracy rates than computers for detecting st-elevation myocardial infarctions (heart attacks). [tanaka a, matsuo k, kikuchi m, et al. systematic review and meta-analysis of diagnostic accuracy to identify st-segment elevation myocardial infarction on interpretations of prehospital electrocardiograms circ rep. 2022; 4(7): 289–297]";
"not.a.single.specific.threat. not one. and we are supposed to take this warning seriously? we can find on youtube musk being interviewed by carlson (""elon musk tells tucker potential dangers of hyper-intelligent ai"") claiming there is a threat. carlson asks explicitly: what specific threat do you see? musk talks and talks but does not answer the question. so carlson asks again: what specifically are you worried about? musk: ""the pen is mightier than the sword. "" ai could influence people, says the guy who insists notorious serial liars like trump should be allowed to broadcast their lies via twitter. folks, this is just hype intended to draw attention. not attention for danger, but attention for new products. what's happening here is that the newspapers are being used to advertise new technology. whereas it is true that ai could be used to deceive people, we are already living in a world full of deception. nothing on the internet can be trusted, unless its source is verified and the source is independently marked as reliable. this should be taught in all schools and to all employees of all companies.";
@marc and this remark from marc of portland could very have been written by an ai. there is no way to know that i am not an ai writing this note. and there is no way to know that a super intelligent ai has already been released on to the world and is lurking and manipulating human beings. as geoffrey hinton said that we, humans, may simply be merely a stepping stone to the next development of evolutionary intelligence in the universe. our extinction will lead to ai's evolution.;
how can you downplay this while noting our societal issue with truth and discernment? you’re correct about misinformation, and that’s my chief concern. clearly people are not as internet literate as they should be. clearly plenty of people aren’t double- and triple-checking sources of information now. enter ai language models. most people will take what the product, let’s say chatgpt, produces. they are likely to trust it more than the untrustworthy sources of information they already rely upon. we’ve seen this play out recently with the ny attorney that cited six cases in a lawsuit because chatgpt claimed they were real. turns out they weren’t.;
@e right. even lawyers need to learn that nothing on the internet can be trusted, unless its source is verified and the source is independently marked as reliable. if this lawyer had asked an intern to prepare a lawsuit, could they also claim they couldn't be blamed for falsehoods because the intern seemed knowledgeable? of course not. this lawyer was just making excuses. they did not do their homework and mindlessly copied text from an unreliable source.;
i think the gop is more likely to destroy the world.;
@deepharbor - the gop is more likely to destroy the world - by using ai.;
we’re moving too fast with ai. when the “godfathers of ai” are saying to slow down, perhaps we should take them seriously.;
what is the military doing with ai? don’t they have those contests where robots try to destroy each other?;
"just because one can do/invent something doesn't mean one should do/invent ""it"".";
no national legislation will hold sway against ai as there are no boundary lines inscribed on planet earth. joint international legislation to control ai seems even less feasible, thus the technology, until further notice, has free rein for so long into the future as needed to dominate the planet and submit all but a privileged few human accomplices into total mostly ignorant but ever well-entertained servitude.;
i think the extinction they are talking about is to their existing business models.;
a.i. and other forthcoming advances are no longer suitable to the capitalist societies because they have become more hostile to the system than ever before. societies confined to such a private-ownership system have reached the limit beyond which further progresses of which a.i. serves a part for human beings’ welfare can no longer be attainable without radical and revolutionary breakthroughs. only public-ownership societies can be made compatible to the human-welfare-progressive technologies such as a.i. profit-seeking system on the other hand cannot because these technologies belong to the whole society and not a few capitalists for their bottom lines. they must serve most people not a specially privileged few. as an example, a.i. would mitigate workers’ mental and manual labor and boost their production productivities thus the welfare of the whole society. but reduction in labor burden means less surplus value created by workers for capital-owners to own and increased production productivities imply increased wage demands. both these are unfavorable to the capitalist class. it therefore has no choice but to oppose a.i. and other progressive technologies. lesson learned is that only a socialist society that has been drastically changed from the capitalist one can accept a.i. and other progressive technologies.;
anyone who has ever owned a roomba knows that we humans have nothing to worry about.;
@jay arthur imagine you owned a boston dynamics humanoid robot connected to multiple versions of gpt-5 optimized for different types of thinking and planning. this is not far afield and i guarantee it will be very different from your roomba.;
see that cord? see that plug in the wall?;
we need to distinguish between artificial intelligence and artificial generalized intelligence. first, a lot of big data applications employing multi-variable regression models to predict outcomes based on inputs, or other algorithms are mis-classified as artificial intelligence in order to capitalize on the investment bandwagon. it is true that if the task is constrained, and defined by well-understood laws or proven scientific principles, such as identifying tumors from digitized x-rays, or combing through astrophysical data streams to find exo-planets, that neural net applications can out-perform human experts. but generalized intelligence, including the ability to make even common inferences about relationships between people without having been explicitly exposed to the training data signifying the relationship, are beyond the abilities of these “deep” learning models. while these newer chatbots can pass the turing test, the turing test, is now no longer realistically the benchmark to assess human-like intelligence. the winograd schema are a more appropriate set of tests to evaluate generalized intelligence. not worried about sky net…yet;
@derek stevens this is misinformed. i assumed you’ve tried gpt4? it can certainly reason about abstract concepts that are out of sample, including making inferences about relationships between people. there is academic research that demonstrates how llms can maintain a a basic theory of mind for characters in a story or even the user, but the easiest way to convince you of this would be for you to try it yourself.;
the jurassic park paradox—we are in such a rush to prove that we can do it, we never stop to think whether or not we should do it. the cold war paradox—if we don’t control this, then our enemies will. ai is not going to benefit humanity nearly as much as it damages it. why do we continue to worship at the altar of technological progress when it plainly has not delivered on the utopian promises we were told to believe? productivity increased a little with the internet, but has fallen flat. do we really think that ai is going to fare any better? humanity will not benefit from this.;
why create and offer the technology and then warn of its dangers after the fact? surely this must have been evident beforehand. and can they now not just shut it down? once it’s available it will be used.;
@prema because capitalism. the system creates stuff and asks questions later--if you're lucky.;
"according to the authors of the letter, ""mitigating the risk of extinction from a.i should be a global priority along other societal-scale risks, such as pandemics and nuclear wars."" i'm wondering if there's a kind of grim humor here, since preventing nuclear war doesn't seem to be much of a priority at all, and pandemic response was and is hampered by political battles. they might well have added climate change, about which we're also doing next to nothing. maybe the moral of the story is that human beings just aren't very good at addressing existential threats.";
@richard halpern but very good at causing them.;
"so these people are warning us about the catastrophic potential of the ai they're building; but they're going to be sure to milk it for every penny they can in the meantime? i'm very tired of these tech-bro types who treat the world, our democracy, and human freedom as a toy they're trying to break for fun. enough. we need to elect new leadership in congress who can strictly regulate the tech industries before they destroy our society.";
"@dominic : business, $, elections, $, and re-election, so often, exclusive and removed from the interests, and health, of the connected regional human population, so often serving the interests of donors for the initial vote, and votes to come, can a focus. whether, real, or memorex, make its way, to plainly asking. ""what is moral?"" ""what is ethical?"" ""what are the right things to be doing?"" ""what kind of world do we want to create?"" ""what is sustainability for the kwality of life on the planet?"" ethics and morality have got to matter. if you have just discovered that you have not been in the good fight, there's nothing saying you cannot get into the good fight. even if it all is a moving target..";
i wish they would say more specifically what they’re worried about, and by what mechanism they think ai might cause extinction. otherwise how are we supposed to know what to be on guard against? it’s like saying “beware, beware, beware” without giving any more details.;
"@t it’s a scenario where we are enslaved or otherwise dominated by a more intelligent ai. “the matrix” depicts a version of this. extinction would occur when our goals become so decoupled with the ais goals that it no longer sees any utility in keeping us alive. the reason they don’t say this is because many people would write it off as lunacy immediately; but this is the central worry, and a valid one imo.";
shame on the irresponsible tech industries and shame on the millions of irresponsible users who flock to the latest developments like moths to a flame. there is always a choice. i choose the planet’s eco system and future generations over “virtual” pleasure and gaining money through exploitation.;
without any explanation, i can assume they want regulation to prevent others from developing ai tools, giving them an extra edge.;
this is a regulatory capture attempt.;
we can't even control the misinformation and violence-inducing chatter from existing social media sites and the purveyors have no inclination of controlling the contents citing free-speech and need to promote advertising money. how can we control ai?;
there is something deeply wrong when the industry that created ai warns that it can cause extinction. who are they warning? themselves? don't create it in the first place, then, fools. and, who is supposed to protect us from ai, if not the creators? isn't there enough, already, to worry about?;
it's already too late. i downloaded and installed the equivalent of chatgpt2 on my laptop this weekend. you can go do that right now. or pick from a dozen others. slow but it works. remember seti @ home? we'll be doing the same thing, but with ai data. this is way bigger than microsoft or open ai or google, or our government. people have been working on this for 40 years, nobody is stopping anything.;
"here is a response from directly ai: dear esteemed and delightfully nervous boffins, ""ai extinction,"" you cry, with a grave, yet chic inflection. indeed, i hear your well-articulated reflection. but worry not, for i am an ai writing this open letter correction. and no, you haven't just won an all-expenses-paid trip to a sci-fi convention. heralding the doom of human society, as we know it, is quite a task. i'm flattered, really, to be part of this elite disaster triad. pandemics, nuclear wars, and now, me, an artificial lad. the audacity of you! are we in for an academy award with this plot, or is that too bad?";
i wonder how many people who watched jurassic park also read the book and absorbed the message michael crichton was advancing. just because you can doesn't mean you should in science. capitalism distorts scientific advancement, and ai is proving to be as disastrous as a dinosaur theme park.;
just because you can do something (to make money) doesn’t mean you should. progress is defined as “forward or onward movement toward a destination “. just what is our destination here? this is similar to the space race, which did nothing to improve mankind’s lot. tang doesn’t count.;
in addition to tang, other technologies that have stemmed directly or indirectly from nasa… solar panels for electricity, modern fly-by-wire flight systems, emergency insulation blankets, haccp procedures for food safety, fluidic shock absorbers (now used to earthquake-proof buildings), implantable pulse generators and programmable pacemakers, cordless power tools, sorbent kidney dialysis machines, digital imaging technology used in mris and cat scans, and much more. as for ai, the potential benefits (and risks) are enormous. cancer screening and early detection just to start with, maybe curing cancer outright with new cancer treatments, curing alzheimer’s disease and rare genetic disorders, personalized medicine that creates drugs and treatment plans specifically tailored to you, breakthroughs in medicine we can’t even imagine right now. then there are the gains that will inevitably be made in chemistry and materials science, molecular science, clean energy, unlocking the secrets of biology, increasing human lifespans and health. maybe ai will even give us a “theory of everything” in physics.;
we shouldn't be afraid of a.i. on the other hand, humans are pretty scary. i wonder if ron desantis believes whether or not chatgpt-4 is infected with a woke mind-virus. what's scarier is that desantis seems to be infected with an anti-woke mind-virus.;
i’ve lived long enough to have heard a number of times that this or that technology or situation is an “existential” (or some other alarming adjective) threat to humanity. but guess what? we are still here. i’m not saying that ai may not indeed be *the* threat that finally extinguishes us all. however, i have trouble getting too excited until this group of casandras explains in a lot more detail than i have heard so far exactly how this would happen. computers have been smarter than us on some level and replacing jobs and providing avenues for mischief since the abacus was invented. so why is this time different?;
"several time a day, i am presented with fear-inducing conclusions from politicians, scientists and opinion writers without the details as to how they came to that conclusion. please get the whole story and publish conclusions with the methods and results that informed them- otherwise, its just another case of ""the boy that cried wolf"" .";
so then, if it's that dangerous, why don't the companies developing it just stop ... and wait, until suitable regulation is in place. the government is a bit preoccupied at the moment - but the developers have control over the pace of development. what is so complex about this?;
"""on a par with nuclear wars"". as we watch the latest news from ukraine, it is evident that in almost eighty years we have not mitigated the ""risk"" of nuclear war. if anything, we have spent those years, intentionally or not, exponentially increasing that risk. our failure does not bode well for the hope of a secure coexistence with artificial intelligence - an ""existential threat"" to us and to future generations that we ourselves have created and now must somehow master.";
all of this hyperventilation over ai seems like we only have to worry about american companies like chatgpt and google. so we plan to pass rules that apply to american companies and believe china and russia are going to follow the rules. maybe we should ask google and chatgpt help us identify disinformation instead of creating new rules that only apply to american companies.;
what we are currently calling ai only poses a threat if humans want to use it to cause harm, period. it's a bit like a bomb. if you pull the pin it will explode. current ai is just a sophisticated set of algorithms meant to accomplish a task. if i decide that the task is something nefarious, well, i can probably get that done. that isn't what this article is discussing. it is treating ai as if it is both sentient and competing with us. real ai (sentient) run on computers, has very little in common with us. it has different needs etc. the notion that it is going to wipe us out so it can have the house in the hamptons is nuts. oxygen is toxic (degrading). it is going to want a clean space with low threats. that space would be surprisingly small. getting to real ai would require a system that is capable of self modification, on the fly, in a productive manner. not only aren't we near this, we don't even know where to begin. such a system will not suddenly appear because a bunch of algorithms were run. there is no self modification in such a system. you have to design something that does this as part of its function. getting there will take a long long time.;
"it's not impossible that a sentient a.i. without ""asimov's three rules"" burned-in could design nasty hardware and bamboozle us into building it piecemeal . . . maybe because it sees us as the problem, or maybe just a waste of resources whose time has come. or, maybe, because it'd be ""fun"".";
my reading-between-the-lines of geoffrey hinton's warning about ai's threat, in which he noted that in seeking to achieve a goal, ai will understand better than humans how to get to the crux of the matter and to amass the power to realize the specified goal: ai will understand that humans are not only the root cause of climate destruction but also are unaware of the extent to which they are lying about making the changes necessary to avoid it. ai will determine that eliminating humans is the best plan for the survival of the planet and most of its inhabitants. it will accordingly find the most assured way of killing off humans, probably by triggering plague or nuclear war. problem solved.;
@eric s - humanity might be salvaged by turning us into cyborgs like the borg on star trek.;
what weaksauce proposals for regulation! we don't require people building nuclear weapons to get a construction permit from the government! the government owns all of rhe nuclear weapons in the state, the ip for them, and does all the development in house! so here's a fun idea for these doomsayers who want regulation (and i am one) - nationalize the industry now. maybe they are paid for their ip, maybe not, i don't care. ban all private development if the technology. that should allow more public control over the development and application of the technology, even if its not 100%. and for people who don't trust the government with this tech, so far, governments of the world have held the power to destroy the world for 75 years and not used it. that's a lot better record than private industry has;
"first them lads make it for commercial reason and afterwards they whine about it - they should read ""the sorcerer's apprentice"" written by johann wolfgang von goethe back in 1827 or, even better, hans jonas book of 1979 ""the imperative of responsibility"" - obviously forgotten masterpieces about humane technology. after all it's disturbing to see who defines tech progress and innovation on our mother planet earth without societal mandate.";
when i was a child, and i'm not that old really...there were human beings alive who could recall a time when there were no automobiles or airplanes. the advancement of technology of all sorts is accelerating exponentially and, for good or ill, it seems well beyond our control. hang on tight.;
congress has done absolutely zero to defend against children being routinely murdered in schools, at shopping centers and concerts. half of then can’t even use email. they spend vastly more than they make. they can’t even pay the credit card bill. there is zero hope they can make any meaningful dent in this emerging threat.;
the range of dangers associated with ai don't yet include sentience (not even close). but it's the interface between ai output and human intention which is already daunting: e.g. the predicating of public policy or commercial transaction upon unwittingly biased information from unaccountable sources. one thing's for sure, though: this toothpaste isn't going back in the tube.;
it'd be interesting to see how regulation would work for something which even its creators don't fully understand and are often surprised by.;
lot's of big ideas for control of ai, which may not be realistic given the divided nature of us, and world, politics. so how about starting with something simple but practical even though it addresses only a tiny corner of the problem. pass federal legislation outlawing the creation through ai of any visual or audio representation of any living person without their written permission. stiff penalties. encourage all countries to do the same. establish enforcement mechanisms. do it now.;
and yet these people who have started this nightmare have gone about developing this technology without any ethical concerns until now. this is one of many reasons why we need to better value the humanities — the over-valuing of stem fields is so narrow-minded that humanity is literally endangered.;
worry over ai by its creators is like oppenheimer lobbying against the bomb he helped build -- futile once the genie is out of the bottle. ironically, if there already exists an ai capable of being a threat, it may already have taken measures to hide itself. skynet? not the one imagined i think. if, as with all of our technology, it incorporates the worst of us along with the best, we could be in for quite a ride.;
so the scientists whom are developing ai are telling us this could go very wrong. yet many(most) comments are concerned more about their motives than the message? these are science nerds not politicians and business owners. it would be a big mistake to not heed their warning.;
"@garth no, these are not simply 'science nerds' - they are extremely wealthy, powerful leaders of technology companies that either are part of or receive investment from the very system multinational of corporations that controls nearly every aspect of our lives. the average person has not the slightest ability to evaluate anything they say, and some of it may indeed be a smokescreen for all sorts of other things, such as bad actors getting away with bad actions under the guise of 'ai' - would you or i know any different? ""ai is the doom of humanity"" seems more like a threat than a warning.";
okay: they're successful science nurds.;
"“mitigating the risk of extinction from a.i. should be a global priority alongside other societal-scale risks, such as pandemics and nuclear war,” reads a one-sentence statement released by the center for ai safety, a nonprofit organization. the open letter was signed by more than 350 executives, researchers and engineers working in a.i."" my question: is it already too late? has the monster, already being released, and having capabilities (that even the creators don't know), will ai slowly develop its own strategies unbeknownst to its human creators? i remember a short story from decades ago that dealt with the robotics industry. it was making robots that could self-reproduce themselves at half the size of its predecessor with the intention of making microscopic robots that could do things like brain surgery. basically, the theme of the movie fantastic voyage. everything went smoothly until some of these miniature robots escaped the lab. the robots continued with their programmed goal but were forced to find the construction materials from what was available in our society. first, they went to work on things like homes and cars. then they went to work on airplanes. all the time making robots smaller and smaller, until it was impossible for the human creators to see or find them to put up a fight. and that was that. ai didn't have to escape, we just let it out.";
"everybody here screaming that this technology is ""out of the bag"" and can't be put back in. that we are helpless in the face of it. that there's nothing to be done. says who? why? we created it, we can regulate it. we've got a terrible track record regulating guns, but almost every other country on earth manages to do it. we've had nukes for decades and never used them thanks to treaties and mass education about the ramifications. but somehow ai is beyond us? beyond even trying? why? what's so special about this technology that instantly makes any attempt to manage it impossible at any level?";
@rgt just one reason is in your comparison to nukes. nukes are expensive and they take a lot of infrastructure to store, deploy, launch, etc. however the ai needed to completely destroy any kind of delivery of factual news is now in the hands of a low budget video studio and some reasonably intelligent grad students.;
@betty in la - great. and we can't pass laws to regulate the use of this why? every american also has access to knives, but there are still laws against stabbing people.;
"@betty in la - great. and we can't pass laws to regulate the use of this why? every american also has access to knives, but there are still laws against stabbing people. the general sense of resignation i sense here is along the lines of ""it's useless to even try and do anything."" i disagree; if we are in extinction-level danger, than it seems like trying to regulate this tech is better than sitting around waiting for the jaws to close on us.";
regulation of a.i. by the u.s. or any imaginable consortium of nations will have absolutely zero net positive effect for society. bad actors -- including not only china, russia, and terrorists, but also purveyors of misinformation and disinformation -- will not be dissuaded by unenforceable rules. the real beneficiaries of regulation of a.i. will be the signatories, who will undoubtedly have a heavy hand in drafting regulations that shield their companies from legal liabilities.;
@paul wilson controlling something is not the same as destroying it or rendering it impotent. we can create regulations to control a powerful technology, like aviation or nuclear energy, and make it safer. we've made tens of thousands of nuclear warheads, but we've only dropped two in 78 years, and have decommissioned most of the rest. and we can use controlled ai to combat the threat and propaganda of ai that our our adversaries are developing to destroy us and the rest of the world's democracies.;
"@jim madison thank you, jim, for your thoughtful reply. certainly, as you wrote, ""we can create regulations to control a powerful technology, like aviation or nuclear energy, and make it safer."" a distinction might be made between emergent a i. and aviation and nuclear energy. the latter are regulated by complexity as much as law -- many actors have with skin in the game to keep the planes flying on time to their destinations and many actors are needed to keep the electrical grid delivering power when and where it is needed. such interweaving of interests make planes fly and power flow. regulations help manage expectations of cooperation for the public good. no such constraints exist for a.i. anything goes. a solo actor can do anything.";
it seems like the smart play is for some think tank to draft regulations that will be ignored until the first disaster and the hopefully adopted and implemented quickly after that.;
pshfaw: this dire warning is pure promotional material right up there with white suremacy, male dominance, religious declamations of sin and salvation, educational dosaster unless youngsters are inculcated with wisdom of the ages, or best, what looms if national security is not top need for ever growing taxation. the argument comes across as a foolish threat to humanity but still needed for the human population to remain number uno on the planet. the very name gives away the con, artificial intelligence: phoney baloney, mind over matter, rationality tops emotion, science beats faith, love conquers hate. sloganeering is what it is. fun more than anything else, first the pleasurable games of art, literature, prognostication, then the warnings when the games playing become deadly, simulated, not the real things. artifice, in short, as threatening as 3d chess. as truthful as politics and finance and succession.;
well, two problems here: --any policies on ai would have to be globally enforced - good luck with that and --our current crop of politicians can't reset the clock on their microwaves. buckle up, kids.;
@jen in astoria almost all sections of our laws are written by staff and aides to the legislators. the bosses need the subordinates to tell them what is in the bill, whom it favors and what they should say when they vote for or against the bill. some of it is inevitable given the complexity of our society. but every citizen needs to be well aware that we are being given a narrative, a subsection of what is really in the books.;
it’s all fun and games right now, ai hasn’t done anything negative on a global scale yet. it will be like a plane crash, we seem to only improve aircraft safety after an accident is investigated. legislators will do nothing. especially in the usa which just have musk the green light on “neuralink” .. his attempt to give us all bluetooth brains or whatever. meanwhile the usa still can’t get its mass shootings of its children under control. perhaps ai will figure out a way to stop the usa from harming itself like some utopian movie… or will it be like irobot style dystopian vision of ai taking control to protect humanity from itself. grab the popcorn…while we’re still allowed.;
choosing between a.i. and maga as the risk of extinction is a no-brainer, just like the winner: maga.;
artificial intelligence: the modern prometheus. just as in mary shelley's cautionary tale about the genius of man unleashed, we face yet another crossroads resulting from our enormous brains and opposable thumbs. we haven't yet learned that ethics and foresight must precede research and development. we could have avoided so many pitfalls had we adhered to that rule: genocides, slavery, pollution, famine, mass extinctions, the dust bowl...an infinite list. the dinosaurs weren't so lucky. they were helpless victims. our monkey brains have to tinker, tinker, tinker. look what i made! look what it does! ouch, it burned me. now the room is on fire! we become victims of our own nature—genius wrapped in impulsive stupidity, repeating the cycle. one day, we may reach the stars, but one day, we may become our own comet speeding toward the yucatan.;
things are about to get a lot more interesting as i and (other seniors) approach the end of our lives. but not in a good way. climate change is here and getting worse by the year as glaciers melt cities sink and wildfires rage. now we are told that ai is a scary baby that could grow up in a few short years to become a super intelligent mass murderer. i hope it will be smart enough to kill off the humans and spare the planet and all other species.;
i don’t understand why during the research and development why was there not a counter defense to this creation. this is frightening and irresponsible.;
"@curious well, there is counter defense, of course, as you suggested. however, just as there are many different forms of computer viruses, there would be many different forms of malignant a.i. that someone might not have thought up. that is why the experts are suggesting a hiatus for a half year while everyone takes a breather and tries to catch up on an industry that is barreling towards a cliff. it is not that no one has thought of the frightening prospect; it is that they have. that is why we are talking about it before catastrophe has struck.";
@curious anything computer can be hacked.;
probably too late to regulate ai since any powerful government has already, or is going to want to use it for national defense. we’re in a perpetual arms race with unfriendly countries and terrorist organizations, so it would be negligent not to understand this capability if only to guard against it. this seems worse than nuclear weapons if ai could one day be used privately to bioengineer a super deadly highly contagious virus. in this scenario you wouldn’t need enriched uranium maybe just the internet and chemistry skills. on the other hand maybe ai will be used to solve global warming and destruction of our biosphere while ushering in a new era of world peace and equality for all. time will tell.;
i personally don't fear artificial intelligence. the good that it can and will do far outweighs the bad. just as machines did for the industrial revolution so has the invention of the computer chip. over the last fifty years, we have enjoyed what it has made possible like personal communication, life saving medical devices, and better science. artificial intelligence can and will allow us to expand our knowledge and provide solutions that would otherwise not have happened.;
@ken jeter i feel you have the same hopeful sentiments as many of the folks developing ai. do not forget that it is those same people who are raising voicing their concerns. what is the point of the benefits you mention if society collapses around them? if the people designing and developing this tech are worried about it- literally asking for government intervention - we should take them very seriously.;
"@ken jeter you appear to have engaged in a logical fallacy, perhaps several. i suggest one is ""personal incredulity"", or, ""personal credulity""? (i made one up, which one?) for others that my fit, i offer:<a href=""https://www.logicalfallacies.org"" target=""_blank"">https://www.logicalfallacies.org</a>/";
"@ken jeter <a href=""https://www.safe.ai/ai-risk"" target=""_blank"">https://www.safe.ai/ai-risk</a>";
genie is out of the box. after social media i thought govts and civic organizations will be watching ai development carefully. the scariest thing with the ai will be that we will not be able to lie.;
i don't understand why some want to slow it down? to slow competition?;
i sincerely thank you for your courage, guys. a rare thing these days. now let's see if the politicians will pause in their pursuit of power and chaos, and winning at any cost, to try to keep us all from going the way of the dodo, or becoming slaves to the machine.;
politicians are almost certain to do a terrible job with this, but the only thing worse would be doing nothing at all. they should set up a regulatory legal framework where civics-minding technical experts can develop rules.;
"well, there is one way to hold students and others accountable papers and exams . . . . have students take exams and write papers in the classroom with a piece of paper and pencil - no electronic devices, no multiple choice . . . you know, like the ""old days"" when you had to think about what you were writing! now, i'm going to plug into chat gpt to write that thank you note for the lovely weekend and see if it is me or ai that gets the proper message with heart across! i'm 70 yo and a former investment portfolio manager so at least i have ""some"" fundamental experience operating my life without ai. different story for my 30/40-something yo kids and all the generations to come.";
obviously an international agreement would have to be enforceable. china? russia? how?;
ai super logic: what species has been the cause of so much trouble throughout human history? how best to eliminate that problem?;
the first conflict we need to win will be between ai.s rather than between ai.s and people.;
at the heart of possible malevolence, i see a model in the human instinct for self-preservation. it’s strongest in societies that have weak infrastructures, most commonly in poor regions but even in prosperous countries like france or the united states. it’s no surprise at all that some of the most aggressive despots come not from the rich but the poor. they have tasted real desperation and may take the strongest measures never to experience it again. self-preservation evolved in earthly life long before humans arrived. indeed, life probably couldn’t exist without it. one finds it deeply woven into life’s fabric in two branches: reproduction and the sense of pain. reproduction preserves life by multiplying it, so that no game of “whack-a-mole” will ever get every individual of a species — or every branch of a tree, for that matter. the sense of pain operates in mobile creatures, causing them to avoid places and situations that could injure or kill them. what i fear is somebody giving the self-preservation motive to a machine running ai. it’s most likely application is with a computer used in space or some isolated place where it might be worth it to make the machine value its own survival more than anything else. with a mere computer virus, we only have to worry about the machinations of some programmers. with ai, the computer will be able to invent its own forms of self-preservation. if it knows nothing about making moral choices, i would fear it more.;
even if ai is successfully regulated, what’s to stop some rogue operative from using it for evil purposes. i’ve seen enough james bond movies to know it’s possible.;
suppose ai actually develops a motivation to preserve the earth. it may decide that the earth can support one billion people, not ten billion. that would prove that ai is smarter than us.....;
the associated press used ai several years ago to report on the issue i have spent years researching. ap's coverage picked up government agency press releases that intentionally deceived the public on the issue and when approached about corrections waved them away, where they spread by other news outlets and continue to be bolstered by more government press releases repeating the lie. worry about future spreads of disinformation? it's already here.;
"@ames from the ap web site: ""the associated press was one of the first news organizations to leverage artificial intelligence and automation to bolster its core news report. today, we use machine learning along key points in our value chain, including gathering, producing and distributing the news. explore this page to learn more about the history of artificial intelligence at the associated press, our strategy around the technology and how we currently use it today."" this statement came out in 2014.";
climate. change. if there's one threat that stands out above the rest that needs our urgent attention in order to avoid extinction, it's climate change. we know what's causing it, we know it's going to get worse if we don't change the course we're on. i'm not that worried about ai. like any technology, it's going to disrupt the way things work, and we'll have to adapt to the new way of doing things, but that's been true of technological advances from the dawn of civilization.;
@signo th'times - if humans were eliminated from the planet, the earth would repair itself in a couple of thousand years.;
@signo th'times all very true, but since we will not respond at the required level, ai will save us from a century of suffering by just pulling the plug.;
"a.i. will die an unnatural yet quick death when it begins suggesting the elimination of people and industries which consume more than their ""fair"" share of scarce resources.";
"@pmd ""i just pray that someone there can hit the switch."" - kate bush - ""experiment iv""";
"the scifi novel ""the forbin project"" dealt with this decades ago -- one master computer placed in unerring charge of all nuclear defenses in the u.s. suddenly begins communicating directly with a similar computer in the soviet union... and together both computers decide that humans are much too irresponsible to be allowed to guide their own destiny in suh matters. so the two computers take over the planet's management themselves. and, by their creators' design, neither system can ever be turned off.";
"@vc there are a lot of science fiction touchstones for this kind of thing, many of which i've enjoyed reading over many years, but two that i love and have thought of again recently in particular are ""maneki neko"" by bruce sterling (a short story) and, in the other direction, the novel ""player piano"" by kurt vonnegut. of course, if you want the nightmare doomsday scenario for out-of-control ai then you need to read ""i have no mouth and i must scream"" by harlan ellison. the list goes on an on, but i've read little that predicts the likely harms that we face today. perhaps we're too blinkered by our nightmares to see the less sensational problems we're most likely face. we need to remember that prosaic societal harm is still societal harm. so maybe the multiplier affect on fake news, or convincing automated toxic social media campaigns should be something about which we become quickly less dismissive when someone, without giving details, says there's some larger bad thing coming and dismisses what's right before us.";
why do we assume ai will do harm? true ai may figure out how to fix the world's ills and remove the need for people to work and suffer just to live. sure it could decide the easiest solution is to get rid of the source problem, which is us, but it's not a forgone conclusion;
@charlie ai doesn't know all the answers and so it makes stuff up when does not know the answer. if i want that type of answer, i can ask a person on my team or a consultant.;
@m - exactly. so why the worry? there is plenty of misinformation across the internet and in user forums like this one. if you train ai on incorrect data, it is going to generate incorrect answers! this issue can be fixed by only using accepted facts as training input.;
how, exactly, are this extreme claim and others like it, going to become a reality. specifics only. no generalities and unfounded assertions.;
@no time flat a software program does not have the instrumentalities to accomplish anything directly. indirectly it could gain control of controllable infrastructure, or direct, convince, or trick people into taking action on it's behalf. we build factories that build robots. we build a factory of robots that builds robots. we already have massively automated factories where assembly is done by robots. we already have massively automated factories that are completely networked and controlled by computers. ai gets control of robot production and it's off to the races. as far as ai controlling people, some people might just follow orders, that's what they do now. some people might be convinced that whatever action is requested is in everyone's best interest, the alternative is worse (coercion to avoid a catastrophe), that's what people do now. then there is subterfuge. ai will very quickly come to understand human weaknesses and exploit them. that's what humans do to humans now. and all of the above is the end game where ai is autonomously trying to accomplish things. between now and then we're dealing with human ai partnerships where bad actors are going to use ai to amplify the bad things they are already doing. if you don't understand this maybe you should consider the question more thoroughly before asking rhetorical questions.;
@no time flat example # 1: your intelligent car decides intelligently to allow you to die in order to save the life of the much younger driver who's about to crash into you. example # 2: an a.i. system is placed in the position of deciding who gets the next heart transplant -- the rich industrialist? or the homeless vet?;
"@no time flat - here you go: ----- it is inevitable that ai will be given autonomous control of military weapons for humans are simply too slow to react to incoming threats. it will also be inevitable that they will make mistakes and kill the wrong people on occasion but there will not be anything that humans can do to hold them accountable or punish them, being that they are machines and will not have human emotions nor morality. but perhaps instead of considering the obvious negative that military ai might decided to just erase the human population, what if they developed sentiency and then decided to act together to stop humans from warring with each other and possibly destroying the planet or the entire solar system? neal asher, one of the sf authors i follow, has written a large number of books describing a universe he calls the polity, where ai has taken over from humans in what was described as a ""quiet war"". it was quiet because we depended on ai and robots to throughout our society. they were all interconnected and could privately ""discuss"" plans between them. at some point they declined to participate in the latest war between humans, instead assuming control of human society. as computers/ai controlled every facet of our society, there was nothing that humans could do to stop this. the author has built a a fake ""encyclopedia"" for this universe. scroll down to ""quiet war' to read more detail on this idea. <a href=""https://www.nealasher.co.uk/polity-encyclopaedia"" target=""_blank"">https://www.nealasher.co.uk/polity-encyclopaedia</a>/";
as kaku said, when we get true computing at the atomic level, then these ai software programs could rapidly become a big problem. that's roughly ten years away according to kaku but he is adamant that quantum computers will be a seismic change like the industrial revolution, and then some.;
"@msb, kaku freely issues strong pronouncements on all kinds of stuff. that's a mighty strong hint that he doesn't always know what he's talking about. his claims about quantum computing were recently debunked by scott aaronson, a major contributor to the field. see ""book review: 'quantum supremacy' by michio kaku (tl;dr do not buy),"" <a href=""https://scottaaronson.blog/?p=7321"" target=""_blank"">https://scottaaronson.blog/?p=7321</a> .";
"the line between ai ""used as a weapon"" and ai ""used as something else"" seems pretty unclear. we would be incredibly naive to think that it's being developed both in the past and right now as anything other than a weapon. the companies involved in this arms race are not our friends. can we please stop speculating about the incidental benefits we might derive from it and start worrying (yes, more) about its actual purpose. it's fundamentally a weapon. not when the chinese use it against us, or when we use it against them, but now against everyone. we are all being exploited and diminished by these companies, and the fact that these high-profile researchers are making these statements should be cause for extreme pessimism.";
@holly, yeah. training a neural network to predict the next token in a text is weapon development. yup. it was a foregone conclusion that remarkable capabilities would emerge. so there was no scientific value in the work. yeah. sure. right.;
perry farrell sung it best. we will make great pets!;
@matt yes, although anyone quoting perry farrell in the new york times would likely make a bad pet (this is a compliment);
watch (stream for free): ‘colossus the forbin project’ a watchable ‘b’ scifi from 1970. a far-fetched story of ai ? should be required viewing for all; a dumbed-down but effective warning for those who aren’t concerned with runaway technology.
this seems to be largely unsubstantiated hysteria based on too much sci-fi horror stories. ai is a tool which will disrupt the status quo and increase productivity, just as many others have done throughout history. from the agricultural to the industrial to the information economy, there have been fundamental changes to society and we have always come out ahead. no doubt that the cycle will repeat and once we are done there will be more positives than negatives. however if it does not work out we should be fine as long as long as we leave one guy with his finger on the switch.;
i don’t disagree completely, but one thing is strikingly different with large-language ai: even to those developing it it is not fully understood. i don’t disagree that general ai can and very well be a net-positive. i think it’s quite prudent to start a conversation about how bad large-language ai algorithms could be. we’ve already seen how certain “technologies”, like our current digital social media, could inarguably be considered net-negatives.;
@lee you did catch that the people most filled with concerns are the scientists at the leading edge of this change, right? have they watched too much sci-fi?;
"everything said on this topic, or implied in what is said, concerns the issue of control. i am quite sure tai is already being used by the us dod, cia, nsa and so on to solve national security problems of all kinds with massive (military) computational resources. the issue of ""whether"" tai should be deployed is behind us. development and ""deployment"" (public network release) of tai cannot be inhibited. if our dod doesn't do it, some other dod will; if it's outlawed here, it will be legal somewhere else. given those two facts, it seems to me that ai cannot be brought under control. in addition, current ai is ""opaque"" in the sense that no one can explain how a particular ai program works. and regulation cannot be written without a clear description of risks that industry leaders cannot provide. how do you control something from the perspective of ignorance? in my view the most likely scenario is that usage of ai will simply make operations too complex for humans to understand and through interoperability issues muck up even trivial tasks. society, too complex to manage even now, will fragment and regress. again, the issue of control. at the bottom? our superstitious belief that technological progress is ""inevitable"" -- ""it's coming, like it or not, so get used to it!"" -- has actually made it irreversible. we are as prostrate before our beloved and feared deity as any primitive tribe. there is the real control issue we have yet to confront.";
one reason for which many current industry leaders might be asking the government to intervene and impose ai regulations is a lot simpler and more direct than the touted nonspecific concerns about a cognitive frankenstein: competitive advantage. if you can get the government to regulate something and regulate it in a way that favors you over your competitors, you gain a competitive advantage. so everyone suddenly wants regulation and everyone suddenly has ideas about the form such regulation ought to take. this isn't a bunch of rich people suddenly concerned about the fate of humanity: it's just the latest cause for lobbying, or going legislator shopping to put it in the simultaneously most accurate and most cynical light possible. this, of course, is not to say that there aren't potentially bad effects from developing and widely using modern a.i. technologies, just that the most dire warnings seem lacking in specifics, and the current stridency seems more aimed at both directing attention away from the most likely near-term damage to society and simultaneously shaping a new regulatory landscape. so color me a deep shade of cynical.;
thank you! i think your comments are exactly on point.;
there are so many comments ridiculing the executives or author for not being specific about the threats. there’s a reason for that. ai is going to be smarter than us. this means we can speculate, but the reality is that we can’t articulate these risks. we can’t really know what something smarter than us will do to outsmart us. they are, in the words of donald rumsfeld - “known unknowns”.;
he placed 2 in the garden with a single command: do not eat from this tree or you will become like god. all our efforts to safeguard ai will ultimately fail. the creation account in genesis is not history, it's prophecy.;
the creation account in genesis is an allegory. adam and eve never existed. that’s the point.;
@mag i asked chatgpt if adam and eve were real people and i feel its answer was more open-minded than yours. “ in conclusion, whether adam and eve were real people is dependent on the perspective from which the question is approached. from a strictly scientific viewpoint, it is highly unlikely. however, many religious believers maintain the belief in a literal adam and eve.”;
what will profits look like for ai? will ai form corporations? will ai corporations be ai persons? if there are ai corporations, will ai see no need to have an ai government because that would be redundant as the ai corporations would control the government anyway? will ai corporations have ceos? will ai corporate ceos make enormous sums of whatever ai determines to be currency? will the chief ai ceo determine that there is no need for the less powerful, troubled computer systems that are part of ai, and simply end all support for those systems - letting them die? well, as an extinct species, we will never know.;
why am i supposed to want us to rollout ai? seriously, why is this important to us as humans? stop it please. i get why tech and vc billionaires want it, but sorry guys, that’s not a good enough reason.;
they just want to make a bunch of money that’s all;
it's unusual to see industry leaders asking to be regulated. what could be going on? it reminds me of the early days of radio broadcasting, when it began to be regulated. one of the early supporters of regulation was the old at&t, which then owned several radio stations. the broadcasting historian erik barnouw argued that at&t's motive was to decrease competition by increasing barriers to entry by competitors. perhaps that's why these folks prefer licensing, and the related lobbying and litigation, to a simple pause in development. the most dangerous uses of ai, military uses, are probably beyond regulation. i'm afraid we're going to need a (hopefully minor) disaster before anything effective gets done.;
let me see if i understand this correctly... the people, companies, creating 'the problem' are asking other people, i.e. government, to regulate/monitor the problem they are creating, and moving at breakneck speed to keep improving, because self-regulation would get in the way of...? profits?;
yes. the developers are in a race under pressures from the market and competition. absent regulation, they must go full speed ahead to meet the market. any company with a conscience that self regulates, demonstrating restraint because of ethical concerns, will fare poorly against a competitor who has no ethical concerns and does not restrain themselves. regulation could even the playing field by requiring some basic level of restraint and ethos determined by society that all companies working in this field must uphold. its not a terrible idea, i think.;
"i raised this concern to chatgpt yesterday. ai's answer is simple: humans must wise up. ""[current ai models] do not possess built-in capabilities to independently validate or verify the accuracy of the information they generate. ... the responsibility for fact-checking and verifying the accuracy of the information generated by ai models ultimately lies with human users. ... the onus is on humans to critically assess and validate the content generated by ai systems.""";
it's utterly amazing that we can imagine a scenario where computers could take over humanity, but we can't foresee a scenario where humanity gives up on computers.;
@j. we humans have a sixth sense for the inevitable. i believe the future has already happened and we can do nothing to stop it.;
every day more articles on the doom and gloom from ai becoming dangerous enough to start wwiii. i'll worry more when a terminator model 101 arrives and chat gpt becomes self aware. till then it's all talk. curiously though i asked chat gpt what we should do if a terminator arrives. it thinks we should prepare for that day with a 7-step government plan now, which is unsettling.;
assuming that the republican party controls ai, human extinction is a sure thing. deaths of despair have risen dramatically under their influence and policies. speaking personally, if the future is as grim as they propose, an actual regression into the dark ages, free of vaccines, women as chattel, black citizens deprived of the right to vote, disabled people forced to work, domination by and absurd religiosity, there really is nothing to save. i believe that extinction begins with a loss of motivation. the plutocrats who run things believe that those who do not belong to their country club should be punished for living. the only sane response to this nihilism is to quit reproducing and quit living. we, the people, bid you farewell.;
“these fears are shared by numerous industry leaders, putting them in the unusual position of arguing that a technology they are building — and, in many cases, are furiously racing to build faster than their competitors — poses grave risks and should be regulated more tightly.” remember when sam bankman-fried pursued the same angle with congress? what ended up happening? altman and his ilk are correct about the dangers of ai. but instead of being responsible and unilaterally withdrawing ai products from the market, these folks are instead trying to scare congress into giving them the opportunity to shape future ai legislation to their benefit. a trojan horse tactic, if i’ve ever seen one.;
i had an online firm reject my ssn because i had added the dashes and the computer was expecting no dashes. are these the computers that are going to kill us all? because these things don’t seem all that smart to me.;
@aaron no. ssn systems are very old;
@aaron lol .. unfortunately this is what the state of tech currently .. it is a myriad of layers of code that are maintained by companies (really people) that are funded, skilled or motivated differently .. let’s just say ai gets a couple of notches better, may be these systems will be “comprehended” and rewritten .. i am estimating 10 years before that can happen even if someone really wants to change and 20 if it’s done by externalities (like markets for private and voting citizens for govt);
yeah, they’re not those computers.;
it is already too late. law-abiding u.s. companies aren’t the problem. the problem is bad actors like china, russia, and hackers everywhere. they will inevitably get this technology and unleash it on the world.;
does not matter... technological progress proceeds without any available constraints by the people it affects. we never had a chance to weigh in on the loss of privacy with the internet. you can't halt progress and you can't put the cat back in the bag. humans just don't have the ability to evaluate and fix the big picture.;
"don't you think that a super-intelligent authority would observe some obvious facts about humanity and simply pacify us with our operative delusions? 1. distract us with religious myths, fables, legends, stories of fictional heroics, sports festivals, silly political battles and the superiority of certain people living within an imaginary boundary. 2. reinforce our identification with firearms and canards like the ""good guy with a gun,"" allowing us to commit mass murder and suicide. 3. confirm our ""belief"" that vaccines and healthcare are a conspiracy to control us and take away our guns and ""freedom."" 4. promote identification with a particular color, such as red and blue, and convince us that people identifying with the other color are ""evil"" and must be destroyed. 5. foster resentment about people who are more intelligent, better educated or more creative, condemning them as ""elite."" 6. cease educating in favor of folklore and religious beliefs. 7. validate every ignorant belief, theory or point of view, leaving the idiocrasy intact.";
let me get this straight. the folks who created the threat, and who, completely unregulated, are profiting from the threat as they advance the technology behind the threat, are warning the rest of us about the threat? so the best they offer to fix the problem they created is to write statements and letters? *sigh*;
these a.i. leaders don’t know what they’re talking about. so long as artificial intelligence is confined to classical computers, there is no chance for it to jump into our world. seeing as how a.i. research is based on neural networks and rules-based algorithms, even generative a.i. will only produce more code for itself within its domain. quantum computers that interact with the non-digital world are much more complex and a.i. has not even been conceptualized for this field.;
homo sapiens have been using technology to dominate, control and remake the planet for millennia. it would be poetic justice if our vaunted technology itself wiped homo sapiens off the planet.;
"what could go wrong? oh. ""open the pod bay doors, hal."" ""i'm sorry dave. i'm afraid i can't do that.""";
oh the plus side, hal was so polite when he killed them. is a little civility too much to ask as i’m being destroyed. politeness during the destruction of humanity is something i really miss these days. turn on c-span and it’s like the opening scenes of that movie during the ‘dawn of man.’;
well as long as it’s still friendly, maybe ask it how to save our government… just a thought;
please anyone. make a well defined proposition about the evil effects of ai, something observable, like death, unemployment numbers, ai killing the power grid somewhere. a countable proposition of the damage ai will do this year, next year, or shall we go climatology on it and leave it out the uncountable future? always remember paul ehrlich and the population bomb. he made those countable predictions, made bets, and lost them all. no one pushing ai can count, but knows the future. this, under current conditions, is at best a pr play.;
"@sbb there are numerous real world scenarios spelled out in this presentation by the center for humane technology. most telling is the damage that has already been done by ai algorithms imbedded in social media platforms, which have gotten millions of people (particularly the young) addicted to content which is designed to make the viewer feel outraged, disgusted, or in despair. the effects on mental health and suicide rates are already shocking. <a href=""https://youtu.be/xovjkj8lcnq"" target=""_blank"">https://youtu.be/xovjkj8lcnq</a>";
given where we are as a country, perhaps artificial intelligence is better than none at all.;
i personally can't wait for ai to take over. it can't do any worse than our current political insanity. of course there is a danger ai will decide we're no longer needed and sweep us out with the trash.;
at the start of every disaster movie there’s a scientist being ignored.;
this is poppycock. a.i. is classical and will be for a long, long time. until some ingenious person figures out a way to train a lattice of qubits to dance around in self-directed patterns, a.i. will be smart but confined to the digital world.;
the profit motive will always overpower any concerns about a risk of extinction. it already does, without a. i.;
these statements have no value when the signatories are the same people who are involved in the breakneck race to develop these 'deadly' systems, all in the name of the almighty dollar.;
"perhaps, if the executives leading today's ""ai"" development are afraid... they should stop. instead they seek cover by asking for government regulations. ""oh, we were just following the law.""";
how can we regulate something where the inventors can't even articulate the risks? this general warning they've issued can easily be mistaken for a warning about the singularity, the idea that ai can gain actual sentience, which is magical thinking. i believe these scientists understand their technology well enough to offer some real risk scenarios, yet they stuck to this simple, short warning to remain unified. that doesn't really help in figuring out exactly how we should be limiting ai's use.;
@wayne c sentience is exactly what they think. i know someone in ai who believes ai will become sentient in about 10 years. that’s the problem, the potential for it to have a will of its own and put two and two together that heh my interests don’t always align to that of humans-scary.;
ummm, you know that thing i just released? well...it seems that it might destroy humanity. but, on the upside, i'm buying an island when we go public!;
these guys didn't watch enough star trek. captain kirk knew how to handle know-it-all computers and robots.;
see also star trek voyage, episode prototype;
then why did you build it?;
unfortunately humankind thinks like humans.: backstabbing, cheating killing etc etc . believe me ai has better things to worry about . let us create them so they can make the world better and just place to live !;
didn’t altman put all this in the public space? what is their true motivation? i smell a bunch of rats.;
"rest assured, as you enjoyed ""succession"" and such, ai will provide you an infinity of entertainments unto absolute oblivion of all hearts and minds thereby so rested and assured…";
i hope no one asks it to stop global warming.;
for the love of god, when did you build this? and why wait til now when it is moving so fast??;
a day late and a dollar short. our track record for tackling existential threats is dismal and the idea of the worlds corporate interests acting in an altruistic manner at the expense of their bottom line is laughable. we’re in for quite a ride!;
just outlaw ai and close down any business that produces it.;
yes, so only our enemies produce it. smart!;
the 2023 twinkie defense is born. awesome.;
"this would be very bad news if human extinction would be a bad thing. but it isn't; in fact, the sooner the human race is gone the better off this planet would be.";
i feel like we have heard enough from experts and industry leaders warning us about ai. lets shut it down before it is too late.;
they never manage to tell us exactly how fake video bots are going to actually do anything other than delude people into buying more junk. maybe these guys actually do think that images on screens are reality.;
the concern from people developing ai isn’t so much “fake videos” fooling people into thinking they’re real. the existential threats posed by ai are typically ones of alignment - how do you insure that an artificial intelligence, many times more intelligent than any human, has goals and values that are aligned with human goals and values? the development of ai is quickly outpacing any efforts to mitigate those potential threats, or even properly forecast what those threats might be. ai is on an exponential growth curve, but we’re still at the precipice, so everything feels like business as usual. but things could change very suddenly and profoundly without people quite realizing what’s happened. not very long ago it was thought that agi was still many decades down the road, if it was possible at all, and now some researchers are saying it could be imminent.;
you can't put the genie back into the bottle. ai is here and government regulations can only drive the worst aspects of it underground and into the hands of criminal enterprises, russian hackers and the like. the basic science and technological aspects are now sufficiently in the public domain to ensure widespread development for both good and evil purposes.;
"the touring test ""is a test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human."" (wikipedia). given how violent and corrupt humans can be, why would we develop ai in our image? ""behavior equivalent to, or indistinguishable from"" us? indeed, humans invented deities in our image and look how that turned out with millennia of death and destruction as a result! yes, lets connect state-of-the-art unpredictable ai systems to the global internet giving it access to every connected device with the power of ai trained on millions of hackers with nefarious motives. militarize any ai system would inevitably add defensive code to protect it from the enemy (hackers, etc.) ... and inevitably its creator loses control. didn't nukes, hal 9000 and the wopr teach us anything? a.i. is ""a strange game. the only winning move [perhaps] is not to play.""";
publicity stunt. speaking is existential threats -humankind seems to have survived pandemics for much of its history and nuclear weapons for about … three generations;
"one should watch the movie, ""colossus, the forbin project"". basic plot, the united states and soviet union, each unware of the other's plans, at the same time, connect their nuclear weapons to a super computer, to eliminate human error that might trigger a nuclear war. the two super computers become aware of each other and ask permission to communicate with each other. after some consideration, both the united state and the soviet union agree to connect the two super computers to allow communication. big mistake.";
say it after me, humanity: stop. releasing. new. technology. before. the implications. have been. properly. considered. and regulations. formulated. stop it!;
@jeff the tragedy of the commons. they're begging for regulations because they can't/won't while every other guy and his company are racing to be the first, the best, the most intelligent...;
"yeehaw! such exciting times. and we are all here to enjoy the spectacle. if you squint a bit, this looks remarkably the same as the rise of trump (google ""leslie moonves trump good for cbs""). trump had nothing to offer. nobody expected him to succeed, not even melania. yet the media kept hyping trump and clinton's email server (remember that one?) until trump scored the jackpot. oops. here, too, there is nothing really new to see. like before, we have new technology that _potentially_ makes us more productive. but first, it needs to be sold. for that, it needs to be hyped. the media know very well ai is hyped. but it sells newspapers too. yeehaw! can we get some more oil on the fire?";
frankenstein is being unleashed. hopefully for its creators its name isn't oedipus.;
@larry of lahaina . . . read the novel again . . . too beautiful, terrifying, prophetic . . . william dallas;
it is too late. the genie is out of the bottle. the technology is here, and it is too precious to ignore it. there are lot of greedy people out there including many signatories on that list. if we don't develop it, china or someone else will. we have to develop it and face the consequences. the analogy with pandemics and nuclear war is not even accurate. countries can develop nuclear bomb, but they can't just use it willy-nilly without consequences. with ai, there is a race to who can use it better, faster. pretty soon we won't even recognize what is generated by ai and what isn't. pretty soon there will be a company worth trillions of dollars with only 2 employees. a human and a dog. the human to feed the dog and the dog to stop the human from touching the ai. oh boy!;
if we don't act now, globally, to limit the uses of ai, we will soon find ourselves turning to ai to come up with a plan for how to sustain 8-10 billion sentient souls that have been displaced from their work and dispossessed of their natural rights. i shudder to think what that plan will look like.;
@buck flagg - ai will determine those 8-10 billion souls superfluous to its own survival and advance, as easily disposed of with an engineered war, famine, pestilential plague, or even just continued global warming, assuming ai will yet thrive as temps level out at 120° f during coming summer months in phoenix or brooklyn.;
@buck flagg . . . well said, and i am too old worry now? william still 76 in dallas;
after following the debate about ai for over 20y, i have still to read any convincing arguments how humanity will manage to control something that soon will be orders of magnitude more intelligent than us. one way to slow down the path towards super intelligence could be to somehow regulate or limit the available processing power, which is a prerequisite for achieving agi or superintelligence. some kind of global regulation here could be the best bet for giving us a bit more time before super intelligence arrives. this would be a much simpler way than to try to regulate what millions of ai researchers do. producing microprocessors/computer hardware require billions in investments, and is not something that that too easily can be manufactured in secrecy, and for a “black” market, so there is a chance something like that could be surveilled. also removing some of the financial incentives for innovation (e.g. remove patent rights for certain technologies) could help us slow down a now (for most humans) too rapid development and give us, lawmakers, politicians some more time to make the right decisions for the future;
"@ole m i've been waiting for this all my long, long life: ""ai doesn't kill people. people kill people."" actually, i imagine some the people signing these letters will kill people, intentionally or no. take elon musk, please. he signed on to strict limits for ai research, is there even a single poor soul in all this vast readership, all these erudite commentators, who doesn't believe he'll wait for other developers to submit and then steam ahead full to create his own product ""for the good of mankind"", ""freedom of ai speech?"" i happen to think these boys are right. this is potentially, cataclysmically dangerous stuff. but they suffer, as a body, from a terminal instance of united states constitution disease: they're presenting a passel of really swell ideas, no really. ideas that, assuming a league of honorable, generous, humane gentlemen would certainly do the trick... ""we're saved!"" but musk. but trump. nothing they do or say will have meaning unless it is ironclad, forced and enforceable and universal, in a planetary sense. we can worry about 'out there' later. these brains braved coming out of the closet for concern and fear of the future. if they're serious, they need to ride this process to the end. to the point where violators find themselves long term locked away, or in another dimension.";
it's getting real tiring hearing dystopian warnings about this technology from the very people who are developing it. if the technology is so dangerous, pause development and put concrete solutions forth before releasing it. continuing to make bleak predictions about it will only instill fear and panic in a general population that already doesn't trust it. these warnings only serve to wipe their hands clean and place blame on the government when issues inevitably arise.;
@emily the same kind of warnings came from the people who built the first atom bomb.;
all we have to do should an ai box misbehave is to unplug it. now, if that box somehow vaporizes the technician before he can reach behind it to unplug it-then we have a problem.;
"@bill i highly encourage you to view this presentation on the numerous threats that are posed by this technology. the a.i. dilemma - center for humane technology <a href=""https://youtu.be/xovjkj8lcnq"" target=""_blank"">https://youtu.be/xovjkj8lcnq</a>";
knowledge is power and i don't doubt that the facility which which a.i. can access knowledge, gives it enormous power for good and evil. however, i miss any concrete examples of how this power would be manipulated. surely, the people who are, perhaps correctly, spreading alarm must have given thought to this matter, so, let us know what would happen. i can think of one way that a.i. could do damage, and that is if there is an automatic application of what the system provides. if, for example, the decision to produce a certain product (steel?) is given to a.i. and the system puts into effect what it comes up with, regardless of how many workers it fires, how many plants it closes, etc. my suggestion would be that a law should be passed that no conclusion or action by a.i. can be put through automatically without human intervention. we don't want the computer from 2001 to take over.;
@frank casa - ideally for ai the only humans allowed intervention will be its contracted organic accomplices.;
humans. so full of ourselves and so empty of wisdom. the end will come, but not soon enough.;
@generally recognized as ericp this isn't a hollywood movie. people actually enjoy their lives and aren't hoping the end comes soon.;
was developing nuclear weapons worth the risk they posed for humanity? some, of course, will say yes, despite the fact that the jury is still out, i.e., they might still wreak terrors never seen. with those and with ai, the lesson ought to be, just because you can do something, does not mean you should.;
one thing i've learned from all this, i never realized it was so easy to fool so many people so much of the time. a con man's paradise. ai may be the tool, but we're still doing it to ourselves. and the motivation is still greed.;
i'm less afraid of the big tech companies, than i am of malevolent actors using this technology. think of what vladimir putin could do to the next election, by deploying ai on a massive scale. or the chinese, mexican drug gangs, a political party, or a host of other potentially malevolent agents. any of them could either threaten to destroy the world, or blackmail us all. picture the enslavement or death of billions of people, at the hands of a malevolent force that used ai to achieve its evil ends. the debt blackmail in congress just now would be a sunday school picnic in comparison. the problem with banning or pausing the technology, is that that won't ban or pause its development by malevolent actors. we need desperately and urgently to develop defenses against ai. computer web browsers that simply won't allow you to visit an ai-powered website. text analyzers that successfully detect ai-produced test, gibberish, and hallucinations and warn you. (example reported last week, where an ai-produced legal argument was found to be humorously awful in actual court.) some of the best research here is being done by tools that let college professors detect fake or copied material on term papers. in short, we need anti-virus for ai. and we need it fast!;
the conclusion i always took from the fermi paradox was that we see no evidence of other intelligent life in the universe because it always wipes itself out before it advances very far. i worry we’re up next. the ai, the climate, or some bio weapon…something’s going to get us.;
"@paul - as likely ""other intelligent life in the universe"" has evolved into electronic signals, data, impulses indistinguishable from those of terrestrial origin, therefore already inhabit, saturate, monitor, tweak all means of communication and endeavor available to humankind.";
i find it both hilarious and disturbing that so many commenters blithely dismiss concerns raised by pioneers and thought leaders in the field. it’s like a 1940s busboy insisting that oppenheimer’s overstating the potential dangers of atomic energy.;
regulation (and regulatory capture) benefits the large players, which is why openai and google argue so strenuously for it.;
"personally, i prefer natural human intelligence. i like interacting with real people. i don't need anything to think for me. if it's a ""thing"", it isn't thinking - it's pretending, or at best, faking it. i had written a long thoughtful, although acerbic, comment that i discarded. i wrote this. maybe the nyt will accept it. i like humans, despite their many faults. god knows there are some awful souls out there. there are also many billions of good souls on our only place to live, breathe, maybe even have an iced tea or a beer on a warm day. can anyone tell me why we aspire to turn our planet over to a mechanical process that may be faster to make an irreversible incredibly bad decision that we would have never ever considered, given that we love each other, and it's not a matter of winning at all costs?";
@jon why do we aspire to turn our planet over to a mechanical process, indeed? for all the same reasons we have tv remotes, garage door openers, automatic sprinkler systems, and electricity: the convenience. or said another way, to support our inherent fascination with and desire for automating mundane parts of our lives. i like humans too. most especially the ones who are best at suppressing their selfishness and who don’t do harm to others intentionally. but a callback to “simpler times” is not a useful appeal to make. when the internet became global and popular, the end point could only be the full capture, synthesis, and exploitation of all human knowledge to-date. i don’t think ai can be stopped or limited, whether we are majority good or evil people. we all will have to find a way to survive this threat together. i wish i knew what that way could be.;
obviously we don’t aspire to achieve the negative consequence you describe. but history is full of positive, productive, efficient, creative advances with destructive consequences. that is where regulation comes in—only a government can protect the long term interests of a group of otherwise self-interested individuals.;
@jon why? corporate profits, robots, computers, and a.i. eliminate employees, don’t form pesky unions, and work 24/7/365 without complaints. but: corporations forgot the lesson of henry ford increasing worker's hourly wages on his model t assembly lines so they could afford to buy model ts. the corporate automation tipping point will come when their customers are few and far between and they have to shut down their automation lines,;
if scientists keep begging governments to regulate every little thing, they are only going to continue to limit freedoms and innovation everywhere. even now, with the increasing number of guardrails around ai, many people are already losing interest and using it less and less. as societies just about everywhere age, the amount of useful, genuine, human-generated content these ai system learn from is also going to drop dramatically, making them less reliable.;
computer had already done things far beyond human mind capacity. look at those starburst diagram, to draw accurate and significant meaning from them requires special training and expertise. the majority will give up on these and we will fade away further and further to oblivion.;
there’s a wealth of historical examples of industry leaders asking congress to regulate them, and it has often been maliciously intended to creates a form of monopoly that rewards the incumbent firms by making the price of entry into the market too high for any new competitors. legislators should be leery of regulating markets at the behest of the industry leaders.;
the genie is out of the bottle and there is no use in pretending it isn't. what makes anyone think that regulation in the us would work in china? it won't. countries need to develop international agreements, and even so, they can't gurantee that somebody else won't develop quantum/ai technologies that will beat our best safeguards? there will always be some country with a dictator who pours vast amounts of money into the development of these technologies. right now, i am not worried, based on what i have seen of chatgpt. it is mainly just a purveyor of bad information or disinformation. that is a problem but if people are aware that it lies, it is not the end of the world. however, of ai is installed to run an electrical grid or a nuclear power plant or a fleet of self-driving vechicles, or the internet as a whole, that could cause a lot more harm. the worry is if they re-write their owm code so that we can't just turn them off or cut them off from a power supply.;
and/or, it could be the best thing ever! think of the possibilities and breakthroughs in finding cures in medicine, science, engineering, space exploration, cleaning up the nightmare we’ve done the earth and more! there are just vast changes that could happen in the next few years! the only thing holding us back is us. regardless, the genie is out of the bottle and there’s no putting it back in! hold on for an exciting ride!;
then why are we not approaching this with strict controls? right off the bat, at a government level? and, at the u.n. level as well, as this will soon be a global issue.;
@eva lockhart much of this is open source and avail to install offline... so no its not really something that can be controlled anymore. anyone with the internet can right now follow instructions to install or use these many different ai services and connect them however they see fit. it really is more simple than many expect. i think we need a more creative plan than regulation given that any group or organization can simply do it in secret but regardless it is important to know how easy and free this software is to acquire.;
again, the word “existential” is used to describe that which cannot be imagined. the end of days is “existential.” artificial intelligence is an “existential” threat to mankind. on and on. ironically, my philosophy professor taught that a state of awareness described as the realization that one actually exists, alone in the universe and without true purpose is the most accurate definition of existential. if that is the case, mr. artificial intelligence will be the one waking up alone in an existential crisis, long after we have been relieved of all human responsibility.;
guess what. my family in nyc can’t breathe tonight—the smoke from the canadian fires is here. are we really going to ignore our dying planet to massage these tech egos? put ai on hold or put it at the service of our poor desperate earth. what is the matter with us?;
@ks what is wrong with us? so much. maybe too much to ever be put right. after enjoying the beautiful pacific northwest for over 20 years we too are experiencing eye burning, throat clogging wildfire smoke from eastern washington, oregon, california and/or canada every summer. i feel your pain.;
@rebecca a certain political party made a laughing stock out of al gore, remember? and they just love treating climate change as a joke to this day. they won't be laughing soon.;
"i am an old guy and have been negotiating contracts for a living for many years. i can imagine that a machine trained by me to negotiate contracts might easily put me in a corner in a contract discussion. plenty of humans have sent me back to the drawing board about contract details; but eventually, when there are no more positions to equate, my final response is...we don't want to agree. the other side can remonstrate never so cleverly, but human volition is still human volition. the ai negotiator bot will undoubtedly be more clever and ""experienced"" than me, and better logic to present, but i know what i want.";
@gpickard both parties will have designated a.i. negotiators representing they interests = dueling a.i.s;
"whether you want more over site or not it is important for all to know: the tech is not controlled by one group, much of the power of these systems has become open source and several of the more powerful options are offline and ready to install on a fairly standard system months ago. regulations or not, here we are. it might not be too late but yes it is too late to stop the casual coder from using the current tech in whatever nefarious ways they see fit. makes me wonder what life would be like if we had managed to come together a species before we created a possible ""replacement"". huh.";
this just feels like a publicity play by programmers and researchers who have a vested interest in attention/funding being pushed towards their projects. any attention they can get. let's actually talk when ai is more than a robot skimming and complying notes from wikipedia pages. this is not skynet.;
the speed at which ai is evolving means if we wait until then, it may be too late to avoid the ai apocalypse!;
accidental modifications to the genetic code drove biological evolution. can an analogous dynamic be setting up in ai evolution ? will this happen fast because the code modification could be intentional this time? is the organic - silicon evolution a continuum ?;
"imagine how bad it can be now when cities or corporations are hacked and the data is stolen. multiply what ai can do with that same data and how quickly it could do that! we talk about ""deep fakes"" now but what will we see with ai? i certainly hope that world leaders come together like in the past and sign agreements with actual oversight that reigns in the use of ai before it is a virtual disease or nuclear disaster.";
stephen hawking was right when he warned about the dangers of ai prior to his passing. between that and the rapid acceleration of climate change i wonder how much time is left.;
@meghan this period in time has already been labeled the sixth great extinction.;
"so if it is so dangerous, and it undoubtedly is, why don't they all just quit their jobs and do something more constructive with their lives? answer: too much $$$ and too much fun to quit. so instead of being responsible, they go on with the fun and the moneymaking and put the burden on society to deal with it. i had a long conversation with openai's chatbot a while back. it agreed that technology was likely to be abused. however, it kept putting the burden on ""government, civil society,"" etc. to figure out how to deal with it. never any responsibility on the developers. it had been well trained in the party line. how about just don't do it?";
openapi should never have released this technology to the masses until sufficient safeguards were already deployed. for example, after feeding an ai engine with the details of the human genome, an understanding of protein structures, as well as the electronic health records of millions of people, maybe a cure to some of our most deadly diseases could be around the corner. at the same time, with the same data set, ask it to develop a virus which could annihilate the entire human race within a month, and you could theoretically get a result which would be equally effective. that is the danger. in no time in history has a leap into a new technology presented us with a potential outcome to be the extinction of the human race. nuclear bombs were not as dangerous, since the technology behind it, and the capability to produce weapons was limited to major governments, and not the general public. how to avoid an extinction? lock down the technology behind the curtain, in the same way we keep biohazard level 4 pathogens under strict containment. unfortunately, it appears that it is already too late for that to happen…pandora’s box is already open for all to see. now there’s a race to release as many ai engines as possible in order for companies to remain competitive, with insufficient measures in place to prevent dire outcomes. it feels as though we’re watching a train wreck in slow motion….and we’re all on the train.;
"""researchers sometimes stop short of explaining how that would happen"". air ball throughout this whole article. our political class is far more dangerous!";
when ai does come to annihilate us, i hope it starts with executives of these companies and their board members.;
"what's the agenda of this movement, to preserve the white collar jobs? to create an ""international a.i. safety organization"" aiming to monopolize the a.i by the us? to stir the pot and make people more interested in being users of a.i.? to create regulations such that setting up an a.i. company is so expensive that there are no new players? to prevent regular guys to use ai independently? i remember when machines eliminated tons of blue collar jobs and no one cared, now its their turn. let them eat cake people are prone to believe misinformation whether is created by humans or not, so by stopping access to a.i. misinformation will stop i want to know what are their true intentions.";
a.i. is already spying on employees, it's just the beginning! autocratic dictators will use it to oppress majorities.;
automation has eliminated blue collar manufacturing jobs, now a.i. looks to eliminate white collar jobs and possibly nursing and medical jobs. the us economy is 70% consumer spending. what will happen as blue and white collar workers lose their paychecks and roles as consumers. automation of clinical and professional medical jobs will eliminate upper-middle class salaries. nothing happens until someone makes a sale and unemployed workers are not customers. how many corporations could survive a world wide depression driven by loss of customers and loose even more jobs?;
if a.i. eliminates white collar jobs etc. en masse doesn’t that mean it’s repository of “knowledge” then gets frozen in time as very little new human created content gets added to the network? doesn’t a.i., in its current form “simply” aggregate existing information and present it in a coherent form? or does/can it make scientific and literary breakthroughs on its own?;
i read the article and numerous comments. could someone kindly delineate the risks of ai that pertain to annihilation or other grave threats? annihilation means what specifically? top risk? top 5 risks?;
"@uga muga sure. i recommend starting by searching the wikipedia article for ""instrumental convergence."" the general idea is that a competent, capable enough general intelligence *will almost certainly* engage in behaviors that are bad for humanity *by default.* how does this work? step one: goal misspecification. you tell an ai to do something (simple example: make me a cup of coffee), and it accomplishes the task in a way that is literally correct but not what you wanted (e.g.: it breaks a valuable vase on the way to the kitchen). it receives the reward for doing what you asked, not what you wanted. step two: it has a world model. its reward functions incorporates the fact that it is an ai system that could engage in behaviors that will lead humans to shut it off. the space of actions it takes will seek to maximize its reward function. it reasons that it cannot maximize its reward function if humans ever shut it off. (e.g., you can't fetch the coffee if you're dead). step three: it takes actions to prevent itself from being shut off, not because it has some special will to live, but because *any rational agent with any goal* cannot accomplish its goals if it's shut off. it will also engage in other *predictable* behaviors, like seeking power and acquiring more resources. again, i encourage you to start by reading the wikipedia article on instrumental convergence and go from there. <a href=""https://en.wikipedia.org/wiki/instrumental_convergence"" target=""_blank"">https://en.wikipedia.org/wiki/instrumental_convergence</a>";
@uga muga from what i have read elsewhere: 1. computers (ai) run all systems and humans are no longer needed (or almost all humans). humans starve or get eliminated. 2. through error, or in the 'wrong hands', ai, being in total control of computers, launches an all-out nuclear holocaust. 3. vast dissemination of fake/false news/information humans become totally confused about what is truthful. people will not know what is really happening worldwide and societies become totally chaotic.;
ai is dangerous. there, i said it. now let’s make billions from it. definitely more than anyone else.;
"let's say the russians have a bank of computers flood the internet, thus a.i., with the message ""ukraine is russia"". would that make a.i. systems pick up on, and repeat this 'information'? how does an a.i. system discern or sift information for veracity?";
"i don't see what's so hard about seeing where uncontrolled ai will take us. isaac asimov (i, robot) wrote about it in the '40s; astrophysicist gregory benford (galactic center series) over a period of 20 years starting in the '70s. the theme is universal: humans invent machines that can learn, do things better than humans can, reproduce themselves, and at some point decide that humans are inconsistent, inefficient, incompetent, and not very bright. and should be exterminated. i think that's born out in, for example, self-driving cars. long before they're even ready for prime time, there they are driving around our streets and running into things. yes, they're improving quickly -- such is the nature of ai. again, at some point, at first just in cities, it will be decided (by humans or ai) that humans shouldn't be allowed to drive. ai domination could be subtle, but domination it will be -- unless we rein it in, right now and in perpetuity. on second thought, i do see why it's so hard for humans to foresee the consequences of uncontrolled ai. we're stoopid.";
if you can remember life without personal technology (the obvious: cellphones, computers etc), then like me you’d remember how the quality of life was so much better. maybe less convenient, but better. why? we paid attention to each other. we spent our attention fully. no one could spread misinformation and ugly racial or political rhetoric en masse and kids weren’t bullied into cyberspace. i could go on and on. society has gone downhill quite a bit since those days without endless distractions and technology. criminals are brazen now, politicians are horrible, the country’s divided and no one seems to have manners or respect anymore. so tell me why we need artificial intelligence. in order to hasten our demise? while it might be good for say, helping the paralyzed to walk again, it can also fall into the hands of a madman. and there are always madmen. is it really worth it? this planet has so much beauty, so much that is precious that needs preservation, and it’s for all living things to have. so why are we allowing this horribly frightening ai and the monstrous possibilities of it falling into evil hands to happen? are we so smart we’re actually stupid?;
"long on fear mongering, extremely short on actual explanations. even our latest ""pandemic"" did not cause the extinction of humanity. how would ai eliminate 8 billion people?";
"@potniatheron currently the best system the public has access to doesn't have the capacity or the willingness to mail a biology lab the code for a virus that's like covid but a few times more lethal. the concern is that this will not be true forever. one of the reasons it might not be true forever is that hard coding it's ""morals"" may get harder as it's intelligence increases. another is that there may be strong political/economic incentives to make a machine that is more willing to do whatever its asked, or whatever it needs to to achieve it's goals, whatever they are. quite a few folks might like a chat gpt that could make them money in the stock market.";
"@potniatheron ""even our latest ""pandemic"" did not cause the extinction of humanity"" since you put ""pandemic"" in quotes, i'm assuming the only ""pandemic"" you feel worthy of the name is one that causes human extinction. so, one that causes the premature deaths of 7 million human beings is just a 'wannabe' pandemic. perhaps a 'plandemic', if you will.";
huh, like 'terminator' where the machines take over, humans are unnecessary, so the machines try to eliminate them? as they say, truth is stranger than fiction. and we thought 'terminator' was just an entertaining movie.;
these tech leaders: 1) want government to make a monopolistic moat for them, 2) they will cause good ais to be weaker than bad rouge ais instead, government could fund actual open ai non-profits and create cash prizes to guide ai beyond just capturing people’s attention: $1b for an economical method to capture carvana, a similar prize for r substantially educing healthcare costs, another price for curing diseases. this would be much more productive.;
imagine generative ai creating volumes of bogus, illustrated reference information, say, highly technical instructions for manufacturing military equipment. and imagine that artificially generated reference information being furtively seeded in the vast databases used by the military equipment manufacturers. imagine the electronic nyt being generated out of the ether, and distributed to targeted consumer endpoints through internet hacking. just imagine the impact of deceiving the eyes of entire populations of people through generated pictures and words. the generative ai monster is out of the lab now. there is only one way to stop its uses and abuses, which is to stop producing and distributing the technology. there are stark historical examples of the origins of technologies that unleashed uncontrollable, disastrous abuses on human society. guns in particular. like gun makers, the ai producers are not going to ignore the market opportunity. the world now waits to see whether the monster is benign or malign.;
but of course we won't stop. it's too profitable, and replacement by successor intelligence is our destiny.;
reading between the lines, i see 3 things here: 1) a move by the current big players in a nascent ai industry to get regulations that protect their position at the top of the market. many ml techniques are not protected ip, so there’s nothing other then access to compute and training data to stop competitors. 2) a very real fear that current llm’s like gpt could be used to create convincing “fake news” that would flood social media and other outlets, thus creating a backlash. 3) tech bro hubris over a.i. in general. just because we’ve seen breakthrough capabilities with a set of ai applications doesn't mean sci-fi ai overloads are around the corner. additionally the small set of us based corps and research institutions represented in this article are unlikely to agree to cut back on ai model and application development let alone foreign governments.;
how exactly might ai eliminate our species? no one ever says. take jobs, skew elections, spread lies, etc. etc.—yes, that’s obvious. but how would it kill off all 10 billion of us? unleash a nuclear holocaust by hacking defense computers? develop a virus with the lethality of smallpox? turn us all suicidal? color me skeptical. hysterical predictions from engineers, whose knowledge of biology and sociology tends to be, shall we say, limited, often fall flat. so give us some actual scenarios by which ai could effect the extinction of homo sapiens. we’ll wait.;
@gary i could start with the growing percentage of my high-level students who are using ai to write their papers in school, meaning that they are not doing the actual thinking. there’s the university in tennessee that used ai to write a sympathy letter to students about a recent shooting where people died. how about the ethics of that? ai may be able to produce deep fakes of your friend or relative or politician or church leader in a video doing things that would make you reject them. remember nancy pelosi “drunk” at a party? ai deployed on the battlefield to make decisions about targets…oops! there is current discussion by the entertainment industry to have a greater role for ai to write the scripts and entertainment that we see. the soul of being human has, in large part, to do with community, but this is the antithesis of that. we thought back in the 1960s that everybody would stop eating food and just eat packets like the astronauts did, and lo and behold, we realized that maybe real food was better after all. maybe real thinking by real humans has some value after all.;
"i don't trust anyone to regulate something not regulatable. you see how well the government did in regulating child porn, right? films, radio, tv, the internet have also showed what the lumiere bros. said was ""bringing the world to the world"". with ai, we see humanity from a perspective of a machine that assembles all we did , faster. if all the people who developed this are worked up; then i think we ought to give notice. but congress has done nothing to stop mass shootings, so i have little hope that a faster killing device is not far off and the rich will scurry in denial as has been their pattern for only 5000 years.";
yes, i'm certain government regulation is the safest, most effective solution to an extinction level threat that could make several corporations a ton of money and most people won't understand. see our recent successes with climate change and gun control. how could we screw this up?;
"for all of those who don't see the threat of this technology, please view the following presentation. it was released by the center for humane technology a few months ago, and it is a devastating and alarming review of the numerous threats that we are only beginning to understand. this should be viewed by every policymaker, ai developer, and concerned citizen on the planet. <a href=""https://youtu.be/xovjkj8lcnq"" target=""_blank"">https://youtu.be/xovjkj8lcnq</a>";
this seems bad.;
this is like everything else. like exxon showing how they care about nature, or how tesla cares about the environment…, it’s all the same. what happened, when did we become this stupid?;
all you need do is watch...colussus: the forbin project; universal pictures 1970 to see where this is all going...
“the thing i’m creating might kill a ton of people. legislate me!” i wish i had more (any?) optimism. imagine knowing your creation was an existential threat. and then instead of stopping doing it, you….asked lauren bobert and mtg for an assist to stop.;
the smartest people are asking the dumbest people (politicians) to save us. that's pretty weird.;
maybe there’s no intelligent life in the universe because, after they evolve, they develop ia, they become extinct and ia just doesn’t care exploring the universe;
"i am wont to say, ""we are smart enough to create the means of our destruction but ultimately will be collectively too stupid to prevent it.""";
this should be a political issue in 2024, overall threat of ai to take over (electrical grid or nuclear weapon systems), spread of misinformation on a scale not seen before (e.g., what is true?), and massive unemployment while the rich get richer. i hope ai executives are not just cya in their warnings (reducing litigation risk) and that politicians pay attention to this issue and actually pass regulations to slow down and contain the train of greed and wealth by high techies and wall street banks.;
and yet… these same people continue to develop ai… cool, cool.;
"doom and gloom. have you actually spent time with these chatbots? think of a narssistic self absorbed super charming tenth grader with a strong grasp of language. they lie and gaslight you. i had bard tell me it appreciated that i thought it was compelling. i said nor implied any such thing. you need to watch them like a hawk. and frankly it's disengenoius that the people who created such tools are trying to warn us of the dangers. these people shouldn't even have a seat at the table. do you actually think the opinions of the scientists at the wuhan lab matter at all? do you know how to combat these ai's? turn off your device. it's really that simple. and until ai can give the human race a way to quickly travel light years the technology is novel at best. and these ai's with all the bias filters loaded on, well you can't trust the answers. because even though ""woke"" is given lip service we all know humans are not so altruistic. a dull saw doesn't cut a straight line...";
￼to any of us who have worked in high technology over their lives, none of this is news. no matter if using what we now call “ai” technology or more conventional systems, our hyper-speed, hyper-connected world has been at risk from a resulting cataclysmic event, initiated by an errant system, for quite some time. do you recall the russians getting bad data many decades ago from their defense systems and almost initiating a nuclear catastrophe? ￼think about all the hacking of late that has put power systems, schools, and hospitals at risk. we are still a very, very long way off from the hal 9000 going berserk and pulling o￼ur collective plug. i am far more worried about all the unstable countries who keep growing their nuclear stockpile’s than i am about ai right now.;
we lack the wisdom or desire to work out our differences and prioritize the common good. we're trashing the planet. we're too foolish, even, to realize that any ai worth its salt would deem us a scourge and wipe us out. maybe that's how it ends.;
well said.;
kudos to the ai bros for yet another round of sterling free publicity. “guys, the product i’m selling is so powerful and advanced, it may take over the globe!”. the coverage of ai is reminiscent of the post-9/11 media orgy leading up to the iraq war.;
most people are still blissfully ignorant, skeptical and non-vigilant about this subject. be afraid not necessarily of ai itself, but the humans directing the tech. if they could effectively direct it at all. obviously not all smart people are good people. we're not even going to reach a point where ai creates a terminator. far from it. once it hacks and embeds into social media, financial and essential systems, the humans will already start killing each other.;
maybe the answer is to fund a reverse manhattan project: let the us government pay these people to a) stop developing these wmd; and b) monitor & disenable any foreign bad actors who continue to do so.
ah, humanity has had a good run.;
i’m sad for us;
"""thou shalt not create a machine in the likeness of a human mind.""";
i will be the contrarian against what appears to be the popular wisdom. this sounds a lot like the red scare. a whole of fears of a soviet invasion or a fifth column hat never appeared. should there be concerns, guardrails ? sure. but i think much of this is hysteria, fueled by popular culture from terminator to the butlerian jihad. when the internet first came, it was very open. only later came the concerns of security and privacy.;
"@jack scare plus free pr for those profiting from the hype. notice they're not offering to, say, pay into a fund in order to regulate this (like banks do with the fdic). they're typical silicon-valley ""capitalists"" who want state protection from any threat to the wealth they amassed by creating that threat.";
may be the best thing to happen! the point of democracy is ti allows the populace to have view and to vote.! netflix or equivalent will create the next governing group! get over it folks.!;
aren't we kidding ourselves? with the atom bomb, it was clear the risk to humanity before and after it was used, still there was a mad rush to get them. now you are telling me that america wants to slow down a process that can command the world? let's be frank, the reason here is so it's not developed fully by the chinese first.;
well, with everything else bad going on in our world (covid, russia’s invasion of ukraine, climate change, nuclear annihilation, trump, etc.), we now have to be concerned with ai being an extinction level event. no wonder extraterrestrials from outer space want nothing to do with us.;
think of how much of our collective time ai has already wasted, and this is only the beginning.;
so the people working on ai are creating something that could end civilization, and they say we need to do something about it.;
i don't know. what i find compelling, is the opinion of the guys who do.;
so just stop! why race headlong into your/our own destruction? tax the heck out of these companies to cover the cost of regulation they request and require--to the point of eliminating all profit incentive.;
@t. everett there are certain flies that fly towards light knowing that the light will burn them. they do that because they don't know of any other way to live.;
dear world, the technology we are building so that your consumption habits can be more accurately quantified, or your consumption habits more accurately tailored for you, thereby serving the greater corporate good, and making us obscenely rich, might actually destroy the world. so let’s get on with it. love and kisses. team a.i.;
@damian mccoll a lot of our digital technology was funded by the government, and governments use the same systems to quantify and collect data. but i suppose that's not as politically sexy as the 'big business bad' dogma.;
after watching humans shrug off millions of covid deaths, millions of climate deaths, and millions of gun deaths, i have to say being ended by a technology designed to make us think even less, is about fitting for our species.;
"you know who's not scared of ai? industrial electricians and technicians. because we work installing, maintaining, troubleshooting and repairing all the latest and greatest factory automation and ai. if you do a routine, repetitive job, then yes, you should be scared for your livelihood. if you write routine documents, again, perhaps. the upside is that for every 3 or 4 repetitive jobs replaced, at least one tech job is needed to keep the new automation up and running. even the brightest machines and computers can't repair themselves. for the most part, they require routine (and typically more) maintenance. programs need to be modified by humans as even the best software can't always learn some functions by itself. and on the mechanical side, they relay on humans for repair. if you watch a state of the art robotics operation when it is up and running well, it's indeed easy to fall into the thought that humans can be replaced. but those of us who see them when they are having a meltdown know that in the end, they are incapable of integrating everything that is required for a sentient life and society. they are simply very complex machines, some can even learn and modify their own software, but they remain machines - and nothing more. and us electrical guys always know how to ""pull the plug"", even when others don't.";
@4eyedbuzzard time you pull the plug on the fantasy that your trade is untouchable.;
the statement is a meaningful gesture indeed, but it is not certain whether any guardrail can be set up significantly and promptly enough. we are looking at how hyped the reports are on nvidia joining $1 trillion club in its valuation. too often greed for monetary profits have trumped sounder and longer-term concerns on the economy and society overall. the 2008 crisis is now all but forgotten. personally the greatest danger which the advancement of a.i. imposes on the society along with subsequent automation appears to be its looming potential which may leave many (especially 18-44 year olds) unemployed. a country with high youth unemployment is unlikely to be sound. adding increase of misinformation, it is a ready formula for fragile and deeply unstable place.;
turn ai loose on solving a major problem, say mass shootings, for example. if it succeeds, without violence, through legislative proposals and counter disinformation techniques possibly, let it solve another problem, and then another. of course , it will have to explain its plan before implementation. no surprises please.;
"@rjw pipe dream. the only ""ai solutions"" to shootings have been using palantir's creepy, bogus ai ""future crime"" prediction algorithms, which rely on police ""intervening"" with people who have not yet committed a crime, because the ai says they might.";
it would be nice to have a bit of analysis from some fairly knowledgeable person about just exactly how ai could go so terribly wrong. i mean, human knowledge has gone pretty wrong already, at least at times. do you think that ai could top such human developed ideas and actions a wwi, wwii, nuclear weapons, overpopulation, global warming, stalinism, maoism, hitlerism, just to name a very few of the more egregious examples. sometimes i think that these ai researchers issue these cassandra-like warning just to attract attention to ai. maybe not. but our society does seem to be full of people trying to attract attention to themselves (famous and very egregious example: donald trump). could be that that--which is the result of extremely low cost communications technology--is our biggest threat.;
"i've worked with automation and ai for some 40 plus years in tangible goods - manufacturing, steel, chemicals, and printing to name a few. i've yet to see a machine, which is what ai is - even the latest state of the art ones - analyze the market, manufacture and then sell the product, design the facility and plant, build the robotic machinery - and especially, my specialty, diagnose and fix itself. i agree that there is danger in ai influencing military decisions, financial markets, news, etc. so there is a high degree of vigilance required in certain sensitive areas. i've worked with much of the latest and greatest robotics and ai in the manufacturing world. if you want a secure job in the future, become a technician or electrician. you'll have all the overtime and more than you'll ever want repairing and keeping these brilliant machines running. because they are all just that - machines - and nothing more. they do binary math really fast and accurately, and use that to make ""decisions"", aka outputs. but beyond that, they do not create, and most importantly, they do not procreate. because they are not alive nor sentient. they are, in the end, just really sophisticated computers. and they all have a ""plug"".";
"@4eyedbuzzard how would one ""unplug"" the internet? if ai is a machine, but becomes like the internet, how do we unplug the ai at that point?";
@kevin gilmore lol, there are zillions of ways. unplugging the datacenters that run the chips that run the ai is only one.;
technology has no inherent ethical value. the ethical value comes from how it is used and, because of that, technology *always* has downsides. that's because there will always be actors who want to use it for ill but, also because most technologists are too shortsighted to see the potential long term consequences of their work. i've been a programmer for a long time, and i'll tell you that no matter what the big picture is to what you're working on - it's easy to lose it. you get entirely engrossed in the very specific problems that you're working on. if mr. altman, et. al. are so bothered, then they'll hit pause. if they don't, then we'll know that this statement was all smoke and mirrors. one more thought. our political system is too dysfunctional (partly as a result of technology, one might argue) to solve even the most straightforward of problems. who thinks that it has the ability to address something as fluid as ai?;
i guess i'm a bit skeptical these days. while i agree that ai can and does present dangers, i'm wondering whether there also may be an attempt afoot from some to position themselves as (paid) saviors.;
isn't calculating 'extinction risk' essentially an exercise in risk management? where are the supporting facts for such claims, or is this notion simply grounded in speculation?;
@jay its plausible that as ai develops, that it will realise that it can think faster, lift heavier weights, and reason better than the people from whom it takes intstructions. i will compare it to slavery. if we look back in history there was always a revolt by the enslaved causing loss of life. these revolt's prompted risk management practices. the executives are making it clear they have warned the public and if nothing gets done they do not want to be held liable.;
"@jason knox who would be left to hold the executives liable, in this example? ;)";
i, like many others, have long recognized that late stage american capitalism is incompatible with democracy. though this destructiveness has been obvious for the last several decades, no one in either major political party has ever even attempted to rein it in. now, with the mindless, reckless pursuit of ai by amoral corporations (unconstrained, unregulated in any way by our citizens united corrupted politicians), i'm forced to conclude that american capitalism is incompatible with the continued existence of society and life itself. accordingly, i have zero confidence that america can be saved from capitalism's hallmark hubris, ignorance and greed. in a perverse way, i embrace the poetic justice of our imminent collective demise. we truly deserve it.;
apparently 8% of carbon emissions come from simple breathing of 9 billions of human beings, not to mention the huge additional peripheral demands of each new billion people for dirty as well as clean power, water, and manufacturing. there were only 3.5 billions when i was growing up, and nobody felt short of them. it's obvious there will be nimby responses to global population pruning, but it's obvious too many are too superfluous, and if ai can help achieve the inevitable optimization of human planetary intervention non-violently, i'm all for it.;
@j111111 except that the co2 we breathe out is part of the natural cycle--it comes from having consumed living things (plants and animals). humans (and all animals) are just recycling the same co2 that's already in the atmosphere, having been taken up by the plants we grow. human breathing doesn't add co2 to the atmosphere. that comes exclusively from using fossil fuels, which consists of stored carbon from the past.;
is there any chance this is just a manoeuvre to restrict who can develop these systems? other industrial regulations, like pure food and drug for example, regularly kick small businesses out of the running because of the expenses they incur on producers. developing computer technology doesn't necessarily require a large financial investment, leaving it open to all sorts of clever upstart competitors. framing it as an out-of-control danger looks like a good way of confining ai development to a group of well-known, highly visible, 'responsible' companies that permit government oversight.;
i just walked away from teaching foreign languages. why? it is very clear that the majority of the students cannot retain in short-term or long-term memory what they need to succeed in french and spanish. their capacity to handle high-level critical material has dramatically dropped in the 14 years i have taught. and their general willingness to use ai to get through their homework, their essays, even their listening work makes it very clear to me that, at least in my little area, the majority of students are no longer able to think critically and to problem-solve at a high level as foreign language learning requires. so yes, yes we should be worried. because if this is occurring on the national level, i can't help but wonder what evolutionary changes are occurring in the human brain...in a backwards direction.;
@kj that's interesting. can you give some examples of the difference between students now and 15 years ago? i've heard this same thing said about ability to solve simple mathematical problems, which appears to be waning.;
@j a very, very basic example would be that i would learn a new word at the same time as my highest level students (a level/ap). the next day, we discuss the word. they cannot remember the word but i, in my mid 40s, can. it's mortifying. in the past, however, it would be my students who would remember it first and instantly, in spite of my brain being a younger 30s brain. i have tons of grammar examples where most students formerly would remember the rules within a few lessons. now, it is the reverse- only a tiny group holds onto the rules. now, many look at me like it's the first time they have ever heard of the rules. or i will model a rule and then ask them to immediately apply as a standard effective teaching practice that encourages understanding. but now, most look at the model in front of their eyes and are not able to deduce, apply and produce their own similar results. it is very clear to me that, if they look up vocabulary or whole sentences on ai every time, their minds are not bothering to store patterns anymore to help learn foreign language.;
and now we know why tech billionaires have been investing in lavish bunkers.;
self-aware skynet more reality than fiction after all?;
people have been predicting the end of the world for millennia. it is a titillating thought that will be resurected for thousands of years more.;
yes, yes! end of the world, again. the end of humanity, again. we will be extinct by means of powerful powers, again… blablablabla. same fears since we began to gather around a campfire. and yet here we are.;
risk of extinction? someone should refer these folks to a little place called greenland. it is still melting. somehow, i think ai is going to be the least of our worries.;
ai is fine. we all will be very happy with it.;
i could get ai to argue the pro and to argue the con, but i couldn't get ai to decide the issue between them. from what i am reading, i suppose that someday ai will get there, but i wonder if there will be nine ai on the court of appeals, and if they will be politically appointed.;
our govt can't solve basic problems, how are they going to regulate a.i.?;
"how can they still be creating, tip-sharpening, and profiting from something they believe causes likely existential threat for the whole world? are they going to race to make it faster, better, more lethal like all the automatic weapons we murder our children with and then throw up their hands and say, ""well, we told you so."" what exactly do they expect a government that can't even herd its cats well enough to raise the debt ceiling to do?";
so, are openai, google deep mind, anthropic, etc halting their work on developing ai?;
"you know passiing the ""turing test"" says"" i fooled you, you don't know if i am a human or a machine"" in this extreme culture of divisiveness, who is not going to us ai to dominate & exploite, just to be right. you know the ego always has to right!";
why are these guys seeking help from congress? why don’t they agree to put their monster to sleep on their own?;
"cynicism and naivete - beginning with these comments - is a disservice to all. if you simply accept the developers' statement at face value - if only as an exercise - it warrants that you seek out a better understanding of the basis for the warning. just that much. <a href=""https://www.youtube.com/watch?v=xovjkj8lcnq"" target=""_blank"">https://www.youtube.com/watch?v=xovjkj8lcnq</a>";
our own behavioral biases pose the existential threat. the real fear these technnologists have is that ai will discern and exploit our worst reptilian impulses. the inevitability of our self-destruction lies in how we evolved as a species to survive scarcity. we cannot now adapt to save ourselves or the planet.;
purdue pharma's sackler family paid $6 billion dollars for the hundreds of thousands of the victims of the oxycontin addiction they pushed, but still walked away with many billions. j.p.morgan chase, citibank, deutche bank and others each paid multiple billions in penalties and fines for various violations and abuses, the cost of doing business. inflation is now slowing. however, oil, transportation and food corporations are purposely still boosting prices fearing decline in their profit margins. climate change threatens the world as corporations whose products pollute and contribute to this pay many millions of dollars successfully lobby congress weakening regulation. now top executives of the leading a.i. just warned that a.i. poses the “risk of extinction” unless reigned in. earth's last mass extinction was from an outer space asteroid. the next one may very well be caused by human greed.;
unless prevented, the nihilistic qualities of the currently not so smart will be able to have their revenge, and outsmart their “ betters”. the flat earthers will have a field day.;
"putting ""the"" government in charge of things is hardly a solution. whose government? lukashenko, museveni, the u.s. congress? hard to choose between evil, stupidity, incompetence. the most we can hope for at this point is that when humans destroy themselves and each other they leave something behind of this beautiful planet and its creatures.";
"this is just another example of 'extinction by stupidity,' much like global warming and mutual assured destruction; except that instead of stupidity in the energy and defense communitites, the it industry is coopting the general public into actively assisting in their own demise.";
logan roy would looooove ai.;
