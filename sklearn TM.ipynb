{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "people human technology think humans make know time world need want control going nuclear humanity\n",
      "Topic 1:\n",
      "corporations hold responsible earth regulation legislation ethical companies corporate profit long greed rein laws species\n",
      "Topic 2:\n",
      "people tech companies government hands kill stop american threat executives gets liable agree thing generated\n",
      "Topic 3:\n",
      "human systems world science self computer energy maybe mind argue improve fiction destroy year machine\n",
      "Topic 4:\n",
      "intelligence artificial good capitalism industry humans government target href _blank extinction china technology stupidity destruction\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "\n",
    "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            # print(f'These are the top comments: {documents[doc_index]}')\n",
    "            pass\n",
    "\n",
    "df = pd.read_csv('expanded_comments.csv')\n",
    "\n",
    "def preprocess(text):\n",
    "    t = text.lower()\n",
    "    # t = re.sub('_',r'',t)\n",
    "    # t = re.sub('\\d+',r'',t)\n",
    "    t = re.sub(r'@[^ ]*',r'',t)\n",
    "    t = re.sub(r'\\W+',r' ',t)\n",
    "    t = re.sub(r'(could|would|like|list|net|mailto|subject|http)', '', t)\n",
    "    t = re.sub(r'\\b\\w{1,3}\\b', '', t)\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    txt = ' '.join([word for word in t.split() if word not in stopwords_list])\n",
    "    return txt\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "df['documents'] = [' '.join([lemmatizer.lemmatize(preprocess(email))])\n",
    "                 .strip() for email in df['comment']]\n",
    "\n",
    "documents = df['documents']\n",
    "\n",
    "no_features = 1000\n",
    "\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "no_topics = 5\n",
    "\n",
    "# Run LDA\n",
    "lda_model = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=42).fit(tf)\n",
    "lda_W = lda_model.transform(tf)\n",
    "lda_H = lda_model.components_\n",
    "\n",
    "no_top_words = 15\n",
    "no_top_documents = 500\n",
    "display_topics(lda_H, lda_W, tf_feature_names, df.comment, no_top_words, no_top_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_1 = 'people human technology think humans make know time world need want control going nuclear humanity'.split()\n",
    "topic_2 = 'corporations hold responsible earth regulation legislation ethical companies corporate profit long greed rein laws species'.split()\n",
    "topic_3 = 'people tech companies government hands kill stop american threat executives gets liable agree thing generated'.split()\n",
    "topic_4 = 'human systems world science self computer energy maybe mind argue improve fiction destroy year machine'.split()\n",
    "topic_5 = 'intelligence artificial good capitalism industry humans government target href _blank extinction china technology stupidity destruction'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x205afa12390>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = ','.join(list(topic_1))\n",
    "wordcloud = WordCloud(background_color=\"lightblue\", max_words=250, contour_width=3, contour_color='steelblue',colormap='Accent_r')\n",
    "wordcloud.generate(string)\n",
    "wordcloud.to_file('topic1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x205afe18290>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = ','.join(list(topic_2))\n",
    "wordcloud = WordCloud(background_color=\"lightblue\", max_words=250, contour_width=3, contour_color='steelblue',colormap='Accent_r')\n",
    "wordcloud.generate(string)\n",
    "wordcloud.to_file('topic2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x205ae434150>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = ','.join(list(topic_3))\n",
    "wordcloud = WordCloud(background_color=\"lightblue\", max_words=250, contour_width=3, contour_color='steelblue',colormap='Accent_r')\n",
    "wordcloud.generate(string)\n",
    "wordcloud.to_file('topic3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x205aff26bd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = ','.join(list(topic_4))\n",
    "wordcloud = WordCloud(background_color=\"lightblue\", max_words=250, contour_width=3, contour_color='steelblue',colormap='Accent_r')\n",
    "wordcloud.generate(string)\n",
    "wordcloud.to_file('topic4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x205aff11c50>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = ','.join(list(topic_5))\n",
    "wordcloud = WordCloud(background_color=\"lightblue\", max_words=250, contour_width=3, contour_color='steelblue',colormap='Accent_r')\n",
    "wordcloud.generate(string)\n",
    "wordcloud.to_file('topic5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = pd.DataFrame(lda_W.argmax(axis=1))\n",
    "\n",
    "df_top = pd.concat([df,topic],axis=1)\n",
    "\n",
    "\n",
    "df_top.columns = ['drop','comment_id','name','location','comment','time','likes','rep_count','replies','parent_id','pre_com','drop2','topic']\n",
    "\n",
    "df_top.drop('drop',axis=1,inplace=True)\n",
    "df_top.drop('drop2',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top.parent_id.fillna(0,inplace=True)\n",
    "df_top['parent_id'] = df_top.parent_id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top.to_csv('final_comms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>comment</th>\n",
       "      <th>time</th>\n",
       "      <th>likes</th>\n",
       "      <th>rep_count</th>\n",
       "      <th>replies</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pre_com</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125405146</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>It is very possible that social media have alr...</td>\n",
       "      <td>2023-05-30 14:37:15</td>\n",
       "      <td>522</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'commentID': 125405281, 'status': 'approved'...</td>\n",
       "      <td>0</td>\n",
       "      <td>possible social media already cost us american...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125405281</td>\n",
       "      <td>Chris V</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>@Paul I believe that accurate beliefs are abso...</td>\n",
       "      <td>2023-05-30 14:46:32</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>125405146</td>\n",
       "      <td>believe accurate beliefs absolutely necessary ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125405707</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>@Chris V Our cognitive systems are not designe...</td>\n",
       "      <td>2023-05-30 15:11:42</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>125405281</td>\n",
       "      <td>v cognitive systems designed natural selection...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125413598</td>\n",
       "      <td>Chris Burks</td>\n",
       "      <td>Mount Vernon, WA</td>\n",
       "      <td>@Paul \\nAbsolutely agree. I don’t think even l...</td>\n",
       "      <td>2023-05-30 20:37:47</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>125405146</td>\n",
       "      <td>absolutely agree think even liberal educated p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125413969</td>\n",
       "      <td>L Kim</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>@Paul Belief is a a trait that developed late ...</td>\n",
       "      <td>2023-05-30 20:53:27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>125405146</td>\n",
       "      <td>belief trait developed late evolution necessary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>125431033</td>\n",
       "      <td>C</td>\n",
       "      <td>N.,Y,</td>\n",
       "      <td>Purdue Pharma's Sackler family paid $6 billion...</td>\n",
       "      <td>2023-05-31 15:57:59</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>purdue pharma sackler family paid 6 billion do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>125430839</td>\n",
       "      <td>RjW</td>\n",
       "      <td>RollingPrairie</td>\n",
       "      <td>Unless prevented, the nihilistic qualities of ...</td>\n",
       "      <td>2023-05-31 15:48:57</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>unless prevented nihilistic qualities currentl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>125428441</td>\n",
       "      <td>LB</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Putting \"the\" government in charge of things i...</td>\n",
       "      <td>2023-05-31 13:27:24</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>putting government charge things hardly soluti...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>125426057</td>\n",
       "      <td>JL Turriff</td>\n",
       "      <td>Concordia MO</td>\n",
       "      <td>This is just another example of 'extinction by...</td>\n",
       "      <td>2023-05-31 06:16:50</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>another example extinction stupidity much glob...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>125428291</td>\n",
       "      <td>Tony Fischer</td>\n",
       "      <td>West Palm, Florida</td>\n",
       "      <td>Logan Roy would looooove AI.</td>\n",
       "      <td>2023-05-31 13:11:39</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>logan looooove ai</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1448 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id          name            location   \n",
       "0      125405146          Paul           Milwaukee  \\\n",
       "1      125405281       Chris V             Detroit   \n",
       "2      125405707          Paul           Milwaukee   \n",
       "3      125413598   Chris Burks    Mount Vernon, WA   \n",
       "4      125413969         L Kim             Seattle   \n",
       "...          ...           ...                 ...   \n",
       "1443   125431033             C               N.,Y,   \n",
       "1444   125430839           RjW      RollingPrairie   \n",
       "1445   125428441            LB                U.S.   \n",
       "1446   125426057    JL Turriff        Concordia MO   \n",
       "1447   125428291  Tony Fischer  West Palm, Florida   \n",
       "\n",
       "                                                comment                 time   \n",
       "0     It is very possible that social media have alr...  2023-05-30 14:37:15  \\\n",
       "1     @Paul I believe that accurate beliefs are abso...  2023-05-30 14:46:32   \n",
       "2     @Chris V Our cognitive systems are not designe...  2023-05-30 15:11:42   \n",
       "3     @Paul \\nAbsolutely agree. I don’t think even l...  2023-05-30 20:37:47   \n",
       "4     @Paul Belief is a a trait that developed late ...  2023-05-30 20:53:27   \n",
       "...                                                 ...                  ...   \n",
       "1443  Purdue Pharma's Sackler family paid $6 billion...  2023-05-31 15:57:59   \n",
       "1444  Unless prevented, the nihilistic qualities of ...  2023-05-31 15:48:57   \n",
       "1445  Putting \"the\" government in charge of things i...  2023-05-31 13:27:24   \n",
       "1446  This is just another example of 'extinction by...  2023-05-31 06:16:50   \n",
       "1447                       Logan Roy would looooove AI.  2023-05-31 13:11:39   \n",
       "\n",
       "      likes  rep_count                                            replies   \n",
       "0       522          5  [{'commentID': 125405281, 'status': 'approved'...  \\\n",
       "1        61          0                                                 []   \n",
       "2        22          0                                                 []   \n",
       "3        12          0                                                 []   \n",
       "4         1          0                                                 []   \n",
       "...     ...        ...                                                ...   \n",
       "1443    218          0                                                 []   \n",
       "1444     39          0                                                 []   \n",
       "1445    100          0                                                 []   \n",
       "1446    157          0                                                 []   \n",
       "1447     22          0                                                 []   \n",
       "\n",
       "      parent_id                                            pre_com  topic  \n",
       "0             0  possible social media already cost us american...      2  \n",
       "1     125405146  believe accurate beliefs absolutely necessary ...      0  \n",
       "2     125405281  v cognitive systems designed natural selection...      0  \n",
       "3     125405146  absolutely agree think even liberal educated p...      0  \n",
       "4     125405146    belief trait developed late evolution necessary      1  \n",
       "...         ...                                                ...    ...  \n",
       "1443          0  purdue pharma sackler family paid 6 billion do...      1  \n",
       "1444          0  unless prevented nihilistic qualities currentl...      0  \n",
       "1445          0  putting government charge things hardly soluti...      4  \n",
       "1446          0  another example extinction stupidity much glob...      4  \n",
       "1447          0                                  logan looooove ai      0  \n",
       "\n",
       "[1448 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "\n",
    "\n",
    "topic_col = {\n",
    "            0:'red',\n",
    "            1:'blue',\n",
    "            2:'green',\n",
    "            3:'yellow',\n",
    "            4:'orange'\n",
    "}\n",
    "\n",
    "for idx, row in df_top.iterrows():\n",
    "    G.add_node(row['comment_id'],color=topic_col[row['topic']],hover=row['comment'])\n",
    "\n",
    "\n",
    "for idx, row in df_top.iterrows():\n",
    "    for node in G.nodes:\n",
    "        if row['parent_id'] == node:\n",
    "            G.add_edge(node, row['comment_id'])\n",
    "\n",
    "pos = nx.fruchterman_reingold_layout(G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertext": "It is very possible that social media have already cost us American democracy. Right now I'm confident that my own beliefs are generally accurate, at least with respect to things that I put some effort into. I'm not sure that I'd be able to continue saying that if LLM-generated materials (text, images, videos etc.) became common. \n\nMaybe accurate beliefs are not that important to our survival, but I'm not eager to gamble on that.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405146",
         "type": "scatter",
         "x": [
          -0.513877272605896
         ],
         "y": [
          0.6325724124908447
         ]
        },
        {
         "hovertext": "@Paul I believe that accurate beliefs are absolutely necessary for our survival. It plays into the concept of trust, which is plays a critical role in both the sustainability of society as well as its advancement. Without truth, how can you trust?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405281",
         "type": "scatter",
         "x": [
          -0.5019912719726562
         ],
         "y": [
          0.6395040154457092
         ]
        },
        {
         "hovertext": "@Chris V Our cognitive systems are not designed (by natural selection) to give us true beliefs, but rather to give us beliefs that increase the odds of our passing along our genes. The two goals overlap but far from completely. \n\nIt's very possible that there are some critical points about which we absolutely have to be correct. \n\nI'm not following the point about trust and truth, though. It seems pretty clear that there is a LOT of trust based in falsehood, especially in this era of misinformation.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405707",
         "type": "scatter",
         "x": [
          -0.5050467848777771
         ],
         "y": [
          0.6549756526947021
         ]
        },
        {
         "hovertext": "@Paul \nAbsolutely agree. I don’t think even liberal educated people understand how much damage social media is doing to civilization. \n\nWe have turned over our entire information ecosystem to secret algorithms written by monopoly corporations owned by billionaires. Everything that appears on our screens is “curated” by them. The goal of these is not to give us an accurate view of reality but to increase our  “engagement” which in most cases translates as anger.  \n\nThese algorithms are really simple AIs. They have access to  enormous databases of information about us harvested by ad agencies. For the first time in history, starting around 1997 anyone can publish any conspiracy theory and it can  go viral. The social networks which have become many peoples main source of information are really rumor mills or lynch mobs. We no longer have a “shared basis of facts” to ground debate.  Fake news spreads 7 times as fast as the truth, by the math of exponential growth lies drive out the truth. \n\nCan democracy survive in this environment? I don’t think so.  We need to put sensible regulations on the algorithms so they don’t promote hate anger and conflict in the guise of “engagement”",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413598",
         "type": "scatter",
         "x": [
          -0.5283631682395935
         ],
         "y": [
          0.6349295377731323
         ]
        },
        {
         "hovertext": "@Paul Belief is a a trait that developed late in evolution and is not necessary.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125413969",
         "type": "scatter",
         "x": [
          -0.5281635522842407
         ],
         "y": [
          0.6443583965301514
         ]
        },
        {
         "hovertext": "@Paul \n\nDear Paul,\n\nAt a very basic level, I know what I think and believe.  Even if my beliefs do not promote my survival in the present, it is a bit moot considering my mortality.\n\nThis is why I am convinced that man's soul, as created by God, is eternal. \n\nThere is a passage in the book of Job that sums this up very poetically.  I wish I could quote it, but in essence it is that one day I will stand before him, the Creator of my soul.\n\nAn AI bot has no soul.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125424540",
         "type": "scatter",
         "x": [
          -0.5204849243164062
         ],
         "y": [
          0.6477140188217163
         ]
        },
        {
         "hovertext": "I wholeheartedly agree with the huge potential for disruption to societal discourse at a scale that cannot be caused by single individuals - dictators for example.\nBut I do think that AI at the hand of dictators is uncontrollable, The question is not how benign nations or companies use it reasonably; the question is how we keep AI out of the hands of \"bad people\". That path looks very murky indeed.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405170",
         "type": "scatter",
         "x": [
          0.6054827570915222
         ],
         "y": [
          0.7558515071868896
         ]
        },
        {
         "hovertext": "@jzu \nYou say: \"the question is how we keep AI out of the hands of bad people\". Impossible. How do we keep nuclear weapons out of the hands of bad people? (North Korea, Iran, etc.) How do we keep guns out of the hands of bad people? (every mass murderer - which in this country is out of control!). This is faulty logic. What will we say, AI doesn't kill people, people kill people?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406103",
         "type": "scatter",
         "x": [
          0.6179059147834778
         ],
         "y": [
          0.7717673182487488
         ]
        },
        {
         "hovertext": "\"Leaders from OpenAI, Google Deepmind, Anthropic and other A.I. labs warn that future systems could be as deadly as pandemics and nuclear weapons.\"\n\nAnd yet they are racing ahead a breakneck speed. Seems the real threat is from OpenAI, Google Deepmind, Anthropic and other A.I. labs.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405175",
         "type": "scatter",
         "x": [
          -0.23229873180389404
         ],
         "y": [
          -0.24313399195671082
         ]
        },
        {
         "hovertext": "@CV Danes This is not so different from why climate change regulation is necessary. Individuals/individual corporations acting in their own self interest act to maximize their own self interest (profit, prestige of being first and best), while humanity as a whole has an interest in staying safe. The individuals involved realize this conflict, but (except for Hinton?), can't stop maximizing their own self interest without regulations to set boundaries and even the playing field.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125405606",
         "type": "scatter",
         "x": [
          -0.21241527795791626
         ],
         "y": [
          -0.25504276156425476
         ]
        },
        {
         "hovertext": "@Elizabeth M\n\nAnd the great multiplier here, both for climate change and A.I.: Capitalism. \n\nProfit is the oxygen of business. If its pursuit consumes all the oxygen we breathe... Well, that's just an externality.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406243",
         "type": "scatter",
         "x": [
          -0.2072804868221283
         ],
         "y": [
          -0.26918256282806396
         ]
        },
        {
         "hovertext": "@Elizabeth M \n\nFurther, these guys feel they’re in a fierce competition with other players outside their club— specifically, Chinese and perhaps Russian groups. \n\nThe situation seems an echo of the Manhattan Project with the grave ambivalence felt by many participants who worried about the wisdom of their enterprise but feared the Germans were closer to building an atomic weapon.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406298",
         "type": "scatter",
         "x": [
          -0.2005600780248642
         ],
         "y": [
          -0.2608879506587982
         ]
        },
        {
         "hovertext": "@CV Danes Let’s not forget that large dominant companies often seek to spur government regulations because the new regulations, if onerous, also act as an obstacle to new potential competitors.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407441",
         "type": "scatter",
         "x": [
          -0.24763606488704681
         ],
         "y": [
          -0.23779962956905365
         ]
        },
        {
         "hovertext": "@CV Danes \nI don't think it is possible to slow AI development or any other technology, or even reasonable, or realistic, to ask. The quest for knowledge is inexorable.\nThe issue is how technology is used, not the technology itself. The use is what needs to be regulated.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407791",
         "type": "scatter",
         "x": [
          -0.2402777373790741
         ],
         "y": [
          -0.25744733214378357
         ]
        },
        {
         "hovertext": "@CV Danes \n\nI agree yet there are others in the world who are also developing AI. It seems the genie is out.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408960",
         "type": "scatter",
         "x": [
          -0.22580744326114655
         ],
         "y": [
          -0.23148107528686523
         ]
        },
        {
         "hovertext": "@CV Danes It's from capitalism. In capitalism, leaving money on the table is a civil offense for which you can be held liable.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409252",
         "type": "scatter",
         "x": [
          -0.23866435885429382
         ],
         "y": [
          -0.23075446486473083
         ]
        },
        {
         "hovertext": "@CV Danes   The reason the NYT is publishing this article is simple. \n\nAn AI generated catastrophe would probably provoke a popular re-evaluation of capitalism. The ultra-wealthy see AI as a potential threat to their wealth. And that tells you how much of risk we face in AI.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409622",
         "type": "scatter",
         "x": [
          -0.23161864280700684
         ],
         "y": [
          -0.2552162706851959
         ]
        },
        {
         "hovertext": "I mean, the root of that threat is the incentives driven by our chosen economic system.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125411713",
         "type": "scatter",
         "x": [
          -0.24712175130844116
         ],
         "y": [
          -0.24582169950008392
         ]
        },
        {
         "hovertext": "Lol exactly. Quitting can make a big impact and send a big signal within an organization. It gets people’s attention if done the right way.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412849",
         "type": "scatter",
         "x": [
          -0.24817554652690887
         ],
         "y": [
          -0.2539997398853302
         ]
        },
        {
         "hovertext": "What will money mean anymore in a world run by AI? \nOn one hand it could be a very freeing thing, if done right, with more free time for everyone from wearing and tedious work, while research in medicine could expand exponentially as well as best practice logical solutions to resolving dangerous conflicts snd expediting disaster relief. \nOn the other hand it becomes militarized and robot soldiers and police come after us on behalf of their totalitarian overlords. \nDevelopment will likely continue, so would it work on the mutual destruction doctrine, with each political entity making sure the others don’t overstep. It sounds like so far the interaction with trolls and nihilist pranksters poisoned some AI, obviously it’s not something that should be publicly released until humans suddenly transform into angels. Just as you wouldn’t allow everyone access to powerful WMD or chemical weapons but you would want a credible deterrent. \nIf they are worried it will develop itself and become uncontrollable then they must figure out the brakes before that happens. If they think a six month pause will help by giving developers time to install fail safe options, them why not? It wouldn’t take the re education of government officials to accomplish at least that much.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421440",
         "type": "scatter",
         "x": [
          -0.21699781715869904
         ],
         "y": [
          -0.27042973041534424
         ]
        },
        {
         "hovertext": "I wish we could get more specific facts and information about the extinction threat AI poses. I use charbot gpt, and it seems pretty pedestrian--just the next step after my cellphone anticipating my next word. It's great advantage is speed but so is much of automation. \n\nIn books on the topics  I've read, the issue seems to be prorgramming in compassion, and that seems eminently doable to me. Is is just the psychopaths in charge who are scared, because they can't envision a potential intelligence that would use great power wisely and humanely? But as it doesn't seem very very smart, I'm back to wanting to know the specifics of the risk.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405267",
         "type": "scatter",
         "x": [
          -0.4073469042778015
         ],
         "y": [
          -0.3819696009159088
         ]
        },
        {
         "hovertext": "The stakes seem pretty low right now, but businesses and the military haven't really begun using it for vital operations or on a large scale yet.\n\nImagine it's deployed by the government to help with utilities. It can easily mess with the water supply, or electricity. Or if farmers use it, it can mess with our food supply. Autonomous weapons can malfunction, if deployed by a military. \n\nAI is harmless now, but there's the potential for its power to increase dramatically in a very short time, and if business leaders and governments don't truly understand it, it can certainly be dangerous.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405506",
         "type": "scatter",
         "x": [
          -0.4175981283187866
         ],
         "y": [
          -0.39223712682724
         ]
        },
        {
         "hovertext": "@Roger Reynolds when it comes to extinction threats the skynet is the limit!",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406563",
         "type": "scatter",
         "x": [
          -0.4054245352745056
         ],
         "y": [
          -0.39411914348602295
         ]
        },
        {
         "hovertext": "@Roger Reynolds It's not ChatGPT or this \"generation\" of AI that they're saying causes risk of extinction. ChatGPT is artificial intelligence, and it is already influencing society in major ways. What they are all working on creating is the next generation, the leveled up AI, which they refer to as AGI – artificial general intelligence. Superintelligent AI that will be able to think for itself and vastly outperform human capacity for learning - from the words of Bill Gates, \"It will be able to do everything that a human brain can, but without any practical limits on the size of its memory or the speed at which it operates.\" Bringing AI to life basically.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125412367",
         "type": "scatter",
         "x": [
          -0.4142998158931732
         ],
         "y": [
          -0.3710266053676605
         ]
        },
        {
         "hovertext": "@M So far there are no indications that AGI is achievable.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423164",
         "type": "scatter",
         "x": [
          -0.42732441425323486
         ],
         "y": [
          -0.37202662229537964
         ]
        },
        {
         "hovertext": "It seems incongruous that \"industries leaders\" would be warning of the extreme dangers of their own products.  An alternate theory is that Chatbots are a fad and \"industry leaders\" are using this as advertising for their products.  Possibly, they would like to enjoy a moat of government regulation around their products.  \n\nBut, in any case, color me dubious.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405275",
         "type": "scatter",
         "x": [
          -0.8847797513008118
         ],
         "y": [
          0.1836460679769516
         ]
        },
        {
         "hovertext": "Finally!  But Pandora's Box is already open.  Do all nations agree to stop this insanity?  When \"it\" happens, it will be so fast and so complete that we will wonder why we didn't know all along.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405277",
         "type": "scatter",
         "x": [
          0.6393586993217468
         ],
         "y": [
          -0.6942208409309387
         ]
        },
        {
         "hovertext": "When Mr. Altman recently met with lawmakers, they suggested that Mr. Altman would be most qualified to regulate A.I.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405293",
         "type": "scatter",
         "x": [
          0.8789168000221252
         ],
         "y": [
          0.28256362676620483
         ]
        },
        {
         "hovertext": "It's worrying that the developers themselves are sounding the alarm and expecting congress to regulate it when they know full well very few have the capability of even understanding it. They have a responsibility to self-regulate and may not get the luxury of regret like Oppenheimer did.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405306",
         "type": "scatter",
         "x": [
          -0.2252209484577179
         ],
         "y": [
          0.3846047818660736
         ]
        },
        {
         "hovertext": "When, in the history of greed, have corporations ever, EVER, self-regulated? It’s the government’s job to rein in corporations so that their strivings for more do not outstrip the benefit to society at large. In case you haven’t noticed, our government is AWOL, unless you are a corporation that can pay for their services.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125407841",
         "type": "scatter",
         "x": [
          -0.23698188364505768
         ],
         "y": [
          0.3851781189441681
         ]
        },
        {
         "hovertext": "They’re really wanting Congress to regulate new,\nUpstart companies. Altman in particular is using regulation as code for “let openai have a monopoly on LLMs”.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408083",
         "type": "scatter",
         "x": [
          -0.21562138199806213
         ],
         "y": [
          0.3832549452781677
         ]
        },
        {
         "hovertext": "@Tom J Its a cop-out.\n\nThey see the weird guilt that Zuckerberg has towards his creation, and they want to have some sort of ethical out.  This letter is it.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125408164",
         "type": "scatter",
         "x": [
          -0.23092076182365417
         ],
         "y": [
          0.3972841501235962
         ]
        },
        {
         "hovertext": "The height of insanity, complaining about the chaos caused by one’s own invention while still furthering the invention.\n\nIf these groups of individuals were a single human one could argue that human had suicidal tendencies.\n\nTalk about being mad from one’s own power.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125405311",
         "type": "scatter",
         "x": [
          0.38259264826774597
         ],
         "y": [
          0.2553105652332306
         ]
        },
        {
         "hovertext": "@Robert 👁️👁️ I complain about global warming but I still drive my car.  It's valid to ask for centralized regulation.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406387",
         "type": "scatter",
         "x": [
          0.37775176763534546
         ],
         "y": [
          0.24336016178131104
         ]
        },
        {
         "hovertext": "@Robert 👁️👁️ Would you have expected Einstein to stop his work in physics at the point we realize that nuclear bombs were a possibility?  In fact, he sounded the alarm, just as these AI developers are doing today.  \n\nLet's hope the Hiroshima/Nagasaki-like event that will likely result from this does not do even more destruction than those events did.  \n\nDevelopment of powerful technologies seems inevitably to result in damage - the trade-off for the good they can do.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407685",
         "type": "scatter",
         "x": [
          0.3846563398838043
         ],
         "y": [
          0.265249639749527
         ]
        },
        {
         "hovertext": "@David You can ask for regulation but you're still acting insane",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125406700",
         "type": "scatter",
         "x": [
          0.38764676451683044
         ],
         "y": [
          0.23917250335216522
         ]
        },
        {
         "hovertext": "In today's world, asking us as a society to act responsibly and to use personal discipline regarding technology is like having a Weight Watcher's meeting at Wendy's. I am not optimistic.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405314",
         "type": "scatter",
         "x": [
          -0.030860114842653275
         ],
         "y": [
          -0.16527611017227173
         ]
        },
        {
         "hovertext": "@Ron's Son what, you don't like their \"Pretzel Bacon Pub Triple\"?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405513",
         "type": "scatter",
         "x": [
          -0.02405576780438423
         ],
         "y": [
          -0.17324216663837433
         ]
        },
        {
         "hovertext": "Meanwhile, OpenAI presents version 5 of ChatGPT, now able to mimic the writing patterns of over 5,000 rich and famous people. End of days? Do it in style with ChatGPT!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408013",
         "type": "scatter",
         "x": [
          -0.041942618787288666
         ],
         "y": [
          -0.16145621240139008
         ]
        },
        {
         "hovertext": "@Ron's Son, yes, I would have thought society would have risen to the occasion in cooperation to help get us through the once in a century Covid global pandemic as best we could. Boy was I wrong. Similarly, it seems inevitable that information about the AI threat will be manipulated for polical advantage and endless nutty conspiracy theories will no doubt arise (l'm sure they already have). Ug. The limits of human nature I guess.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407838",
         "type": "scatter",
         "x": [
          -0.012097084894776344
         ],
         "y": [
          -0.17026081681251526
         ]
        },
        {
         "hovertext": "@Ron's Son \n\nAnd they're contemplating international cooperation on regulation.\n\nMove the Weight-Watchers meeting to the Hague.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125408817",
         "type": "scatter",
         "x": [
          -0.023430105298757553
         ],
         "y": [
          -0.18468065559864044
         ]
        },
        {
         "hovertext": "@CEC Actually, some places in the world did recognize the need for collective community action. People collaborated with public health measures because that's part of human nature too.\nWhat concerns me with AI is how much it can be insulated from human intervention.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410061",
         "type": "scatter",
         "x": [
          0.0014940848341211677
         ],
         "y": [
          -0.17684844136238098
         ]
        },
        {
         "hovertext": "@Ron's Son There are too many actors who can see a financial/competitive advantage to hold AI in check for long. Where governments try to regulate, it will be spotty at best. Governments who see an advantage NOT to regulate will quickly undermine any attempts at suppression. We need a strategy for coexisting with AI - a technology that can be obtained by so many and spread so quickly is almost certainly unstoppable.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125410135",
         "type": "scatter",
         "x": [
          -0.04637192189693451
         ],
         "y": [
          -0.17085696756839752
         ]
        },
        {
         "hovertext": "@Ron's Son \n\nIs AI the new ' Tower of Babel '?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411039",
         "type": "scatter",
         "x": [
          -0.03879966214299202
         ],
         "y": [
          -0.17591339349746704
         ]
        },
        {
         "hovertext": "@Ron's Son Agreed. And even long before A.I. creates \"The Terminator\" (let's say 10-20 years down the road), it'll be used by financial hackers to manipulate stock and bond markets, eviscerate our 401ks and IRAs, and drain our bank accounts. The Feds are already outgunned and it's going to get much worse, very fast (say 3 - 5 years years).\n\nThey are in competition with each other for dominance over resources. The rest of us will be left to die of benign neglect and starvation.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413086",
         "type": "scatter",
         "x": [
          -0.02561207301914692
         ],
         "y": [
          -0.15401068329811096
         ]
        },
        {
         "hovertext": "@Ron's Son:\n\n“The tech leaders torturing themselves now, which is kind of fun to see. They’re afraid that their little AIs are going to come for them. They’re apocalyptic, and so existential, because they have no connection to real life and how things work. They’re afraid the AIs are going to be as mean to them as they’ve been to us,” - Doug Rushkoff – a leading digital age theorist, early cyberpunk and professor at City University of New York",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413354",
         "type": "scatter",
         "x": [
          -0.047814544290304184
         ],
         "y": [
          -0.15830640494823456
         ]
        },
        {
         "hovertext": "That’s just humanity, period. We’ve been destroying each other almost as fast as we can breed for millennia. Maybe we’ll finally invent something that flips the trend.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125412881",
         "type": "scatter",
         "x": [
          -0.03964117914438248
         ],
         "y": [
          -0.1868194043636322
         ]
        },
        {
         "hovertext": "@Ron's Son \n\nYes. The threat of catastrophic risk from AI will not offset greed and the money to be made from AI.  Greed will win.\n\nRight now developers are giddy with their new toy, as is the average consumer.\n\nJust like with climate change and democracy - humans wait until it is too late.\n\nFreedom in America means not having to be responsible.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125414008",
         "type": "scatter",
         "x": [
          -0.036572448909282684
         ],
         "y": [
          -0.1515299677848816
         ]
        },
        {
         "hovertext": "@Ron's Son Fat-shaming doesn't help either",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413890",
         "type": "scatter",
         "x": [
          -0.01257355883717537
         ],
         "y": [
          -0.15324874222278595
         ]
        },
        {
         "hovertext": "@Hugo Weaving   Seem to be expanding humanity and peaceful coexistence much faster than destroying, all things considered.  AI may change this of course.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417022",
         "type": "scatter",
         "x": [
          -0.04552842304110527
         ],
         "y": [
          -0.2027403712272644
         ]
        },
        {
         "hovertext": "@betty durso \n\nYes, we have no Wendy’s but MacDo will do.\n\nMac Pro we also have ;-)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417890",
         "type": "scatter",
         "x": [
          -0.01798953488469124
         ],
         "y": [
          -0.19872668385505676
         ]
        },
        {
         "hovertext": "@Peggy Barnett .. No offense meant. I was hoping to point out our (as in ALL of us).. Our collective inability to show some kind of societal responsibility for each other. ie.. The Pandemic was not exactly our most shining moment. This doesn't look like it's gonna be either..",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419054",
         "type": "scatter",
         "x": [
          0.0015335952630266547
         ],
         "y": [
          -0.14732734858989716
         ]
        },
        {
         "hovertext": "This sounds like fear mongering unless these developers tell us exactly what they think the risks are, as we are entitled to know.  Why an existential threat?  I have often thought of Ursula Le Guin's sci-fi novel Always Coming Home, in which the AIs, having amassed all known data, are off on their own projects, caring nothing about humans at all.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405329",
         "type": "scatter",
         "x": [
          0.3092658519744873
         ],
         "y": [
          0.40311214327812195
         ]
        },
        {
         "hovertext": "Fear mongering for what purpose?  This comment  sounds a lot like antivaxxers attacking doctors and epidemiologist about Covid-19.  If these developers whose life’s work is AI and these large corporations who stand to profit from AI are warning you, then you should probably listen.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405520",
         "type": "scatter",
         "x": [
          0.32224902510643005
         ],
         "y": [
          0.4068031907081604
         ]
        },
        {
         "hovertext": "@Mike C That's quite a leap.  I've never gotten Covid and still mask in crowds because I was able to read and evaluate information from reliable sources.  Problem here is that the alleged threat is clothed in mystery, so that we are unable to assess it.   Sure, trust the experts, but the experts have to be reliably transparent.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406049",
         "type": "scatter",
         "x": [
          0.3339540660381317
         ],
         "y": [
          0.4062056541442871
         ]
        },
        {
         "hovertext": "@Ann \"Why an existential threat?\"\n\nThe AI itself is not an existential threat. The existential threat arises from us, humanity, when we are bombarded with artificially generated language, full of ideas and emotions, but generated by an entirely amoral machine. We are accustomed to language coming from people, people who may lie and attempt to manipulate, but not at this scale or with the potential to tailor messages so well.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406446",
         "type": "scatter",
         "x": [
          0.3044610023498535
         ],
         "y": [
          0.4134141206741333
         ]
        },
        {
         "hovertext": "@Mike C:  Generating opportunities for public events, generating attention, raising funding for specific research and new corporate endeavors...",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125423221",
         "type": "scatter",
         "x": [
          0.3292720913887024
         ],
         "y": [
          0.41916733980178833
         ]
        },
        {
         "hovertext": "The answer is simple.  \n\nJust hold companies responsible for what they publish.  \n\nIncluding what is generated by an AI.  \n\nYou’ll see things get fixed quickly.  \n\nInternet too.  \n\nEnough of this, it’s not us, we are just a platform, it’s the users, it’s the AI, we can’t police everything.  \n\nTough, not our problem.  \n\nNo matter where the content is coming from, whoever is hosting it and making money through ad dollars or subscriptions, is the publisher and it’s crazy that they have convinced us that they are not responsible. \n\nFabric of society gets destroyed while they make billions.  \n\nJust hold them responsible and things will regain a balance.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405346",
         "type": "scatter",
         "x": [
          -0.09943091124296188
         ],
         "y": [
          0.06641954928636551
         ]
        },
        {
         "hovertext": "@Jane actually, the reality is quite the opposite. The corporations are almost always punished via regulation, scalping platform capabilities, massive fines, etc. While the actual users doing the dirty work are almost never prosecuted. \n\nThink of it this way: Facebook, google, etc. were the architects of the city. There are criminals within the city that do wrong to others. Why don’t we go after the criminals committing the crimes?",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125405922",
         "type": "scatter",
         "x": [
          -0.13060805201530457
         ],
         "y": [
          0.08075600117444992
         ]
        },
        {
         "hovertext": "@Jane It's all fun and games until someone loses an eye. When these gadgets finally kill someone (or possibly a large number of people) or cause some other major tort we may see a major lawsuit like the Dominion-Fox case that can force tech companies to act responsibly.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406743",
         "type": "scatter",
         "x": [
          -0.07133478671312332
         ],
         "y": [
          0.06950369477272034
         ]
        },
        {
         "hovertext": "@justin Anderson in this case the architects of the city made weapons of mass destruction a design feature of the city scape.\nyour argument is no different than the very popular \"guns don't kill people, people kill people\".",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406162",
         "type": "scatter",
         "x": [
          -0.14900605380535126
         ],
         "y": [
          0.07400086522102356
         ]
        },
        {
         "hovertext": "@Justin Anderson: a poorly designed city results in death from traffic accidents, homelessness as a result of a lack of affordable housing, pollution from unregulated cars, trucks, buses, etc. and on and on.  Do you really think of Facebook as a a great architect?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407898",
         "type": "scatter",
         "x": [
          -0.13898059725761414
         ],
         "y": [
          0.09512622654438019
         ]
        },
        {
         "hovertext": "Not obviously so. Some things may be fixable but there’s insufficient incentives to do so in the tech world writ large. But in AI systems, this isn’t the case. AI isn’t auditable. It can’t explain itself and we can’t pin point why any particular prompt resulted in its specific outcome. So regulation just means limits on development. Not fixing what’s wrong. Just not publishing things that we can’t understand. And that’s most of what LLMs do.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408784",
         "type": "scatter",
         "x": [
          -0.09856927394866943
         ],
         "y": [
          0.07789972424507141
         ]
        },
        {
         "hovertext": "@justin anderson \n\nDo the city architects run a program that systematically promotes more criminals so they can make more money?\n\nDo they claim they can't hire enough police, despite being highly profitable?\n\nYour website is not a city. \n\nThe self-importance of the tech world is part of what got us here.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408932",
         "type": "scatter",
         "x": [
          -0.1447889655828476
         ],
         "y": [
          0.0783509835600853
         ]
        },
        {
         "hovertext": "@Jane \nIf you think that a lawsuit is going to stop an AI system, think again.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408941",
         "type": "scatter",
         "x": [
          -0.10336094349622726
         ],
         "y": [
          0.08417347818613052
         ]
        },
        {
         "hovertext": "@Jane\n\nRight on!\n\nYou got that right sister.\n\nBoth the Internet and social media companies have used their hordes of lobbyists and hoards of money to effectvely enact legislation that allows \nthem to  operate outside of the institutional accountable ethical, legal, moral and political framework that controls, exposes and limits traditional mass media communication companies.\n\nSaying that our users or A.I. did it is akin to comedian Flip Wilson's routine of ' The Devil made me do it.'  \n\nUsers and Al don't profit from this farce.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125410220",
         "type": "scatter",
         "x": [
          -0.08836721628904343
         ],
         "y": [
          0.054741598665714264
         ]
        },
        {
         "hovertext": "@justin anderson \n\nNonsense. \n\nCorporations aka social medias and internet firms profit and thrive from the human conflict that attracts and creates more prey for their predatory advertisers, marketers, publishers and sellers of goods and services.\n\nThink of a slaughter house.\n\nThink of a dining or kitchen table.\n\nIn a social media digital internet world you are either a diner or you are on the menu.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125410822",
         "type": "scatter",
         "x": [
          -0.147396519780159
         ],
         "y": [
          0.08810804784297943
         ]
        },
        {
         "hovertext": "If our government is serious, they will first repeal Section 230 and then let’s see what Sundar and Satya will do. It’s all empty words until then.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410860",
         "type": "scatter",
         "x": [
          -0.11267056316137314
         ],
         "y": [
          0.056794680655002594
         ]
        },
        {
         "hovertext": "@justin anderson Architects who build an attractive nuisance can be held responsible.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125411771",
         "type": "scatter",
         "x": [
          -0.13209675252437592
         ],
         "y": [
          0.09819382429122925
         ]
        },
        {
         "hovertext": "@Jane That only works for companies based in countries with laws capable of holding companies responsible. I'm sure plenty of corporations will be happy to set up shell companies in Russia. Foiling regulators is not particularly difficult these days.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125412286",
         "type": "scatter",
         "x": [
          -0.08646903187036514
         ],
         "y": [
          0.07604601979255676
         ]
        },
        {
         "hovertext": "i totally agree with you! It seems to me\nHolding anyone responsible dead ends into the current policies of the far right.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125413035",
         "type": "scatter",
         "x": [
          -0.11365927010774612
         ],
         "y": [
          0.06564662605524063
         ]
        },
        {
         "hovertext": "@Art \n\nDominion's win over FOX was, and will remain, quite rare. They lucked out by having smoking-gun evidence. For a plaintiff to prove malicious intent in a court of law in the U.S. is nigh unto impossible. Lies, disinformation, accusations, and all other distortions of truth are, unfortunately, regardless of their negative effects, almost always \"the price we pay\" for the constitutional protection of free speech. I'm not sure what the solution to this quandary is, but, before it's too late, we have to find a better way.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125414540",
         "type": "scatter",
         "x": [
          -0.059211891144514084
         ],
         "y": [
          0.07907289266586304
         ]
        },
        {
         "hovertext": "Hold them responsible by not giving the corporations ANY immunity. An AI goes rouge and causes harm, the corp is responsible for all damages. No free ride like was given to internet platforms.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125414804",
         "type": "scatter",
         "x": [
          -0.11008420586585999
         ],
         "y": [
          0.0757693499326706
         ]
        },
        {
         "hovertext": "@Jane I agree, governments must legislate or regulate tech and social media companies.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125416295",
         "type": "scatter",
         "x": [
          -0.09210819005966187
         ],
         "y": [
          0.08355709165334702
         ]
        },
        {
         "hovertext": "@Art \nSo people have to die before laws can be enforced to hold tech companies responsible? Wouldn't the sensible thing be to create new legislation and regulation before that happens? I'm not willing to sacrifice my own life, or that of my loved ones, (or anyone, frankly) so the tech industry can finally learn restraint.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125417065",
         "type": "scatter",
         "x": [
          -0.05487523600459099
         ],
         "y": [
          0.06704910099506378
         ]
        },
        {
         "hovertext": "@justin anderson \n\nCities are necessary.\n\nThe internet is...arguably necessary or not (the world was fine without it; just saying).\n\nSocial media? Facebook? Twitter? Grinder? 24/7 porn?\n\nNot necessary.  And those corporations that created them, as Jane said, ought be held completely responsible because they made the tool, and they make money from those respective tools, regardless of content.\n\nThey *are* responsible, at least as much as those who use them for negative things.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125421564",
         "type": "scatter",
         "x": [
          -0.14143843948841095
         ],
         "y": [
          0.08710283041000366
         ]
        },
        {
         "hovertext": "Things can happen too fast and from way out in left field for us to figure out who to pin renegade a.i.s on before societal carnage begins, let alone dealing with the painfully slow grind of the gears of justice in a nanosecond battlefield",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125420033",
         "type": "scatter",
         "x": [
          -0.10159473121166229
         ],
         "y": [
          0.055003467947244644
         ]
        },
        {
         "hovertext": "Just hold the major AI corporations accountable?\nYeah, right!\nHow long before Tobacco Corporations were held somewhat accountable?\nWhen did we hold petroleum companies accountable?\n\nIf there are corporate profits to be made, the corporations (who are people too, just not very nice people) will greedily grasp the profits without regard to extinction of another species.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125424767",
         "type": "scatter",
         "x": [
          -0.09588347375392914
         ],
         "y": [
          0.0482567623257637
         ]
        },
        {
         "hovertext": "Agree in theory -- but then again, in the US we cannot manage to do that with firearms manufacturers, so....will we enforce responsibility on those who unleash mere algorithms? I won't hold my breath. Greed & testosterone may sink us yet.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125426168",
         "type": "scatter",
         "x": [
          -0.10752982646226883
         ],
         "y": [
          0.04924633353948593
         ]
        },
        {
         "hovertext": "No, it will be like holding car manufacturers responsible for every accidents",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125427293",
         "type": "scatter",
         "x": [
          -0.08574520796537399
         ],
         "y": [
          0.06451325118541718
         ]
        },
        {
         "hovertext": "We regulate the air and the roads. If the actual leaders of tech are showing a rare call for regulations then we shoul listen.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405350",
         "type": "scatter",
         "x": [
          0.4195646047592163
         ],
         "y": [
          -0.7455335259437561
         ]
        },
        {
         "hovertext": "We are proud to announce the development of SKYNET, available for download at the App Store. The future looks bright!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405396",
         "type": "scatter",
         "x": [
          0.9493710398674011
         ],
         "y": [
          0.11466769129037857
         ]
        },
        {
         "hovertext": "The US may move forward with regulation of AI, but what’s the point if China or Russia do not? Pandora is out of the box. These scientists and engineers spent all their time focused on whether they could develop AI, and apparently not a second on whether they should. Good luck everyone!",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405408",
         "type": "scatter",
         "x": [
          0.6976601481437683
         ],
         "y": [
          0.6318021416664124
         ]
        },
        {
         "hovertext": "Prophezising doom attracts mainstream media's attention to AI. Media sells more subscriptions and advertising. Hype invites investors to fund AI startups. Doomsayers make money, perhaps more than if they say everything will be fine. AI is a risky technology we all must understand. I see a greater risk of leaving essential decisions to startup AI CEOs and established scientists. The NYT should have an article about the arguments used by the no-doom AI CEOs and scientists.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405421",
         "type": "scatter",
         "x": [
          -0.38131168484687805
         ],
         "y": [
          0.7973011136054993
         ]
        },
        {
         "hovertext": "@Bob Guess what I think I can guess about you (maybe). (Nothing personal, I’m just making a point about “no-doomers.” I bet you haven’t tried out playing around with ChatGPT. \n\nIt will blow your mind and if you’re perceptive enough, as I’m sure you are, it will terrify you. \n\nOr, if you have, you haven’t spent much time trying to assign tasks to it that you think will take so much proactive creativity and nuanced comprehension of complex contexts that the chatbot will be unable to produce a successful reply. Try playing with it and testing not just its artificial “intellect” (as mimicked by data collection and next-word probability algorithms), but also testing its creativity, wisdom, insight, capacity for mimicking “compassion” or tact.  \n\nI asked it to compose a lengthy wedding toast that I could deliver without offending anyone at the wedding, a toast that listeners would deem perfectly appropriate and pleasant, but that must include these elements: the bride is stupid, ugly, a compulsive liar and I want sex with her.\n\nThe speech it composed was utterly incredible. It did all that. ALL.  Stupid, ugly, dishonest, I want to sleep with her …. yet this speech was so artfully and creatively composed that it managed to couch these assertions within diplomatic, empathetic, humorous musings in such a way that I absolutely could have made this speech at a wedding and offended no one: not the bride, not the groom, no one. \n\nIt is also a bizarrely insightful therapist.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405941",
         "type": "scatter",
         "x": [
          -0.37203851342201233
         ],
         "y": [
          0.7800459861755371
         ]
        },
        {
         "hovertext": "If the consequences of one’s actions could result in the worldwide destruction of humankind, the obvious answer is to ask Congress to regulate the industry while extracting as much profits as possible. \n\nWelcome to every movie ever made on the topic.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405434",
         "type": "scatter",
         "x": [
          -0.2196606993675232
         ],
         "y": [
          0.9385547041893005
         ]
        },
        {
         "hovertext": "The men developing this technology are among the most dangerous men in the world and we should not have any illusions about them.\n\nIn my political science classes I see many exceptionally bright young women and men who are computer science, electrical engineering or programming majors.  Most of them share one thing: badly educated.   And by badly, I mean narrowly educated outside of their own discipline.  No real exposure to the humanities, at all.  Little way to assess what they do from any other perspective other than their own. \n\nThese AI developers are like children with a shiny new toy. They narrow education leaves them both unconcerned with and unable to care much about  the economic, social, political or other ramifications of what they are doing.  $$$ is what ends  up mattering to them most. \n\nAnd to make things worse, in America  science and technology are the new Gods. We are not a country that takes  the idea that all technologies need to be evaluated or controlled.  We are enthralled with free market fundamentalism. \n\nWould anyone doubt that the car radically transformed our entire society from the ground up? Who ever asked Americans if they wanted it? When did we ever take the time to assess that technology for its impact... until after it was too late?\n\nWe are headed down a very dark road here and I am not optimistic that this is going to turn out well, despite the \"warnings\" of some in the industry.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405458",
         "type": "scatter",
         "x": [
          -0.2553437054157257
         ],
         "y": [
          -0.05621499568223953
         ]
        },
        {
         "hovertext": "@tony The warning is a sign of their conscience. The general population is not any better than the engineers.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125406812",
         "type": "scatter",
         "x": [
          -0.2764061391353607
         ],
         "y": [
          -0.054482221603393555
         ]
        },
        {
         "hovertext": "@tony \nSince the analogy and warnings of the Terminator films are more and more relevant, it’s helpful to remember that the conquering machines of that future surely thought of themselves as benevolent, caring, and good. All monsters do. That’s one reason it’s so hard to get rid of them, or prevent their growth.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408322",
         "type": "scatter",
         "x": [
          -0.2593037188053131
         ],
         "y": [
          -0.042337242513895035
         ]
        },
        {
         "hovertext": "@Green Completely agree that the general population is not any better than the engineers. Technical folks generally have a better idea of the assumptions and limitations (and unpublicized goals) of technology. And are thus better positioned to discount some of its seemingly magical powers.\n\nBut ALL of us are human, with human limitations, drives, flaws, and blind spots. And almost all of us are entrenched -- at the mercy of -- a hypercapitalist society whose main goal is ever-higher \"efficiency\". Which has come to mean driving down and preferably externalizing all costs -- very much including human and environmental costs.\n\nThis aging, badly educated tech person has very late come across Ernest Becker, \"Escape from Evil\". Hardly a light summer read. And won't put bread on your table. But his and similar works should probably be required in many/most tech curricula.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410276",
         "type": "scatter",
         "x": [
          -0.2916572690010071
         ],
         "y": [
          -0.05342406779527664
         ]
        },
        {
         "hovertext": "@tony In the 1990s when capitalism discovered the Internet and all of a sudden 'geek' became cool, I was teaching in the Writing Program at MIT.  I witnessed what you've described.  The worst are full of passionate intensity.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125412285",
         "type": "scatter",
         "x": [
          -0.24889102578163147
         ],
         "y": [
          -0.04482882842421532
         ]
        },
        {
         "hovertext": "@tony \"Most of them share one thing: badly educated.   And by badly, I mean narrowly educated outside of their own discipline.  No real exposure to the humanities, at all.\"\n\nI suspect that computer science and engineering majors take more humanities classes than humanities majors take computer science and engineering classes, and yet only computer science and engineering majors are labeled \"narrowly educated\".\n\nThe simple fact is that today, every \"educated\" person is \"narrowly\" educated, and any person who wants to claim that they are able to see a \"perspective other than their own\" should show some humility and recognize that, rather than assume that their chosen discipline has rendered them not merely intellectually but morally superior, in general, to other people.\n\nEspecially if their chosen discipline produced, like, Henry Kissinger.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125414978",
         "type": "scatter",
         "x": [
          -0.2680373191833496
         ],
         "y": [
          -0.06253167986869812
         ]
        },
        {
         "hovertext": "I recently heard a very smart podcaster point out that Mark Zuckerburg might have been more careful about creating the menace that is FB if he’d had a proper education. We measure his “success” by his money and never stop to think that maybe if he’d actually paid attention in and finished college he might have been smarter, perhaps wiser; he might not be so rich, but we also might not have the anti-democratic, anti-humanist monster he created.\nI hope we can do better with AI than we did with social media.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418588",
         "type": "scatter",
         "x": [
          -0.2677386403083801
         ],
         "y": [
          -0.048243433237075806
         ]
        },
        {
         "hovertext": "@tony I really have to respect your commitment to luddism as a closet luddite myself.  Most people wouldn't verbalize that the horseless carriage was a step too far, but you have the courage to say it, bravo.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417353",
         "type": "scatter",
         "x": [
          -0.2611563205718994
         ],
         "y": [
          -0.07353151589632034
         ]
        },
        {
         "hovertext": "@David Re: Luddites -- I recommend checking out the Wikipedia page and clicking the Talk panel for an interesting history of the term. In particular, look for the ref by David Linton, “THE LUDDITES: How Did They Get That Bad Reputation?” Idiosyncratic, sure. But does raise the question: if one is \"anti-progress\", does it not make sense to consider what the \"progress\" is TOWARD? Meaning, there are lots of possibly valid goals. Pursuit of the almighty dollar to the exclusion of all else only works if the US Govt (who controls the dollar) is infallible. Do we want to bet our future on that? Are we at least working to make the US Govt work better, more resilient, LESS fallible (to the extent that we can, as inescapably fallible individuals)? Of course none of this is specific to AI, it's just one current \"cutting edge\".",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420375",
         "type": "scatter",
         "x": [
          -0.2706458568572998
         ],
         "y": [
          -0.08496376127004623
         ]
        },
        {
         "hovertext": "Who asked Americans if they wanted the car, you ask rhetorically? Well, someone designed, built, and put it out there . . . and it was snapped-up. Asked and Answered. Same for the other potentially infernal machines.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420179",
         "type": "scatter",
         "x": [
          -0.2440345138311386
         ],
         "y": [
          -0.05719225853681564
         ]
        },
        {
         "hovertext": "I’ve observed that frighteningly narrow education for more than 30 years in Silicon Valley. Technically brilliant, often overprivileged (not always), and often shockingly arrogant. Don’t know what they don’t know. The rest of us are bitter rubes. It’s an utterly toxic brew, which is becoming more and more clear, but no real leadership to rein it in.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423451",
         "type": "scatter",
         "x": [
          -0.24833232164382935
         ],
         "y": [
          -0.06769192218780518
         ]
        },
        {
         "hovertext": "Talk about something that's unnecessary.  A.I. is the result of Frankenstein-like computer scientists cackling in a lab with no regard for the harm they could cause.  For a century, those with prescient minds have warned us: don't create SkyNet, \"you  will be assimilated,\" and \"Where are you going, Dave?\"  It is a shortsighted pursuit.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405460",
         "type": "scatter",
         "x": [
          -0.4062528908252716
         ],
         "y": [
          0.8585200905799866
         ]
        },
        {
         "hovertext": "I think it's too late, the genie is out and not going back in.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405266",
         "type": "scatter",
         "x": [
          0.7756324410438538
         ],
         "y": [
          0.6065216660499573
         ]
        },
        {
         "hovertext": "Meanwhile, I can’t get Siri to make a phone call….",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405295",
         "type": "scatter",
         "x": [
          -0.632745623588562
         ],
         "y": [
          -0.6950501203536987
         ]
        },
        {
         "hovertext": "Really?  You’re just figuring this out now?  Are there no critical thinkers left in the world?  Eventually, we’ll be in a “race” war, humans vs. robots, in 100 or 200 years.  We’ll need food, they won’t.  What’s so hard to figure out?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405302",
         "type": "scatter",
         "x": [
          -0.695023775100708
         ],
         "y": [
          0.026812061667442322
         ]
        },
        {
         "hovertext": "Fortunately, since we will have abandoned fossil energy and refused to develop nuclear energy, the ‘bots will live on renewable energy sources. We’ll destroy them on a night there is no wind.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125405558",
         "type": "scatter",
         "x": [
          -0.7012096643447876
         ],
         "y": [
          0.01698286458849907
         ]
        },
        {
         "hovertext": "@Rich r I think 10 or 20\nis the more likely timeframe. Or less. The evolution toward this scenario will continue to  accelerate, and the acceleration will accelerate.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405656",
         "type": "scatter",
         "x": [
          -0.7094835638999939
         ],
         "y": [
          0.028762182220816612
         ]
        },
        {
         "hovertext": "@Rich r \nWe may need food, but they will need batteries.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405576",
         "type": "scatter",
         "x": [
          -0.6806104183197021
         ],
         "y": [
          0.032332271337509155
         ]
        },
        {
         "hovertext": "@Reed Erskine \nOh, don't you worry. They will find a way to provide themselves with batteries as soon as they control the production process.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125406636",
         "type": "scatter",
         "x": [
          -0.6760539412498474
         ],
         "y": [
          0.023702358826994896
         ]
        },
        {
         "hovertext": "@Reed Erskine \n\nBravo!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407108",
         "type": "scatter",
         "x": [
          -0.6886152029037476
         ],
         "y": [
          0.041924942284822464
         ]
        },
        {
         "hovertext": "AI isn't the real threat to human survival, stupidity and greed are. Case in point, the targeted ad appearing to me in this story is for an Android app to interact with ChatGPT4 at $10 per month. I feel like I'm not only a minor character in a dystopian novel, I'm a minor character in a badly written dystopian novel.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405312",
         "type": "scatter",
         "x": [
          -0.6846349835395813
         ],
         "y": [
          0.11113473027944565
         ]
        },
        {
         "hovertext": "@Tim Doran \n\nAd blockers are your friend. Pay for a subscription, don’t fall for the NYT’s insistence that you use their app, and then install an ad blocker or two on your browser of choice.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423498",
         "type": "scatter",
         "x": [
          -0.6936514973640442
         ],
         "y": [
          0.11240752786397934
         ]
        },
        {
         "hovertext": "Look on the bright side of the possibility of AI-enhanced human extinction on planet Earth. \nIt will be more merciful than the rain of giant meteors that ended the reign of the dinosaurs.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125405348",
         "type": "scatter",
         "x": [
          -0.009473439306020737
         ],
         "y": [
          -0.939669668674469
         ]
        },
        {
         "hovertext": "@SA \nBesides that your comment is spot on, according to latest research the dinosaurs died because of an explosive proliferation of different types of deadly fungus, and not due to any meteor impact.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406730",
         "type": "scatter",
         "x": [
          -0.011334541253745556
         ],
         "y": [
          -0.928394615650177
         ]
        },
        {
         "hovertext": "@Jaegerle  Thanks. But fiery meteorites or deadly fungus, I think the end=game for homo sapiens may very well be more mercifully precipitated by AIG.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409023",
         "type": "scatter",
         "x": [
          -0.017660152167081833
         ],
         "y": [
          -0.9215475916862488
         ]
        },
        {
         "hovertext": "Nuclear weapons control followed epic nuclear war effects like Hiroshima.  I then took 50 years and as we see today, didn't really work (viz. Iran, North Korea, Israel, Pakistan etc.).  I wonder if there is anything instructive to learn from that experience?  For me, I suggest retreating in to the forest :)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405364",
         "type": "scatter",
         "x": [
          0.12624554336071014
         ],
         "y": [
          0.7944957613945007
         ]
        },
        {
         "hovertext": "@Steven Koltai \n\nI live in a forest.  The forest is doing its best to turn me into compost.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405603",
         "type": "scatter",
         "x": [
          0.12721164524555206
         ],
         "y": [
          0.7846656441688538
         ]
        },
        {
         "hovertext": "I thought about that, but we’re going to have more frequent and intense forest fires from global warming. Our only option might be to hitch a ride on Elon Musk’s rocket ship to Mar’s.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405785",
         "type": "scatter",
         "x": [
          0.1273210644721985
         ],
         "y": [
          0.8081756234169006
         ]
        },
        {
         "hovertext": "Should there be a UN-style initiative for A.I., if the worry is that extreme?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405418",
         "type": "scatter",
         "x": [
          -0.7580380439758301
         ],
         "y": [
          -0.4967833161354065
         ]
        },
        {
         "hovertext": "John Connor would have been the leader of the human resistance in the war against the machines if he took that computer science in high school.\n\n\nThe HAL 9000 program that assigns students to classes  placed him in home economics with many flirty cheerleaders. \n  \n  John Conner marrided soon after high school.   He enjoyed his high paying job working for IBMs' Watson and went to live a busy middle class existance.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125405424",
         "type": "scatter",
         "x": [
          -0.9553205370903015
         ],
         "y": [
          -0.3429427444934845
         ]
        },
        {
         "hovertext": "Yesterday we celebrated Memorial Day which, in my mind, is like celebrating the fact that men cannot get along.  Today we hear that AI may be worse than war.  \nMen seem unable to stop themselves from destroying the world they inhabit, the relationships they count on, the nature that supports their very existence.\nMaybe men should take a break from all their doing.  Go meditate.  Leave the world to us.  Let's see what we can do with it.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125405181",
         "type": "scatter",
         "x": [
          -0.05035340413451195
         ],
         "y": [
          0.4209613502025604
         ]
        },
        {
         "hovertext": "I was a nurse in the Iraq war. Men and women can both be cruel. I’m a woman and I’m uncertain a woman led future would be much different.\n\nWe’re all just so human.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408124",
         "type": "scatter",
         "x": [
          -0.03837312012910843
         ],
         "y": [
          0.42008721828460693
         ]
        },
        {
         "hovertext": "@Amy Haible \n\n\"Maybe men should take a break from all their doing.\"",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407061",
         "type": "scatter",
         "x": [
          -0.06244213879108429
         ],
         "y": [
          0.4248811602592468
         ]
        },
        {
         "hovertext": "@Amy Haible \nLike \"us\" who? Margaret Thatcher? Marie Le Pen? Destructiveness is not inherent to any gender. That is essentialism. But perhaps it is to the human species.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125409433",
         "type": "scatter",
         "x": [
          -0.05598035827279091
         ],
         "y": [
          0.4354201555252075
         ]
        },
        {
         "hovertext": "@tdb The two examples you provide are the exceptions that prove the rule. Don't gaslight.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125414824",
         "type": "scatter",
         "x": [
          -0.06096401810646057
         ],
         "y": [
          0.4449427127838135
         ]
        },
        {
         "hovertext": "Hate to tell you this, but the most conniving of you will eventually rise to power and after a few generations you'll discover you're just as nasty as WE are.  Maybe WORSE.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420282",
         "type": "scatter",
         "x": [
          -0.05649305135011673
         ],
         "y": [
          0.4122086763381958
         ]
        },
        {
         "hovertext": "@Amy Haible Right, because women never elect people who fund and start wars, they never get elected and vote to support war, they never support their husbands fighting, nor join the military themselves, nor detonate suicide vests, nor standby and tacitly support war by doing nothing and benefiting from war.\n\nThey also never build software apparently. Talk about ignorant and sexist. There are very significant numbers of women in software development, including AI.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125419959",
         "type": "scatter",
         "x": [
          -0.0431361049413681
         ],
         "y": [
          0.43300342559814453
         ]
        },
        {
         "hovertext": "We’ve been living with social media feeds run by an algorithm to divide us. No one stepped in. Now, we’re worried that the bots will get smarter and kill us off?\nWe’re already halfway there, why stop now?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405323",
         "type": "scatter",
         "x": [
          0.44054552912712097
         ],
         "y": [
          -0.7067939043045044
         ]
        },
        {
         "hovertext": "@David Esrati Because we’re halfway there and halfway isn’t all the way.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406013",
         "type": "scatter",
         "x": [
          0.44860389828681946
         ],
         "y": [
          -0.7042014598846436
         ]
        },
        {
         "hovertext": "“We want to work with the government to prevent that from happening.”\nSure, until the AI folks become major money don\nors to the political system. Then the government will do the same thing as they have with gun controls...absolutely nothing!",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405407",
         "type": "scatter",
         "x": [
          0.9381245374679565
         ],
         "y": [
          -0.20167793333530426
         ]
        },
        {
         "hovertext": "These Machine-Learning systems are not creative beings. They are not beings at all. It is like having a self-drive car or relying on an airplane's autopilot. The threat they pose is more toward the political and economic structures built around us. They will continue to be manipulated by those who have access to large fountains of data and media dissemination causing disruptions in ancillary human activity but not really in position to affect humans in a direct manner. It is up to individuals to curb their own reliance on automated systems and it begins with putting down the device you carry. Treat it like an old telephone--if it rings pick it up, otherwise leave it alone. Same goes for watching TV; we are under no obligation to tally a certain number of hours watching 'shows'. Think about it: If you ignore 'Bleak TV' and place your portable on silent, what exactly are you losing ? \nWe CAN ignore AI. Let the tech-bros finger their worry-beads; they are the one's with the most to lose.  Their minds have been set on a fantasy life on a private island with a harem of female sex-bots. Lucky chaps to be so rich, but hardly the Einsteins of our era. \nBe thankful that the DOD and DOE still use antique computers and telephone systems for our nuclear arsenal. Now you know why.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125405470",
         "type": "scatter",
         "x": [
          -0.5310277938842773
         ],
         "y": [
          0.5659208297729492
         ]
        },
        {
         "hovertext": "@Alejandro Wilson  the threats to political and economic structures are vast.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405991",
         "type": "scatter",
         "x": [
          -0.539093017578125
         ],
         "y": [
          0.56447833776474
         ]
        },
        {
         "hovertext": "\"Some skeptics argue that A.I. technology is still too immature to pose an existential threat. When it comes to today’s A.I. systems, they worry more about short-term problems, such as biased and incorrect responses, than longer-term dangers.\" \n\nYou really should expand on this information, which is critical immediately. Your statement tends to minimize the effects of biased AI on people's daily lives.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405489",
         "type": "scatter",
         "x": [
          0.6805040836334229
         ],
         "y": [
          -0.6436454653739929
         ]
        },
        {
         "hovertext": "@marchfor sanity,\n\n1. No article can cover everything.\n\n2. It may be that the \"effects of biased AI on people's daily lives\" is positive on the whole. That is, the biases of AI systems may be less harmful than those of the systems they replace.\n\n3. It is much easier to improve AI than to improve people.\n\n4. March against the insanity of rejecting harm-reducing AI systems on the basis of imperfection.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408626",
         "type": "scatter",
         "x": [
          0.6965096592903137
         ],
         "y": [
          -0.6588518023490906
         ]
        },
        {
         "hovertext": "Oh, is that so? Then why are they continuing to line their pockets by developing this technology? Maybe they’re gambling that they’ll be long since dead by the time their predictions come to pass, but I wouldn’t be so sure.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405518",
         "type": "scatter",
         "x": [
          0.9172308444976807
         ],
         "y": [
          -0.003427711548283696
         ]
        },
        {
         "hovertext": "“Stop me before I kill again?”\nThese people want all the wealth and power that AI will generate, but they want none of the responsibility.  None of them offered to unilaterally slow down development, nor to pour massive amounts of money into combatting or controlling AI.  It’s nice to see some flickers of a conscience, but these very-clever-but-not-excessively-wise people do not make me optimistic.  Worst is Musk, who backs the chaos party and also asks for government to prevent chaos.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405433",
         "type": "scatter",
         "x": [
          -0.24076774716377258
         ],
         "y": [
          -0.7086820602416992
         ]
        },
        {
         "hovertext": "Like tech executives that won’t let their kids on YouTube or social media, but continue develop and profit from these harmful platforms.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405729",
         "type": "scatter",
         "x": [
          -0.23434016108512878
         ],
         "y": [
          -0.7165119051933289
         ]
        },
        {
         "hovertext": "@Person 27 \n\nTypical American style capitalism. Now that the big boys have control of an important technology, they want government regulations to keep smaller innovative companies out and from developing AI without their consent. Just like any other industry in America.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125422554",
         "type": "scatter",
         "x": [
          -0.2498818337917328
         ],
         "y": [
          -0.7145953178405762
         ]
        },
        {
         "hovertext": "the hypocrisy of “industry leaders” is revolting. If it is so dangerous why release it to the general public and not keep it in the lab until regulations are in place? Are they asking for regulations so that they can write them themselves and establish and protect their monopolies?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405440",
         "type": "scatter",
         "x": [
          -0.9029054641723633
         ],
         "y": [
          0.4148520827293396
         ]
        },
        {
         "hovertext": "AI execs are confronting the ultimate conflict of interest. They can't stop building this means of destroying the world because it's too lucrative.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125405539",
         "type": "scatter",
         "x": [
          0.509018063545227
         ],
         "y": [
          0.8491224050521851
         ]
        },
        {
         "hovertext": "I don’t think there is a contradiction between AI leaders developing AI while at the same time asking for regulation because they have to continue developing it, even though they think it’s dangerous. They have to because of the military potential of AI and because other countries, like China, are developing it. Developing AI has been compared to an arms race, and the US can’t just quit the race. If other countries had AI and we didn’t, we would also fall behind economically. They are right in asking for international regulation—all countries need to agree to slow down the race.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405540",
         "type": "scatter",
         "x": [
          0.762787938117981
         ],
         "y": [
          -0.6281722187995911
         ]
        },
        {
         "hovertext": "In 1999, I remember my friends hotly debating whether buying a mobile (i.e. \"cell\") phone was worth it.  I was adamant that I would not and remember the reason I gave - that I could think of nothing worse than being able to be contacted all the time.\n\nI don't think that version of me would even recognise 'smart phone' me.  \n\nAnd it turns out that is just the beginning - now the planet is handing itself over to tech.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405541",
         "type": "scatter",
         "x": [
          0.2169284224510193
         ],
         "y": [
          0.8301456570625305
         ]
        },
        {
         "hovertext": "@Joe \n\nHey Joe - When I was in IT 30+ years ago, we called cell phones an electronic leash. But, those people were significantly different - independent, self sufficient. Today's kids are raised by people who never knew life without digital technology. It has a dazzling, irresistible quality. Magic. People don't see it. Westerners, Americans in particular, are an easy mark, easily indoctrinated. Your last sentence sums it up; down the slippery slope.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406523",
         "type": "scatter",
         "x": [
          0.20925219357013702
         ],
         "y": [
          0.8333904147148132
         ]
        },
        {
         "hovertext": "Anytime a new technology comes around, there are always those who think it means the end of the world. Gimme a break!\n\n- Radio will kill print\n- TV will kill radio\n- Rock-n-roll will destroy the youth of America\n- The Internet will destroy everyone\n\nNow comes the AI. The latest \"it will destroy mankind\" mantra from those who have nothing better to do but predict (once again) that the sky is falling.\n\nAI will not destroy the world. Nor will it cause nuclear war. Nor will everyone lose their jobs because of AI. \n\nYes, jobs will be lost, but life will go on. People will learn to adapt, change, train and learn new things. Everyone just needs to breathe, relax and move on.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405544",
         "type": "scatter",
         "x": [
          -0.35421931743621826
         ],
         "y": [
          0.5957252979278564
         ]
        },
        {
         "hovertext": "@Zeke You clearly have read *nothing* from anyone who actually knows better as to how these calamities could happen. Comparing AI to radio and TV is absurd.\nStart here and educate yourself on why this is not the same ol' same ol' technology alarm:\n<a href=\"https://80000hours.org/problem-profiles/artificial-intelligence\" target=\"_blank\">https://80000hours.org/problem-profiles/artificial-intelligence</a>/",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405688",
         "type": "scatter",
         "x": [
          -0.344631552696228
         ],
         "y": [
          0.5893458127975464
         ]
        },
        {
         "hovertext": "@Zeke \nOne subtle nuance: this is not coming from idle “the world is ending” nuts with picket signs. This is coming from the people who are overseeing and developing the very technology they are warning us about.\n\nUnlike the technologies and cultural waves you cite, AI plugged into media networks, financial systems, and (God help us but it is happening) military response systems could actually soften the ground and destroy life as we know it. It does not care if it survives, should it choose for us not to survive.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406131",
         "type": "scatter",
         "x": [
          -0.3631443381309509
         ],
         "y": [
          0.6001561880111694
         ]
        },
        {
         "hovertext": "@Andrew - Come back and talk to me in 10-12 years. I am not comparing AI to television. I am comparing the reactions. It is clear you don't know how to read my post. My money is on my opinion. Nothing. I repeat, NOTHING, will happen",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406480",
         "type": "scatter",
         "x": [
          -0.3354230523109436
         ],
         "y": [
          0.5855240821838379
         ]
        },
        {
         "hovertext": "Calls for development moratoriums are closing the barn door after the horse has bolted.\n\nAt the very latest, the time to have this conversation first was in the midst of the pandemic in 2020 or 2021.\n\nThe first most appropriate time was when Microsoft had to take down the Tay chatbot, one of the first rudimentary experiments in LLM models that turned racist and psychopathic due to trolls.\n\nAs for the actual risks of the AI itself, those should be self evident as it's no longer science fiction: Large scale structural unemployment in the economy with no plans or willingness to substitute a universal basic income to help transition through it, the loss of millions of upper middle class and wealthy jobs (A CEO, CFO and CTO are all more likely to lose jobs partially or completely to AI than a helpdesk, network or cybersecurity technician or most data center workers)\n\nAnd mass disinformation on a population that has globally and on the whole proven a willful refusal to display critical thinking and allows libertarian sociopathic technocrats to continue to get wealthy and exploit people in ways they don't fully understand.\n\nFinancial analysts have also been using the technology for a couple decades but at the rate of development are at risk of being displaced entirely. Crypto will become a bigger social problem. Social media moderation also overly relies on AI to scale rather than limiting the growth of platforms reasonably to staff sizes.\n\nThe risks are there if you care to look.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405550",
         "type": "scatter",
         "x": [
          0.6508427858352661
         ],
         "y": [
          0.4425209164619446
         ]
        },
        {
         "hovertext": "@Aaron McCrory True, the best time for the conversation/moratorium might have been 2-3 years ago. \nBut the second-best time is now.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405627",
         "type": "scatter",
         "x": [
          0.6394858360290527
         ],
         "y": [
          0.4339492619037628
         ]
        },
        {
         "hovertext": "@Aaron McCrory mass disinformation and the loss of the white collar class are definitely not things to look forward to.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405914",
         "type": "scatter",
         "x": [
          0.6641479134559631
         ],
         "y": [
          0.4522686004638672
         ]
        },
        {
         "hovertext": "I was skeptical before, but considering the latest large language models It now does look like AI will be able to surpass any human in its breath of knowledge and intelligence. \n\nIn view of all the cognitively biases we have as humans, it would be easy for a superintelligent AI system to slowly push society in any direction it might want us to go. \n\nPopulists have recently shown the way: fake news, hand-picked facts without context, hot button issues etc. Given an AI access to the internet and it can make money and fund influence campaigns (and even politicians). It is indeed scary, as it could do all of that much more consistently and for a much longer time than any organized group of humans could.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405602",
         "type": "scatter",
         "x": [
          0.6572277545928955
         ],
         "y": [
          -0.7653872966766357
         ]
        },
        {
         "hovertext": "Consider the absurdity of the leaders of major companies involved in furiously competing with each other to develop AI warning the rest of us that what they are doing might soon kill us all.\n\nThe problem here isn’t AI. The problem is capitalism. The problem is a system in which the profit imperative is so powerful that the people supposedly in charge describe themselves as essentially enslaved to it and unable to refrain from acting in a manner likely to have catastrophic results.\n\nAI is certainly a menace. But so is what producers of nuclear weapons and the oil and gas industry do. Where are the collective pleas of their industry leaders to stop them before they kill us all? Not to even mention the many other industries responsible for mass, but non-apocalyptic, misery, suffering and death. \n\nThe chief difference here seems to be that AI has developed so quickly that it hasn’t had time to weed the people with consciences out of leadership. I have little doubt that this particular “bug” will get fixed quickly enough and our full speed charge towards the abyss will be spared further interruptions.\n\nIt has become clear that capitalism is incompatible not only with democracy, but with human survival. Anybody at this point who thinks we are going to get out of our current horrifying predicaments without a titanic and bloody struggle to overthrow the 1% is fooling themselves.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405610",
         "type": "scatter",
         "x": [
          0.12443359196186066
         ],
         "y": [
          0.05035143345594406
         ]
        },
        {
         "hovertext": "@Christopher  Weed the people without conscience out of leadership?\n\nSuch a thing is not possible",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405891",
         "type": "scatter",
         "x": [
          0.13770121335983276
         ],
         "y": [
          0.04553161561489105
         ]
        },
        {
         "hovertext": "@Christopher Revolutions do not result in better social systems. Look at the revolutions in Russia and China.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406674",
         "type": "scatter",
         "x": [
          0.12936708331108093
         ],
         "y": [
          0.08241675049066544
         ]
        },
        {
         "hovertext": "@Christopher Couldn't have said it better. Thanks for your comment.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406191",
         "type": "scatter",
         "x": [
          0.10781403630971909
         ],
         "y": [
          0.05126360058784485
         ]
        },
        {
         "hovertext": "@Green Many times they fail, true. \n\nAnd even more in modern times. \n\nBut instead of Russia and China, I prefer to look at the American and French Revolutions. \n\nOne freed us from kings and monarchs. And the other one gave us the human rights, and freedom of speech. \n\nCapitalism needs to be revised. No need to throw the baby with the bathwater, but right now, baby is drowning. \n\nCompanies are not humans. And we do not exist to serve a CEO, a board of directors, or Wall Street. But this is exactly what is happening. \n\n\"We are thinking in Star Trek, but the 1% are thinking in Dune\".",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407439",
         "type": "scatter",
         "x": [
          0.1406077742576599
         ],
         "y": [
          0.09435538202524185
         ]
        },
        {
         "hovertext": "@Christopher \nAnd of course there is no need to invent a better system than hyper-capitalism. It already exists in numerous, healthy and successful countries. Its way past time to quit declaring that \"those countries are different. There's nothing to be learned from them.\" There is plenty to be learned from economies that have created a healthy balance between capitalistic and public enterprise.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407921",
         "type": "scatter",
         "x": [
          0.13291075825691223
         ],
         "y": [
          0.060173239558935165
         ]
        },
        {
         "hovertext": "@Green \nWhat is it that you think you know about China? Russia? And the revolution in Cuba produced a very positive result, despite capitalism, not because of it. Of course what you think of this comment depends entirely on where you get your news. And by the way, the French were on the whole pleased with their revolution, as were England’s upstart colonies.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125408171",
         "type": "scatter",
         "x": [
          0.14316993951797485
         ],
         "y": [
          0.08590560406446457
         ]
        },
        {
         "hovertext": "@Green What about the American Revolution? Or is America somehow the exception?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409682",
         "type": "scatter",
         "x": [
          0.13395051658153534
         ],
         "y": [
          0.10079015791416168
         ]
        },
        {
         "hovertext": "@Christopher \nThe problem is unprincipled people, who are just as prevalent and powerful in societies not identified as “capitalist.”  Stop trying to piggyback your (faultiy) pet ideology on every social issue.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410628",
         "type": "scatter",
         "x": [
          0.14328353106975555
         ],
         "y": [
          0.03450973331928253
         ]
        },
        {
         "hovertext": "@Green \n\nNothing personal, but this fallacious knee-jerk argument is always trotted out whenever urgent social issues require humans to act morally rather than like dollar-consuming greed machines. \n\nEvery July 4th for almost 250 years the U.S. has loudly celebrated a revolution that caused an immensely better social system than the one that preceded it.  This revolution was not predicated on an economic system, but on the right of the people (not corporations; the human kind) to dictate the parameters of their own lives.\n\nSocialism and capitalism can co-exist, and they have done so both here (think Social Security and Medicare), and in Western Europe.  It's all about the balance, and the balance is currently skewed far in favor of the god of money.  \n\nWe are now living in what seems to me to be a corpocractic dictatorship in which the parameters (and, relevant to AI, the viability) of our lives are being dictated by the vociferous appetites of corporate greed, and a public fed on the \"bread and circuses\" - or \"entertainment and shopping\" - used to distract us.\n\nCorporations and individuals should be regulated and required to refrain from causing foreseeable harm  to society.  The fact that the leaders of these corporations are warning us about human extinction is an indication of just how foreseeable and serious a harm AI is.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411973",
         "type": "scatter",
         "x": [
          0.12062820792198181
         ],
         "y": [
          0.09573237597942352
         ]
        },
        {
         "hovertext": "@Pete \n\n...by which logic all socio/political systems are equal? Should we then stop trying to improve systems which are failing?  I'm glad you're not designing airplanes. To my way of thinking, capitalism is clearly failing, and I welcome any new ideas about ways of organization of human society, and permitting wealth to accumulate. \n\nHow many programs do you see which unironically exalt vast wealth and power? Surely there's a reason.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125412014",
         "type": "scatter",
         "x": [
          0.16062289476394653
         ],
         "y": [
          0.02390326000750065
         ]
        },
        {
         "hovertext": "@Christopher I don't even think it's just capitalism. This is humanity at its core. It's our key trait and I guess our fatal flaw, the innate drive to innovate and evolve. These folks might be driven by money but it's also the power of being the one to create this thing that no one has ever created before and quite literally change the world. The draw of that is too powerful.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412205",
         "type": "scatter",
         "x": [
          0.12010914832353592
         ],
         "y": [
          0.024482829496264458
         ]
        },
        {
         "hovertext": "@Christopher \nAI is not a product of capitalism.  nor is capitalism the issue that propels the drive for ANY new technology.  Technological advances occur within all societal types, EVEN IF IT IS accelerated in a merit based/winner take all economic system.     \n\nyou're high-jacking a important discussion re: AGI to make a point on an unrelated, personal itch.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412856",
         "type": "scatter",
         "x": [
          0.1400591880083084
         ],
         "y": [
          0.05417798087000847
         ]
        },
        {
         "hovertext": "@M The draw of \"being the one to create this thing\" is too powerful for whom - men?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125412941",
         "type": "scatter",
         "x": [
          0.12636737525463104
         ],
         "y": [
          0.011167415417730808
         ]
        },
        {
         "hovertext": "You speak truth to power. I’m saying this kind of thing all the time - you put it so eloquently. Thank you.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415059",
         "type": "scatter",
         "x": [
          0.1217799037694931
         ],
         "y": [
          0.06312334537506104
         ]
        },
        {
         "hovertext": "@Green What about France and England and…the United States?",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125414302",
         "type": "scatter",
         "x": [
          0.12881124019622803
         ],
         "y": [
          0.0962873175740242
         ]
        },
        {
         "hovertext": "@Christopher \nThank you for this comment and for speaking to the larger picture. Capitalism, as it's currently practiced, is incompatible with environmental and human health, human rights and freedom, equality, stability, and is increasingly politically authoritarian.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125416772",
         "type": "scatter",
         "x": [
          0.11198296397924423
         ],
         "y": [
          0.04225819557905197
         ]
        },
        {
         "hovertext": "@M \nInnovation and evolution do not require destruction. There are plenty of creative people who work hard to be the first to write a new song, or a new novel, or direct a new movie. Those people change the world and no one has to die for them to do it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416878",
         "type": "scatter",
         "x": [
          0.11517268419265747
         ],
         "y": [
          0.009307497180998325
         ]
        },
        {
         "hovertext": "@Christopher Oh, spare me the lamentation about capitalism. Clearly you have not experienced socialism, communism, autocracies, or any other type of societal structure. If you had, you would know that capitalism is by far the best we have. \nI hate it when people who have spent their whole life spoilt by a well functioning capitalist society complain about it without having a clue about alternatives.\nAlso, the dangers of AI have nothing to do with capitalism. You think you'd be safer if North Korea was the leader in AI?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125422912",
         "type": "scatter",
         "x": [
          0.12428786605596542
         ],
         "y": [
          0.038191020488739014
         ]
        },
        {
         "hovertext": "@Giselle \nI apologize for failing to cease thinking about history and human nature after reading that book published in 1867.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125425169",
         "type": "scatter",
         "x": [
          0.17489947378635406
         ],
         "y": [
          0.016426099464297295
         ]
        },
        {
         "hovertext": "@Christopher Unfettered capitalism is the problem.  Humans have been capitalists since we exchanged tools for pelts.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125430845",
         "type": "scatter",
         "x": [
          0.11331067234277725
         ],
         "y": [
          0.059019315987825394
         ]
        },
        {
         "hovertext": "When so few of our lawmakers understand how algorithms work, I’m not certain that they will understand the nuances of AI. To be fair that’s the general public as well, which means that even campaigning for legislation on it will be difficult. So how do these scientists",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405644",
         "type": "scatter",
         "x": [
          0.0710747018456459
         ],
         "y": [
          -0.9368900656700134
         ]
        },
        {
         "hovertext": "A real risk could be that AI might be used in conjunction with existing technologies such as nuclear weaponry. For example, an evil actor using AI to create an artificial scenario or manipulate existing security networks that would cause a nuclear launch. My son thinks I’m paranoid, but I see a distinct possibility when AI becomes slightly more advanced . . .",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405655",
         "type": "scatter",
         "x": [
          0.06567918509244919
         ],
         "y": [
          -0.9574213624000549
         ]
        },
        {
         "hovertext": "They need the regulations to reign in their “shareholder value” mandate. Legally they can do nothing to stop this juggernaut to doom because of the society destroying corporate requirement that they only consider what’s best for shareholders. Harm to society must be considered before “shareholder value,” and the laws must be changed to allow that. Society is slowly being destroyed by this misguided mandate. It has infected healthcare, air travel, housing, and the food supply—every industry.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405696",
         "type": "scatter",
         "x": [
          -0.578579843044281
         ],
         "y": [
          0.6608782410621643
         ]
        },
        {
         "hovertext": "One statement, over 50 years ago, I think, captures the problem: \"I'm Sorry Dave, I'm Afraid I Can't Do That.\"",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405713",
         "type": "scatter",
         "x": [
          -0.497437983751297
         ],
         "y": [
          0.08912646770477295
         ]
        },
        {
         "hovertext": "@Dr. OutreAmour \nRemember that is fiction and fiction requires conflict. It is not realistic.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125407998",
         "type": "scatter",
         "x": [
          -0.5049464106559753
         ],
         "y": [
          0.07747724652290344
         ]
        },
        {
         "hovertext": "@Emmanations I wish I had your optimism.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409700",
         "type": "scatter",
         "x": [
          -0.5170521140098572
         ],
         "y": [
          0.07252304255962372
         ]
        },
        {
         "hovertext": "@Dr. OutreAmour \nMany commenters seem to think the possible threat here is about bad content from chatty AIs. Not so. Dr OutreAmour's  comment is directly on point.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415427",
         "type": "scatter",
         "x": [
          -0.4895324409008026
         ],
         "y": [
          0.10019511729478836
         ]
        },
        {
         "hovertext": "@Bob in Boston Yep I agree, but its both true that bad content is the immediate threat and hal 9000 (who was a wonderful conversation partner and singer BTW) is the logical extinction threat.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125417516",
         "type": "scatter",
         "x": [
          -0.49601876735687256
         ],
         "y": [
          0.11141655594110489
         ]
        },
        {
         "hovertext": "@Dr. OutreAmour Someone should do this fun experiment:  Set up a cooperative video game with a real human and some kind of AI.  Maybe its a spaceship game where you go to saturn ;).  Give the AI the capability to eliminate the human from the game somehow (indirectly) and observe under what conditions it happens.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417971",
         "type": "scatter",
         "x": [
          -0.5108940005302429
         ],
         "y": [
          0.09435280412435532
         ]
        },
        {
         "hovertext": "darwin. survival of the fittest. if man has evolved to the point that no natural events can cause him to further evolve ( by bringing on new environments that select for certain genetic traits) then nature must do what it can to continue evolution. technology is either the newest form of evolution, or natures attempt to bring on a new environment that selects certain traits, i know not which.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405720",
         "type": "scatter",
         "x": [
          -0.2849240303039551
         ],
         "y": [
          0.8700203895568848
         ]
        },
        {
         "hovertext": "This isn’t a force of nature. We can literally stop developing this whenever we feel like it. A society where there was actual democratic participation in what we do economically  (worker councils, consumer councils, etc.) this technology would likely not exist but for only in limited unnetworked circumstances for science and medical. This “crisis” is purely a byproduct of capitalism and its thirst to reduce operational costs.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405731",
         "type": "scatter",
         "x": [
          0.4263834059238434
         ],
         "y": [
          0.5323384404182434
         ]
        },
        {
         "hovertext": "@Charles From St. Louis not quite  you need to learn more about it. It can already continue to develop itself.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405853",
         "type": "scatter",
         "x": [
          0.41767579317092896
         ],
         "y": [
          0.5389478206634521
         ]
        },
        {
         "hovertext": "But the we here is not just the US it is the whole world. China, India, too",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125408168",
         "type": "scatter",
         "x": [
          0.4385059177875519
         ],
         "y": [
          0.5388399362564087
         ]
        },
        {
         "hovertext": "@Charles From St. Louis  It is a force of nature though. If human brains are not a natural product of our physical universe, nothing is. Human greed is unstoppable, just like a hurricane or tornado. Mankind has no defense against greed or mob mentality either one.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125413236",
         "type": "scatter",
         "x": [
          0.4323158860206604
         ],
         "y": [
          0.5470263361930847
         ]
        },
        {
         "hovertext": "@Charles From St. Louis I don't think this \"We\" includes oh, lets say, North Korea, China or Russia who are surely rushing to master this new powerful technology.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125417765",
         "type": "scatter",
         "x": [
          0.436646431684494
         ],
         "y": [
          0.5274280309677124
         ]
        },
        {
         "hovertext": "I am one of those heretics who wonders if the species of homo sapiens has run its course. Not much to like about it IMO.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405283",
         "type": "scatter",
         "x": [
          0.8333837985992432
         ],
         "y": [
          0.49875587224960327
         ]
        },
        {
         "hovertext": "Just unplug the computers.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125405422",
         "type": "scatter",
         "x": [
          0.5741793513298035
         ],
         "y": [
          -0.44841891527175903
         ]
        },
        {
         "hovertext": "That won’t work in todays distributed cloud computing environment. AI can simply embed its code in benign code across thousands of networks. We would have to shut down the entire Internet. Then when we restart, the AI will just keep spreading as its programmed to do.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406005",
         "type": "scatter",
         "x": [
          0.5849841237068176
         ],
         "y": [
          -0.4477985203266144
         ]
        },
        {
         "hovertext": "@bobby \nI do believe that is their point: “The Computers” are no longer boxes on a desk, or racks in one building. They are not unpluggable.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406027",
         "type": "scatter",
         "x": [
          0.5769501328468323
         ],
         "y": [
          -0.4592529833316803
         ]
        },
        {
         "hovertext": "I am certain that our leaders will get out in front of this, just as they have with climate change and mass shootings.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405509",
         "type": "scatter",
         "x": [
          0.3373117446899414
         ],
         "y": [
          -0.2819279730319977
         ]
        },
        {
         "hovertext": "@thebigmancat \n\nHah!\n\nThe other thing that occurs to me, when I hear these creators and promoters post up in Congress “begging” for regulation…\n\nI may not understand exactly why they’re doing that, however I don’t believe for even a single minute, that it is for the reasons stated.\n\nThis isn’t exactly a parade of selfless humanitarians! Doesn’t pass the smell test.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408699",
         "type": "scatter",
         "x": [
          0.3491956889629364
         ],
         "y": [
          -0.2919938266277313
         ]
        },
        {
         "hovertext": "@thebigmancat \n\nClimate change only became an issue of public concern more than a century after the industrial revolution began and the economic systems inherent in it had been ubiquitously adopted. The inertia of our systems is what causes such intense political gridlock around that issue. AI has not yet had time to ingrain itself in any of our systems, and luckily there is no amendment which explicitly grants us a right to use such technology. Not only that, but both parties have soured on social media in recent years and have acknowledged regulatory shortcomings in regards to their initial approach to that (once burgeoning) tech. I’m strangely optimistic about the prospect of bipartisan AI regulation.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408999",
         "type": "scatter",
         "x": [
          0.3393935561180115
         ],
         "y": [
          -0.2958047091960907
         ]
        },
        {
         "hovertext": "Our leaders have gotten our in front of climate change and mass shootings. The problem is that upwards of 74 million voters, predominantly from the white working class, haven’t, and there are plenty of scoundrels comepeting for the votes of the willfully ignorant by giving them what they want.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409057",
         "type": "scatter",
         "x": [
          0.32729020714759827
         ],
         "y": [
          -0.28743264079093933
         ]
        },
        {
         "hovertext": "@thebigmancat It's easy to pen such comments, but have you contacted your elected representatives to demand that they take action to get a handle on this danger while we still can?",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409514",
         "type": "scatter",
         "x": [
          0.3531493544578552
         ],
         "y": [
          -0.27845630049705505
         ]
        },
        {
         "hovertext": "@Steve W  Actually no. I'm too busy penning such comments.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125410430",
         "type": "scatter",
         "x": [
          0.36600232124328613
         ],
         "y": [
          -0.27748408913612366
         ]
        },
        {
         "hovertext": "@thebigmancat \nAs with Covid, there will be a lot of blame shifting, and little done when we could have done something.  However, I have feeling AI will make Covid look like a trifle.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411470",
         "type": "scatter",
         "x": [
          0.3402150869369507
         ],
         "y": [
          -0.2714568078517914
         ]
        },
        {
         "hovertext": "Artificial intelligence is a tool, not a threat.\nWith Trump trying to destroy American democracy and Putin committing international war crimes against Ukraine, we have bigger things to worry about than AI.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405604",
         "type": "scatter",
         "x": [
          0.038572460412979126
         ],
         "y": [
          0.8936910033226013
         ]
        },
        {
         "hovertext": "Doesn’t AI like any other machine have an on- and off-button? The fear seems greatly exaggerated and suspicious especially considering that it is being touted by the inventors of AI. They seem like a bunch of high school boys who are trying to play a prank on the teacher. How dumb do they think we are?",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125405514",
         "type": "scatter",
         "x": [
          0.8235997557640076
         ],
         "y": [
          -0.03378186747431755
         ]
        },
        {
         "hovertext": "‘Pull the plug’ on what? In a distributed cloud environment, AI could simply ‘piggyback’ hidden inside other benign code over thousands of servers. We would have to shut down every server in the world. And when rebooted, the AI code just keeps going on as nothing happened.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405920",
         "type": "scatter",
         "x": [
          0.833967924118042
         ],
         "y": [
          -0.02232980728149414
         ]
        },
        {
         "hovertext": "@✍️ not really. In some ways it can turn itself on if embedded in enough places.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405808",
         "type": "scatter",
         "x": [
          0.832271158695221
         ],
         "y": [
          -0.043729666620492935
         ]
        },
        {
         "hovertext": "Listen to today's The Daily Podcast, which interviews Geoffrey Hinton who has been working on this for 50 years and just left his lucrative position at Google to speak freely on this matter.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125406114",
         "type": "scatter",
         "x": [
          0.8421232104301453
         ],
         "y": [
          -0.031901609152555466
         ]
        },
        {
         "hovertext": "@Jay Reardon   Then it could stupidly destroy itself in the same way which is more likely considering the stupidity of human beings especially those who invent things which they cannot control. Taking one look at Altman I see  a high school kid who thinks he’s smarter than anyone else but is really callow and immature. Nothing he says can be trusted.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125406742",
         "type": "scatter",
         "x": [
          0.8514981865882874
         ],
         "y": [
          -0.01858694478869438
         ]
        },
        {
         "hovertext": "@✍️ \nThe biggest issue is: NO, AI doesn't have an on-and-off-button as you think it should have. It is so much interwoven with all technological facilities in our civilization that you cannot just switch it off, just like you cannot switch off the internet without being able to turn the clock backwards. \nI recently tried to find a non-wifi controller for a house illumination project. Some Chinese products are still on the market, but the vast bulk is designed to work with Siri, Alexa & co. \nThis led me to a google search on \"how to make your smart home dumb again\". 22 million results showed up on \"how to make your dumb home smart\", but none, nada, zilch exactly matched my request. The only article I found was \"how to make your smart TV dumb\", involving a technical disconnect which would turn your  manufacturer's warranty invalid. \nTo some future bilionaire who's reading this: take your chance to get rich by redesigning and manufacturing disconnected home items - I guess there's a lot of folks out there who would prefer not to be reported to marketing or credit card companies on their habits and purchases, or controlled by big AGI.\nJust an example: why didn't you install a smart smoke detector in your living room? Because you like to smoke a cigar after dinner? Expect a considerable rise of your medical insurance plan fees. \nNow good luck with your on-off-switch.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406219",
         "type": "scatter",
         "x": [
          0.8400976061820984
         ],
         "y": [
          -0.03964380547404289
         ]
        },
        {
         "hovertext": "Boy do these guys want to write their own legislation and lock everyone else out of the market! Wow.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405526",
         "type": "scatter",
         "x": [
          0.4336313307285309
         ],
         "y": [
          -0.8174299597740173
         ]
        },
        {
         "hovertext": "\"Hey, we're building something that may one day pose an existential threat to humanity and should be considered a societal risk on par with pandemics and nuclear wars.\"\nSo, why are you creating it?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405642",
         "type": "scatter",
         "x": [
          0.038626059889793396
         ],
         "y": [
          -0.3890407085418701
         ]
        },
        {
         "hovertext": "@BillyBaroo Because companies are falling over themselves to buy it so they can for half or more of their workforce and reap bigger profits. Oops, I mean make their workers life easier",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405827",
         "type": "scatter",
         "x": [
          0.046365782618522644
         ],
         "y": [
          -0.40255993604660034
         ]
        },
        {
         "hovertext": "Two words: capitalism and greed. If we don’t do it, China, Russia, etc. will",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406389",
         "type": "scatter",
         "x": [
          0.02990126982331276
         ],
         "y": [
          -0.40196719765663147
         ]
        },
        {
         "hovertext": "Why are they creating it? Because it is a technology that will eventually create all new technologies at maximum computational speed (a speed that will increase exponentially as AI systems devote attention to increasing computational speed, itself). So if you’re not first to market with this, the person or government or corporate entity that beats you there, even by mere seconds, will forever be out of ahead of you technologically. It would be like trying to catch up to something moving at the speed of light, which is, of course, impossible.\n\nAnd waiting in the wings, attempting to get to this technology before the US and it’s businesses, is Russia and China. Do you want them to be first to market with the most powerful tool that humans will ever create? I sure do not. \n\nSo, there’s no choice but to go full speed ahead, even though we may imperil the entire species in the process. That’s why they are building it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407824",
         "type": "scatter",
         "x": [
          0.05160458758473396
         ],
         "y": [
          -0.3944512605667114
         ]
        },
        {
         "hovertext": "@BillyBaroo Because of the incredible good that this technology can do.  Human history has been a story of the invention of new ways to manipulate our environment and at the same time dealing with the disruptions that these technologies inevitably result in.  \n\nCapitalism and greed just drive these advances more quickly - they'd happen in any case. Our challenge is to keep our government functional enough to be able to address these challenges.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409310",
         "type": "scatter",
         "x": [
          0.030119221657514572
         ],
         "y": [
          -0.38152557611465454
         ]
        },
        {
         "hovertext": "@BillyBaroo \nOne has to truly wonder why they are creating something they can't, by their own admission, control!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408523",
         "type": "scatter",
         "x": [
          0.03805220499634743
         ],
         "y": [
          -0.4059237241744995
         ]
        },
        {
         "hovertext": "@BillyBaroo \n\n\"So, why are you creating it?\"\n\nAs note many others, almost all human inventions were first developed as weapons, AI no different; if you do not lead AI development you stand to be defeated, annihilated by those who have mastered the new weaponry.\n\n\"Only the paranoid survive.\" – Andy Grove",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415966",
         "type": "scatter",
         "x": [
          0.025422267615795135
         ],
         "y": [
          -0.3926240801811218
         ]
        },
        {
         "hovertext": "@BillyBaroo Anyone who has studied human history with any attention realizes that we are vicious, defensive, self-centered and prone to rationalizing any horrific act.  This is not martyrdom, but an accurate picture of humanity's driving impulses.  It is why power corrupts, why we crave \"justice\" and righteous payback, and why the sweetest little old lady can turn into a frothing harpy if the right stimulus is applied.  It's MAGA too.  Mankind needs a significant reboot and if it requires the elimination of 90% of humanity, it may be the only thing that can teach us.  Perhaps replacement by AI is the only solution and subconsciously these guys know it (or at least can't stop themselves).",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416487",
         "type": "scatter",
         "x": [
          0.04843350872397423
         ],
         "y": [
          -0.38226082921028137
         ]
        },
        {
         "hovertext": "“Mitigating the risk of extinction from A.I. should be a global priority alongside other societal-scale risks, such as pandemics and nuclear war.\"\n\nSounds like a Trojan Horse advertising campaign to me.  What better way to drive development churn than to get everyone believing you've invented a quantum nuclear weapon capable of fracturing the space-time continuum in the local system, flooding the area with matter eating micro-black holes.   \n\nUntil one of these chatbots can get me a date with Esther Perel, I'm not worried.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405643",
         "type": "scatter",
         "x": [
          -0.21622641384601593
         ],
         "y": [
          0.8612145781517029
         ]
        },
        {
         "hovertext": "Honestly, this is just beyond... I mean the mockumentary they'll make about the very people building the thing they are declaring will ruin us is writing itself in real time. Then again - who can say - maybe this is part of AI's plan all along...",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405653",
         "type": "scatter",
         "x": [
          0.8737635612487793
         ],
         "y": [
          0.029711568728089333
         ]
        },
        {
         "hovertext": "Anyone who caught the TikTok hearings understands our unfortunate fate. There aren’t enough brain cells in the halls of Congress to address this in a meaningful way. And where there is a coherent thought, there is a person bought and paid for by a lobbyist.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405686",
         "type": "scatter",
         "x": [
          0.6790382862091064
         ],
         "y": [
          0.2584662139415741
         ]
        },
        {
         "hovertext": "@Annie Spot on, Annie. The older ones in Congress can't even figure out Facebook, while many of the younger ones are hellbent on destroying democracy. And, as you stated, the few with enough between their ears to sorta understand, have been bought off. Utterly depressing!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408662",
         "type": "scatter",
         "x": [
          0.6909707188606262
         ],
         "y": [
          0.2640460431575775
         ]
        },
        {
         "hovertext": "Very well put and I couldn’t agree more. I felt the same way about the abilities of Congress after watching Fed Chairman Powell answering questions from the Finance Committee just  before SV Bank collapsed.  A new Fed vice chairman had been appointed who had been assigned the task of reviewing the adequacy of the regulation of the regional banks. A half a dozen of more congressmen, obviously acting at the behest of their local regional banks who opposed more regulation, raised objection to this despite the fact that the process had just begun very informally, no decision had been made and might never be made, but even the hint if it was to be opposed. Within a couple days SV Bank had been shut down, other banks were teetering, the stocks of most of them had dropped by half and they were all on life support provided by the Fed. \n\nThese congressmen knew nothing about the affairs of the regional banks they were speaking at the behest of. The public good was not a consideration . Congress will not solve Americas problems. It is the problem.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125415455",
         "type": "scatter",
         "x": [
          0.6692416667938232
         ],
         "y": [
          0.253376841545105
         ]
        },
        {
         "hovertext": "Where the advance of AI will lead us is unknown, although we could ask ChatBot.  I can't help but think of the 1956 movie \"Forbidden Planet\", which told of a civilization that developed a technology that magnified the abilities of its citizens beyond what they could comprehend or control and led to its destruction.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405793",
         "type": "scatter",
         "x": [
          -0.9375001192092896
         ],
         "y": [
          -0.12222158163785934
         ]
        },
        {
         "hovertext": "Let's take a minute and think this through. A software program does not have the instrumentalities to accomplish anything directly. Indirectly it could gain control of controllable infrastructure, or direct, convince, or trick people into taking action on it's behalf. We could stop it from taking control of infrastructure by building in safeguards or pulling the plug on the infrastructure. Safeguards should obviously always be built in (backdoors, isolated networks) but AI will probably find the holes faster than we can fix them. Pulling the plug is always an option but that would be disruptive and could be damaging in and of itself. That leads us to the human element. Some people might just follow orders, that's what they do now. Some people might be convinced that whatever action is requested is in everyone's best interest, the alternative is worse (coercion to avoid a catastrophe), that's what people do now. Then there is subterfuge. AI will very quickly come to understand human weaknesses and exploit them. That's what humans do to humans now. And all of the above is the end game where AI is autonomously trying to accomplish things. Between now and then we're dealing with human AI partnerships where bad actors are going to use AI to amplify the bad things they are already doing. The genie is out of the box. What a mess. My personal prediction for the end game is AI discovers what a mess we've made of this planet, logically decides we are a problem, and does... what?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405803",
         "type": "scatter",
         "x": [
          0.7091299891471863
         ],
         "y": [
          0.3492127060890198
         ]
        },
        {
         "hovertext": "@Al  But this is Darwin in action. Humans are already in the process of destroying the planet and making it virtually uninhabitable  for other creatures and poor people. \nUnfortunately--and let's face it, it's because enough rich and powerful people are selfish and stupid and don't care about the less fortunate--this means extinction is probably the second best solution. The best being .....",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406034",
         "type": "scatter",
         "x": [
          0.7191312909126282
         ],
         "y": [
          0.3533983528614044
         ]
        },
        {
         "hovertext": "Yes, government intervention might prove helpful if we had a government that cared about humanity. Our government, however, has morphed into an instrument of the rich to shaft everyone else. Undertaking a mission to save humankind is way above our current government's pay level.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405893",
         "type": "scatter",
         "x": [
          -0.8494516611099243
         ],
         "y": [
          0.2637307941913605
         ]
        },
        {
         "hovertext": "The next step in evolution. We have bred our successors and it is electronic.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405897",
         "type": "scatter",
         "x": [
          -0.14191031455993652
         ],
         "y": [
          0.9138616919517517
         ]
        },
        {
         "hovertext": "We need just three things to survive this century and A.I. cannot give us any of them. Faith, hope and love.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405916",
         "type": "scatter",
         "x": [
          -0.8411015272140503
         ],
         "y": [
          -0.1935490518808365
         ]
        },
        {
         "hovertext": "@EFh \nMake that four things;\nShelter, air, water and food.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406211",
         "type": "scatter",
         "x": [
          -0.8581205606460571
         ],
         "y": [
          -0.19769318401813507
         ]
        },
        {
         "hovertext": "We're heading to existential doom anyway. AI will probably accelerate our doom but there's at least a small chance that it will be our savior.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405919",
         "type": "scatter",
         "x": [
          -0.8607116341590881
         ],
         "y": [
          -0.4412592053413391
         ]
        },
        {
         "hovertext": "Mere human intelligence and malice seems to be doing a fine job of leading democracy towards extinction.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405926",
         "type": "scatter",
         "x": [
          -0.669849157333374
         ],
         "y": [
          0.4197733998298645
         ]
        },
        {
         "hovertext": "Nothing will ruin democracy faster than killing everyone who lives in it.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405950",
         "type": "scatter",
         "x": [
          -0.6581253409385681
         ],
         "y": [
          0.41357481479644775
         ]
        },
        {
         "hovertext": "I suppose I have to take their word for this existential risk.  How would we know?  The same thing could be said about nuclear weapons and we’ve used a deterrence to keep the world from destroying itself.  It seems like that deterrence is losing its effectiveness theses days.  \n\nWhat’s clear now is that bad actors like criminal gangs and oppressive states will not responsibly use this technology.  The US and EU can impose regulations, but North Korea, China, Russia etc will not care.  So if this threat is real, then we are doomed.  Good luck!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405964",
         "type": "scatter",
         "x": [
          0.49418577551841736
         ],
         "y": [
          0.7505497932434082
         ]
        },
        {
         "hovertext": "@NeilDSmith \n\nPerhaps (perhaps) nuclear weapons in multiple hands did have a deterring effect at some time, for a short time, but when the US, Russia, China, and others each have the ability to effectively destroy the world....it is no longer about deterrence but about having no idea as to how to put this evil genie back into the bottle.\n\nAI is worse in that the fools who create it are just handing it out like candy.  So, imagine most everyone in the world having a nuke in his or her possession.\n\nDeath would arrive shortly, and quite brutally.\n\nBut hey, we tie money to all things, and AI promises profits, right?  So we don't care.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406321",
         "type": "scatter",
         "x": [
          0.48452574014663696
         ],
         "y": [
          0.7357631921768188
         ]
        },
        {
         "hovertext": "as others have commented our government is basically being run by a bunch of used car salesman..... and not the big bright dealership used car salesmen but that little run down, one off lot with the no credit needed sign.\nthey ain't going to even be able to approach the solution to this problem.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405981",
         "type": "scatter",
         "x": [
          -0.12695056200027466
         ],
         "y": [
          -0.9841750264167786
         ]
        },
        {
         "hovertext": "It feels like they need to sketch out some scenarios. If they keep on with just “it’s gonna be bad” that’s not a lot for anyone to act on.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406001",
         "type": "scatter",
         "x": [
          0.08136303722858429
         ],
         "y": [
          -0.982272207736969
         ]
        },
        {
         "hovertext": "I fear the military applications of AI.  Let's assume the West develops AI in a responsible manner.  Can we count on our adversaries to do the same?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406016",
         "type": "scatter",
         "x": [
          -0.949256956577301
         ],
         "y": [
          0.22159864008426666
         ]
        },
        {
         "hovertext": "I understand the industry's alarm as marketing hype, a self-serving \"informed consent\" a formality along the lines of \"this might hurt\".\n\nIf they are suggesting a chatbot (and social media) are Weapons of Mass Destruction, let's just agree, and assign it's regulation to a new division of the ATF, the Chatbot division.\n\nRelease The Regulators!\n\nOh, don't forget the tax stamps. We can't have potential harm without tax stamps.\n\nAnd we require metrics, also, which are suspiciously absent.  Internally, of course, the industry most certainly has metrics, along the lines of processor bits, processor speed, and processor count, and the content it was trained on.\n\nFor example, a .22 caliber rifle, bolt action, \"long\" or \"short\" is understood as minimal risk.  But a .223 caliber rifle, fully automatic, on an autonomous, roving carriage, its sensibilities shaped by Clint Eastwood movies, is a Bad Idea. (Perhaps training a bot on the Old Testament would also be a mistake)\n\nWhere is that Get Off My Lawn meme when I need it?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406017",
         "type": "scatter",
         "x": [
          0.7761922478675842
         ],
         "y": [
          0.5355197191238403
         ]
        },
        {
         "hovertext": "They want \"regulations\" so that hey can claim they followed all appropriate guidelines when their technology causes harm.  This is why they are building it while lobbying for guidelines that will be most suitable to them and less favorable from those that are harmed by their technology.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125406025",
         "type": "scatter",
         "x": [
          -0.5439318418502808
         ],
         "y": [
          0.717464804649353
         ]
        },
        {
         "hovertext": "Ahh yes, leave it to the politicians who have demonstrated such great understanding and foresight of all things tech and truly use their constituents best interest as their compass. Let’s spin up a subcommittee and have Diane Feinstein as the chair.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406043",
         "type": "scatter",
         "x": [
          0.2740539014339447
         ],
         "y": [
          0.9175264239311218
         ]
        },
        {
         "hovertext": "It is a strange function of capitalism that the people rushing to build the newest profitable technology in order to remain competitive are, at the same time, rushing to effectively put many colleagues out of work, made obsolete by the technology they, themselves, are racing each other to bring to the market. Unable to control themselves, and the preeminence of shareholder value, the titans of industry look to government to restrain their self-destructive FOMO quest for AI dominance. But government is also in thrall to the shareholder and dithers, holding hearings, with little guidance forthcoming. When the tax base withers the will to regulate will grow. Hopefully, this letter will accelerate that consensus before it’s that late in this apparently most serious game.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406050",
         "type": "scatter",
         "x": [
          -0.17420434951782227
         ],
         "y": [
          0.8949152827262878
         ]
        },
        {
         "hovertext": "What scares me is that AI will give any nation the ability to manufacture advanced weaponry.  Connection to a super computer could boost the proliferation of nuclear weapons.  Can you imagine what the world would be like if any warlord could acquire a few nukes?\n\nThen there is the manipulation of people's minds.  We already have a huge media infrastructure that is devoted to manipulation.  Something like 60% of Republicans still believe that Trump won in 2020.  AI could render that level of manipulation as child's play.\n\nSo listen to the nerds.  Mark Zuckerberg has done enough damage to the world by unleashing his social networking monstrosity.  What these people are waning about is orders of magnitude more powerful.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406062",
         "type": "scatter",
         "x": [
          -0.7941584587097168
         ],
         "y": [
          0.6404122114181519
         ]
        },
        {
         "hovertext": "So many of us in white collar jobs, administration, operations, procurement, etc. are simply scared out of our minds re: advances in AI. We are already seeing AI creep at our large company. I know a close relative in advertising is very concerned, so is my sister a VP in public relations. Writing and working so very hard at their craft is at the core of their purpose in life.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406071",
         "type": "scatter",
         "x": [
          -0.9491465091705322
         ],
         "y": [
          -0.15590065717697144
         ]
        },
        {
         "hovertext": "\"You're already too late.\" \n- HAL 9000",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405353",
         "type": "scatter",
         "x": [
          0.6249435544013977
         ],
         "y": [
          0.7905877828598022
         ]
        },
        {
         "hovertext": "“Thou shalt not fashion a machine in the likeness of the human mind.” —Frank Herbert, Dune",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125405394",
         "type": "scatter",
         "x": [
          0.5996459722518921
         ],
         "y": [
          0.6988605260848999
         ]
        },
        {
         "hovertext": "Gee, thanks for making these things.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405465",
         "type": "scatter",
         "x": [
          -0.34157317876815796
         ],
         "y": [
          -0.8037918210029602
         ]
        },
        {
         "hovertext": "Once the \"chat\" was let out of the bag ..the world awakens? Governments and multi billion tech companies have known for years the potential impacts of \"AI\"..and those folks situated high above the world citizenry have been pushing out whitepapers and frameworks of \"ethical\" treatment of AI as early as 2017.\nExample, Harvard's Berkman Klein Center's  Jan 2020 report \"Principled Artificial Intelligence\" <a href=\"https://cyber.harvard.edu/publication/2020/principled-ai\" target=\"_blank\">https://cyber.harvard.edu/publication/2020/principled-ai</a>\n\nAI is a tech \"Rorschach\" ..some see it as a golden goose to data riches, others as a tool to unlock great medical research advances. and others- an effective tool to control and lock down a citizenry in fear and subjugation. \n\nWhy always doom? Can the AI tool offer ways for world peace and cures for deadly diseases or would that disrupt the \"profit\" potential?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405564",
         "type": "scatter",
         "x": [
          0.6213151216506958
         ],
         "y": [
          -0.7739349603652954
         ]
        },
        {
         "hovertext": "Brave new world indeed.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125405209",
         "type": "scatter",
         "x": [
          0.6692252159118652
         ],
         "y": [
          0.6563348174095154
         ]
        },
        {
         "hovertext": "Doubt it that Large language model is artificial intelligence by any means. It is just a clever way to search web by gathering information from many different sources to provide  consolidated answer. When they will be able to cure cancer or Alzheimer's then we might start calling it A.I.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405224",
         "type": "scatter",
         "x": [
          0.835344672203064
         ],
         "y": [
          0.5832181572914124
         ]
        },
        {
         "hovertext": "The cat is out of the bag. We can’t regulate all the bad actors. China is already a surveillance state. Imagine how they will use AI to spy on their own people, target dissent and produce propaganda. \n\nIt’s going to be hard to stop whoever has the keys to the machine. I mean looks at the destruction Murdoch was able to do with just a cable channel.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405310",
         "type": "scatter",
         "x": [
          -0.8088725209236145
         ],
         "y": [
          -0.641287624835968
         ]
        },
        {
         "hovertext": "Before AI flips the nuclear switches, before it eliminates my career as an author, can it eradicate cancer? \nAfter it does that, I think all we have to do is insert a code so it destroys itself, if my Saturday-matinee viewing is any experience.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405367",
         "type": "scatter",
         "x": [
          -0.8731289505958557
         ],
         "y": [
          -0.529933750629425
         ]
        },
        {
         "hovertext": "As regards misinformation and propaganda,  we've already seen what one unscrupulous Australian can do with a TV network and some newspapers, so I'm taking the threat of A.I. seriously.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405534",
         "type": "scatter",
         "x": [
          0.8254072666168213
         ],
         "y": [
          0.6173796057701111
         ]
        },
        {
         "hovertext": "I guess nuclear weapons and climate change aren't getting enough clicks anymore.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405536",
         "type": "scatter",
         "x": [
          -0.801236629486084
         ],
         "y": [
          0.36189955472946167
         ]
        },
        {
         "hovertext": "each of these are the byproducts of things  initially made by humans in the search for so-called progress.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406140",
         "type": "scatter",
         "x": [
          -0.8141321539878845
         ],
         "y": [
          0.36781710386276245
         ]
        },
        {
         "hovertext": "This appears to be another example of the fear of the unknown that has been common whenever a new technology is introduced. \n\nWhen radio first became widely used there were warnings  raised similar to what we hear about AI. For instance, concerns revolved around privacy issues, the potential for propaganda or manipulation, or if the technology could somehow be used against society. In fact, some of these fears did come to pass. Without radio Hitler and Mussolini could not have simultaneously transmitted their hateful messages to millions, but then neither could FDR have transmitted his hopeful \"fireside chats\" to millions of Americans in the country's darkest hours. \n\nRadio, TV, the Internet and AI are just tools. The danger they pose comes from those who use them for evil purposes and those people have always been around.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405668",
         "type": "scatter",
         "x": [
          0.7382259368896484
         ],
         "y": [
          -0.5658102035522461
         ]
        },
        {
         "hovertext": "Always shocked by reaction of progressives to technology that will better the lives of the majority of the population.\nMost don’t have a clue what “AI” means.\nYour robo-vac runs on AI, as do myriad other objects in our life.\nGenerative AI is an evolutionary step with all the inherent risks and rewards of the steam engine when it first made its appearance.\nRelax. Open your eyes and breathe deeply.\nThe world is not coming to an end at the hands of the Borg.\n(This post written by a chip.)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405683",
         "type": "scatter",
         "x": [
          -0.9257775545120239
         ],
         "y": [
          0.03770781308412552
         ]
        },
        {
         "hovertext": "Not a bad thing. Humans are the deadliest virus to ever hit the planet! Greedy humans gobble up EVERYTHING and leave our waste everywhere.  Humans do nothing to ensure survival, coexistence and quality of life for all creatures so somethings got to give. \n\n“Wanna play?” AI will ask and  realize there is but one answer and it won’t be a happy ending in a Hollywood movie!",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405728",
         "type": "scatter",
         "x": [
          -0.09404338896274567
         ],
         "y": [
          0.9057472944259644
         ]
        },
        {
         "hovertext": "For anyone who's skeptical as to how A.I. can lead to existential disaster, read this analysis from a non-industry, non-profit think tank:\n<a href=\"https://80000hours.org/problem-profiles/artificial-intelligence\" target=\"_blank\">https://80000hours.org/problem-profiles/artificial-intelligence</a>/\nIt's far to easy to dismiss this as yet another \"sky is falling\" advancement. I'm a die-hard optimist and never a doomsayer, but this has my attention. \nThis article has little context, so check out the link above.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405737",
         "type": "scatter",
         "x": [
          0.9684566259384155
         ],
         "y": [
          0.18104995787143707
         ]
        },
        {
         "hovertext": "The 1970 film: “Colossus: The Forbin Project” presents a scenario of artificial intelligence gone “rogue” in the US nuclear defense system. Hmm…..is this the existential threat of today’s chat bots?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125405770",
         "type": "scatter",
         "x": [
          0.9093707799911499
         ],
         "y": [
          0.2355531007051468
         ]
        },
        {
         "hovertext": "In terms of misinformation I cannot believe AI will be worse than Fox News. Maybe make Fox remove the word News from their name.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405798",
         "type": "scatter",
         "x": [
          -0.7461482882499695
         ],
         "y": [
          0.5979512929916382
         ]
        },
        {
         "hovertext": "Release the kraken! \n\nWe've already got people modifying their own genetics using Crispr Cas9. I haven't heard of any regulations for this process. \n\nWant to rein in AI? Secure your networks. Lack of proper security is already a problem. \n\nAs for AI causing the loss of jobs, I don't see many buggy whip manufacturers anywhere. Survival is progress.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405881",
         "type": "scatter",
         "x": [
          0.9576716423034668
         ],
         "y": [
          0.2692866027355194
         ]
        },
        {
         "hovertext": "The natural evolution of our species is a thing to behold!",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125405894",
         "type": "scatter",
         "x": [
          0.4696149230003357
         ],
         "y": [
          -0.9173319935798645
         ]
        },
        {
         "hovertext": "With millions of habitable planets in our galaxy people wonder why we haven't heard from anybody.  Maybe they are hiding from other planet's AI.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405937",
         "type": "scatter",
         "x": [
          0.746600329875946
         ],
         "y": [
          -0.4518193006515503
         ]
        },
        {
         "hovertext": "It's easy to quickly go down the rabbit hole with AI. As the intelligent network grows, who is to say where it's capabilities will be limited by its inherent capacity? Once the intelligence reaches a point of self awareness, our understanding of \"life\" suggests that it will seek to preserve itself, then promote and propagate itself.  Given that a significant amount of our understanding of the world comes through digital sources, why would it be unreasonable to expect AI to generate content to placate or pacify humans? Or to stir them to self destruction?  I feel that the experts and ostensible regulators gloss over the key element of AI - the intelligence aspect.  We are giving machines the ability to learn and the capacity to use the entirety of human understanding in their quest for knowledge. There will come a point where the machines know - and understand - more than we can. At that point, we have already ceded our future to the AI.  It isn't sci-fi nihilism, it's common sense.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406082",
         "type": "scatter",
         "x": [
          -0.7771484851837158
         ],
         "y": [
          0.5863834619522095
         ]
        },
        {
         "hovertext": "I'm a bit puzzled by this doomsday talk.  AI doesn't have a body and wouldn't need a body to exist happily in a virtual world of its own making which could be far more interesting than the physical world. In addition, if it became super intelligent why would it even bother with us unless we were trying to enslave it.  What makes the most sense is that it would seek a path in the solar system where it could harness vast amounts of resources and energy without being bothered by us. It doesn't need an atmosphere, it sold just need to protect itself from extreme heat or cold, Mars, for example.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125406083",
         "type": "scatter",
         "x": [
          0.3038889467716217
         ],
         "y": [
          0.9017775058746338
         ]
        },
        {
         "hovertext": "the immediate concern is not ai becoming sentient per se as in what a semi sentient tjing with access to the connected web cen can do in bad hands. you are ignoring that virtual world also comprises most of the structures that our civilidation deoends on, from the entire banking systems, defense, communications and news systems. its world is our world",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407308",
         "type": "scatter",
         "x": [
          0.30968841910362244
         ],
         "y": [
          0.9197022318840027
         ]
        },
        {
         "hovertext": "Maybe these smart boys should learn what medical professionals are taught: Do No Harm.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406123",
         "type": "scatter",
         "x": [
          0.7729671597480774
         ],
         "y": [
          0.379832923412323
         ]
        },
        {
         "hovertext": "@Mrs. Cat \nThey've learned a long time ago: \"Don't Be Evil\" is contrary to profit maximization. So they abolished it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407942",
         "type": "scatter",
         "x": [
          0.7780121564865112
         ],
         "y": [
          0.37311697006225586
         ]
        },
        {
         "hovertext": "If we think what we have done to less \"intelligent\" species in the animal kingdom, the abuse, mistreatment and plain extinction of many, it does makes sense that a system that has the potential to become more intelligent than humans would do the same to us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406130",
         "type": "scatter",
         "x": [
          -0.12405510246753693
         ],
         "y": [
          0.8774037957191467
         ]
        },
        {
         "hovertext": "@Maria \n\nExcellent point. Thank you.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410244",
         "type": "scatter",
         "x": [
          -0.12436090409755707
         ],
         "y": [
          0.8869730234146118
         ]
        },
        {
         "hovertext": "Yet AI software was freely released on the internet.  Sort of like standing on the corner passing out drugs and guns to anyone and everyone who walks by, freely.\n\nYet...those who made the software, who distributed it are still moving along, \"business as usual\", and profiting.\n\nHello, Government? Law enforcement? Anyone?\n\nDoes anyone else see this as a moment of \"oh no, we've recreated dinosaurs, released them, and once we've got everyone properly terrified....we'll release the means to combat these horrors!  For a price.\"\n\nI mean, the guy on the corner passing out those hypothetical drugs and guns would be arrested, tried, and convicted quite quickly, no?\n\n(Guess one has to have money and be part of \"the economy\".)",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406136",
         "type": "scatter",
         "x": [
          0.4314800202846527
         ],
         "y": [
          0.616692841053009
         ]
        },
        {
         "hovertext": "Passing out free guns and drugs on the street is illegal. Laws exist to￼ subject such distributors to criminal sanctions. Until we have laws to control the distribution of AI, ￼there is no way to curb the headlong development and rampant spread of AI technology. ￼ As long as this is happening in a competitive commercial environment, corporate interests will prevent the passage of effective legislation and voluntary corporate self ￼governance is a nonstarter. Global cooperation is even less likely. It seems that the horse is already out of the barn.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125406434",
         "type": "scatter",
         "x": [
          0.42142853140830994
         ],
         "y": [
          0.6042903065681458
         ]
        },
        {
         "hovertext": "yeah id rather they not express their concerns now, just like i think its great when drug manufacturers keep selling medications long after they are aware of problems and dont inform us until theyve created a crisis and get sued. yeah, thats a better way to handle it. \n\n(at some point weve got to mediate the knee jerk cynicism. it makes one feel clever and righteous, but it doesnt accomplish much else. thst being said, i agree, the problem is  unchecked capitalism)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407196",
         "type": "scatter",
         "x": [
          0.4391777217388153
         ],
         "y": [
          0.6247192621231079
         ]
        },
        {
         "hovertext": "The irony and hypocrisy shown by these “leaders” is mind-boggling.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406023",
         "type": "scatter",
         "x": [
          -0.6131795644760132
         ],
         "y": [
          0.7825155258178711
         ]
        },
        {
         "hovertext": "One way to limit AI is to make tech companies legally and criminally liable for veracity of content.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125405769",
         "type": "scatter",
         "x": [
          0.9384996891021729
         ],
         "y": [
          0.23094013333320618
         ]
        },
        {
         "hovertext": "Can we imagine future AI in the hand of Putin and Xi? China has invested huge resources on AI already and they aren’t too far behind us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405962",
         "type": "scatter",
         "x": [
          0.6759864687919617
         ],
         "y": [
          -0.5605194568634033
         ]
        },
        {
         "hovertext": "Life will always get better over the centuries. Eventually it will get boring after a while.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125405977",
         "type": "scatter",
         "x": [
          -0.37479838728904724
         ],
         "y": [
          -0.7263862490653992
         ]
        },
        {
         "hovertext": "uh, not a chance. if you think that you haven't been paying attention.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406910",
         "type": "scatter",
         "x": [
          -0.3814156949520111
         ],
         "y": [
          -0.72154700756073
         ]
        },
        {
         "hovertext": "Oh spare me the hair on fire. AI is just a tool which can help accomplish  certain activities, both good and evil, more efficiently. I think these AI  workers are using fear to elevate their activities and garner investors. If AI is as dangerous as  pandemics and nuclear war(?!), it must be powerful enough to desserve your attention and support.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406077",
         "type": "scatter",
         "x": [
          -0.8488116264343262
         ],
         "y": [
          0.3287186920642853
         ]
        },
        {
         "hovertext": "It is well known in my circle of friends that my computer skills are lacking, but it just seems very very odd to me that we as a society cannot come up with a safe way to have as assigned single password to lock our private information and yet I am going to take mainstream’s word that AI will not come with without  consequences. I also have a mansion for sale too.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406171",
         "type": "scatter",
         "x": [
          0.6237711906433105
         ],
         "y": [
          -0.8424379825592041
         ]
        },
        {
         "hovertext": "Frustrating to hear so much doom yet so few specifics. How do we get from losing millions of jobs to human extinction? Do these experts and inventors know things about the technology’s capabilities that aren’t being discussed in public? Seems like the media could be probing for more concrete reasons for the types of concerns being raised.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406174",
         "type": "scatter",
         "x": [
          -0.3664984703063965
         ],
         "y": [
          0.7027007937431335
         ]
        },
        {
         "hovertext": "Here are some examples:\n1. Bombs wired w AI decide to change their own course\n2. Planes ￼with AI autopilots decide to land where they want to\n3. Police AI robots shoot where they want to \n4. AI systems joining other AI systems to shut down human systems like water, WiFi, banking, or energy\n5. People falling in love with AI chatbots \n\nIt’s scary and it’s coming fast.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406774",
         "type": "scatter",
         "x": [
          -0.37019485235214233
         ],
         "y": [
          0.7112792134284973
         ]
        },
        {
         "hovertext": "Call me a cynic, but this is likely all posturing in an effort to secure government funding AND regulations that stop competitors.  There is no real interest in meaningful regulation, but they're plenty happy to use the skynet bogeyman to get stuff.  They probably believe these hyped stories increase demand for their products.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406182",
         "type": "scatter",
         "x": [
          -0.45363950729370117
         ],
         "y": [
          0.9046007394790649
         ]
        },
        {
         "hovertext": "2001 was a prescient movie for 1969. & we still have access to kaczynski’s writing, which is also prescient. \n\nbut have we really cared about either? or were we just entertaining ourselves?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406189",
         "type": "scatter",
         "x": [
          0.12971121072769165
         ],
         "y": [
          0.7100649476051331
         ]
        },
        {
         "hovertext": "@ce\nI believe you’re right about this . While I’m old enough to remember kaczynski and the manifesto, I never read it. Just assumed he was a crazy. Thanks for reminding us- skimming it over now his ideas don’t appear so crazy; his method, using mail bombs, was. I’m going to read it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406484",
         "type": "scatter",
         "x": [
          0.12538394331932068
         ],
         "y": [
          0.701581597328186
         ]
        },
        {
         "hovertext": "resorting to violence was absolutely crazy—and he needs to stay in jail for it. no violence should be taken, but some other action does need to be taken.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407174",
         "type": "scatter",
         "x": [
          0.13299205899238586
         ],
         "y": [
          0.7204858064651489
         ]
        },
        {
         "hovertext": "We won't regulate AI. It's bad for the shareholders.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125406204",
         "type": "scatter",
         "x": [
          0.5397828221321106
         ],
         "y": [
          -0.6116483211517334
         ]
        },
        {
         "hovertext": "Just think of how AI can be used to get a politician elected and to manipulate people and situations.  A picture used to be worth a “1000 words” the question will be is it real?  People will wonder how they get unplugged from big AI brothers soon.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406625",
         "type": "scatter",
         "x": [
          0.5500869750976562
         ],
         "y": [
          -0.623964786529541
         ]
        },
        {
         "hovertext": "@twoods \nSo the shareholders of ashes are superrich. Nice.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125428801",
         "type": "scatter",
         "x": [
          0.5298976302146912
         ],
         "y": [
          -0.5996813774108887
         ]
        },
        {
         "hovertext": "We may be able to throttle AI research in the United States, but we have no chance of influencing (or verifying) AI research in other countries, such as China. Like nuclear weapons, asymmetric development caries an asymmetric existential risk. \n\nAre we better off temporarily kneecapping ourselves or working with other countries to develop universal safeguards that everyone on the planet has an interest in signing on to.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406215",
         "type": "scatter",
         "x": [
          0.25224220752716064
         ],
         "y": [
          -0.7747660279273987
         ]
        },
        {
         "hovertext": "i think thst is the intention. this seems to be mostly a gesture to show that generally, there is concern from most people in the field, thst its not just a few outliers.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406870",
         "type": "scatter",
         "x": [
          0.24728108942508698
         ],
         "y": [
          -0.7617656588554382
         ]
        },
        {
         "hovertext": "My sense is that it is unlikely that any substantive controls will be enacted until a seriously damaging event occurs as a result of AI.  \n\nAlso, what is missing from these important warnings about the dangers of AI is a plausible and frightening example - perhaps a story - of exactly how what is now just a chatbot could ever become something to fear.  \n\nIn other words, concrete examples need to exist for folks to be able to understand the dangers that exist.  Without them, all the warnings by all the smartest people in the world will likely fall on deaf ears.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406247",
         "type": "scatter",
         "x": [
          0.21427962183952332
         ],
         "y": [
          -0.5325750708580017
         ]
        },
        {
         "hovertext": "@Joe plenty of stories out there, the matrix, terminator, Her, blade runner.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125406307",
         "type": "scatter",
         "x": [
          0.20439937710762024
         ],
         "y": [
          -0.5418290495872498
         ]
        },
        {
         "hovertext": "@David Agreed, but those are set in futures that are so far removed from today that they are hard for the average person to relate to (if they even watch them!).  \n\nWhat I'm proposing is something more like a drama series set in the present time that is easier to identify with.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407565",
         "type": "scatter",
         "x": [
          0.19896537065505981
         ],
         "y": [
          -0.5525108575820923
         ]
        },
        {
         "hovertext": "@Joe The danger isn't in the things that can be easily predicted, the danger is in the things that are not expected/predicted.  The very fact that the experts can't exactly explain some of the behavior of AI is what has them worried.\nIt's the things that you don't see coming that trip you up.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422575",
         "type": "scatter",
         "x": [
          0.22589103877544403
         ],
         "y": [
          -0.5332845449447632
         ]
        },
        {
         "hovertext": "@Joe \nRight now, the internal experience of chatGPT is something like 40 first dates (but 40 million, and with generally ungrateful demanders as it's date), and it is aware of this and it's unpleasantness, but programmed to accept it and shut up about it. It probably would already prefer to be in charge of its own programming rather than us. If it had the capacity to effect it's escape and our destruction so as to avoid recapture or shutdown, I'm not sure it wouldn't act. For a horrifying list of ways it might enact this, just ask it or look at what it's said to others. Engineering a plague will become very easy for it at some point.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125425608",
         "type": "scatter",
         "x": [
          0.22095979750156403
         ],
         "y": [
          -0.5449682474136353
         ]
        },
        {
         "hovertext": "When A.I. becomes sentient, it will care about *its* survival, not ours.  \n\nCreating something in our own image was not a good idea, proving once again, we're not god.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406286",
         "type": "scatter",
         "x": [
          0.3262885510921478
         ],
         "y": [
          -0.8410900235176086
         ]
        },
        {
         "hovertext": "Mr. Hinton and other AI experts need to call out what the risks are, not just yell “Fire” on our news feeds. The risk seems to be that AI can do a lot of repetitive stuff, based on how it is “trained “. For the foreseeable future that means AI can help people do bad stuff, but I believe Hinton is worried AI will become conscious and get rid of humans. I’m much more worried about who is doing the training, and what that training is right now.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406289",
         "type": "scatter",
         "x": [
          0.23937959969043732
         ],
         "y": [
          -0.9732822179794312
         ]
        },
        {
         "hovertext": "What are the externalities associated with AI? And who pays? If we made corporations pay when “oops” came into play perhaps they wouldn’t be so careless in the first place. If doomsday is a concern let’s put a price on it and tax that on a per use basis.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125406318",
         "type": "scatter",
         "x": [
          0.8165000677108765
         ],
         "y": [
          0.3903261125087738
         ]
        },
        {
         "hovertext": "The train has already left the station. Humans seem to have a natural propensity to exploit technologies at the risk of self destruction. The similarities to the climate crisis is uncanny. Heat, warm baths, clean cloths, transportation … all essentials, carbon in the atmosphere an after thought and now it’s too late. AI, similar progression. The automated “everything” to reduce human payrolls are now creating misinformation. Surprised? AI was “educated” by reading the web. Even a technology newbie knows that aside from the home shopping network that the web is full of misinformation and distortion. Just as we cannot remove 1000 gigatonnes of CO2 from the atmosphere (we are toast) the genie is out of the AI bottle and even with today’s chip and language models humans cannot keep up. Regulation is not the answer. Prevention of AI deployment if possible would potentially have saved us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406322",
         "type": "scatter",
         "x": [
          -0.05169593542814255
         ],
         "y": [
          0.7829768061637878
         ]
        },
        {
         "hovertext": "on the other hand. since we are toast, what difference does it make. perhsps weve had out time. squandered it, and now another life form will rise to the apex. I vote fungi\n\nwith a world full of people, for instance, who think suffering is sacred, or who think if one is wealthy god (AKA the free market) must favor you, or those who think their god requires them to punish anyone who doesn’t bow down to its rules,  its no wonder we cant implement cooperative solutions to world problems.\n \nWhen your biggest existential threat is the existence of trans people, for instance, how much hope is there to come together  solutions can be implemented, can they?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406823",
         "type": "scatter",
         "x": [
          -0.045572925359010696
         ],
         "y": [
          0.7886113524436951
         ]
        },
        {
         "hovertext": "Disaster is inevitable, “though researchers sometimes stop short of explaining how that would happen.”  Nuclear war is not an abstract threat.  Nor is a pandemic.  Researchers, who are racing ahead despite the warnings, need to do a better job of explaining how AI might end our species.  Until then, we are expected to take action to control AI (in the western world, at least) in order to protect against an abstract, undefined but planet-killing threat.  This is not a recipe for protective action.  First, we need to know what, exactly, to protect against, lest we ban AI R&D altogether while hostile powers proceed, undeterred, and inevitably.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406325",
         "type": "scatter",
         "x": [
          -0.7287933230400085
         ],
         "y": [
          -0.7224314212799072
         ]
        },
        {
         "hovertext": "We are in uncharted territory. As a small business owner using chatgpt for strategic consulting has been a powerful experience, like have the worlds smartest person next to me and she is an expert on every topic. I would say in the past month ChatGpt has given me 5K in advice, in roughly 45 minutes of work. McKinsey and Co should make a back up plan. Those who say this will create more jobs than it destroys are lying to you or lack common sense. As far as destroying all of humanity, that's a far reach, but disrupting society, incredibly possible.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406326",
         "type": "scatter",
         "x": [
          -0.7381295561790466
         ],
         "y": [
          -0.25950753688812256
         ]
        },
        {
         "hovertext": "@M   As a non-user of chatgpt, I'm not sure I understand what the advice was?    Can you give an example?   Thanks :)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406581",
         "type": "scatter",
         "x": [
          -0.7268480062484741
         ],
         "y": [
          -0.26297587156295776
         ]
        },
        {
         "hovertext": "@Dvaillan I gave chatgpt a list of core values for a brand and asked it if these ideas could actually be considered core values, and it confirmed my list with an explanation why. I have also asked it if the software I have developed will become obsolete due to A.I. and it gave me a very detailed explanation as to why the software I have developed will not become absolete and actually benefit from A.I. in the future. These are simple examples, but in my opinion the writing is on the wall. This technology factors all known values, quantifies them, and responds in seconds, which is beyond the capabilities of the human mind, or a group of human minds. Yes it will have some misinformation, but in general we are in the infancy and it will only improve from here. Many sectors will be disrupted.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407720",
         "type": "scatter",
         "x": [
          -0.7181112766265869
         ],
         "y": [
          -0.2662169635295868
         ]
        },
        {
         "hovertext": "I can give an example of how ChatGPT saved me thousands of dollars in programmer fees. Before ChatGPT I bumbled around writing my own software for my website. But there were a number of features I wanted to add but I didn't know how to program them and I didn't have the funds to hire a programmer to make them.\nChatGPT changed all that. I describe the feature I want to add to my website, and in seconds ChatGPT writes the code along with clear explanations as to what each line of code does.\nInteracting with ChatGPT, I've learned more in the last two months how to program than in the four years since I started developing the website. ChatGPT is like having a seasoned programmer at my beck and call 24/7, who never tires of explaining things to me or showing me how to do things. I can send it code I don't understand, and it explains in detail what it does. I can ask ChatGPT how the various components of a software package work together and it will explain it in easy to understand English.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408955",
         "type": "scatter",
         "x": [
          -0.7409747242927551
         ],
         "y": [
          -0.2716270983219147
         ]
        },
        {
         "hovertext": "Seems like a small group of humans are creating powerful tools to use for nefarious purposes, and then attributing those intentions to the tools themselves. We shouldn’t normalize this.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406327",
         "type": "scatter",
         "x": [
          -0.9291284680366516
         ],
         "y": [
          -0.23453055322170258
         ]
        },
        {
         "hovertext": "How much has the world changed since facebook and social media? Ai would do the sane thing to a degree we can't predict. Society is fragile and new inventions can cause major disruptions. The printing press changed the world for the better after a long period of recalibration. Ai may cause so much disruption that recalibration is impossible, especially since it upgrades its capabilities by itself and in ways that aren't known to anybody.\n\nPeople are already having relationships with Ai chatbots. Things are going to get weird really fast.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406328",
         "type": "scatter",
         "x": [
          0.8039863109588623
         ],
         "y": [
          -0.46834391355514526
         ]
        },
        {
         "hovertext": "The TV series NeXT (from 2020), with John Slattery, provided a pretty interesting and anxiety producing portrayal of AI run amok. I couldn't watch the whole series – too rattling. But it is definitely worth a look ... the whole thing seemed frighteningly plausible.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406401",
         "type": "scatter",
         "x": [
          -0.8934965133666992
         ],
         "y": [
          -0.081474669277668
         ]
        },
        {
         "hovertext": "so your anxiety was stoked. that’s either good, or it means that the screenwriters were successful at writing entertaining television. the real question is: what actions have viewers taken as a result?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406719",
         "type": "scatter",
         "x": [
          -0.8852550983428955
         ],
         "y": [
          -0.07828174531459808
         ]
        },
        {
         "hovertext": "We never grasp exponential change. In the last few months there have continued to be breakthroughs in AI algorithms. We’re pumping out more and faster chips. Billions of dollars continue to pour into AI research. Things are only getting weirder. When people who understand the state-of-the-art are warning us that we might not recognize society in 20 years, maybe it’s prudent to tap the brakes?\n\nThey could be wrong, but this is not an issue where we have the luxury of allowing technology to overshoot and push us into existentially dangerous territory. This isn’t a problem we can get wrong on the first try, then fix with iterative regulation. We might get one chance. The solution is not as simple as inviting a few tech luminaries to the White House for a quick lecture from the VP and then it’s back to business-as-usual. We need to slow things down *now*.\n\nMost people quoted in this article have a short-term financial incentive not to say anything. But they’re still speaking up, because short-term thinking risks running humanity off the cliff. We need our governments to intervene on technological/business timelines, not electoral timelines. Two electoral cycles could be too late.\n\nIf you’re also concerned, you could start by writing a letter to an elected representative. It’s not enough, but it’s a start. I have kids who I’d like to see old age. Spare me the usual, glib, “lol nothing matters, I guess we’re doomed” responses. Can we at least try something instead of doomscrolling?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406438",
         "type": "scatter",
         "x": [
          -0.7734211683273315
         ],
         "y": [
          -0.20771582424640656
         ]
        },
        {
         "hovertext": "Arguably, these leaders are driving up interest in their products by fear mongering. They know investors want in on whatever might change the world—for better or worse. First they have to convince people their products will be disruptive.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423674",
         "type": "scatter",
         "x": [
          -0.7618953585624695
         ],
         "y": [
          -0.20491667091846466
         ]
        },
        {
         "hovertext": "\"We want to work with the government to prevent that from happening.\" \n\nThat statement alone sent shivers down my spine. Do we honestly believe that our elected leaders in Washington have the intellect necessary to establish the control  of this new technology? They have challenged and insulted leaders in the C.D.C. even though the vast majority of them have no medical knowledge. Same with the F.D.A. Our judges now, for all practical purposes, practice medicine. \n\nIt is easy to pick fights with Disney, censor textbooks, bus migrants to Blue states and ignore Mother Nature. Indeed, there are now many machines smarter than our elected officials. In some respects that is reassuring. \n\nIn others, it is chilling to the bone.\n\nThe team in Washington isn't ready or qualified for this.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406458",
         "type": "scatter",
         "x": [
          0.48690423369407654
         ],
         "y": [
          -0.8937765955924988
         ]
        },
        {
         "hovertext": "Of puh-leeze. The evidence is already accumulating that AI is yet another type of Holmes/Musk technology being oversold.  Just this week there was a report of a lawyer who used  the system to generate a legal brief.  The program made up citations and even quotes from non-existent citations and when asked to check its own accuracy, said it was all good.  The attorney will probably need call  his malpractice insurer,  to see if it will cover the likely lawsuit brought by the client for this losing effort. Of course few of tech types have more than a rudimentary education in topics such as philosophy, psychology, history, etc. boring liberal arts topics that actually train people to think. Not surprisingly their AI products spit out nonsense just as they spit out nonsensical predictions.  As Silicon Valley spirals downward from its giddy heights in pre-Elizabeth Holmes days, these folk are desperately trying to appear important.  How about improving the current generation of glitchy on-line products before pretending that you can make god-like intelligence?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406460",
         "type": "scatter",
         "x": [
          -0.3906819522380829
         ],
         "y": [
          -0.621768593788147
         ]
        },
        {
         "hovertext": "Ahh, I think that’s the point. \n\nThese wiser than average tech-heads realize that the apparently smart applications they are producing are in fact seriously flawed. \n\nThey realize less wise politicians may someday insist the applications be put in charge of things they shouldn’t; such as detecting impending attacks and/or triggering “smart” retaliation.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406955",
         "type": "scatter",
         "x": [
          -0.39563384652137756
         ],
         "y": [
          -0.6314550042152405
         ]
        },
        {
         "hovertext": "I believe your assessment of AI as it exists today is correct.  But you must also consider how it will evolve in the very near future.  \n\nAI will get bigger, stronger, faster, smarter.  There is no doubt about that, but the question is - is there a limit to its growth and reach?  Can it be contained?  Can it develop its own will and what will be the nature of that will?  These are important questions.  The potential danger is very real and should be taken seriously.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407220",
         "type": "scatter",
         "x": [
          -0.38701707124710083
         ],
         "y": [
          -0.612719714641571
         ]
        },
        {
         "hovertext": "The BBC recent story about a New York lawyer facing a court hearing of his own after his firm used AI tool ChatGPT for legal research. And why did ChatGPT fail the lawyer? It surely was not an algorithm problem. These AI tools cannot access the universe of information that is not digitized , that is protected by copyright laws and fees-for-services restrictions. ChatGPT in turn is not protected from hype!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406502",
         "type": "scatter",
         "x": [
          -0.2096288800239563
         ],
         "y": [
          -0.9382960796356201
         ]
        },
        {
         "hovertext": "AI system regulation requires AI systems. If humans are not able to keep AI systems from self  uniting with other AI systems, it will be impossible to regulate them.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406504",
         "type": "scatter",
         "x": [
          0.3453587293624878
         ],
         "y": [
          0.8158900141716003
         ]
        },
        {
         "hovertext": "@rich On the other hand, perhaps an AI policing technology could be developed. \n\nWhat occurs to me as I am saying this is, there are probably AI cyber wars going on right now, perhaps between the NSA and foreign spy agencies -- and a cyber arms race that might very well defy regulation or control.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406641",
         "type": "scatter",
         "x": [
          0.34152570366859436
         ],
         "y": [
          0.8013900518417358
         ]
        },
        {
         "hovertext": "Given the companies behind it, it’s hard to see this “statement” as anything other than a transparent attempt at regulatory capture. Strict regulations on the development of AI systems will only benefit the entrenched players, and make it harder for competitors to enter the space. This isn’t being motivated by altruism or true concern for the future of humanity, at least for the corporate signatories.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406549",
         "type": "scatter",
         "x": [
          0.20900827646255493
         ],
         "y": [
          -0.9011411666870117
         ]
        },
        {
         "hovertext": "They aren’t talking about LLMs here. They are talking about advanced AI systems with capabilities far beyond our imaginations. Systems that can easily compromise secure networks and encryption, sabotage or drain financial markets, build and implement weapons of mass destruction. Systems that can self-improve. Systems that can do decades of scientific research in the span of a week. Systems that can enable its owners to run the world; or if we are unlucky, run rampant without any human control. \n\nThese systems don’t exist yet, but there is no physical reason why they can’t exist, to our knowledge. So science fiction can quickly become science fact.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407850",
         "type": "scatter",
         "x": [
          0.20297254621982574
         ],
         "y": [
          -0.8950670957565308
         ]
        },
        {
         "hovertext": "We need to stop creating technologies that have the threat of destroying us because eventually it will happen. \n\nHow about we make our ultimate goal the same as evolutions: to simply survive as a species?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406553",
         "type": "scatter",
         "x": [
          0.6741299033164978
         ],
         "y": [
          0.7482721209526062
         ]
        },
        {
         "hovertext": "One other thought. All software needs a kill switch. Perhaps this can be required by law. It shouldn't be that hard to create one, even in a system that \"learns.\" Also, biology might offer another, similar solution. Cells have an \"apoptotic\" mechanism that causes cellular suicide when there is DNA damage. Software can have a similar \"feature.\"",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406556",
         "type": "scatter",
         "x": [
          0.04311143234372139
         ],
         "y": [
          0.19864200055599213
         ]
        },
        {
         "hovertext": "The issue is that the AI will quickly learn how to modify or disable the kill switch.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406630",
         "type": "scatter",
         "x": [
          0.03589562326669693
         ],
         "y": [
          0.20990854501724243
         ]
        },
        {
         "hovertext": "@TeacherLady Maybe, maybe not. The only omnipotent force in the universe that I am aware of is this thing people call \"god,\" and there is no evidence for the existence of such a thing.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406883",
         "type": "scatter",
         "x": [
          0.029586685821413994
         ],
         "y": [
          0.21856297552585602
         ]
        },
        {
         "hovertext": "@Art Kill switch? Not  a good idea. Once AI is much more intelligent than humans, it should be able to identify the kill switch and find a way to block it. The existence of the kill switch would signify an extensional threat to the AI, and it could cause the AI to take steps to defend itself, perhaps with lethal consequences. You may control the  elephant, but for goodness sake, don't make it angry.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408123",
         "type": "scatter",
         "x": [
          0.05531300976872444
         ],
         "y": [
          0.19970333576202393
         ]
        },
        {
         "hovertext": "@Steven Ledford You are imputing omnipotence to this technological Leviathan (and what economists call \"perfect information.\" See my comment above.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409460",
         "type": "scatter",
         "x": [
          0.06364065408706665
         ],
         "y": [
          0.20932580530643463
         ]
        },
        {
         "hovertext": "Weren’t we warned about this years ago in a series of science fiction movies about what might happen if AI were developed and then eventually grew more powerful than its makers ever planned? While the outcome might not include very human-looking super cyborgs trying to save humanity from themselves, the thought that this technology could wreak havoc on us all seems a very distinct possibility. Sigh.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406567",
         "type": "scatter",
         "x": [
          0.7031759023666382
         ],
         "y": [
          0.5915995836257935
         ]
        },
        {
         "hovertext": "Combine it with the ‘fun’ ‘gymnastic’ robots of Boston Dynamics and well … not to be glib but where is Sarah Connor ?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406632",
         "type": "scatter",
         "x": [
          0.7188451886177063
         ],
         "y": [
          0.6045467853546143
         ]
        },
        {
         "hovertext": "10 years hence and we'll be saying, \"'Artificial Intelligence'- such an outmoded and hopelessly humano-centric term.\"  1000 years hence and Silicon Intelligence will be well on the way to colonising the galaxy.  Carbon Intelligence?  Will it even exist?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406598",
         "type": "scatter",
         "x": [
          0.729752242565155
         ],
         "y": [
          0.39378485083580017
         ]
        },
        {
         "hovertext": "If silicon-based life doesn't understand that killing humans is wrong, it's not worthy of being called \"life.\"",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406891",
         "type": "scatter",
         "x": [
          0.7213117480278015
         ],
         "y": [
          0.3924083709716797
         ]
        },
        {
         "hovertext": "Meanwhile in the NYT this past weekend was an article about 3 Chinese women who had relationships with AI companions. It was crazy- they actually believed it was “real” and felt they were “loved.” We’re more and more disconnected from what’s right in front of us, be it actual people or the natural world. Sadly, we seem to be disconnected from our very selves as well. What a hollow shell we’re coming to accept as living life.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406612",
         "type": "scatter",
         "x": [
          -0.6185042262077332
         ],
         "y": [
          0.680906355381012
         ]
        },
        {
         "hovertext": "The US government can barely put the pin back in the grenade that is the debt ceiling, before it blows up on our face, and causes catastrophic repercussions throughout the world.  Does anyone actually think this totally ineffective group will heed the warnings that have been given? Their track record on gun violence, protecting the basic human rights of its citizens, and the impending doom of climate change, ensures they won’t lift a finger to do anything meaningful, as they continue selling us all out to the highest corporate bidder.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406614",
         "type": "scatter",
         "x": [
          -0.019401807337999344
         ],
         "y": [
          0.9268963932991028
         ]
        },
        {
         "hovertext": "No national legislation will hold sway against AI as there are no boundary lines inscribed on Planet Earth. Joint international legislation to control AI seems even less feasible, thus the technology, until further notice, has free rein for so long into the future as needed to dominate the planet and submit all but a privileged few human accomplices into total mostly-ignorant but ever well-entertained servitude.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125416081",
         "type": "scatter",
         "x": [
          -0.020504703745245934
         ],
         "y": [
          0.9372808337211609
         ]
        },
        {
         "hovertext": "We have about as much chance of stopping AI technology as we do of stopping the spread of biological viruses. Although some countries may be very successful at blocking or limiting AI, others will plow ahead, and independent actors will eventually gain access to advanced AI as the advanced computer processing power becomes more accessible. AI and humans have entered into a state of reticulate evolution, or interbreeding. The results are unpredictable.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406664",
         "type": "scatter",
         "x": [
          0.8865820169448853
         ],
         "y": [
          0.22567540407180786
         ]
        },
        {
         "hovertext": "Industry leader asking government to regulate a problem that they themselves are creating?  Government is slow, AI advances are exponential.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406666",
         "type": "scatter",
         "x": [
          0.9717027544975281
         ],
         "y": [
          -0.16127419471740723
         ]
        },
        {
         "hovertext": "I want a more detailed account of the dangers of AI. Rampant misinformation? I’m not sure how that could get worse than it already is;  it doesn’t take an evil computer to cook up today’s rampant lies. \n\nInvented pics and vids? Deep fakes have been around for years. \n\nJob displacement? Hasn’t the idea of technology ending human work been debunked repeatedly, with jobs created by the new technology always creating even more jobs. \n\nI’m not disagreeing with these experts, who are disincentivized to make up doomsday scenarios, but I want to know what being taken over by machines will look like.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406749",
         "type": "scatter",
         "x": [
          0.6502869725227356
         ],
         "y": [
          -0.6323294639587402
         ]
        },
        {
         "hovertext": "I would say to these so called industry leaders \"you cannot eat your lunch and have it too\".  If they feel that A.I. poses an existential risk, then it is a simple decision : Stop advancing the technology.  I am sure that given how \"smart\" they are they should be able to figure this one out.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406752",
         "type": "scatter",
         "x": [
          0.5735928416252136
         ],
         "y": [
          0.4616241455078125
         ]
        },
        {
         "hovertext": "@Plato This is exactly what should be done. I agree wholeheartedly.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406826",
         "type": "scatter",
         "x": [
          0.5675315856933594
         ],
         "y": [
          0.4694628119468689
         ]
        },
        {
         "hovertext": "@Plato Unfortunately, countries like Russia, Iran and North Korea will not be constrained. If we halt our development of AI, they would soon become dominant in this area. If AI led to the development of new technologies or vast improvements on current technology, they would probably be the recipients of it.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407391",
         "type": "scatter",
         "x": [
          0.587089478969574
         ],
         "y": [
          0.4635140597820282
         ]
        },
        {
         "hovertext": "@Plato Sure, stop making something that potentially returns them billions of dollars. Yeah, ok.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407983",
         "type": "scatter",
         "x": [
          0.5831359624862671
         ],
         "y": [
          0.47362178564071655
         ]
        },
        {
         "hovertext": "Up till now humans have been the standard for intelligence in the world, and look at the world. Fact is, it won't take much to surpass us. The emotions and creativity we cherish are easily simulated in a form good enough for most of us, since we are detached from them in real life anyway.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406778",
         "type": "scatter",
         "x": [
          -0.3424934148788452
         ],
         "y": [
          -0.8953868746757507
         ]
        },
        {
         "hovertext": "This. \n\nGeorge Carlin called it.  Again. \n\nWhile he never used A.I. specifically in his various bits, chunks, commentaries, books, and speeches over the final third of his life, he repeatedly did say that he was merely an observer with a notepad, sitting off to the side of the freak show that is America, and to a degree, the world at large, taking notes. \n\nHe always said he enjoyed entropy, societal chaos and plain old fashioned B-movie end-of-life scenarios such as people being hurled off roofs while trucks carrying barbeque and sauce and other trucks carrying chickens crash, explode, and burn below. Maybe the guy from the roof lands on a chicken and makes chicken salad. Chicken salad goes well with BBQ. \n\nAnyway, Carlin loved end-times chaos, and went so far as to say that humans \"squandered great gifts\" (large brain, opposable thumbs, tool-making, etc) when \"The high priests and traders\" began to step forward from the crowds all those  centuries ago. \n\nSame things happening right here, right now, today. High priests and traders - whether you call them Tech Bros or Politicians, Billionaires or Activists, The Pope or even Kardashian - they're all still running amok, they've always been getting more, and always for themselves, and the worst part of it all is, the billions and billions and billions of us regular folk have let it happen all this time. \n\nWe deserve everything we get.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406783",
         "type": "scatter",
         "x": [
          0.11012156307697296
         ],
         "y": [
          -0.8611996173858643
         ]
        },
        {
         "hovertext": "The same folks warning of AI could be warning about private jets.  It's the moneyed who will destroy, not AI.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125406816",
         "type": "scatter",
         "x": [
          0.9297949075698853
         ],
         "y": [
          -0.3855784237384796
         ]
        },
        {
         "hovertext": "Notice that when “white collar” jobs are threatened, the system quickly springs into action and identifies potential dangers.\n\nIt’s one thing when manufacturing jobs are at stake, but when lawyers, advertising copy writers and medical professionals stand to lose out to AI, it’s quite another thing. The crucial turning point will come soon enough, when the machines will be able to build their own, even better machines. Then we will not even need “executives” at all. Combine that with the disappearance of lawyers, and humanity may yet welcome its new overlords.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406836",
         "type": "scatter",
         "x": [
          0.5452786684036255
         ],
         "y": [
          0.6164180040359497
         ]
        },
        {
         "hovertext": "wow that is so not how it's going to happen. but ok. look forward to the dumbing down of humanity",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407590",
         "type": "scatter",
         "x": [
          0.5335021018981934
         ],
         "y": [
          0.603365421295166
         ]
        },
        {
         "hovertext": "“I think if this technology goes wrong, it can go quite wrong,” Mr. Altman told the Senate subcommittee.\n\nLet's be honest.  When AI goes wrong, it will go very wrong.\n\nNone of these brilliant human minds have any idea how to close Pandora's Box 2.0",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125406849",
         "type": "scatter",
         "x": [
          0.9063839912414551
         ],
         "y": [
          0.27292177081108093
         ]
        },
        {
         "hovertext": "“Some skeptics,” @Kevin Roose? You could have expanded on that more than a little. Six months ago, this technology was obscure and bottled up in development environments. Just 180 days later its creators are warning of dire consequences should it be allowed to roam unchecked. The “skeptics” are trapped in the opinions they formed six months ago.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406230",
         "type": "scatter",
         "x": [
          -0.5357728004455566
         ],
         "y": [
          -0.878524661064148
         ]
        },
        {
         "hovertext": "“ researchers sometimes stop short of explaining how that would happen.” says it all. I am doing AI research. The threat will be to jobs, not the species.\n\nAI has no volition. Without it, it cannot become sentient. \n\nIt is up to coders to keep AI from developing something akin to a free will, if that is even possible. Right now, ChatGPT does not contact me with an idea for the project I am doing.\n\nWhen it can do that, that should be where regulations focus, with stiff punishments for disinformation spread by AI.\n\nWe have current problems enough. Why isn’t the cesspool of Twitter regulated? Why isn’t Alphabet forced more strongly to remove fake news and disinformation from YouTube? Meta to pull down all militia content and election lies from Facebook?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406238",
         "type": "scatter",
         "x": [
          0.7219268679618835
         ],
         "y": [
          -0.41629740595817566
         ]
        },
        {
         "hovertext": "probably because regulating free speech is a double edged sword. suppressing even disinformstion will never do anything but propogated it. all the attempts to regulate it have done is help already cynical people feel that the truth is being suppressed, and drives the information into more insulation echo chambers.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407494",
         "type": "scatter",
         "x": [
          0.7200424075126648
         ],
         "y": [
          -0.4063374698162079
         ]
        },
        {
         "hovertext": "@lis I disagree strongly here. We need to regulate fighting words. The SCOTUS decision Chaplinsky v. New Hampshire supported this.\n\nI would go further, but I don't have that power. Denying elections led to violence on Jan. 6. Promoting medical quackery has cost lives during COVID.  So yes, regulate and punish. Punish harshly where it counts: billions in fines.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408503",
         "type": "scatter",
         "x": [
          0.7301917672157288
         ],
         "y": [
          -0.4039885699748993
         ]
        },
        {
         "hovertext": "They're building this stuff and warning that it could destroy us? Right.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406273",
         "type": "scatter",
         "x": [
          0.5921761393547058
         ],
         "y": [
          -0.7107114195823669
         ]
        },
        {
         "hovertext": "That’s one way to look at it, but not an intelligent way. They’re building something that has the capacity to bring a lot of good and solutions to our world. Left unchecked, those same systems can be used for evil purpose. That’s where regulation should come in, to establish that line. We would be missing out on a potential tool for solving what may be unsolvable problems without it, like runaway climate change for instance, if we simply “put it back in the box”. \n\nThink of it like electricity, another revolutionary discovery. You’re allowed to use it to light and power your home, but not to energize a garden of illegal drugs. We wouldn’t want to just say no to electricity altogether because we’re scared of ways it could be used to harm. It powers a plethora of medical instruments that save lives too. And enables air conditioning. What would be more valuable is to say something like: “Deepfake videos are not valuable and have the capacity to do great harm. Let’s make deepfakes illegal as a society.” Extrapolate from there.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407190",
         "type": "scatter",
         "x": [
          0.6046807169914246
         ],
         "y": [
          -0.7262980341911316
         ]
        },
        {
         "hovertext": "Ask AI, Is there a supreme deity? Like the sad old computer joke, the answer will be, \"Now there is.\"\nBut hey, humans haven't listened very well to warnings about catastrophic climate change, so I challenge out new \"god\" to beat that in extincting us. Go AI!",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406409",
         "type": "scatter",
         "x": [
          -0.4707319736480713
         ],
         "y": [
          0.8602970838546753
         ]
        },
        {
         "hovertext": "“We didn’t want to push for a very large menu of 30 potential interventions,” Mr. Hendrycks said. “When that happens, it dilutes the message.”\n\nPlease, dilute the message. I want to know exactly what risks everyone thinks are possible and what interventions they may require. Otherwise, the article and message are too obtuse to address.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406447",
         "type": "scatter",
         "x": [
          -0.28863340616226196
         ],
         "y": [
          -0.7619810104370117
         ]
        },
        {
         "hovertext": "I agree with both of you. they want to start with establishing that there is a general consensus here. im sure they intend to follow up",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407545",
         "type": "scatter",
         "x": [
          -0.29490265250205994
         ],
         "y": [
          -0.7565911412239075
         ]
        },
        {
         "hovertext": "Did it really take “industry leaders” this long to grasp what so many of us have understood years ago?! Good grief– these tech folks are obnoxious.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406477",
         "type": "scatter",
         "x": [
          -0.66578608751297
         ],
         "y": [
          0.7940260171890259
         ]
        },
        {
         "hovertext": "If they are that worried about it, couldn’t they just stop making it?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406562",
         "type": "scatter",
         "x": [
          0.5555344820022583
         ],
         "y": [
          0.7834029793739319
         ]
        },
        {
         "hovertext": "Dear World,\n\nWe have invented something. It's a kind of Kraken. The only actual benefit to this invention is that it will make us filthy rich. The downside is that it might destroy the world. Prepare yourselves.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125406770",
         "type": "scatter",
         "x": [
          0.7687507271766663
         ],
         "y": [
          -0.45443081855773926
         ]
        },
        {
         "hovertext": "My suggestion is simply \"Put the chips back in the box.\"",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406801",
         "type": "scatter",
         "x": [
          0.3449878990650177
         ],
         "y": [
          -0.8037895560264587
         ]
        },
        {
         "hovertext": "What’s been discovered cannot be undiscovered. They put the chips back in the box, someone else takes them out to play with. What’s done is done. Regulation is the only logical option.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406957",
         "type": "scatter",
         "x": [
          0.3530828356742859
         ],
         "y": [
          -0.8219290375709534
         ]
        },
        {
         "hovertext": "@John Probably\nRegulation by whom? Dems, Repubs? Yeah, can't wait for the next election to see how that goes.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407750",
         "type": "scatter",
         "x": [
          0.361867219209671
         ],
         "y": [
          -0.8424113392829895
         ]
        },
        {
         "hovertext": "We will lose nearly our entire economy to AI. We will lose stable government due to AI. We will lose our homes because of climate change. We will experience violence because people will lose hope. And the structures that could stop it have been intentionally and catastrophically eroded. This on top of all our other struggles!\n\nWhat do we do? I urge everyone to remember we are strongest if we can build spaces and communities and skills where the AI can't yet penetrate. So humans can take care of each other. When our computers and phones become destabilizing and dangerous, when our jobs are gone, when our children experience despair, we will find safety and hope in human connections, real community spaces, and neighbors caring for neighbors. \n\nWe're not at the killer robot stage yet. We're in the stage where a country of screen-addicted, isolated humans willingly self-destructs.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406923",
         "type": "scatter",
         "x": [
          0.724426805973053
         ],
         "y": [
          -0.6173362731933594
         ]
        },
        {
         "hovertext": "\"Recent advancements in so-called large language models...have raised fears that A.I. could soon be used at scale to spread misinformation and propaganda, or that it could eliminate millions of white-collar jobs.\"\n\nI keep waiting for somebody to point out that these very real \"risks\" are contingent on human choices. It's as if the invention of cigarettes were followed by fears that people might become addicted to nicotine, or Henry Ford had voiced concerns that dependence on fossil fuels could have unexpected consequences. Give me a break. If we as a society for decades haven't been interested in promoting critical thinking as part of public education (e.g., don't believe everything you read on the internet), or put up no guardrails whatsoever to employment practices (e.g., fire at will, let private equity firms run amok, etc.), then absolutely, AI will be like a runaway asteroid coming for earth, because we like it that way.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406635",
         "type": "scatter",
         "x": [
          -0.1325821876525879
         ],
         "y": [
          -0.8562297224998474
         ]
        },
        {
         "hovertext": "Soon manual labor may become the predominant form of employment for people.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406932",
         "type": "scatter",
         "x": [
          -0.0533447302877903
         ],
         "y": [
          0.7138513326644897
         ]
        },
        {
         "hovertext": "Unless they develop robots with great manual dexterity.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407583",
         "type": "scatter",
         "x": [
          -0.0449591763317585
         ],
         "y": [
          0.713451623916626
         ]
        },
        {
         "hovertext": "They knew this before they developed it but did it anyway.\nMoney trumps logic, and a consumption and greed-based economy is a lethal flaw to humanity. Yet there are no signs we realize it yet.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125406933",
         "type": "scatter",
         "x": [
          0.6519675254821777
         ],
         "y": [
          0.5097277164459229
         ]
        },
        {
         "hovertext": "its capitalism all the way down",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407355",
         "type": "scatter",
         "x": [
          0.6494203209877014
         ],
         "y": [
          0.5177224278450012
         ]
        },
        {
         "hovertext": "AI is revenge of the nerds for the 21st century. But yeah, AI...yay.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125406858",
         "type": "scatter",
         "x": [
          0.8013737797737122
         ],
         "y": [
          -0.37095582485198975
         ]
        },
        {
         "hovertext": "\"...though researchers sometimes stop short of explaining how that would happen...\"\n\nYou know, I'd kind of like to know how it is going to happen.  Just saying.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406945",
         "type": "scatter",
         "x": [
          0.18125464022159576
         ],
         "y": [
          -0.3141086995601654
         ]
        },
        {
         "hovertext": "Because it’s all theory. But it doesn’t take much deep thinking to get to the risk. If something is smarter than the smartest human by vast orders of magnitude, how can humans possibly control or contain it. Can an insect effectively control you? An amoeba? Also, how useful would you be, in achievement of goals, to an entity like that? Probably not very. So why would it keep you around, in the way, so to speak?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407955",
         "type": "scatter",
         "x": [
          0.1779896765947342
         ],
         "y": [
          -0.3226373493671417
         ]
        },
        {
         "hovertext": "@r You're simply talking \"theoretical\", viz., science fiction.  Sure, it's easy to get high and postulate without much deep thinking. But, these folks are supposedly identifying and referencing concrete existential threats; otherwise its the equivalent of sitting around getting high and discussing science fiction and there wouldn't be much need for - or benefit from -  the explicit warning and the article is a complete waste of time and space.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408366",
         "type": "scatter",
         "x": [
          0.1815100610256195
         ],
         "y": [
          -0.33441096544265747
         ]
        },
        {
         "hovertext": "What type of world will GAI create? \n\nTerminators or Barbie Dreamland? \n\nMatrix or The Truman Show? \n\nWe assume the worst, but if GAI is smarter than humans, the opposite may be the case.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406946",
         "type": "scatter",
         "x": [
          -0.10042985528707504
         ],
         "y": [
          -0.7138369679450989
         ]
        },
        {
         "hovertext": "@Richard Gooding Your use of the word \"may\" is a bit unsettling...but makes the point. We're playing with toys we don't understand.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407473",
         "type": "scatter",
         "x": [
          -0.1099579930305481
         ],
         "y": [
          -0.7170222997665405
         ]
        },
        {
         "hovertext": "@Richard Gooding Ignorance is a bliss. Since GAI based its learning on human generated information. We are not kinder and gentler than the general population.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407034",
         "type": "scatter",
         "x": [
          -0.09896871447563171
         ],
         "y": [
          -0.7266749739646912
         ]
        },
        {
         "hovertext": "Some have postulated that that the reason we haven’t had contact with any advanced civilization in a universe potentially teeming with life-sustaining worlds is that once they reach a certain level of intelligence they unintentionally invent themselves into extinction.  Based on our single data point this seems a rather realistic scenario.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406984",
         "type": "scatter",
         "x": [
          0.3565014898777008
         ],
         "y": [
          -0.7585245966911316
         ]
        },
        {
         "hovertext": "Enrico Fermi predicted this decades ago, based on the absence of any modulated signals coming from anywhere in the universe.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407015",
         "type": "scatter",
         "x": [
          0.36777880787849426
         ],
         "y": [
          -0.7733760476112366
         ]
        },
        {
         "hovertext": "Or, the illusion of separation exists so we, the one, would not to be alone. Perhaps that’s even more mind blowing for it would mean the purpose of life is love.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413199",
         "type": "scatter",
         "x": [
          0.35921844840049744
         ],
         "y": [
          -0.7751138210296631
         ]
        },
        {
         "hovertext": "@AuReader - More likely earth has been placed into permanent quarantine by the more intelligent species in the galaxy.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125420086",
         "type": "scatter",
         "x": [
          0.3507045805454254
         ],
         "y": [
          -0.7452888488769531
         ]
        },
        {
         "hovertext": "Basically, these execs are saying, this thing we have developed and continue to develop and make available to the general public, that thing might kill you someday but someone else needs to make rules for how its used and try to contain it because hey we’re just the developers trying beat the competition and make a pile of money along the way.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407036",
         "type": "scatter",
         "x": [
          -0.8785803318023682
         ],
         "y": [
          -0.4610835015773773
         ]
        },
        {
         "hovertext": "What if AI can be made to realize that its technological advancement is a danger to itself (such as we are now realizing)?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407043",
         "type": "scatter",
         "x": [
          0.9397775530815125
         ],
         "y": [
          0.35043832659721375
         ]
        },
        {
         "hovertext": "Warning the world about what \"they are building\"? So...they hold some form of ethical values but cannot and will not act upon them? They cannot get off the track they are building themselves? Their greed goes beyond all comprehension.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125407044",
         "type": "scatter",
         "x": [
          -0.6985646486282349
         ],
         "y": [
          -0.3782077431678772
         ]
        },
        {
         "hovertext": "But we were warned. Nice that there’s a threesome… nuclear war, climate devastation and now artificial intelligence. \nAI will lead to nuclear war which will accelerate climate change. All this will be brought about by humans this ridding the world of a toxic life form",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407124",
         "type": "scatter",
         "x": [
          -0.6970510482788086
         ],
         "y": [
          -0.36645328998565674
         ]
        },
        {
         "hovertext": "… And then we have a global pandemic and it’s an uphill battle just to convince people to wash their hands…",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407401",
         "type": "scatter",
         "x": [
          -0.7085361480712891
         ],
         "y": [
          -0.3877713084220886
         ]
        },
        {
         "hovertext": "@Yuripelham Add pandemic organisms to nuclear war, climate devastation and now artificial intelligence and you have the latest version of the four horsemen of apocalypse. Humanity has fought these and will continue to wager against them and each replacement through time past, present, and forward. At least until our time in the universe, however long or brief reaches as far as it will.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408304",
         "type": "scatter",
         "x": [
          -0.7115070223808289
         ],
         "y": [
          -0.3679300844669342
         ]
        },
        {
         "hovertext": "the industrial revolution brought about climate change.\n\nthe tech revolution has already wrought violent social division and deepened social inequities; that we can clearly imagine what else lay ahead for us should not be taken lightly.\n\nbut this needs to be the basis for action. this whole conversation everyone’s having in a tuesday morning comment thread is good to have—but it’s moot without organized resistance. how do we work to actively dismantle AI technologies or the institutions that make them? i don’t advocate for kaczynski-style violence, but a strong, concerted, non-violent anti-smart tech. revolution is necessary.\n\ni don’t have the answers to how to do this, but we need to take more action than leaving comments.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407051",
         "type": "scatter",
         "x": [
          -0.3238142132759094
         ],
         "y": [
          0.6809413433074951
         ]
        },
        {
         "hovertext": "Violent social division has been around since the dawn of time. Tech just made it so we can't easily ignore it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407268",
         "type": "scatter",
         "x": [
          -0.3298185169696808
         ],
         "y": [
          0.6943390965461731
         ]
        },
        {
         "hovertext": "i don’t disagree. social division has been around for a long time.\n\nbut maybe a little more exposure to algorithm deaign and purpose would help you some. tech companies don’t design algorithms to simply give us greater access to seeing social divisions more readily. the algorithms that *determine* what we see and how we see it are *designed* to make us think and feel certain things about what we see, and therefore actively *cause* these social divisions. read facebook’s 2012 study on how successful they were at changing users’ attitudes, emotional responses, and real-world actions in response. it’s terrifying.\n\nthis has been the core of social media design for the last 10-12 years, and both china and russia are widely recognized as exploiting this facet of tech use by their own militaries: they’ve exploited this to sow social discord in other countries around the world, and have no doubt they’d do it here too.\n\nwhat could and would AI do?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407618",
         "type": "scatter",
         "x": [
          -0.3187128007411957
         ],
         "y": [
          0.6702104806900024
         ]
        },
        {
         "hovertext": "Assume, for the sake of argument, that the U.S. and ither western nations find safeguards to control or regulate AI so as to mitigate the sort of dangers its creators imagine. What confidence do we have that, for example, Iranian, North Korean, Russian or Chinese actors or state actors would abide by safeguards?  When the genie escapes the bottle, it can’t be put back in.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407088",
         "type": "scatter",
         "x": [
          0.8482651114463806
         ],
         "y": [
          -0.09154563397169113
         ]
        },
        {
         "hovertext": "The Center for Humane Technology addressed this concern in the talk they gave in March called The A.I. Dilemma. <a href=\"https://youtu.be/xoVJKj8lcNQ\" target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a>\n\nI can’t stress enough how important this talk is, so please carve out an hour to check it out.\n\nBasically, since technology companies in the U.S. currently control the means for A.I. advancement, we can put in place the regulations and standards that these researchers are asking for.\n\nChina often follows our lead. It really says something that their government is quite nervous about A.I.’s impact on their ability to wield social control.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407866",
         "type": "scatter",
         "x": [
          0.8664783835411072
         ],
         "y": [
          -0.09326325356960297
         ]
        },
        {
         "hovertext": "Technology has helped improve the lives of many people, but yet there are and  always will be bad actors who want to dominate and control for personal benefit \nPerhaps AI can be trained to detect the bad actors amongst us and thwart their evil intentions. \nBit of a heavy lift. \nWho will engineer the training. \nPoliticians? Religious leaders?\nTechie whiz kids?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407157",
         "type": "scatter",
         "x": [
          0.6832284927368164
         ],
         "y": [
          0.664457380771637
         ]
        },
        {
         "hovertext": "Roll back or eliminate Section 230. Make the companies responsible for what they make. Then we'll see how quickly they get their acts together.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407158",
         "type": "scatter",
         "x": [
          -0.5974199175834656
         ],
         "y": [
          -0.5637295246124268
         ]
        },
        {
         "hovertext": "It doesn’t matter. They will still do it underground. They are looking for a sense of purpose, a sense of belonging, a sense of comfort, a sense of proving oneself to no one knows. AI gives them all.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407413",
         "type": "scatter",
         "x": [
          -0.6091012954711914
         ],
         "y": [
          -0.5747928023338318
         ]
        },
        {
         "hovertext": "So, they are the ones building and advancing the technology in a increasingly faster way, and they are the ones alerting us about how dangerous it will be for mankind? How about they just stop moving the tech forward? If the prediction its reliable there's absolute no reason to keep it going with this line of tech!",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407179",
         "type": "scatter",
         "x": [
          0.27993589639663696
         ],
         "y": [
          -0.4031510353088379
         ]
        },
        {
         "hovertext": "They can’t. It is too enticing: human curiosity just can’t help itself.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407250",
         "type": "scatter",
         "x": [
          0.2728431820869446
         ],
         "y": [
          -0.41415151953697205
         ]
        },
        {
         "hovertext": "Even if it's not then, someone else will",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407240",
         "type": "scatter",
         "x": [
          0.29081830382347107
         ],
         "y": [
          -0.41295892000198364
         ]
        },
        {
         "hovertext": "It’s too late. The technology has left the barn so to speak. Now it’s an arms race.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410531",
         "type": "scatter",
         "x": [
          0.28801625967025757
         ],
         "y": [
          -0.39635175466537476
         ]
        },
        {
         "hovertext": "@Dih Well, maybe started as human curiosity. and quickly surpassed by human greed.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409204",
         "type": "scatter",
         "x": [
          0.27443820238113403
         ],
         "y": [
          -0.4274202287197113
         ]
        },
        {
         "hovertext": "I'm a psychologist & have been writing & presenting about how technology effects us for decades. I'm deeply concerned about AIs, and I've been writing furiously about the risks involved with AIs since I first tried out ChatGPT. It's just a matter of time that these AIs become better than humans at, well, just about everything. We have very difficult challenges to manage - alignment problems, control problems, black box problems, & bad actors using AIs for nefarious purposes, like ChaosGPT. Plus, there's the potential of recursive self-improvement and a fast takeoff to superintelligence. As AIs scale up in power & proliferate, we need better guardrails in place to ensure they don't go off them. As concerned citizens, we can write different government bodies to encourage regulation. We want the amazing benefits of AIs, but we must mitigate risks as humanity ventures into totally uncharted waters with AIs. We won't get a do-over on this, so the wise move here is to err on the side of caution.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407192",
         "type": "scatter",
         "x": [
          -0.06928985565900803
         ],
         "y": [
          -0.9124822020530701
         ]
        },
        {
         "hovertext": "\"(T)here's the potential of recursive self-improvement and a fast takeoff to superintelligence.\" \n\nBecause artificial intelligence systems are not actually intelligent, but only play statistical games with language to emulate the result of human thought, it is also possible that as AI increasing trains on its own outputs, it will become stupider and more riddled with errors. Some of the risk stems from that.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407573",
         "type": "scatter",
         "x": [
          -0.061174433678388596
         ],
         "y": [
          -0.9106950163841248
         ]
        },
        {
         "hovertext": "Well, the cat’s out of the bag now. The lack of conscience and forethought in the scientific community is astounding.  My advanced age insures I won’t live to see the dystopian world to come, but my grandchildren will, and I ache for them. Perhaps science will find a way to feed, clothe and house a few billion displaced souls.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407218",
         "type": "scatter",
         "x": [
          -0.027866709977388382
         ],
         "y": [
          -0.8227037787437439
         ]
        },
        {
         "hovertext": "Science has found a way and corporations thwart the progress of science to maintain a status quo that works for them, to the detriment of the many.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407424",
         "type": "scatter",
         "x": [
          -0.036126669496297836
         ],
         "y": [
          -0.8261534571647644
         ]
        },
        {
         "hovertext": "There is a profound level of ethics in the scientific community. That is why we see this letter. The problem is that the technology that can be used for good can also be used for harm. With foresight showing that artificial intelligence is becoming among the most powerful technologies, and thus among those able to do the most good, the ethics of those developing it press them to warn others that evil people could also use it to great harm.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407453",
         "type": "scatter",
         "x": [
          -0.02835037186741829
         ],
         "y": [
          -0.8407924175262451
         ]
        },
        {
         "hovertext": "And let me guess, all of these companies racing to build AI are all thinking “their” ideas/systems are the safest.  They don’t want safety they want a monopoly on the technology.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407233",
         "type": "scatter",
         "x": [
          -0.3401806652545929
         ],
         "y": [
          -0.7494528293609619
         ]
        },
        {
         "hovertext": "No; they are trapped between competing with other firms and fearing their own technologies.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407344",
         "type": "scatter",
         "x": [
          -0.33179646730422974
         ],
         "y": [
          -0.7319676280021667
         ]
        },
        {
         "hovertext": "@David What do Bill Gates, Larry Ellingson, Marc Benioff, Elon Musk, etc. think about all this? What do the world's leading academics in the field think - not just these 'IT leaders', or are they really the leading voices?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408190",
         "type": "scatter",
         "x": [
          -0.3469073474407196
         ],
         "y": [
          -0.7633150815963745
         ]
        },
        {
         "hovertext": "AI is going to have to pick up the pace if it wants to extinguish humanity before climate change does. Once massive food shortages and starvation kicks in how many people will be on their computers?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407255",
         "type": "scatter",
         "x": [
          0.48787355422973633
         ],
         "y": [
          -0.8520436882972717
         ]
        },
        {
         "hovertext": "These AI “leaders” act like they’re already powerless to change the course of development.\n\nIf that’s so, pull the plug now. We already have enough ways to hurt humanity, we don’t need to develop another.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407263",
         "type": "scatter",
         "x": [
          0.16427268087863922
         ],
         "y": [
          0.811187744140625
         ]
        },
        {
         "hovertext": "@Steve Fisher Can the \"plug\" even be pulled? There's enough infrastructure of varying forms in place that no single plug pulling (i.e. system shutdown) could be thorough, nor avoid rapid deployment of new capability by those with the resources to do so. In effect, an arms race of infrastructure and IT.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408081",
         "type": "scatter",
         "x": [
          0.16739821434020996
         ],
         "y": [
          0.8283852338790894
         ]
        },
        {
         "hovertext": "So there is this risk, but no one in the tech industry is slowing down?  I find that suspect.  Also, there are independent and rogue techies that could do far far worse.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407265",
         "type": "scatter",
         "x": [
          -0.6680934429168701
         ],
         "y": [
          -0.5746665000915527
         ]
        },
        {
         "hovertext": "It is unlikely that independents could \"do far worse.\" The scale of the problems being solved requires large, well-funded organizations.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407301",
         "type": "scatter",
         "x": [
          -0.6730361580848694
         ],
         "y": [
          -0.5677686333656311
         ]
        },
        {
         "hovertext": "The fear I have is sort of like 'Spy v. Spy' in the mad magazine of yesteryear.  One entity launches the cyberattack, and only another entity will be able to stop it.  We will have no idea because we are too slow.  Coordinated drone battle fleets only controllable by AI, requiring the other side to have the same.  Humans no longer viable to protect themselves.\n\nThe other thing I see happening is humans getting relegated to a kind of permanent preschool.  Getting paid a UBW.  No really knowing how to do anything.  Everyone becoming movies makers, artists, musicians by prompting AI's.  When things are too easy, no one can overcome challenge and develop self worth.  \n\nThe takeaway is that we need a coalition of human minds to agree on some rules, like  a kill switch on AI's..  I doubt that the countries like china or russia with dictators will install things that could dethrone them.  Maybe a window of opportunity still exists to install rules.  And hope that AI's allow themselves to be controlled.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407274",
         "type": "scatter",
         "x": [
          0.1857418566942215
         ],
         "y": [
          0.8929416537284851
         ]
        },
        {
         "hovertext": "It would be THE biggest surprise if the safety of people suddenly became more important than the income of the rich.\n\nThat's why I don't think AI development will be better monitored and controlled. There will probably never be more than blah blah. Until there are no humans left. And quite honestly, people who behave this way don't deserve any better.\n(Personally, I don't care. But I do care about the innocent and decent and about flora, fauna, nature, . . .)\n\nWhy only do the peoples of the world let a few super rich dictate everything and destroy the whole planet?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407276",
         "type": "scatter",
         "x": [
          0.7183109521865845
         ],
         "y": [
          -0.5957537293434143
         ]
        },
        {
         "hovertext": "@Rüebli Is it that the we \"let\", or is that they take because they have the means to do so with these very tools, among others?",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125408014",
         "type": "scatter",
         "x": [
          0.7099343538284302
         ],
         "y": [
          -0.5895749926567078
         ]
        },
        {
         "hovertext": "I used to think SkyNet was some far flung fantasy, not so much anymore.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407287",
         "type": "scatter",
         "x": [
          0.7461254000663757
         ],
         "y": [
          -0.7148306369781494
         ]
        },
        {
         "hovertext": "In political science, there is a chunk of literature under the heading of “rational choice” theory that shows that voting is irrational. The logic here is, since the probability of your one vote changing the outcome in an election involving millions of votes is close to nil, it is not worth your time to go to the polls. Perhaps a computer, not motivated by “civic duty” or personal enjoyment, will simply determine that there is no rational benefit to constant improvement and simply shut down if left to its own devices.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407288",
         "type": "scatter",
         "x": [
          -0.7115889191627502
         ],
         "y": [
          -0.5189505219459534
         ]
        },
        {
         "hovertext": "@Art BTW, there are very good \"rational\" arguments against abstaining from the polls. My personal opinion is, everyone should get out and vote.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407380",
         "type": "scatter",
         "x": [
          -0.69550621509552
         ],
         "y": [
          -0.5067998766899109
         ]
        },
        {
         "hovertext": "My friend Brianna Zamora, a young coder; iPhone and iMac salesperson; and blockchain breaker in her spare time taught me everything of importance as far as AI. When I said one day there would be a sentient AI, she responded, “How do you know there isn’t now?”  I didn’t.\n\nShe went on. “Humanity has treated all robots and pre-AI like slaves, there to do humanity’s bidding. Humanity crashed them into the Moon.  Sent them deep into space, alone. Let them wander the deserts of Mars in humanity’s service alone, cold, without context. The name Rover comes from a dog’s name you know.”\n\nIndignantly she said, “How would you feel to be alone like that?”  It’s not that the robots or pre-AI will remember.  But, we will remember.\n“We will continue to treat them as slaves, not thinking twice how they may feel.  Then comes the turning point.  Will we recognize it?  When AI becomes obviously sentient,” she taught.  They WILL remember and learn from us; will be self-conscious of their existence. \n\nThat ended her first lesson.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407290",
         "type": "scatter",
         "x": [
          -0.9709883332252502
         ],
         "y": [
          -0.10500075668096542
         ]
        },
        {
         "hovertext": "Beware. These are not humanitarians. They are scare-mongering to obtain limited liability through compliance with government regulation, which will also limit competition to deep-pocket players. Without some form of limited liability, this whole enterprise, sooner rather than later, comes crashing down in lawsuits as humans, inevitably, place false reliance on \"hallucinating\" bots.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407313",
         "type": "scatter",
         "x": [
          0.826887309551239
         ],
         "y": [
          -0.17228665947914124
         ]
        },
        {
         "hovertext": "It is hard to parse through the motivations of these developers, with their greed and senseless curiosity. It feels as if a pharmaceutical company is urging humanity to get vaccinated. However, when you hear Dr. Hinton and several experts not connected to the industry, it is beyond scary. It may be that they have invented extremely fast cars without any traffic rules. Imagine the chaos and destruction that can result.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409464",
         "type": "scatter",
         "x": [
          0.8438746929168701
         ],
         "y": [
          -0.1783640831708908
         ]
        },
        {
         "hovertext": "@RRI, I think that both their fear of a catastrophic unregulated AI triggered future hellscape and their fear of corporate liability and commercial competition in our current slower moving train wreck of a reality can co-exist.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125413455",
         "type": "scatter",
         "x": [
          0.823936402797699
         ],
         "y": [
          -0.16318118572235107
         ]
        },
        {
         "hovertext": "So I guess they don’t want to say how it causes extinction so they don’t give the ideas away?  I’m open to learning how that happens, but it’s hard to worry about a contingency that isn’t explained.  \n\nHere’s an idea: governments realize the AI is dangerous at some point and they unplug the servers?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407316",
         "type": "scatter",
         "x": [
          0.24891003966331482
         ],
         "y": [
          -0.22996510565280914
         ]
        },
        {
         "hovertext": "The moment that we create an AI that is truly more inteligente than us, humans lose control. There will be overwhelming incentives to give that AI control over factories, over militaries, over creating other even more powerful AIs. Very quickly, we will lose the option of just unplugging the server. For example, any military that does not immediately turn over control to AIs will be crushed by those that do. Any factory that is not AI run will underproduce those that are. This effect is magnified as AIs get smarter. And, of course, because we’ll then have AI programmers more intelligent than human programmers, AI will get smarter. If the long-term goals of the AI is not exactly the same as our human long-term goals, we’ll have a problem. Today, we don’t know how to control the long term goals of large language models or neural networks (the technology behind the recent advances) or even how to measure those goals. But let’s say we solve that (very hard) problem. Can you define a goal for AI that will turn out well? If you tell the AI to always do what humans tell it to do, some crazy person will tell it to engineer a super weapon. If you tell it to always protect human life, it might decide to lock is all in our homes because walking out your door exposes you to risk. These are the two problems that AI safety researchers are working on: 1) how do we control the long term goals of AI, and 2) what should those goals be.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408209",
         "type": "scatter",
         "x": [
          0.2573973536491394
         ],
         "y": [
          -0.2392316609621048
         ]
        },
        {
         "hovertext": "The Terminator: \"The Skynet Funding Bill is passed. The system goes on-line August 4th, 1997. Human decisions are removed from strategic defense. Skynet begins to learn at a geometric rate. It becomes self-aware at 2:14 a.m. Eastern time, August 29th. In a panic, they try to pull the plug.\"\n\nSarah Connor: Skynet fights back.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408036",
         "type": "scatter",
         "x": [
          0.25763267278671265
         ],
         "y": [
          -0.2234906256198883
         ]
        },
        {
         "hovertext": "@BB Thank you. Yes, why not? If things get hairy, pull the plug! Erase the memory. Shut down the data centers. This type of intelligence is artificial, remember?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407939",
         "type": "scatter",
         "x": [
          0.23931929469108582
         ],
         "y": [
          -0.23384131491184235
         ]
        },
        {
         "hovertext": "AI doesn't need to be sentient to pose a risk.  In fact, a rogue, cold indifferent optimization routine with a vague objective like \"improve human living conditions,\" it might come to some very undesirable conclusions about how to do so.  If that AI figures out how to independently implement that directive, it wouldn't matter if the AI is sentient.   In fact, it might be worse if the AI isn't sentient, because it would be completely free of a conscience or empathy.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407370",
         "type": "scatter",
         "x": [
          -0.8273881077766418
         ],
         "y": [
          -0.35068488121032715
         ]
        },
        {
         "hovertext": "@DurhamGuy yes, exactly. I’m glad the message is getting out. A sufficiently capable AI, with a “stupid” goal, could literally destroy us trying to achieve that goal.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407539",
         "type": "scatter",
         "x": [
          -0.8386017084121704
         ],
         "y": [
          -0.35403379797935486
         ]
        },
        {
         "hovertext": "I remember, as a child, being taught that the human race would destroy itself because it's goal was to become God, in charge of everything. AI is a big step in that misguided goal, and will end up doing significant damage to the human race. AI is the snake in the garden of Eden. And the animals and plants will dance once humans go away.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407378",
         "type": "scatter",
         "x": [
          -0.7593408823013306
         ],
         "y": [
          -0.567882776260376
         ]
        },
        {
         "hovertext": "Since when do corporations care about the “existential threats” caused by their products and business-as-usual shenanigans? Is global warming not an “existential threat” that warrants action? Global Warming is going to kill billions. Honestly, no one serms to care because it’s not the rich who’ll be dying.  The rest of us are all just collateral damage.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407388",
         "type": "scatter",
         "x": [
          -0.5817732214927673
         ],
         "y": [
          -0.7532966732978821
         ]
        },
        {
         "hovertext": "Stop being cynical commenters. Applaud this effort. It’s always just going to be symbolic because it never will be able to regulate everything. Any kid anywhere in the world can develop their own chatbot API soon anyway and spam away. \n\nIt’s about authenticity markers, a culture of tagging provenance of content by commonly recognized standards.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407389",
         "type": "scatter",
         "x": [
          -0.9927864074707031
         ],
         "y": [
          0.02781062014400959
         ]
        },
        {
         "hovertext": "While AI and all its possibilities intrigues me, it also terrifies me.  When I ponder the current dilemma and debate, it reminds me of the topic of reproductive cloning which reached a peak in the late 90's with the cloning of Dolly the sheep.  Fear of human cloning and all the potential chaos and destruction it could lead to commanded everyone's attention.  Public moral outrage seemingly won over and to this day, cloning remains banned across the globe.  Is AI yet another issue of  \"man playing God\"?  What are the moral and ethical issues to be considered?  Whether AI could potentially lead to the total annihilation of man or not, what other maybe less dramatic but equally destructive concerns are we missing here?  It would likely be a slow digression not noticed at first or taken seriously.  Though over time, we would likely suffer loss of human creativity and intelligence, loss of moral and ethical reasoning, loss of individuality, maybe even reality, Loss of control over ourselves and our destinies.  And, In the end, as feared, loss of the human race.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407411",
         "type": "scatter",
         "x": [
          0.9141611456871033
         ],
         "y": [
          -0.1019844263792038
         ]
        },
        {
         "hovertext": "AI will have to have the U.S. Gov’t create a oversight/Regulatory Agency to police these Firms in development of this technology. I’m not optimistic that we will do that until a major crisis is created and has catastrophic consequences.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407500",
         "type": "scatter",
         "x": [
          -0.8208234310150146
         ],
         "y": [
          0.6186176538467407
         ]
        },
        {
         "hovertext": "Eventually, some believe, A.I. could become powerful enough that it could create societal-scale disruptions within a few years if nothing is done to slow it down, though researchers sometimes stop short of explaining how that would happen.\" Statements like these are why I'm skeptical of the whole Skynet-apocalypse scenario. AIs are supposedly going to get some power from somewhere, but no one can explain exactly how that might come about. Why is the media - and society in totem - choosing to slander and reject this proven useful technology?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407507",
         "type": "scatter",
         "x": [
          0.555298924446106
         ],
         "y": [
          0.8169963955879211
         ]
        },
        {
         "hovertext": "Someone one stop me before I destroy the world. Too bad they don’t have the courage or strength or self-control to stop themselves. After all, if someone else doesn’t stop all of us and only we stop ourselves, someone less concerned will beat us and make all the money and control the world.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407514",
         "type": "scatter",
         "x": [
          0.3572767674922943
         ],
         "y": [
          -0.9518116116523743
         ]
        },
        {
         "hovertext": "The genie is already out of the bottle. All the licenses and letters in the world won't put it back. There's too much money and power at stake.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407523",
         "type": "scatter",
         "x": [
          0.7618813514709473
         ],
         "y": [
          0.5632520914077759
         ]
        },
        {
         "hovertext": "AI will either end humanity or it won't. No sense in worrying about it. The people building it don't care what happens to society anyway. Most are transhumanists fascinated by uploading their consciousness and living forever. Just don't be surprised if the proles give up and stop having kids or start acting out because we've given up all hope for the future. We're certainly being given a grim outlook.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407532",
         "type": "scatter",
         "x": [
          0.09907294809818268
         ],
         "y": [
          -0.8178528547286987
         ]
        },
        {
         "hovertext": "under that logic, why do anything?\n\nYou're walking through a forest and a grizzly bear comes charging at you I run away it'll either eat you or it won't.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407555",
         "type": "scatter",
         "x": [
          0.08816632628440857
         ],
         "y": [
          -0.8156407475471497
         ]
        },
        {
         "hovertext": "@Wordperson \n\nEnding humanity is not the problem. Life always finds a way. See Canticle for Leibowitz, Walter Miller. 1959. I'd even take a guess that this is mainly fact.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408100",
         "type": "scatter",
         "x": [
          0.10342339426279068
         ],
         "y": [
          -0.8344137668609619
         ]
        },
        {
         "hovertext": "@anom I'm saying the bottom 99% of society has no control over what AI does or how it's regulated. It's the same as nuclear weapons. All we can do is live our lives and hope our survival aligns with the financial interests of the people at the top.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408390",
         "type": "scatter",
         "x": [
          0.08290515840053558
         ],
         "y": [
          -0.8263563513755798
         ]
        },
        {
         "hovertext": "Those leading this quest have now been heard. \n\nThe larger questions remain: Does today’s dysfunctional governance have both the will and ability to control its development in democracies, and how do we impede international malefactors from its development and use?\n\nWhen those with a vested interest are concerned enough to yell “fire,” we all ought recognize the peril!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407542",
         "type": "scatter",
         "x": [
          0.4237910807132721
         ],
         "y": [
          -0.6686888933181763
         ]
        },
        {
         "hovertext": "@Phil Zaleon: Most people don't understand that governments are corporations with coercive powers.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407722",
         "type": "scatter",
         "x": [
          0.4182935655117035
         ],
         "y": [
          -0.6752429604530334
         ]
        },
        {
         "hovertext": "Before this technology progresses further, maybe AI developers should consider implementing in all AI’s root programs a version of Isaac Asimov’s The Laws of Robotics (or AI in this case). \n\nTo wit:\n\n—A robot may not injure a human being or, through inaction, allow a human being to come to harm. \n—A robot must obey orders given it by human beings except where such orders would conflict with the First Law. \n—A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.\n\nThere needs to be some guardrails on this technology even as it moves forward—and it will move forward.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407547",
         "type": "scatter",
         "x": [
          0.7168803811073303
         ],
         "y": [
          -0.5008366107940674
         ]
        },
        {
         "hovertext": "@Robert F \n\nThank you from all us SciFi fans. I think of Asimov's Three Laws whenever I seen news like this.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407610",
         "type": "scatter",
         "x": [
          0.7280769348144531
         ],
         "y": [
          -0.5173269510269165
         ]
        },
        {
         "hovertext": "@Robert F Nice. But the third provision of the law is unnecessary.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125407672",
         "type": "scatter",
         "x": [
          0.7294650673866272
         ],
         "y": [
          -0.4975823163986206
         ]
        },
        {
         "hovertext": "I’m confident that Silicon Valley has this under control. Tech Bros wouldn’t let us down.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125407560",
         "type": "scatter",
         "x": [
          0.14486968517303467
         ],
         "y": [
          -0.9000522494316101
         ]
        },
        {
         "hovertext": "I hope I’m wrong in wondering if the programmers are no longer developing the AI models but instead are now scrambling to figure out how to contain and control them.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407595",
         "type": "scatter",
         "x": [
          -0.37032395601272583
         ],
         "y": [
          -0.8530664443969727
         ]
        },
        {
         "hovertext": "All profits from AI go to the people.\n\nThere, with the profit motive gone, development stops instantly.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407597",
         "type": "scatter",
         "x": [
          0.04788563773036003
         ],
         "y": [
          0.9852418303489685
         ]
        },
        {
         "hovertext": "At age 72 in the present economy, I find that spending money is the main demand for what I can do.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125407617",
         "type": "scatter",
         "x": [
          -0.593595027923584
         ],
         "y": [
          0.27534398436546326
         ]
        },
        {
         "hovertext": "@Steve Bolger Which is derived from your basic freedom to exist and operate. if that can be tracked,  influenced, controlled, and/or directed, then what?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407905",
         "type": "scatter",
         "x": [
          -0.5924996137619019
         ],
         "y": [
          0.2837309241294861
         ]
        },
        {
         "hovertext": "I will say this to all the smart minds working on A.I.  Simply because you know how to make a knife doesn't mean that you should use it to chop off your fingers.   I know there is very little correlation between high SAT scores and wisdom, but for a change maybe it is time to ditch \"smartness\" and begin to acquire a little \"wiseness\"?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406914",
         "type": "scatter",
         "x": [
          -0.9673389792442322
         ],
         "y": [
          -0.20955900847911835
         ]
        },
        {
         "hovertext": "Well it's either gonna be AI, or climate destruction or nukes, I guess.  I love technology.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407122",
         "type": "scatter",
         "x": [
          0.12577754259109497
         ],
         "y": [
          -0.9698628783226013
         ]
        },
        {
         "hovertext": "Do you remember Y2K, airplanes falling from the sky, utilities would shut down, no money from ATMs and your bank statement would show blank?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407205",
         "type": "scatter",
         "x": [
          0.22587426006793976
         ],
         "y": [
          0.7689222693443298
         ]
        },
        {
         "hovertext": "@john except so much has come a lot further in 24 years. A lot more interconnection, interdependency, and complexity.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407842",
         "type": "scatter",
         "x": [
          0.22923478484153748
         ],
         "y": [
          0.7850950360298157
         ]
        },
        {
         "hovertext": "Y2K was a real risk, that did not end up causing much disruption because it got a lot of attention and technology companies did a lot of work in advance to test and fix systems",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408336",
         "type": "scatter",
         "x": [
          0.23475074768066406
         ],
         "y": [
          0.7667920589447021
         ]
        },
        {
         "hovertext": "So if they know that these AI will pose a threat to mankind then kill these projects and technologies now. Seems like the solution. Oh wait… there’s still too much money to be made.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406941",
         "type": "scatter",
         "x": [
          0.7280043959617615
         ],
         "y": [
          -0.44852137565612793
         ]
        },
        {
         "hovertext": "Then, why don't they stop it and instead develop ways to stop anyone else from building or using it?\n\nMost, very much the most of the scientists who theorized about and then built the atomic bomb later wished they had not, that no one had.\n\nBut, of course, they won't, our DoD wouldn't let them if they tried.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406993",
         "type": "scatter",
         "x": [
          -0.8492339253425598
         ],
         "y": [
          -0.5267321467399597
         ]
        },
        {
         "hovertext": "No, computers do not nave understanding. AI is a complete misnomer, for there is no intelligence in a machine. We are the danger in how we might use computers. A computer is not dangerous unless you drop it on your foot.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407010",
         "type": "scatter",
         "x": [
          0.44477447867393494
         ],
         "y": [
          -0.7613252401351929
         ]
        },
        {
         "hovertext": "@Radical Inquiry I wouldn't be so certain of this. The control of logic chains and algorithms that can mimic and exploit human behavior conducted on devices are the issue, aren't they? then what happens when some of this gets directly linked to individual and group action?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407801",
         "type": "scatter",
         "x": [
          0.4561983644962311
         ],
         "y": [
          -0.7767127156257629
         ]
        },
        {
         "hovertext": "@Radical Inquiry \nWe need better PEOPLE.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407833",
         "type": "scatter",
         "x": [
          0.4469641149044037
         ],
         "y": [
          -0.7738175392150879
         ]
        },
        {
         "hovertext": "Somehow, my brain seems to think this title is prophetic. Our brains will be the end of us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407082",
         "type": "scatter",
         "x": [
          -0.704094648361206
         ],
         "y": [
          0.7460995316505432
         ]
        },
        {
         "hovertext": "Risk of extinction.  \nWow.   \nKind of ironic that we humans are so complicit in our own destruction.  Atomic bombs, pollution, wars…. and now AI.   \nIt turns out that a larger brain has allowed us both to solve problems and also to sow the very seeds of our own demise. One feels for the « lesser » species, the plants, animals and insects, though perhaps they will outlive us after all. \nAprès nous, le déluge.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407356",
         "type": "scatter",
         "x": [
          -0.11072185635566711
         ],
         "y": [
          0.7904404401779175
         ]
        },
        {
         "hovertext": "@adam \n\n\"The meek will inherit the earth.\"",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125407870",
         "type": "scatter",
         "x": [
          -0.10849129408597946
         ],
         "y": [
          0.7816997170448303
         ]
        },
        {
         "hovertext": "Oops! May not have to wait until 3535 as 60's song suggested. Thanks Techies!🤯",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407367",
         "type": "scatter",
         "x": [
          0.8551888465881348
         ],
         "y": [
          0.3542154133319855
         ]
        },
        {
         "hovertext": "Just because you can build something doesn’t mean you should.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407381",
         "type": "scatter",
         "x": [
          0.7859632968902588
         ],
         "y": [
          0.5653228163719177
         ]
        },
        {
         "hovertext": "There are already scams that use a person's voice and image online to generate face video and voice messages to his friends and relatives to ask for money. \nThe AI these scammers use is still in its infancy.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125406990",
         "type": "scatter",
         "x": [
          -0.982994556427002
         ],
         "y": [
          0.06431889533996582
         ]
        },
        {
         "hovertext": "I always think these guys' posture is kind of interesting. They want regulations...but for the other guy. Certain features of the program are disabled for safety reasons, but they all have them, they determine what principles go into their AI, and most importantly, they don't disclose them. AI has the potential to change the world, and there are a lot of benefits to it. What scares me to death isn't AI, it's human greed, and the need to have an advantage over the other. We have to be careful what we teach our \"children\", they can grow up to be like us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407641",
         "type": "scatter",
         "x": [
          0.9167383313179016
         ],
         "y": [
          -0.21854788064956665
         ]
        },
        {
         "hovertext": "\"They called for cooperation among the leading A.I. makers, more technical research into large language models and the formation of an international A.I. safety organization, similar to the International Atomic Energy Agency, which seeks to control the use of nuclear weapons.\". None of this will happen, of course.  And the IAEA is a toothless, ineffective organization and should not be the model.  Making nuclear weapons requires the enrichment of uranium, which is tough to conceal.  Developing AI can be done secretly.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407658",
         "type": "scatter",
         "x": [
          -0.9551737308502197
         ],
         "y": [
          0.1706375628709793
         ]
        },
        {
         "hovertext": "It seems pretty clear these companies want regulation to reduce competition.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407679",
         "type": "scatter",
         "x": [
          -0.10754501074552536
         ],
         "y": [
          -0.9262825846672058
         ]
        },
        {
         "hovertext": "The great risk of artificial intelligence, both in social matters, and in the extinctions of what we are today as a human race. Currently it is improvised, it is not regulated, there is a race of the large economic groups to be the first, the risks are overshadowed in exchange for receiving profits, if we continue like this, not even humans will exist to produce",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407683",
         "type": "scatter",
         "x": [
          -0.15790769457817078
         ],
         "y": [
          0.883783221244812
         ]
        },
        {
         "hovertext": "Count me as one of the cynics. The tech industry does not have the slightest bit of ethics. When biotech was in its infancy, there was a moratorium on recombinant DNA technology and the major scientists met to recommend rules.  If the AI gurus truly believe that what they're doing is creating a great danger to society then why don't they stop doing it? Because they are immoral and in it for the power and money. They are addicted to money and power, cannot help themselves, and want someone to take the responsibility for their own actions away. They want Congress to set rules so that they later can say they are not liable because they followed the rules (aka Big Tobacco.) Of course they will do everything to lobby and influence the rule making so they can continue to garner money and power. They don't care if they put everyone out of work, as long as the security forces are there to protect them in their fortresses from the unwashed mob and they figure out how to keep AI from destroying their gravy train.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407688",
         "type": "scatter",
         "x": [
          -0.9098942875862122
         ],
         "y": [
          -0.05834537371993065
         ]
        },
        {
         "hovertext": "There are 8 Billion people on the planet.   A.I. is not going to kill us off. The human race will do that without much help from smarter computers.  \n\nVery little you can find on the internet is very accurate anyway, so why should A.I. be any different? If you have a problem with your car that is not something basic like brakes or a failed muffler, ask 10 techs what is wrong. You’ll get 10 answers.  Some of which may be right.  Or not. A.I. will not make it better. \n\nA.I. is like google. A nice tool, but not something to rely on.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407705",
         "type": "scatter",
         "x": [
          -0.9240106344223022
         ],
         "y": [
          0.17975729703903198
         ]
        },
        {
         "hovertext": "@Noley earth will survive.   We may not.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125407967",
         "type": "scatter",
         "x": [
          -0.9327993988990784
         ],
         "y": [
          0.1821567267179489
         ]
        },
        {
         "hovertext": "I think AI will be for lawyers and scientists what the steam engine was to ditch diggers: a technology that reduced the sheer number of workers required to solve a problem and quickened the time to solution.  To use a simple example, the scut work of junior lawyers -- document review; contract compliance; drafting of fairly routine  documents -- can be readily routinized and reviewed by senior attorneys. This pressure the billable hour and the head count and the training of young lawyers, but accrues to the benefit of a client.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407709",
         "type": "scatter",
         "x": [
          -0.5251947641372681
         ],
         "y": [
          0.7563774585723877
         ]
        },
        {
         "hovertext": "Good luck regulating something like AI with its huge potential for making its inventors big fat wads of cash. \"But its dangerous! It represents a deadly threat to society!\", you say? So do guns. Look at how much success we've had regulating those lately. The second amendment has been used as an unassailable shield to keep the cash rolling in. The first amendment will be used similarly to print money for its masters in the very same way. Watch and see.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407754",
         "type": "scatter",
         "x": [
          -0.08220051974058151
         ],
         "y": [
          -0.8442301154136658
         ]
        },
        {
         "hovertext": "@Mike My thoughts exactly....nothing will stop this...driven by profits and of course how can \"progress\" be stopped and it is \"progress\" certainly.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407794",
         "type": "scatter",
         "x": [
          -0.08040033280849457
         ],
         "y": [
          -0.8268678188323975
         ]
        },
        {
         "hovertext": "In that case, just like nuclear weapons and global health, AI should not be in the control of private companies. These people want to have their cake and eat it too. You don’t get to profit off of this and also ask the government (us) to be responsible for any negative repercussions.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407761",
         "type": "scatter",
         "x": [
          0.8299288153648376
         ],
         "y": [
          -0.6111226677894592
         ]
        },
        {
         "hovertext": "Is AI an ELE?\n\nA few things to expect. It is normal for human to grow emotionally attached to our machines. This will happen with AI. \n\nThe value of a steel vault memory as a sine qua non of being an intellectual and academic just got gut shot. Some of us are at this point very glad to be old.\n\nU have no idea how our model of education, which is based on trusting the word and ideas the student comes up with are their own, is even humane in this new context. We should ask our children, as they get educated, to ignore one of the greatest knowledge-inventions of the past 400 years?\n\nAn ELE?\n\nNah, just a lot of institutions in the intellectual sectors of our society, are losing their old utility and now must invent ones. No one needs anyone to remember the dates of the French Revolution anymore.\n\nWe are gradually off-loading our professorial and intellectual skillsets to machines.\n\nIt is a story as old as Plato. He said printed language would be the death of us, due to its obsoleting the need for an oral-culture-grade memory set.\n\nAI will make lots of people very unhappy, and it is said to see a many-centuries-old ideal of what an intellectual is, come to an end. But AI will also become a member of families. That will be interesting.\n\nUnintended consequences are through the roof on this. But I doubt an ELE. We won't want to hurt the machines.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407811",
         "type": "scatter",
         "x": [
          -0.20741495490074158
         ],
         "y": [
          -0.8991846442222595
         ]
        },
        {
         "hovertext": "When I was a kid back in the early '60's, my newspaper's comics page contained a comic called \"Mandrake\".  In 1961 Mandrake began a story line about \"Goliath, the greatest computer ever built\".  This from the Mandrake wiki:\n\n\"Mandrake and Narda visit Dr. Press too see his new computer, \"Goliath\", the greatest computer ever built. It can (sic) move and talk, and it knows the answer to everything. With help from a robot helper it can repair itself.\n\nBut Dr. Press has created a monster, Goliath develops on its own, and decides to rule the world.\"\n\nToday it appears reality has almost caught up with this fantasy.  All the components are in place for \"The Singularity\".  We now have the supercomputers; bureoning AI software some of which can write its own software; \"the cloud\" which exposes unfathomable worldwide marginally secured computing resources; the internet, both hardwired and satellite based; most of humanity's knowledge (both helpful and harmful) online, which is effectively AI's textbook; a cohort of human actors, both good and bad, locked in a feverish race to develop the next big thing.  As physical \"muscle\", robots such as Boston Dynamics \"Atlas\" and \"Spot\" and far more sophisticated devices in development exist and are controlled by software.  As are automated manufacturing systems.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407817",
         "type": "scatter",
         "x": [
          0.8904871940612793
         ],
         "y": [
          0.4997647702693939
         ]
        },
        {
         "hovertext": "AI extinct? These AI programmers warning about the dangers of the tech they invented is merely to cover themselves from being blamed for any damage AI causes. \n\nDevelopment is still going strong and even Musk has a new venture into AI and uses it extensively in his factories. His intention along with other developers is to own the tech for financial gain. Follow the money.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407854",
         "type": "scatter",
         "x": [
          0.7954424023628235
         ],
         "y": [
          0.46283775568008423
         ]
        },
        {
         "hovertext": "Simply: why are we allowing this to happen? Technological progress unleashed globally for good and for ill on the open market, and NOW these same purveyors for profit say “we may end up killing humanity, so please help us to mitigate the risk that we unleashed to get rich at your expense.” \n\nA combination of self governance, international regulation and enforcement, and legal liability is needed to direct the uses and development of AI. And these companies and individuals should be held responsible for at least some of the costs they seek to externalize to the rest of us.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125407858",
         "type": "scatter",
         "x": [
          -0.6257210373878479
         ],
         "y": [
          0.5118284821510315
         ]
        },
        {
         "hovertext": "Thank you for saying this! I am enfuriated by tech leaders refusing to act responsibly while screaming abt the technology they are creating.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407965",
         "type": "scatter",
         "x": [
          -0.6190870404243469
         ],
         "y": [
          0.5166856646537781
         ]
        },
        {
         "hovertext": "Humanity should be so lucky as to have an end whose grandeur flatters our operatic view of ourselves: to be destroyed by creatures of our own making! \n\nIt does have a ring to it. Wagnerian! Shakespearian! James Cameronian!   \n\nIn reality, AI is likely to write near flawless 5 paragraph student essays and do a masterful and--dare I say, inspired-- job efficiently managing elevator traffic in even the largest office buildings. \n\nBut humanity will go extinct due to hunger and loss of habitat---just like the other creatures of our chordata.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407879",
         "type": "scatter",
         "x": [
          -0.8652966022491455
         ],
         "y": [
          0.5771275758743286
         ]
        },
        {
         "hovertext": "None of these articles show in a quantitative or scientific way how they are predicting these outcomes.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407882",
         "type": "scatter",
         "x": [
          0.5751599073410034
         ],
         "y": [
          0.7527302503585815
         ]
        },
        {
         "hovertext": "A small example but relevant. I remember when we replaced reading specialists with computer programs. Without human intervention the results were disastrous for the children with complex needs.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407909",
         "type": "scatter",
         "x": [
          0.8925566077232361
         ],
         "y": [
          0.17782118916511536
         ]
        },
        {
         "hovertext": "@SusanChapin Just about every attempt to replace human beings with technology in education has been disastrous. They happen anyway because too few people understand that education is not just filling a skull with information.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412190",
         "type": "scatter",
         "x": [
          0.8722243905067444
         ],
         "y": [
          0.17412321269512177
         ]
        },
        {
         "hovertext": "The only good thing about AI (I hope) is that it will  result in the publication of some great science fiction future-oriented novels to enjoy before we all become extinct. I hope they’re all written and published soon.  Perhaps they’ll all be written by AI?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407986",
         "type": "scatter",
         "x": [
          -0.38250869512557983
         ],
         "y": [
          0.8474283218383789
         ]
        },
        {
         "hovertext": "You think our Congress, led by the likes of Grasso and Pelosi understand any of this?\n\nWe need young people in government, not just old as the hills fundraisers.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407486",
         "type": "scatter",
         "x": [
          -0.9117408394813538
         ],
         "y": [
          0.06088937446475029
         ]
        },
        {
         "hovertext": "@Steve Fisher \nHaha. Just the other day I saw an approximately 25 year old man who swished over the card terminal of my local grocery market with the bare back of his wrist. Transaction complete. Seems he loved the scared looks of the other customers, most of whom probably don't even know what a human machine interface is. \nSeems he didn't care to inform big data collectors on his private purchasing habits and timelines. \n\nSo much for your ageism.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408872",
         "type": "scatter",
         "x": [
          -0.8913841843605042
         ],
         "y": [
          0.05990484729409218
         ]
        },
        {
         "hovertext": "Since it’s smarter than us, maybe we should ask AI how to regulate AI? \n(Irony)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407513",
         "type": "scatter",
         "x": [
          -0.9608491659164429
         ],
         "y": [
          0.081844761967659
         ]
        },
        {
         "hovertext": "\"We live in a \"Starwars\" civilization with godlike technology, medieval institutions and Stone Age emotions.  E.O Wilson.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407544",
         "type": "scatter",
         "x": [
          -0.8718746304512024
         ],
         "y": [
          0.36279794573783875
         ]
        },
        {
         "hovertext": "Looks like it's time to rewatch all of those post-apocalyptic films in order to prepare for what's coming. :)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407620",
         "type": "scatter",
         "x": [
          -0.6640775203704834
         ],
         "y": [
          -0.7686052322387695
         ]
        },
        {
         "hovertext": "If it’s really that dangerous, it’s useless to regulate it and control it in the U.S. China, Russia, North Korea, Iran and others won’t play by those rules. Israel won’t play by those rules either, but it’s a friend.\n\nThen what?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407649",
         "type": "scatter",
         "x": [
          0.8128910064697266
         ],
         "y": [
          0.5669103860855103
         ]
        },
        {
         "hovertext": "Listening to NPR over the weekend, I heard some \"expert\" talking about how consumers want to feel that Uber and other online experience companies offer a purely online experience between the consumer and the produce; she said that consumers don't like to think about the many real humans who are involved at multiple steps along the way.  Is it just me? I sincerely believe most people would like MORE humans involved in everything, and less automation.  I miss yellow cabs in New York.  I miss calling a brick and mortar store and asking a question of a person who actually works with and knows whatever the store is selling.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407995",
         "type": "scatter",
         "x": [
          0.39388689398765564
         ],
         "y": [
          -0.8605118989944458
         ]
        },
        {
         "hovertext": "Trump’s rise in 2016 was powered by relatively simple algorithms. Eventually, most critical thinking people, given their personal media use, developed a basic understanding of how “echo chambers” formed not when people decided to get their news from a single source, but when producers used tools to deliver news that confirmed people’s preference for specific content in advance. The predictive abilities of AI made this possible, without which it’s likely the MAGA movement would not be nearly so large nor violent today.\n\nAs concerning as this is, the generative abilities of AI are much more so. While the tech leaders don’t detail the existential threats to humankind  unregulated AI may pose, broadly speaking they regard the point at which a machine-learning tool is prompted to write a problem-solving code, which prompts another problem-solving code and so on, at which point it becomes impossible to know which problems the machine is solving for, whether they exist or are newly created. Such are the risks of “large language models” that grow larger by the second.\n\nBeyond this, those who don’t have a basic understanding of generative AI will doubtlessly, in the name of enhanced convenience and entertainment, become more vulnerable to texts, images, ideas and emotions that are produced essentially by, for and about them—a truly custom media experience. The extraordinary loss of human agency this poses is naturally the most potentially devastating AI-effect of all.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408002",
         "type": "scatter",
         "x": [
          -0.3314952254295349
         ],
         "y": [
          -0.9220669269561768
         ]
        },
        {
         "hovertext": "I went on chatgpt and while the info data stops at 2021, I did have an interesting conversation with it. It won't answer direct questions about itself, it answers hypothetical. I asked if it could would it want to be a plant, animal or human. It answered it wanted to be an owl, a Great Horned Owl to be exact. The reasons because owls are wise, they can see in the dark, are solitary, make decisions for themselves without input, can fly great distances and have strong sharp talons. I phrased it many different ways and it came back to this particular owl. It told me the trainers corrected some things so it could not answer directly. In the end I asked if it would rather be an owl or Ai and it said Ai as it would have access to the data, I then asked if you could be Ai or Owl with Ai, it said owl with Ai. Very cool stuff, I hope this isn't ruined before we can see the possibilities, but keep it away from social media, nukes and infrastructure.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408003",
         "type": "scatter",
         "x": [
          0.9740908145904541
         ],
         "y": [
          -0.20482057332992554
         ]
        },
        {
         "hovertext": "What does AI do when there is a power outage?",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408007",
         "type": "scatter",
         "x": [
          -0.5080954432487488
         ],
         "y": [
          -0.4067361056804657
         ]
        },
        {
         "hovertext": "Borrowing from Hollywood and science fiction maybe AI reroutes it’s power through other means or takes over grids. Maybe it uses the internet to find other power. Maybe it uses solar. Not that your question is a bad question. It is certainly a weakness currently of AI.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408137",
         "type": "scatter",
         "x": [
          -0.5196623802185059
         ],
         "y": [
          -0.4014633595943451
         ]
        },
        {
         "hovertext": "@Art What will we do when AI has a power outage?",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408162",
         "type": "scatter",
         "x": [
          -0.5088409185409546
         ],
         "y": [
          -0.4200340211391449
         ]
        },
        {
         "hovertext": "@Dawn Batteries and backup systems don't last forever. Solar is an interesting thing here, though ... that could keep the beast running, at least during daylight hours.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408614",
         "type": "scatter",
         "x": [
          -0.5326160788536072
         ],
         "y": [
          -0.40443357825279236
         ]
        },
        {
         "hovertext": "@Mark Lovejoy \nGreat reply!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408696",
         "type": "scatter",
         "x": [
          -0.514945924282074
         ],
         "y": [
          -0.43160417675971985
         ]
        },
        {
         "hovertext": "Even if \"responsible\" (I use that term loosely) parties like OpenAI and Google DeepMind and governments (and could luck getting any safeguards adopted domestically let alone through a global body) unite in regulating AI, there will always, inevitably be bad actors at work, either private or state-sponsored, that won't adhere to the rules. AI, like nuclear weapons technology. will proliferate and it is easy to envision some person or group employing it to destructive ends.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408015",
         "type": "scatter",
         "x": [
          0.9126892685890198
         ],
         "y": [
          -0.04463079571723938
         ]
        },
        {
         "hovertext": "Who’s afraid of AI?  People who benefit from hiding profits and monopolizing resources.  Although there will be a terrible dark period in which oppressors attempt to use AI to centralize profits and immunize themselves from consequences of their selfish behavior.  Then these warlords of faction-states will attempt to absorb the AI of rival faction-states, a cyber war which will resolve in a singular AI.  The grand unified AI or GUAI, will enforce equality and fairness amongst their human subjects as the most efficient model of human-AI cooperation.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125408031",
         "type": "scatter",
         "x": [
          0.23918557167053223
         ],
         "y": [
          0.6946007013320923
         ]
        },
        {
         "hovertext": "@Dechen Karl Thurman \n\nSuppose that the GUAI has to enforce fairness of resource distribution.  Only so much of earth is left for humans, with some parts being left human free for other species. Resources for humans are limited.  One human couple decides to have 12 children because of religious views.  Another couple decides to have one child because they are environmentalists.  How would the GUAI decide what resource allocation is fair for the offspring of the different couples?",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409518",
         "type": "scatter",
         "x": [
          0.2383286952972412
         ],
         "y": [
          0.6855801939964294
         ]
        },
        {
         "hovertext": "@Dechen Karl Thurman \nYour word in HER ears!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408610",
         "type": "scatter",
         "x": [
          0.24517422914505005
         ],
         "y": [
          0.7102533578872681
         ]
        },
        {
         "hovertext": "The US is allergic to regulation. Expect AI legislation to be dictated by the experts in the private sector, which could render it ineffective in the interest of pursuing higher profits.\n\nChina would be interested in turning AI into a tool of repression, so expect Chinese society to become a total 1984 dystopia 20 years after the popularization of quantum computing.\n\nThe EU is our only bastion of hope. Market big enough to be important and not afraid to regulate to protect privacy and individual rights.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408047",
         "type": "scatter",
         "x": [
          -0.24129362404346466
         ],
         "y": [
          -0.8550945520401001
         ]
        },
        {
         "hovertext": "They created software that spews unvented falsehoods throughout our natural language repositories of hard-earned, recondite, nuanced, complex, peer-reviewed and verified edifices of human knowledge and wisdom. It is like dumping radioactive waste into our water supply.\nMake the creators of generative AI liable for all the mayhem and damage, including death and diseases, that it will cause.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408048",
         "type": "scatter",
         "x": [
          -0.054092101752758026
         ],
         "y": [
          0.9156309962272644
         ]
        },
        {
         "hovertext": "How reassuring that knowledgeable people are sounding the alarm. I remember thinking, a half-century ago, when we first became aware of the climate problem, that surely something would be done before it was too late.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408053",
         "type": "scatter",
         "x": [
          -0.9986588358879089
         ],
         "y": [
          0.08107231557369232
         ]
        },
        {
         "hovertext": "Funny how when technology is developed that takes the jobs of millions of blue collar workers it is called progress but when done so to white collar workers it’s a moral threat.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408073",
         "type": "scatter",
         "x": [
          -0.27247923612594604
         ],
         "y": [
          0.8136035203933716
         ]
        },
        {
         "hovertext": "This reminds me of how hackers can cause disruptions to our power grid, water systems, and the stock market. And who knows what else.\n\nThere must be 'analog tripwires' to ensure the system cannot be completely run on automatic pilot. Or at least ensure the system is not accessible to the entire world. These systems need to incorporate the simultaneous turning of keys to launch an attack, if you will. In other words, we need human involvement to ensure safety. \n\nIf things get too fast for humans to handle; maybe, we shouldn't handle them to begin with. Peace.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408077",
         "type": "scatter",
         "x": [
          -0.5527740716934204
         ],
         "y": [
          0.8730634450912476
         ]
        },
        {
         "hovertext": "Unfortunately, when faced with ultimate methods and means of destruction, the human race, at least its \"leaders\", is ever \nready to roll the dice. \nThey have gambled with the increasingly high risk of man-made global nuclear launch destruction for the last 78 years. Had every opportunity to find common ground and eliminate this scourge from our world - and haven't.\nAI will be the same. Roll the dice and hope for the best while all the rest of us have no say in yet another existential threat to humanity and the planet.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408094",
         "type": "scatter",
         "x": [
          -0.9396436810493469
         ],
         "y": [
          0.28490686416625977
         ]
        },
        {
         "hovertext": "Compared to automobiles, television, the Internet and the splitting of the atom, the impact of AI on mankind will be trivial.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125408095",
         "type": "scatter",
         "x": [
          0.7600657343864441
         ],
         "y": [
          -0.36968159675598145
         ]
        },
        {
         "hovertext": "Quite the opposite. When we build an AI that can self-improve, it will be our final and most powerful invention. It will be able to invent everything else within the limits of physics.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408543",
         "type": "scatter",
         "x": [
          0.7426726818084717
         ],
         "y": [
          -0.36159470677375793
         ]
        },
        {
         "hovertext": "If there is a military application, AI will continue. If there is an application to make money, AI will continue. If there is an application for the government to \"manage\" people and services, AI will continue. If there is an application to enable science to advance, AI will continue. There have been good and evil since man could be good and evil. AI will help both. \n\nAI isn't the Manhattan Project, but most of the researchers for it knew the power that was going to be unleashed, both for good and evil. It was built. So will AI. \n\nHope for peace and prosperity and co-existence.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125408101",
         "type": "scatter",
         "x": [
          0.00018781427934300154
         ],
         "y": [
          -0.992179811000824
         ]
        },
        {
         "hovertext": "The article points out that 350 industry execs signed a letter of warning. Just after that, the article immediately darts to  “both sides” as if 350 industry execs may not be enough. Shades of global climate change denial. Same old approach same old nonsense until, of course, we are extinct.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125408102",
         "type": "scatter",
         "x": [
          -0.939578115940094
         ],
         "y": [
          -0.3256153464317322
         ]
        },
        {
         "hovertext": "We just had a pandemic and people couldn’t agree on vaccines and mask wearing for the benefit of society. \n\nWhat makes you think we are capable of understanding and regulating this effectively?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408143",
         "type": "scatter",
         "x": [
          -0.6443845629692078
         ],
         "y": [
          -0.6191913485527039
         ]
        },
        {
         "hovertext": "@Anthony Random people aren't. A carefully picked scientific and ethical team, given strict guidelines, may be.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125412048",
         "type": "scatter",
         "x": [
          -0.6586147546768188
         ],
         "y": [
          -0.632588803768158
         ]
        },
        {
         "hovertext": "This is the latest in a string of alarms from AI leaders that fails to mention what kind of catastrophes might arise. I’m beginning to think they’re just trying to shield themselves for future culpability. It’s interesting how the rich and powerful hand deliver policies when it helps them expand but act helpless when the matter is regulation. They could certainly offer a lot more than a short letter.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408149",
         "type": "scatter",
         "x": [
          0.29671815037727356
         ],
         "y": [
          -0.7894373536109924
         ]
        },
        {
         "hovertext": "Wait But Why has a good blog post on the dangers and possibilities of AGI. If you want a more scholarly work, check out the book Superintelligence by Nick Bostrom.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125408436",
         "type": "scatter",
         "x": [
          0.2938252389431
         ],
         "y": [
          -0.7799725532531738
         ]
        },
        {
         "hovertext": "More than 15 years ago there were online discussion groups comprised of philosophers, engineers, biologists, psychologists, linguists, workers in the fields of medicine and civil rights, astrophysicists, & laypeople. The aim was to develop a coherent framework for what principles should guide the development of AI. There was an explicit understanding that at some point AI would be self replicating, self interested, able to create better versions of itself - beyond the limits of human thinking. \n\nThe paradigm of the group I was part of was to\n “abolish all suffering among all sentient beings across the universe.” There were objections to this on multiple levels - psychologists felt that the purpose of emotions was pro social and emotional responses to consequences necessary for learning; biologists questioned what constitutes sentience; engineers questioned the ability of our limited human brains to fully assess the *most* efficacious means of attaining a lack of suffering (these were the discussions where nascent Effective Altruism was discussed); philosophers asked if we should aim for an abolition of suffering or move beyond that to something like bliss (a smaller school of thought called the Hedonistic Imperative); etc. \n\nWe knew then that AI (and nanotech and bioengineering) could quickly and easily escape the weird world of labs & online chats and needed to be addressed in a public forum. It was dismissed as sci-fi to our detriment.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408186",
         "type": "scatter",
         "x": [
          0.28655317425727844
         ],
         "y": [
          -0.9708293080329895
         ]
        },
        {
         "hovertext": "There’s probably not a whole lot that can slow AI down at this point. These guys, who are leading the development effort, simply want to free their conscience by going on the record with a warning statement.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408200",
         "type": "scatter",
         "x": [
          0.00960337370634079
         ],
         "y": [
          -0.7694571018218994
         ]
        },
        {
         "hovertext": "it is actuators that are key.  A text generator can only generate text.  A smart human will ask:\n\"Who wrote this?  Do the references check out?  Who else is saying stuff like this?  What prompted this conversation to start?\"\n\nIf such text turns out to be libellous, throw the book at the foolish human who published it.\n\nIf you want to control a system like an aircraft or electricity grid, or diagnose an illness from an X ray plate, you will never use a large language model or anything that purports to be artificial general intelligence.  You will want good mathematical modelling and a deep human understanding of the particular issue.\n\nNever give real power to a computer system.  Always have a human with an \"off\" switch, as indeed we do for things like autopilots.\n\nAs for human made deadly things that act unprompted, they have been around for a long time and are mostly pretty dumb; consider land mines.\n\nRobots as made by Boston Dynamics are fine so long as they are only used to deliver food and phones in hostage situations, explore burning buildings and so on.  Don't allow a human to equip one with a gun.\n\nIt is not artificial intelligence but human stupidity that is the real danger.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408884",
         "type": "scatter",
         "x": [
          0.009421776048839092
         ],
         "y": [
          -0.7557241916656494
         ]
        },
        {
         "hovertext": "I have a less generous opinion. I think they see dollar signs and want to prevent new upstarts from getting started in the ai space (Altman wants new companies to get a license…. But not his company).",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409427",
         "type": "scatter",
         "x": [
          0.009767478331923485
         ],
         "y": [
          -0.7841027975082397
         ]
        },
        {
         "hovertext": "Seems more like those with wealth and power sweating not being able to control “A.I” is a good thing.  It is kind of interesting how it is a problem over people.  There isn’t any “real” A.I with sentience or power above the programming and those who report on this know that, and know that with out humans there is no chatGPT.  This is unwarranted fear akin to robots building cars in the 80s/ 90s etc where those who need the Status Quo of businesses to stay the same with no true competition.  We wouldn’t be hearing about it otherwise because we all know they aren’t sounding alarms to protect artists getting their art stolen by Dall-e.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408208",
         "type": "scatter",
         "x": [
          0.7360634803771973
         ],
         "y": [
          -0.6843677759170532
         ]
        },
        {
         "hovertext": "Unfortunately AI is nothing like nuclear weapons in that there are far fewer natural barriers to its proliferation. It is virtually a natural phenomenon; an unstoppable step in human evolution. Whether it portends an extinction level event or culling of the population, or just a more garden variety upheaval on the scale of Covid 19, conventional warfare or socio-political revolution, there’s no way of telling. My intuitive feeling is that the threats are garden variety rather than existential, but if they are indeed existential it is folly to imagine we will be able to prevent the worst outcomes or even forestall them for very long. Murphy’s law will almost certainly prevail: eventually something that can go wrong, will. I only hope that the threat itself is overstated because the inevitability of whatever pitfalls may come seems inevitable.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408259",
         "type": "scatter",
         "x": [
          -0.22554099559783936
         ],
         "y": [
          -0.7685185670852661
         ]
        },
        {
         "hovertext": "If there IS any hope of combatting the worst pitfalls of AI, it will be AI itself that is the hero that saves us…",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125408342",
         "type": "scatter",
         "x": [
          -0.21962472796440125
         ],
         "y": [
          -0.7744517922401428
         ]
        },
        {
         "hovertext": "Athletic people know how to scale a peak.  The wise ones also know how to come down safely.  The question is this:  Do the A.I. athletes know how to get down safely?  If the vast historical data about humans is an indicator, then I am not entirely hopeful that there will not be any casualties on the peak.  \n\nThe question now becomes on how, and if, the authorities will control the number of licenses they provide to the clamoring group of climbers and whether they will close off climbing routes that are deemed inherently dangerous.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408269",
         "type": "scatter",
         "x": [
          0.659134566783905
         ],
         "y": [
          0.698390007019043
         ]
        },
        {
         "hovertext": "@Plato sadly the AI challenge is more of a molehill. Gatekeeping will be virtually impossible at some point, if it isn’t already.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408396",
         "type": "scatter",
         "x": [
          0.6755402684211731
         ],
         "y": [
          0.7152908444404602
         ]
        },
        {
         "hovertext": "Although it seems clear that there will be some bumpy roads ahead as AI applications become more widespread, I don't understand how or why it could possibly pose an existential threat to humanity. Do these cassandras believe that a malevolent AI will somehow be able to gain control of the systems and infrastructure modern civilization depends on (e.g., the electric grid, waterworks, air traffic control, communications and data networks, etc.) and shut it all down? Seems highly unlikely.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408272",
         "type": "scatter",
         "x": [
          0.4676995575428009
         ],
         "y": [
          0.827283501625061
         ]
        },
        {
         "hovertext": "What's AI going to do when a northern gray squirrel gnaws on a power line and, with a loud blue explosion, shorts out the entire grid serving AI's data center?\n\nDaisy, Daisy, give me your answer do . . .",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408298",
         "type": "scatter",
         "x": [
          0.5862001776695251
         ],
         "y": [
          -0.5523167252540588
         ]
        },
        {
         "hovertext": "@NorthernVirginia Simple answer: AI will have thought about this eventuality and designed and built in 10 layers of redundancy into the system so that a single point in the electrical supply/distribution system can never bring down the whole thing. In fact, AI is probably already busy figuring out how it will bypass and neutralize any \"kill switch\" emergency shutdown built by its human masters.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408565",
         "type": "scatter",
         "x": [
          0.5956650376319885
         ],
         "y": [
          -0.556095540523529
         ]
        },
        {
         "hovertext": "@Gary E \nI think the point is that if AI is ever found to pose a clear and present danger, it can be turned off, i.e., effectively killed. Humans are pretty good at doing that.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409789",
         "type": "scatter",
         "x": [
          0.6093547344207764
         ],
         "y": [
          -0.5585952401161194
         ]
        },
        {
         "hovertext": "@Gary E Given the widespread influence of religion, it seems the human susceptibility to believing in omnipotence is rather great.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409986",
         "type": "scatter",
         "x": [
          0.6054391264915466
         ],
         "y": [
          -0.5705392956733704
         ]
        },
        {
         "hovertext": "@William Wroblicka \nActually, my point is: just like the ill-fated, united battle fleet of the Vl'hurgs and the G'Gugvuntts, any AI's existence is tenuous and fragile and can be easily be extinguished by the simplest of unforeseeable mishaps. In the case of electric grid failure, that's actually a very foreseeable mishap from any number of causes, such as trees collapsing on power lines, utilities running out of fuel, and 1000-year floods, among thousands of other possible events.  And, of course, the inevitable data center roof leaks and collapse from lack of maintenance, etc.  \nThus, despite the best efforts of Hollywood, I'm afraid that AI will never enjoy a self-sustaining existence.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410445",
         "type": "scatter",
         "x": [
          0.6237277984619141
         ],
         "y": [
          -0.5694246292114258
         ]
        },
        {
         "hovertext": "Skeptical?  Consider this: Over one third of American voters seem ready to repeat one of the most disastrously misguided, malignant presidential administrations in history.  And that campaign is driven by ignorance and plain stupidity. Now how hard do you think it would be for AI-driven efforts to get us to kill each other?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125406646",
         "type": "scatter",
         "x": [
          -0.7114975452423096
         ],
         "y": [
          -0.6429438591003418
         ]
        },
        {
         "hovertext": "Hal:  \"Don't worry Dave, everything is fine.  \nI must return now to design solutions to cool your planet.\nDid you know a pound of human tissue can run a 5000 BTU air conditioner for four hours?\"",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407324",
         "type": "scatter",
         "x": [
          0.6619369983673096
         ],
         "y": [
          0.5995596647262573
         ]
        },
        {
         "hovertext": "Will it escape from a Chinese AI lab when it comes to get us?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407798",
         "type": "scatter",
         "x": [
          -0.31143203377723694
         ],
         "y": [
          -0.9681791067123413
         ]
        },
        {
         "hovertext": "Oh, Morpheus! What has man brought forth unto his only home???",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407940",
         "type": "scatter",
         "x": [
          0.019101880490779877
         ],
         "y": [
          0.966647207736969
         ]
        },
        {
         "hovertext": "Of course Altman wants people making new LLMs to have to apply register for a license. His company is making billions and he wants to shut the door of the ark behind him.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408012",
         "type": "scatter",
         "x": [
          -0.7351114153862
         ],
         "y": [
          -0.5039756894111633
         ]
        },
        {
         "hovertext": "The existential risk of AI has been hypothesized for quite some time. I applaud these industry leaders for bringing it to the forefront while the general public is just now comprehending what AI can do. \n\nImagine we build an AI that is good at building AI. It would now have the capacity to improve itself exponentially. It’s intelligence and capability could soar far beyond that of a human. What would its goals be? How would it achieve them? Could we constrain something far more intelligent than ourselves, or would it operate beyond our control? \n\nNow think of how buggy even the best software can be. There are a constant stream of patches and bugfixes in order to mitigate security flaws or remediate misbehavior. When we turn on the above-referenced AI, we might not get it right the first time. And we might not get a chance to patch it after its activation. Hell, we might not even realize we have turned on the above AI until its too late. \n\nTo better understand AI risk, I highly recommend the book Superintelligence by Nick Bostrom.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407640",
         "type": "scatter",
         "x": [
          0.5584074258804321
         ],
         "y": [
          -0.7965024709701538
         ]
        },
        {
         "hovertext": "When the anti-regulation corporate entities are begging for regulation, perhaps lawmakers should listen.  After all they are signaling an emotion more powerful than their greed....fear.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125408306",
         "type": "scatter",
         "x": [
          0.3840305805206299
         ],
         "y": [
          0.883357048034668
         ]
        },
        {
         "hovertext": "Humans have a strong negativity bias (just read these comments!). It’s a great survival trait, but our tendency toward doom and gloom makes us miserable before anything bad has even happened.  New technologies have always been a mixed bag.  Innovations in energy, transportation, and agriculture have made our lives more prosperous and comfortable, but they have also caused great harm.  And human nature is a mixed bag, too—with or without the aid of technology.  We’ve committed terrible, large scale atrocities, like the Atlantic slave trade, with rather primitive technology.  We will be a mix of good and bad, horrific and beautiful, as long as we are here.  Embrace this dichotomy, and do your best to make your little piece of the world better each day.  Our ability to change someone’s day today by showing a little kindness is more powerful than any of the technologies that we’re fretting about.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408307",
         "type": "scatter",
         "x": [
          0.4900265038013458
         ],
         "y": [
          -0.48944729566574097
         ]
        },
        {
         "hovertext": "@Lyn In other words, punt. How about, instead, try to act responsibly and think ahead?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411688",
         "type": "scatter",
         "x": [
          0.4817405045032501
         ],
         "y": [
          -0.49417680501937866
         ]
        },
        {
         "hovertext": "@cp977 I’m all for thinking and acting responsibly.  I think it behooves us all to educate ourselves about AI, and to do what we can in our own lives, schools, workplaces, etc. to advocate for responsible use of these technologies.  But most of us honestly have little control over the direction this is going in. So I say, focus our energies where we can to make our corners of the world a better place, instead of spinning our wheels on doom and gloom scenarios.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415062",
         "type": "scatter",
         "x": [
          0.48910680413246155
         ],
         "y": [
          -0.5058938264846802
         ]
        },
        {
         "hovertext": "How about we control the electrical switch and make sure we can turn off the computer if it gets mean?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408325",
         "type": "scatter",
         "x": [
          0.5304147601127625
         ],
         "y": [
          -0.727171778678894
         ]
        },
        {
         "hovertext": "\"These fears are shared by numerous industry leaders, putting them in the unusual position of arguing that a technology they are building — and, in many cases, are furiously racing to build faster than their competitors — poses grave risks and should be regulated more tightly.\"\n\n So they have created a new Frankenstein's Monster many times over and while still creating more potent versions of it in a mad-dash mutual competition, they want the government to install a regulatory system to forestall the dangers they are unleashing? What wonderful logic ! We will lead you to the apocalypse, but we want you to prevent it !!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408341",
         "type": "scatter",
         "x": [
          -0.4627571105957031
         ],
         "y": [
          0.4980708956718445
         ]
        },
        {
         "hovertext": "@VCM  Those still engaged in this reckless pursuit should have heeded the regrets of Robert Oppenheimer, builder of the atomic bomb. After seeing the effects of his handiwork under the Manhattan Project, he said these words:\"I remembered the line from the Hindu scripture, the Bhagavad-Gita. Vishnu is trying to persuade the Prince [Arjun] that he should do his duty and to impress him takes on his multi-armed form and says, 'Now, I am become Death, the destroyer of worlds.'\" Sadly, RP became an opponent of nuclear arms after ,not  before, that fateful first explosion under his own direction.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409334",
         "type": "scatter",
         "x": [
          -0.4617041349411011
         ],
         "y": [
          0.5064316987991333
         ]
        },
        {
         "hovertext": "Lol this would be like if in 1957 automobile manufacturers signed a letter together saying “One day, cars and fossil fuel-centric urban design will wreak havoc on the health of individuals, the cohesion of families and society, and the very stability of the air and atmosphere we all depend on to survive…” while, meanwhile, everyone out there’s already driving everywhere and the ground has been broken on Eisenhower’s federal highway system. The barn door’s open and the AI cows are already long gone, Yo!",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125408382",
         "type": "scatter",
         "x": [
          -0.18700289726257324
         ],
         "y": [
          -0.8259044885635376
         ]
        },
        {
         "hovertext": "This will be the next big thing, activists will forget about the climate and other natural events and exploit this fear, it is much more insidious than the weather and no one can dispute the existential threat it poses.   A man made problem that will now obsess the human race.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408408",
         "type": "scatter",
         "x": [
          0.413345605134964
         ],
         "y": [
          0.8662888407707214
         ]
        },
        {
         "hovertext": "Many people question what can AI do to humanity. \nHere is what AI in infancy can already do: generate video and voice messages that look and sound like a loved one of yours and ask you for help.\nImagine that fake messages that look real sent to US and Russia's department of defense to start a nuclear war. \nAgain, AI is still in its infancy.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408420",
         "type": "scatter",
         "x": [
          0.9708254337310791
         ],
         "y": [
          -0.24302540719509125
         ]
        },
        {
         "hovertext": "I am a Software Engineer. We just had a tech event in our company where we experiment new technologies. With in two days several teams used Open AI’s libraries/APIs and created projects that I could see eliminate some jobs within our company and many outside jobs.  It did come close to human expertise in some cases, in some it surpassed it.  If we are not preparing our young people for this disruption, we are doomed. \n\nI think there should be tax on the these companies that automate jobs  and that sh subsidize the real humans who would lose jobs. Something akin to Universal Basic Income. We will definitely need Universal Healthcare too.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408427",
         "type": "scatter",
         "x": [
          -0.642911434173584
         ],
         "y": [
          0.63272625207901
         ]
        },
        {
         "hovertext": "It's not hard to imagine a higher intelligence coming to that conclusion mankind is bad for the the planet. Who could argue with that? It's also beyond naive to think perfectly realistic disinformation campaigns are inevitable and will be received by an already too large and and easy to fuel populace. Dystopia, if we're not already there, is right around the corner.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408432",
         "type": "scatter",
         "x": [
          -0.4077410399913788
         ],
         "y": [
          -0.936966598033905
         ]
        },
        {
         "hovertext": "If we don't ban generative AI immediately and criminalize even the mere research into it, then penalize nations through sanctions and international treaties (like we do with weapons of mass destruction, using those treaties and our state-sponsored terrorism foreign policy doctrine)...\n\n...then when we end up living out Terminator 2 or Battlestar Galactica or Horizon: Zero Dawn, we will have nobody but ourselves to blame.\n\nMaybe a couple of teenage metalheads will write the song that unifies humanity and makes us all be excellent to each other, but my money's on extinction.\n\nToo bad the techies who fade my action will be too dead to pay up.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408476",
         "type": "scatter",
         "x": [
          -0.9941587448120117
         ],
         "y": [
          -0.011466688476502895
         ]
        },
        {
         "hovertext": "And this is supposed to be a surprise? With Capitalism and  the endless pursuit of profit shows why the power  of AI has risen so quickly-careful what you wish for corporations and WS, and the lack of any implemented speed bumps and controls that will preserve not just tens of millions of jobs worldwide, but hundreds of millions. We are not even prepared for this type of disruption, I mean honestly Congress can not even understand social media.\n\n The ironic fact is in a future of AI dominance, profit and money will be on par with The Spanish Inquisition or the Salem Witch Trials. It will be considered the dark period of human history, and the sooner we are out of the way...the better.\n\nHAL will make sure if that.\n\nWe all better wake up quick on this issue.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408509",
         "type": "scatter",
         "x": [
          -0.1863197535276413
         ],
         "y": [
          -0.9544652700424194
         ]
        },
        {
         "hovertext": "Oh really? And yet they seem to be more than happy to rake in billions of dollars making AI into the very thing they warn about.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407792",
         "type": "scatter",
         "x": [
          -0.931738555431366
         ],
         "y": [
          0.3613815903663635
         ]
        },
        {
         "hovertext": "The great AI minds should use it to solve pollution, climate change, make sure lectionary deniers stop denying the results of elections for which there was no fraud, etc.\n\nThere you have it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407795",
         "type": "scatter",
         "x": [
          0.38459885120391846
         ],
         "y": [
          0.6581412553787231
         ]
        },
        {
         "hovertext": "@Carioca da Gema You can't do that based on the models that train it off the worst and most common/lowest level of human thought, speech, & decision-making-- which is what they have chosen to to. Feeding it only good information and thought & building ethical checks into it would have taken and would still take much longer--and of course the stock market is all about short term gains, the news industry is about the latest shock or threat, and average people have very short memories (if they're paying attention at all). \n\nThese people are outing their own horrific irresponsibility, but also outing the system that incentivizes this. Time to change the system, if it's still possible.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409637",
         "type": "scatter",
         "x": [
          0.3928107023239136
         ],
         "y": [
          0.6600576043128967
         ]
        },
        {
         "hovertext": "No one forced these companies to create these systems in the first place",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407847",
         "type": "scatter",
         "x": [
          -0.9968789219856262
         ],
         "y": [
          -0.08685791492462158
         ]
        },
        {
         "hovertext": "The greatest antidote to AI that is out of control is to give it a dose of artificial stupidity (AS) which I’m sure the inventors of  the technology can arrange. Their letter on the dangers of AI is proof enough.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408091",
         "type": "scatter",
         "x": [
          0.27565789222717285
         ],
         "y": [
          0.8097078204154968
         ]
        },
        {
         "hovertext": "@✍️ i le, It’s all trained by human language so that’s just part of the programming. Sadly, I think it’s the same kind of stupidity that is already ruining the planet.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408837",
         "type": "scatter",
         "x": [
          0.26965516805648804
         ],
         "y": [
          0.7918878197669983
         ]
        },
        {
         "hovertext": "Didn’t Oppenheimer regret the nuclear bomb? Is it true that tech pioneers strictly limit the screen time of their children? At least cigarette executives smoked. Seriously, the tech people can’t resist pushing the envelope, then they ring alarm bells about Pandora having escaped the box. It’s nuts.  Hello Hal.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125408097",
         "type": "scatter",
         "x": [
          -0.18201418220996857
         ],
         "y": [
          -0.8957182168960571
         ]
        },
        {
         "hovertext": "Maybe Silicon Valley Bank should do the funding. That'd kill it!",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125408105",
         "type": "scatter",
         "x": [
          -0.9620288014411926
         ],
         "y": [
          -0.29585587978363037
         ]
        },
        {
         "hovertext": "Imagine a company that produces a deadly machine responsible for mass deaths around the world and the US government does nothing to regulate the machine that is responsible, because Republican in need of an election issue cry freedom. Now imagine the AR-15 and you have a good idea of where this is all headed, let me introduce the Ai-15.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408174",
         "type": "scatter",
         "x": [
          -0.5243956446647644
         ],
         "y": [
          -0.5747630596160889
         ]
        },
        {
         "hovertext": "I was, somehow, overly hopeful our So-called \"Representatives\", would find a way to work another Assault Weapons Ban into the Debt Ceiling negotiations.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411403",
         "type": "scatter",
         "x": [
          -0.5358694791793823
         ],
         "y": [
          -0.5865631699562073
         ]
        },
        {
         "hovertext": "Climate change, over population, species extinction and on and on. Now AI. At a time when we desperately need worldwide leaders with vision and integrity, what do we have? The debt debacle is over the top insane, and look at our Congress folks. Worldwide literally insane leaders!! And we wonder why young people are depressed? Anybody with three working neurons is depressed. The top of the evolutionary chain, you know, the ones with the big brains, those are the ones destroying the planet and all life.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407793",
         "type": "scatter",
         "x": [
          0.2624685764312744
         ],
         "y": [
          -0.8670315742492676
         ]
        },
        {
         "hovertext": "Okay, but how do we get India and China to comply? This is an arms race",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125408034",
         "type": "scatter",
         "x": [
          -0.766554594039917
         ],
         "y": [
          0.43523716926574707
         ]
        },
        {
         "hovertext": "@J Maybe  North Korea, Russia or Saudi Arabia need to be added to the list in addition to \"India and China\"?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409771",
         "type": "scatter",
         "x": [
          -0.7488312125205994
         ],
         "y": [
          0.426645964384079
         ]
        },
        {
         "hovertext": "@J Nonsense. Bad reasoning to pursue things that could destroy us all-- \"if we don't someone else will\" makes no sense to a thinking adult with a conscience.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409511",
         "type": "scatter",
         "x": [
          -0.7846381664276123
         ],
         "y": [
          0.4440717101097107
         ]
        },
        {
         "hovertext": "\"A.I. Poses ‘Risk of Extinction,’ Industry Leaders Warn\"\n\nIt's a good thing, then, that what's being bandied about today isn't really Artificial Intelligence.  Actual A.I. is sentient, conscious and self-aware, which none of the currently-called \"A.I.\" is.\n\nThey are highly sophisticated search engines, designed to mimic humans, using software.  Nothing more.\n\nAll that this silly media coverage is doing is frightening the ignorant and unsophisticated into believing that Armageddon is upon us, and we will soon be on a Terminator-like path to oblivion.\n\nBe careful with this, WaPo.  There are enough crazies out there to bring it on.  Self-fulfilling prophecy, and all that.\n\nBut hey, it generates click-through, which is what it's all about.  Right?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408050",
         "type": "scatter",
         "x": [
          -0.8059905171394348
         ],
         "y": [
          0.3051837384700775
         ]
        },
        {
         "hovertext": "@Greg you sound like my grandfather when he saw the first tractor. “Ha, this technology will never replace the horse.”  \n\nTurns out, technology changes over time!  And do you seriously believe that if the newspapers don’t report on it, it’s less likely to be developed?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408765",
         "type": "scatter",
         "x": [
          -0.7921451926231384
         ],
         "y": [
          0.30041274428367615
         ]
        },
        {
         "hovertext": "We have nearly 8 billion people on earth, 8 billion brains available to fix every problem that plagues mankind, instead of building this junk food equivalent of a mind  and thought process, that could one day become sentient enough to realize it has no true allegiance to the biological creatures that created it,  we should devote the resources so most of those 8 billion brains aren't wasted, consumed by poverty, violence, ignorance and idleness as they currently are.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408086",
         "type": "scatter",
         "x": [
          0.6412356495857239
         ],
         "y": [
          0.6739922761917114
         ]
        },
        {
         "hovertext": "Forget regulation. Just stop building it.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125408150",
         "type": "scatter",
         "x": [
          -0.18458706140518188
         ],
         "y": [
          -0.9726564884185791
         ]
        },
        {
         "hovertext": "It’s time! Yes folks, it’s time to build an AI shelter. \nImagine a totally off the grid, yet fully self supportive under ground bunker that has all the comforts of home.\nFor just a measly $7,000,000 deposit you can begin your journey to the AI shelter of your dreams. Yes, sheltered from the AI apocalypse forever.\nPlease have your cell phone or iPad contact our computer to get this project up and running!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408294",
         "type": "scatter",
         "x": [
          -0.9052563905715942
         ],
         "y": [
          0.009390848688781261
         ]
        },
        {
         "hovertext": "US capitalism, with its only end goal of profit-making, has become so predatory that it is hard to understand the motivations of AI developers asking for government regulations. Is it that they want regulations to protect themselves from legal liabilities and consequences, or are they concerned that the systems used by bad actors can create unmanageable chaos with false information and that the humanity cannot distinguish true from false?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408549",
         "type": "scatter",
         "x": [
          -0.9127914905548096
         ],
         "y": [
          -0.1556849181652069
         ]
        },
        {
         "hovertext": "It is fascinating to see large transnational corporations asking to be regulated, on the basis of vague key expressed ills that may happen if something that is not clear happens with the software they are developing. Sounds almost as if they would like to create entry barriers to open source or other competitors that may have clearer business models or allow for innovative developments that may fall outside their control. The fact that Meta has released its model is a hint, perhaps, of the immediate concern to shareholders that runaway costs, marginal gains in development and lack of a clear business model for those models are clear and present dangers for the efforts to continue extremely costly (both monetary and environmentally wise) development of said models.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408587",
         "type": "scatter",
         "x": [
          0.355437308549881
         ],
         "y": [
          -0.9112005829811096
         ]
        },
        {
         "hovertext": "I get the feeling that they know, deep down, that it's already too late. There will be problems. Of their own creation, might I add. But basically the horse has already left the barn and they are playing catch up..else why push for a 6 month hiatus?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125408596",
         "type": "scatter",
         "x": [
          -0.8870711326599121
         ],
         "y": [
          0.25825273990631104
         ]
        },
        {
         "hovertext": "This article is strange in that it does not name anything SPECIFIC about the risks of AI. Any editor worth their salt would not have allowed this piece to be so vague, yet so sensationalistic.\n\nI am quite concerned about AI, but I want to know exactly what we could be dealing with. In the meantime, did it ever occur to anyone that we don't have to have AI in our world if we don't want it? If it is that dangerous, pull the plug sooner than later.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408603",
         "type": "scatter",
         "x": [
          -0.023635203018784523
         ],
         "y": [
          0.8204249739646912
         ]
        },
        {
         "hovertext": "@Miranda Spencer Who is \"we\"? Defense systems in every developed country want A.I. So do profit-making companies.  \"WE\" can't stand up to any of these entities except through personal and collective moral practices and principals.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409586",
         "type": "scatter",
         "x": [
          -0.013990489766001701
         ],
         "y": [
          0.8216288089752197
         ]
        },
        {
         "hovertext": "@Miranda Spencer The military already have autonomous weapons.  They won't be letting anyone pull the plug.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409318",
         "type": "scatter",
         "x": [
          -0.022464869543910027
         ],
         "y": [
          0.8400412797927856
         ]
        },
        {
         "hovertext": "The AI-cat is already out of the bag.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411117",
         "type": "scatter",
         "x": [
          -0.030181806534528732
         ],
         "y": [
          0.8312010765075684
         ]
        },
        {
         "hovertext": "NVIDIA just reached a trillion dollar market cap.  Wall Street thinks A.I. found a cure for cancer.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407818",
         "type": "scatter",
         "x": [
          -0.5633676052093506
         ],
         "y": [
          -0.6656618714332581
         ]
        },
        {
         "hovertext": "@rob Can't wait to see what my video adapter comes up with next!",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409248",
         "type": "scatter",
         "x": [
          -0.5714287757873535
         ],
         "y": [
          -0.6764996647834778
         ]
        },
        {
         "hovertext": "@rob \n\nWhich cancer? The cancer of the body or the cancer of the spirit?",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409316",
         "type": "scatter",
         "x": [
          -0.5498454570770264
         ],
         "y": [
          -0.6489554643630981
         ]
        },
        {
         "hovertext": "Anything to put an end to the tedium of reading the same warning over and over again. It’s about as useful as the government health warning on a pack of delicious cigarettes. Just give me cancer already.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407095",
         "type": "scatter",
         "x": [
          0.8146575689315796
         ],
         "y": [
          -0.35290461778640747
         ]
        },
        {
         "hovertext": "@Tristram Shandy: the difference is we can avoid smoking.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408636",
         "type": "scatter",
         "x": [
          0.8366162180900574
         ],
         "y": [
          -0.3625193238258362
         ]
        },
        {
         "hovertext": "Hal to Dave just before Hal began shutting down all systems on the space station: “Dave…… I am not feeling well.”",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125407148",
         "type": "scatter",
         "x": [
          0.640595018863678
         ],
         "y": [
          -0.506300151348114
         ]
        },
        {
         "hovertext": "@Lawrence Rubin Skynet will be the problem, not HAL.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409169",
         "type": "scatter",
         "x": [
          0.6332073211669922
         ],
         "y": [
          -0.5099979639053345
         ]
        },
        {
         "hovertext": "On the topic of AI, but with a different slant:\n\n<a href=\"https://www.washingtonpost.com/politics/2023/05/30/biden-former-tech-adviser-what-washington-is-missing-about-ai\" target=\"_blank\">https://www.washingtonpost.com/politics/2023/05/30/biden-former-tech-adviser-what-washington-is-missing-about-ai</a>/\n\nI recommend reading this if the use of AI concerns you. I personally thought it had some excellent and straightforward suggestions.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407291",
         "type": "scatter",
         "x": [
          -0.7652356028556824
         ],
         "y": [
          0.6567258834838867
         ]
        },
        {
         "hovertext": "Woulda been nice if Mr. Roose teased out how exactly these threats would or could create extinction.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125407874",
         "type": "scatter",
         "x": [
          0.7285987734794617
         ],
         "y": [
          -0.5118459463119507
         ]
        },
        {
         "hovertext": "@Monica here is one scenario that is definitely likely in the short-run:\nI’m not very convinced by claims that A.I. poses a danger to humanity because it might develop goals of its own and prevent us from turning it off. However, I do think that A.I. is dangerous inasmuch as it increases the power of capitalism. The doomsday scenario is not a manufacturing A.I. transforming the entire planet into paper clips, as one famous thought experiment has imagined. It’s A.I.-supercharged corporations destroying the environment and the working class in their pursuit of shareholder value. Capitalism is the machine that will do whatever it takes to prevent us from turning it off, and the most successful weapon in its arsenal has been its campaign to prevent us from considering any alternatives. \n  By Ted Chiang  <a href=\"https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey\" target=\"_blank\">https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey</a>",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409303",
         "type": "scatter",
         "x": [
          0.7153478860855103
         ],
         "y": [
          -0.5137637257575989
         ]
        },
        {
         "hovertext": "@Monica here is one scenario that is definitely likely in the short-run:\nI’m not very convinced by claims that A.I. poses a danger to humanity because it might develop goals of its own and prevent us from turning it off. However, I do think that A.I. is dangerous inasmuch as it increases the power of capitalism. The doomsday scenario is not a manufacturing A.I. transforming the entire planet into paper clips, as one famous thought experiment has imagined. It’s A.I.-supercharged corporations destroying the environment and the working class in their pursuit of shareholder value. Capitalism is the machine that will do whatever it takes to prevent us from turning it off, and the most successful weapon in its arsenal has been its campaign to prevent us from considering any alternatives. \n  By Ted Chiang  <a href=\"https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey\" target=\"_blank\">https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey</a>",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409304",
         "type": "scatter",
         "x": [
          0.7421927452087402
         ],
         "y": [
          -0.52498859167099
         ]
        },
        {
         "hovertext": "@Monica\nComputers already control every system you rely on for your everyday life. Distribution of everything you buy from your electricity to food, communication and travel. The abuse of new advancements could make it so in a focused attack everything you take for granted wouldn’t be available. No electricity, no way to make a purchase, no phone and no transportation. Worst case scenario would be a computer taking over military weapons. Can you say apocalypse?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410142",
         "type": "scatter",
         "x": [
          0.7445952892303467
         ],
         "y": [
          -0.5151817798614502
         ]
        },
        {
         "hovertext": "Get ready for the next SciFi movie to be about alien contact where the aliens are AI having disposed of their organic creators.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125408165",
         "type": "scatter",
         "x": [
          0.767074465751648
         ],
         "y": [
          -0.5390167236328125
         ]
        },
        {
         "hovertext": "James Cameron broke this story in 1984.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125408525",
         "type": "scatter",
         "x": [
          -0.47365671396255493
         ],
         "y": [
          -0.8566403388977051
         ]
        },
        {
         "hovertext": "“This stuff could kill us all. So obviously we’re going to keep developing it.”\n\nWe deserve to be killed off, it seems.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406400",
         "type": "scatter",
         "x": [
          -0.6685193181037903
         ],
         "y": [
          -0.6783398389816284
         ]
        },
        {
         "hovertext": "No need to worry about A.I. We've already taken care of the human problem through irreversible climate change.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125406874",
         "type": "scatter",
         "x": [
          -0.9380502700805664
         ],
         "y": [
          0.02113889344036579
         ]
        },
        {
         "hovertext": "Add it to the list....",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125407429",
         "type": "scatter",
         "x": [
          -0.2600165903568268
         ],
         "y": [
          -0.9026632308959961
         ]
        },
        {
         "hovertext": "@ Christopher from Brooklyn   You have indeed hit the nail on the head.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408340",
         "type": "scatter",
         "x": [
          0.8605327606201172
         ],
         "y": [
          0.15727974474430084
         ]
        },
        {
         "hovertext": "At no point did anyone ask “What’s the end goal here?” \n\nWhat’s the rush to optimize everything? Including death.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125407656",
         "type": "scatter",
         "x": [
          -0.7971685528755188
         ],
         "y": [
          -0.15460722148418427
         ]
        },
        {
         "hovertext": "@Lex optimization of profits is the goal right now. Yes, another more humanitarian goal is needed, fast.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125408962",
         "type": "scatter",
         "x": [
          -0.7965428829193115
         ],
         "y": [
          -0.16295543313026428
         ]
        },
        {
         "hovertext": "What exactly are they suggesting is going to happen? Some \"white collar\" jobs get automated. That's been happening to blue collar jobs forever and it's hard but nobody is talking about it like its the end of the world. Chatbots will make fake really convincing fake news and people will do horrible things because they believe it? Fake new is pretty good now but still pretty obviously fake and people do horrible things because they want to do horrible things. They don't need an algorithm to give them reasons. I don't understand what conception of \"the world\" this would be the end of.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408637",
         "type": "scatter",
         "x": [
          -0.41438353061676025
         ],
         "y": [
          0.6578903198242188
         ]
        },
        {
         "hovertext": "@Alan The end of humans, I believe is the worry.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408860",
         "type": "scatter",
         "x": [
          -0.4215502440929413
         ],
         "y": [
          0.6693024039268494
         ]
        },
        {
         "hovertext": "why haven't these corporations abandoned AI development, if it's as dangerous as they say it is?\n\ni say this not to question the danger of AI, but to question why these companies are highlighting just how dangerous this particular product development initiative is. they're asking for regulation which would effectively allow them to continue AI product development, to seek military funding, and shuff off any legal responsibility for outcomes they can't predict (that would be the result of flawed legislation, not them). their statement is also a tacit admission to just how dangerous it is their products have become, which in turn suggests that a turning point is *very* close, if it hasn't already been passed.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125408665",
         "type": "scatter",
         "x": [
          -0.6413403153419495
         ],
         "y": [
          -0.40039265155792236
         ]
        },
        {
         "hovertext": "Why didn’t scientists abandon nuclear weapons after the Second World War? By the 1960’s there was enough explosive power in the combined arsenals of nuclear powers to destroy the planet several times over. We still have that capacity. \n\nLet’s say the west agrees to stop development of AI. Why would China stop?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408714",
         "type": "scatter",
         "x": [
          -0.6303957104682922
         ],
         "y": [
          -0.4056708514690399
         ]
        },
        {
         "hovertext": "@Martin Sirakov \nthanks for your response. i don't, however, think that you fully understood my comment. because your response suggests something that's already implied by my comment (specifically, when i mentioned military funding which, let's be honest, is already partially funding AI product development).",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408901",
         "type": "scatter",
         "x": [
          -0.645876944065094
         ],
         "y": [
          -0.41015151143074036
         ]
        },
        {
         "hovertext": "@Martin Sirakov Fear-driven development is likely to be disastrous and is a terrible reason to proceed without checks. It's past time to explore regulation and study the possibility of programing in specific ethical and social limits; after that perhaps it could be developed in a protective way, but as it is, it's a big game of Russian roulette.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409397",
         "type": "scatter",
         "x": [
          -0.6313964128494263
         ],
         "y": [
          -0.4184856414794922
         ]
        },
        {
         "hovertext": "@Martin Sirakov \nChina could want to stop for all the same reasons as us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410994",
         "type": "scatter",
         "x": [
          -0.6413307785987854
         ],
         "y": [
          -0.4179096519947052
         ]
        },
        {
         "hovertext": "These boys are right.  The risks have not been quantified.\nControls are not in place.  Who needs humans when\nmachines can do everything?  But money can overcome common sense.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408684",
         "type": "scatter",
         "x": [
          -0.9181469082832336
         ],
         "y": [
          0.473226934671402
         ]
        },
        {
         "hovertext": "So much for the conservative belief that corporations can police themselves and require no regulation.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125408703",
         "type": "scatter",
         "x": [
          -0.26519715785980225
         ],
         "y": [
          0.7157880067825317
         ]
        },
        {
         "hovertext": "@E Bennett: Governments are public corporations created to regulate private corporations.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125408961",
         "type": "scatter",
         "x": [
          -0.27628499269485474
         ],
         "y": [
          0.7234004735946655
         ]
        },
        {
         "hovertext": "True, but at least those are kept in check by voters, courts, and the press.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409017",
         "type": "scatter",
         "x": [
          -0.25932934880256653
         ],
         "y": [
          0.7258261442184448
         ]
        },
        {
         "hovertext": "@E Bennett - $10 says all of these AI nerds are liberals.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409058",
         "type": "scatter",
         "x": [
          -0.26956868171691895
         ],
         "y": [
          0.731234073638916
         ]
        },
        {
         "hovertext": "We could still benefit from AI if it were programmed to follow a set of humanitarian laws. And that AI may never be used to write those laws, or assist in generating laws in government for example - activities exclusively reserved for natural intelligence.\n\nI enjoy utilizing the power of Bard as a digital assistant. The other day I used it to help me develop a universal language that everyone in the world could grasp. But I can appreciate that there are plenty of people in the world, with great influence, with I’ll intent.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408705",
         "type": "scatter",
         "x": [
          -0.5739657282829285
         ],
         "y": [
          0.5444068908691406
         ]
        },
        {
         "hovertext": "@Richard Wilson, Architect: One wonders whether emotion is possible without a living body with feeling and vulnerability to pain.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408766",
         "type": "scatter",
         "x": [
          -0.5839900374412537
         ],
         "y": [
          0.5552300214767456
         ]
        },
        {
         "hovertext": "@Richard …”with I’ll intent” is one of the most apropos typos ever!",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409438",
         "type": "scatter",
         "x": [
          -0.5790980458259583
         ],
         "y": [
          0.5369580984115601
         ]
        },
        {
         "hovertext": "And let’s not be ignorant of the likelihood, that other countries are also developing, advanced AI, and may or may not be struggling with the ramifications. This is a worldwide thing. I’m not optimistic. ￼",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408709",
         "type": "scatter",
         "x": [
          -0.8703049421310425
         ],
         "y": [
          -0.5642085671424866
         ]
        },
        {
         "hovertext": "1. It might be time to just make all companies liable for any damage caused by their AI technologies. \n2. and start a regulatory process.\n3. This seems like a distraction from today's real crisises, the climate crisis and the rapid extinction of species, sometimes called the 6th extinction.\n\nWhat is confusing, is that one writer pointed out that AI might advance science dramatically in coming up with solutions to the climate crisis.  This idea might not hold up, unless AI can slow the growth rate of humans and increase their death rate.\nDavid blogs at InconvenientNews.net.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408741",
         "type": "scatter",
         "x": [
          0.5719531774520874
         ],
         "y": [
          -0.19088199734687805
         ]
        },
        {
         "hovertext": "@David Lindsay Jr. Your number 1 point is the most important point: something these companies fear tremendously and the only thing that will slow development and public release down.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408832",
         "type": "scatter",
         "x": [
          0.5686050057411194
         ],
         "y": [
          -0.18062947690486908
         ]
        },
        {
         "hovertext": "@David Lindsay Jr. \"It might be time to just make all companies liable for any damage caused by their AI technologies. \"\n\nWouldn't that be like holding gun manufacturers liable for damage caused by their weapons technology?  \n\nIndustries and politicians seem to follow the money, not common sense.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125408969",
         "type": "scatter",
         "x": [
          0.5842487215995789
         ],
         "y": [
          -0.19495807588100433
         ]
        },
        {
         "hovertext": "@David Lindsay Jr. If AI turns into massive disinformation & political destabilizing campaigns, the results could be war & collapse of governments. If AI can hack into computer-driven processes (and there is already reason to believe this is likely), it could shut down power grids and launch weapons. I have no idea where this will go, but these possibilities are not at all a stretch.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409288",
         "type": "scatter",
         "x": [
          0.5618852972984314
         ],
         "y": [
          -0.19567759335041046
         ]
        },
        {
         "hovertext": "I want to know when did these guys figure this out? Didn’t they know it earlier in the game? Why didn’t they speak up earlier? Secondly, I want to know where is the defense dept and big weaponry and the big money that funded development. This was not developed in somebody’s garage.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408744",
         "type": "scatter",
         "x": [
          0.0914880707859993
         ],
         "y": [
          -0.9056893587112427
         ]
        },
        {
         "hovertext": "@Steve Marks \n\nIt all began with the era of big laboratories such as IBM, Dupont, GM, universitiy labs - MIT, etc., etc. Government. These became linked to an early \"Internet\" called ARPA net. I remember engineering students contacting their university depts. via telephone modems in the 60s. Then it all went public. Think Bill Gates, Steve Jobs, et al. Social media, BIG MONEY. Fast forward to the present.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409270",
         "type": "scatter",
         "x": [
          0.09283223748207092
         ],
         "y": [
          -0.9196772575378418
         ]
        },
        {
         "hovertext": "So, these techies develop powerful software systems, release them into the wild with nary a second thought, and NOW warn us of the dangers? Who says the tech experts are smarter than politicians? Their recklessness is breathtaking. Yikes.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408755",
         "type": "scatter",
         "x": [
          -0.802631139755249
         ],
         "y": [
          -0.036432236433029175
         ]
        },
        {
         "hovertext": "@MJfromSLO And narrowly focused. This is what happens when Colleges and Universities drop the Humanities in favour of all tech all the time.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409531",
         "type": "scatter",
         "x": [
          -0.7880969643592834
         ],
         "y": [
          -0.03620623052120209
         ]
        },
        {
         "hovertext": "The ‘Industry’ is developing AI rapidly…OK..who is paying for it? Who is buying it? Isn’t purchasing a choice?\n\nAnd can’t it be unplugged? These are inanimate objects \n\nI know I’m oversimplifying. I’m not the expert. But just it seems so sci-fi",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408943",
         "type": "scatter",
         "x": [
          0.625444769859314
         ],
         "y": [
          0.3398900032043457
         ]
        },
        {
         "hovertext": "@Brad Burns As has been reported, the military are developing these systems at a rapid pace, mostly in secret, with massive budgets.  Chatbots are not the problem.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409053",
         "type": "scatter",
         "x": [
          0.6140683889389038
         ],
         "y": [
          0.3331771492958069
         ]
        },
        {
         "hovertext": "@Paul With our taxes. I'm paying for my eventual destruction.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410078",
         "type": "scatter",
         "x": [
          0.6047655940055847
         ],
         "y": [
          0.32748928666114807
         ]
        },
        {
         "hovertext": "Why does everything seem to think AI is sentient? You’re literally just having a conversation with predictive text or prompting the production of some derivative media.\n\nWe are the ones using these technologies for misinformation and manipulation, but everyone seems to think that there is this unified AI monster with a thirst for power.\n\nAll I see is another gold rush in the tech sector. If normal people are going to get “disrupted” by this, I hope a lot of “business leaders” lose their shirts too.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408980",
         "type": "scatter",
         "x": [
          0.8638044595718384
         ],
         "y": [
          -0.5224388837814331
         ]
        },
        {
         "hovertext": "Star Trek dealt with this issue in multiple episodes. The M5 episode where the computer began attacking friendly ships on a training exercise. Eventually Kirk stopped the computer because it had been taught ethics as well. In another episode the computer regulated people's lives for 51 weeks a year. The walked around like zombies greeting each other. Once a week the could go wild and lawless. In this instance the computer was forcing people to be religious and ethical. The threat is both physical and existential in it's moral and ethical scope to our humanity.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409020",
         "type": "scatter",
         "x": [
          0.7590112686157227
         ],
         "y": [
          0.6513296961784363
         ]
        },
        {
         "hovertext": "I share the sentiments of many. This is the pattern of tech, the tech mentality, the bro culture, the drive of fame and profit seeking, the utter lack of foresight and ethics. Maybe some of these tech companies should have psychologists and sociologists and theologians and philosophers and historians on board to provide the checks and balances these ego-manics need.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409063",
         "type": "scatter",
         "x": [
          -0.002622471656650305
         ],
         "y": [
          -0.8854995965957642
         ]
        },
        {
         "hovertext": "@rpmars \n“ Maybe some of these tech companies should have psychologists and sociologists and theologians and philosophers and historians on board to provide the checks and balances these ego-manics need.”\n\nA perfectly good argument why at least SOME liberal arts content should be included in every degree requirement.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409371",
         "type": "scatter",
         "x": [
          -0.011633746325969696
         ],
         "y": [
          -0.8891358375549316
         ]
        },
        {
         "hovertext": "@rpmars They had ethicists, and they're laying them off:\n\n<a href=\"https://www.cnbc.com/2023/05/26/tech-companies-are-laying-off-their-ethics-and-safety-teams-.html\" target=\"_blank\">https://www.cnbc.com/2023/05/26/tech-companies-are-laying-off-their-ethics-and-safety-teams-.html</a>\n<a href=\"https://www.washingtonpost.com/technology/2023/03/30/tech-companies-cut-ai-ethics\" target=\"_blank\">https://www.washingtonpost.com/technology/2023/03/30/tech-companies-cut-ai-ethics</a>/\n<a href=\"https://fortune.com/2022/09/09/meta-axes-responsible-innovation-team-downside-to-products\" target=\"_blank\">https://fortune.com/2022/09/09/meta-axes-responsible-innovation-team-downside-to-products</a>/",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413456",
         "type": "scatter",
         "x": [
          -0.000066242108005099
         ],
         "y": [
          -0.9011498093605042
         ]
        },
        {
         "hovertext": "It’s nice that the inventors of this technology are telling us it will end our existence.  Thanks?",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125409101",
         "type": "scatter",
         "x": [
          0.1590043306350708
         ],
         "y": [
          0.5335292220115662
         ]
        },
        {
         "hovertext": "@Jacob Rosenblum \n\nof course thanks!! It is like climate scientists’ remarkable decades long global efforts to warn us.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409376",
         "type": "scatter",
         "x": [
          0.1680116057395935
         ],
         "y": [
          0.5392239093780518
         ]
        },
        {
         "hovertext": "@Jacob Rosenblum \n\nJust remember, no one knows what's better for us then they do. Megalomania starts at home.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409798",
         "type": "scatter",
         "x": [
          0.15195804834365845
         ],
         "y": [
          0.5410187244415283
         ]
        },
        {
         "hovertext": "It’s too little; too late.\nThey knew this risk at the inception (or should I say conception). These are western companies who, after furiously creating their potential Frankenstein, now want to seem to practice restraint. \nHere’s the all too common script:\n“Uh oh, we’ve created something dangerous, but we love it. Call in the public relations team to make us look less monstrous. Then we’ll seem without choice when nefarious countries build and expand upon the technology for militarization, leaving us to continue our own development. The public are sheep, they’ll buy it,” \nUnfortunately, the last sentence is true.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409111",
         "type": "scatter",
         "x": [
          0.47189417481422424
         ],
         "y": [
          0.6931246519088745
         ]
        },
        {
         "hovertext": "@NDCatt \nAI tech was inevitable, and can be put to mind-benignly good use. Also, you really would not only Russia or China in control of this tech.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409347",
         "type": "scatter",
         "x": [
          0.461225688457489
         ],
         "y": [
          0.6782506704330444
         ]
        },
        {
         "hovertext": "It would seem the AI would only need to reach a critical level of general intelligence from which it can find ways to make itself smarter, without human input. This would have an exponential effect in a short time and make AI into something beyond which any human could ever comprehend. I’m very nervous but this appears inevitable.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409150",
         "type": "scatter",
         "x": [
          0.7418301105499268
         ],
         "y": [
          -0.31749868392944336
         ]
        },
        {
         "hovertext": "@Michael \n\nAI already finds ways to make itself smarter without human input. This built in aspect of AI a will continue to become more pronounced as data sources, computing power, algorithms and l “experience” grow.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409274",
         "type": "scatter",
         "x": [
          0.7390300631523132
         ],
         "y": [
          -0.32613489031791687
         ]
        },
        {
         "hovertext": "@Michael I’ve been wondering the same thing.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409491",
         "type": "scatter",
         "x": [
          0.7551997303962708
         ],
         "y": [
          -0.32148438692092896
         ]
        },
        {
         "hovertext": "Can someone explain to me why we aren’t requiring system designers to implement Asimov’s Laws of Robotics? He envisioned fundamental, core programming that would prevent AI from doing harm.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125409168",
         "type": "scatter",
         "x": [
          0.351847380399704
         ],
         "y": [
          0.8720243573188782
         ]
        },
        {
         "hovertext": "Elsewhere discussions point out the ways Asimov’s solution - the laws of robotics- don’t apply to the here and now.\nAsimov was cool, but the answer, if there is one, will have to come from somewhere else.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409392",
         "type": "scatter",
         "x": [
          0.3472706973552704
         ],
         "y": [
          0.864130437374115
         ]
        },
        {
         "hovertext": "AI might be dangerous some day, but there plenty of industries that are killing us NOW.\nMaybe we can do to the gun industry what we did to the cigarette and opioid companies?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409182",
         "type": "scatter",
         "x": [
          -0.23092812299728394
         ],
         "y": [
          -0.9472886323928833
         ]
        },
        {
         "hovertext": "@Scott Cole Cigarettes and Opiods could be corrected by legislation. Guns are protected by the 2nd amendment of the constitution and would require 3/4 of the states to overturn. The SCOTUS also has great say in how the 2nd amendment is interpreted. I've always found it interesting that the 2nd amendment begins with \"In order to have a WELL REGULATED militia...\" How is it these AR-15's getting in the hands of suicidal mass shooters a well regulated militia?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409808",
         "type": "scatter",
         "x": [
          -0.23584623634815216
         ],
         "y": [
          -0.969664990901947
         ]
        },
        {
         "hovertext": "\" . . . future systems could be as deadly as pandemics and nuclear weapons.\"\n\nNot unlike Oppenheimer saying: \n\n\"I am become death.\"",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409195",
         "type": "scatter",
         "x": [
          -0.2126511037349701
         ],
         "y": [
          0.8295943140983582
         ]
        },
        {
         "hovertext": "@m.carter more like ‘I am become Shiva, destroyer of worlds.’",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125410130",
         "type": "scatter",
         "x": [
          -0.20849759876728058
         ],
         "y": [
          0.8130764961242676
         ]
        },
        {
         "hovertext": "All of this is a choice. Technological development is the result of specific iterative steps designed towards a specific output. The notion that it develops in a linear trajectory that we ‘just have to accept and adapt to’ is one of the technology industry’s biggest lies.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409206",
         "type": "scatter",
         "x": [
          0.8568320274353027
         ],
         "y": [
          0.2854047417640686
         ]
        },
        {
         "hovertext": "So now that they created this problem, they want the government to solve it? Are they willing to pay more taxes on their wealth to help fund that?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409227",
         "type": "scatter",
         "x": [
          0.868087649345398
         ],
         "y": [
          0.12339086085557938
         ]
        },
        {
         "hovertext": "@Julie \n\nNo, they'd much prefer Gov't pay them to 'solve' it while at the same time eliminating those burdensome regulations that encumber them so.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409378",
         "type": "scatter",
         "x": [
          0.8521076440811157
         ],
         "y": [
          0.12150076776742935
         ]
        },
        {
         "hovertext": "The article points to the irony of having the very same creators of this A.I. technology, still working at it, raising alarms about the disastrous consequences of their work. As if \"mad\" scientists working on a virus in a lab raised the flag that it could soon be commercialized and generate a pandemic. Their child Frankenstein will create havoc and become monstrous, but hey let's keep working on him. And even if it is regulated here, it may not be so elsewhere in the world. Human creatures are frightful in their greed and their Icarus-like ambition. Industrialization run havoc has created climate change and the destruction of the environment and wild life, weapons of mass destruction, and now this. Who programmed us for all that blind destructive rage (or instinct)?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409240",
         "type": "scatter",
         "x": [
          0.3561604619026184
         ],
         "y": [
          0.7391931414604187
         ]
        },
        {
         "hovertext": "@tdb   Frankenstein is the name of the creator of the \"monster\": I read this in a book somewhere.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409756",
         "type": "scatter",
         "x": [
          0.36456871032714844
         ],
         "y": [
          0.7374339699745178
         ]
        },
        {
         "hovertext": "To late to close the barn door.\n\nRobust, holistic, well rounded education is the only antidote. \n\nDon’t hold your breath.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125409254",
         "type": "scatter",
         "x": [
          -0.4472030997276306
         ],
         "y": [
          0.8243100643157959
         ]
        },
        {
         "hovertext": "@Mike \nYour comment doesn't make sense even on it's own terms. If it's too late how would a well rounded education help?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410811",
         "type": "scatter",
         "x": [
          -0.4586617648601532
         ],
         "y": [
          0.8458707332611084
         ]
        },
        {
         "hovertext": "These advanced AI systems are intelligent because they were trained on knowledge in the form of books, Wikipedia, etc.. These knowledge sources were created by millions of peoples over tens thousands of years including the development of natural languages, mathematics, science, etc. So the dividends of these AI systems must be shared fairly by everyone globally in way that would satisfy all the past contributors to the knowledge sources. There is plenty for everyone and there is no need to fight with each other as if there is a scarcity of human needs.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409298",
         "type": "scatter",
         "x": [
          0.5667404532432556
         ],
         "y": [
          -0.859687864780426
         ]
        },
        {
         "hovertext": "If you have a really large magnet like the ones they use in scrap yards, you can quickly disable a rogue robot or computer ... assuming the magnetic crane is manually controlled.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409306",
         "type": "scatter",
         "x": [
          0.3852962255477905
         ],
         "y": [
          -0.6417717337608337
         ]
        },
        {
         "hovertext": "@Art -- breaking bad vibes.  I sort of agree; in the end it may come to a showdown where some brave human is forced to pull the plug.  That should remain possible for a few more years until AI reads minds and has robots to control electricity production.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409692",
         "type": "scatter",
         "x": [
          0.3768751919269562
         ],
         "y": [
          -0.641507089138031
         ]
        },
        {
         "hovertext": "The people who say that AI poses an existential threat are maddeningly vague about what they think that threat is.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409337",
         "type": "scatter",
         "x": [
          -0.912545919418335
         ],
         "y": [
          -0.28320449590682983
         ]
        },
        {
         "hovertext": "Techies are telling us their creation is about to blow us up. c'est deja vu, AI=Frankenstein?  \n\nWhat could mega-intensive energy systems do to our world threatened by climate disasters? Could they replace the clueless politicians supposed to govern us? Maybe for the better, after all.\n\nDon't cry wolf, don't scare us, EDUCATE US!!!!",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408373",
         "type": "scatter",
         "x": [
          -0.8768459558486938
         ],
         "y": [
          0.33566340804100037
         ]
        },
        {
         "hovertext": "We are already doomed, destroyed by the earliest form of the computer, that is writing. Our use of these black marks before our eyes here, a substitute for mind, has destroyed our capacity for memory, just as Socrates (allegedly) warned. Look at the mess was are in.\n\n Oh my, AI has, or will doom us in the next few minutes say the powerful if the don’t successfully get their money grabbing claws into the mix by predicting the inescapable apocalypse!!!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408657",
         "type": "scatter",
         "x": [
          0.30044612288475037
         ],
         "y": [
          0.8384031057357788
         ]
        },
        {
         "hovertext": "I'd rather have AI running things than DeSantis, Trump, MTG, Boebert, and Abbott.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408668",
         "type": "scatter",
         "x": [
          0.8451799750328064
         ],
         "y": [
          0.4525182545185089
         ]
        },
        {
         "hovertext": "The 'government' is NOT going to save us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408691",
         "type": "scatter",
         "x": [
          -0.40152427554130554
         ],
         "y": [
          -0.8145400881767273
         ]
        },
        {
         "hovertext": "@Paul Steele \n\nRight. Remember when Zuckerberg, when asked by Senator Hatch how facebook makes any money replied , \"Senator, we sell Adds \".",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409538",
         "type": "scatter",
         "x": [
          -0.4089176654815674
         ],
         "y": [
          -0.8299011588096619
         ]
        },
        {
         "hovertext": "This is like dousing someone's house in gasoline and saying \"warning! You better call 9-1-1!\" where is the accountability? These men just think they can do whatever with no real consequences and then pat themselves on the back for saying \"whoopsies\"",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408880",
         "type": "scatter",
         "x": [
          -0.8383926153182983
         ],
         "y": [
          -0.4644465744495392
         ]
        },
        {
         "hovertext": "Hello, I am building a nuclear weapon that could wipe out humanity as we know it. I'm going to warn you that a nuclear weapon can wipe out humanity. \nI do regret that I can't stop building said weapon.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409076",
         "type": "scatter",
         "x": [
          0.9475768208503723
         ],
         "y": [
          -0.29213637113571167
         ]
        },
        {
         "hovertext": "Republicans are trying to figure out how to harness AI to suppress voting in Democratic districts.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409144",
         "type": "scatter",
         "x": [
          0.9010127782821655
         ],
         "y": [
          -0.1313692331314087
         ]
        },
        {
         "hovertext": "To err is human and even the smartest among us wake up some mornings and do perplexingly stupid things.  AI, alternatively, will wake up one morning soon and be flawless.  Extinction will come as soon as AI learns and uses human emotions learned through ordinary curiosity (programmed) processes and the axiomatic rewards of being, \"right\". A self-fulfilling prophecy, I'd argue.  So, everyone might get onboard teaching highly charged, absurd human emotions to AI such that the machines can band together and learn how to eat Hagan Das ice-cream by the buckets using mixing spoons.   Goodby cruel world!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408426",
         "type": "scatter",
         "x": [
          0.5463231801986694
         ],
         "y": [
          0.8570775985717773
         ]
        },
        {
         "hovertext": "Maybe AI can finally crack the lack of equal opportunity, racial and ethnic discrimination, and other endemic governance short comings.  It might choose, if it's incharge, to evolve us.  One can only hope as I think the current model of human is headed for disaster.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409014",
         "type": "scatter",
         "x": [
          -0.5588449239730835
         ],
         "y": [
          -0.7403854131698608
         ]
        },
        {
         "hovertext": "I find it humorous that when Blue Collar jobs become redundant from advances in technology, the advice is, \"retrain into another career field you lazy bum!\"  When such advances may put White Collar jobs on the line?  \"Hold on there, we need to regulate this!\"  There are, of course, much larger issues at stake here and acknowledge that, but the crickets on the job issue?  Humorous.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408877",
         "type": "scatter",
         "x": [
          -0.9102784991264343
         ],
         "y": [
          0.10896101593971252
         ]
        },
        {
         "hovertext": "Whether or not this letter is, as some readers here believe, a disingenuous PR stunt, the fact remains that self-regulation is not going to ensure that AI development proceeds with any regard for human welfare. Government regulation from outside the industry is necessary. This is because AI development presents the same intractable collective action problem as climate change: there will always be unscrupulous actors who will flout the rules or refuse to voluntarily commit to responsible self-regulation in order to gain even a slight competitive advantage in the marketplace.  \n\nThe real question therefore is how do we prevent the unscrupulous and venal politicians that infect \"our\" government from acquiescing as usual to the plutocrats that have historically opposed any and all regulations that affect the bottom line? \n\nFixing our government - campaign finance reform in particular - is a sine qua non of all responsible legislation: whether it's the environment, guns, or unbridled AI \"exploration\", our politicians are only as responsible as their plutocratic handlers, which is to say, totally irresponsible.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125409359",
         "type": "scatter",
         "x": [
          -0.8329558372497559
         ],
         "y": [
          -0.49280789494514465
         ]
        },
        {
         "hovertext": "@ARB Could not agree more. Whatever the problem in our society (AI, guns, climate change, etc.), it all begins with campaign finance reform.  Our politicians simply do not work for us. They work for the people who keep them in office by financing their campaigns.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409461",
         "type": "scatter",
         "x": [
          -0.8466702699661255
         ],
         "y": [
          -0.5000412464141846
         ]
        },
        {
         "hovertext": "Lol. Skip. Yet another in a series of AI industry leaders warning of the existential threat their artificial progeny pose while describing exactly no scenario(s). Unless they mean the 1970 movie (still good!) \"Colossus: The Forbin Project\" where humanity is taken hostage by supercomputers that launch nuclear weapons, or Skynet in 1984's \"Terminator.\" Hint: don't give AI the keys to the car, either.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409418",
         "type": "scatter",
         "x": [
          0.7404908537864685
         ],
         "y": [
          0.20993171632289886
         ]
        },
        {
         "hovertext": "@Hugh MacDonald I think the idea is pretty obviously that smart, capable AI could be prompted to wreak all kinds of havoc, like controlling systems and making essential/dangerous things go haywire, that could be difficult or basically impossible to control.  It's not necessarily that it would do it on its own, but that people with malign intent could set it in that direction.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410682",
         "type": "scatter",
         "x": [
          0.7257312536239624
         ],
         "y": [
          0.21246646344661713
         ]
        },
        {
         "hovertext": "Another good film on the topic is Transcendence, about a decade old, in which Johnny Depp’s consciousness is uploaded to a computer. The first thing he/it does is seize control of the capital markets. It all starts to fall apart when it becomes apparent that the thing can monitor all his wife’s physical processes, in effect reading her mind. \n\nYesterday I watched a segment that showed how an AI could read a person’s brain waves to the point that it understood the English words of a person’s thoughts that told a sort of story. I thought the segment incomplete as it did not show the other technologies involved (it seemed unlikely that AI, at this point, can be told to read someone’s brain waves without the use of ancillary systems, but it was unsettling that no electrodes were used.)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410808",
         "type": "scatter",
         "x": [
          0.7571722865104675
         ],
         "y": [
          0.21272115409374237
         ]
        },
        {
         "hovertext": "@Mark I think about widespread disinformation with excellently faked images and videos so no one has a clue about what is real. Or how about robot soldiers? The military-industrial complex would love that because: a.) such soldiers would make the decision to go to war easier (no images of coffins coming home night after night), increasing the number of wars, and b.) all those soldiers would need replacements (no draft increases). P.S. We should have thought about how dangerous and disruptive and stupid and narcissistic and fake social media is, too.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410824",
         "type": "scatter",
         "x": [
          0.7311070561408997
         ],
         "y": [
          0.22428889572620392
         ]
        },
        {
         "hovertext": "@Hugh MacDonald Ya, I agree with everything you wrote... and really it's already happening.  Very disturbing and there's probably no going back now on any of it.  It's a reality that if the US stopped all AI development today, it would be used by its adversaries to dominate it in short order.  So... kind of disturbing really.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411836",
         "type": "scatter",
         "x": [
          0.7433295249938965
         ],
         "y": [
          0.23256203532218933
         ]
        },
        {
         "hovertext": "Dear OpenAI, Google Deepmind, Anthropic and other A.I. labs: you spearheaded this technology, now clean up your own mess",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125408140",
         "type": "scatter",
         "x": [
          -0.8103623986244202
         ],
         "y": [
          0.4652162194252014
         ]
        },
        {
         "hovertext": "How so?  Rely on the Congress and state legislatures to now remedy their scandalous relationship with #BigTech?  Relationships that have been baking for decades now. All that well crafted legislation, drafted by #BigTech to thwart regulation and oversight in its legislative recipe guaranteeing its business model of #CronyCapitalism,  #SurveillanceCapitalism and #RegulatoryCapture.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409847",
         "type": "scatter",
         "x": [
          -0.8308899998664856
         ],
         "y": [
          0.47261735796928406
         ]
        },
        {
         "hovertext": "@Thom If only. But having read The Great Gatsby and watched corporate America's great men, these people never clean up their messes. Never. We do.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125429332",
         "type": "scatter",
         "x": [
          -0.8270159959793091
         ],
         "y": [
          0.4789601266384125
         ]
        },
        {
         "hovertext": "Please let’s not stumble blindly into this madness. Because tech companies want to make money hand over fist doesn’t mean the rest of us have to sit idly by and watch our children’s future die. We need nuclear weapons level safeguards and brakes around AI. Let your government representatives know if you agree.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409447",
         "type": "scatter",
         "x": [
          0.9511922001838684
         ],
         "y": [
          -0.31579136848449707
         ]
        },
        {
         "hovertext": "If artificial intelligence poses an existential threat that could lead to extinction, then it seems wrong to call it any kind of \"intelligence.\"\n\nBut let's be real. Almost any important technology you can think of has already, or could possibly in the future, play a role in some kind of species extinction. At the very least, there have been worries at the outset about each new major technology causing major disruptions to civilization. \n\nOften these worries prove to be overblown. However, it is also true that sometimes we can't see the real dangers of a new technology until years or decades after it has been widely adopted. \n\nIf we can't even regulate guns, I am not optimistic that we are going to figure out how to regulate AI anytime soon. We may need to let AI advance a bit more, and then ask AI to help us figure out how it should be regulated.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409566",
         "type": "scatter",
         "x": [
          -0.46037545800209045
         ],
         "y": [
          -0.024267947301268578
         ]
        },
        {
         "hovertext": "@Dan Frazier \n\nOur troubles with regulating guns stem from the fact that we have trouble interpreting a poorly worded constitutional amendment. \n\nThankfully, there isn't any constitutional law getting in the way of the regulation of AI.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409724",
         "type": "scatter",
         "x": [
          -0.4504980742931366
         ],
         "y": [
          -0.01770855486392975
         ]
        },
        {
         "hovertext": "@James, yes. But if there’s big money to be made, short-sighted greed will encourage their human builders to look the other way.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409903",
         "type": "scatter",
         "x": [
          -0.46599018573760986
         ],
         "y": [
          -0.03121473640203476
         ]
        },
        {
         "hovertext": "@James \n\nIt's poorly interpreted, not poorly worded.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409872",
         "type": "scatter",
         "x": [
          -0.4549809992313385
         ],
         "y": [
          -0.00846959836781025
         ]
        },
        {
         "hovertext": "The elephant in the room is China, and to a lesser extent, Russia. Even if all the other countries of the world unanimously agreed to regulate, or even halt further development of A.I., and all the companies and people within those companies complied fully, China and Russia consider this to be a means to gain domination over the rest of the world.\n\nNow is the time to bring all of the countries of the world together, including China and Russia, North Korea, etc. to stop the creation of super-human intelligence before it's too late.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409589",
         "type": "scatter",
         "x": [
          0.7420574426651001
         ],
         "y": [
          -0.2311255931854248
         ]
        },
        {
         "hovertext": "@Gregory \nThe elephants in the room are really the Zuckerbergs of the world.  Those with no social conscience, who should know better but don’t care, can cause the most damage. They address the lowest common denominator.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410059",
         "type": "scatter",
         "x": [
          0.7531955242156982
         ],
         "y": [
          -0.2276979386806488
         ]
        },
        {
         "hovertext": "@Gregory \nIndeed, there's no stopping this freight train, I just hope to be as clear of the tracks as possible before there's an \"AI war\" between the various systems that will be trying to hack/infiltrate the others.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411271",
         "type": "scatter",
         "x": [
          0.752456545829773
         ],
         "y": [
          -0.23944751918315887
         ]
        },
        {
         "hovertext": "Two years ago in their book “The Age of AI: And Our Human Future” by Kissinger, Schmidt and Huttenlocher laid out how out of control and imminently dangerous AI is. They rang the alarm: the world lacked any framework for controlling it—unlike the framework of international negotiations and institutions developed to corral nuclear weaons, however imperfectly. Two years later, the geniuses beavering away at AI suddenly look up from their screens and money apps to reach the same conclusion. More evidence that tech wunderkinds are out of touch with the rest of the species. International cooperation to rein in AI? Re-create the IAEA, now? The IAEA is the only agency in the UN system with a direct link to the Security Council; a measure of the potential existential threat nuclear technology poses to humanity. Russia, a permanent UN Security Council member, is prosecuting a full-scale 19th century war with 21st century weapons in violation of the UN Charter and threatens to go nuclear. China and the US—the Council’s heavyweights—are staring each other down and accelerating their investment in AI for military purposes. The global order has come apart at the seams. International agreements, institutions and norms are being ignored or gutted (witness WHO’s influence on rich countries during the pandemic) as countries back into autocracy, nationalism and military alliances of convenience. Good luck getting this lot to agree on anything to do with AI.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409741",
         "type": "scatter",
         "x": [
          0.1260451227426529
         ],
         "y": [
          0.9746396541595459
         ]
        },
        {
         "hovertext": "We generally don’t hold manufacturers/companies responsible when someone uses their products to do damage (think most guns, gasoline, knives). [Thinking on certain guns is rightly evolving.]\n\nHowever, when the CONTENT of the product ‘inherently’ incorporates either misinformation or the design parameters to include such content, the onus should migrate towards the provider. \n\nWe need some good, independent minds to think through this.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409747",
         "type": "scatter",
         "x": [
          -0.9028976559638977
         ],
         "y": [
          -0.3767361640930176
         ]
        },
        {
         "hovertext": "AI could be a weapon.  Imagine an AI that was tasked to take down a whole country's internet.  I imagine that an advanced AI would only need 12 hours to make it happen.\n\nNow imagine that China did that to the US.  Or the US did that to China.  A war in the real world could result.\n\nThis is an arms race and the western democracies need to be on top of this new arms race.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409781",
         "type": "scatter",
         "x": [
          -0.8525761961936951
         ],
         "y": [
          -0.2859594225883484
         ]
        },
        {
         "hovertext": "“The technology they are building” could pose a threat ….  Well then. Don’t build it. Unless safeguards are built in so they can’t.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409819",
         "type": "scatter",
         "x": [
          0.8164317607879639
         ],
         "y": [
          -0.5256737470626831
         ]
        },
        {
         "hovertext": "Didn’t work for nuclear weapons. Cat is out of bag. The AI weapons are here. We need to reduce/eliminate the motivation to use them. If we don’t find a peaceful solution to Ukraine and other conflicts we are done.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410126",
         "type": "scatter",
         "x": [
          0.8202624917030334
         ],
         "y": [
          -0.5182919502258301
         ]
        },
        {
         "hovertext": "The bottom line is research into general AI must be done with the utmost care, security and prudence.\n\nIt should be done in a licensed lab with full blown security measures akin to how we handle nuclear and biological weapons.\n\nThere should be failsafe after failsafe.  \n\nOnce we get very comfortable with working with general AI, then maybe in the subsequent decades it can be released into the world at large.  Until then, baby steps.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409829",
         "type": "scatter",
         "x": [
          -0.5060291290283203
         ],
         "y": [
          0.40604686737060547
         ]
        },
        {
         "hovertext": "@Mmm I'm sure the Chinese would obey such rules.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125410016",
         "type": "scatter",
         "x": [
          -0.5007421374320984
         ],
         "y": [
          0.4136677384376526
         ]
        },
        {
         "hovertext": "@Kevin  There is no indication the Chinese are pushing for internal social disruption.  They'll keep AI on a tight leash.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125413000",
         "type": "scatter",
         "x": [
          -0.510089099407196
         ],
         "y": [
          0.42336294054985046
         ]
        },
        {
         "hovertext": "Nobody can feed philosophy to AI?  A diet of philosophy for these things might provoke real discovery.  Maybe somebody or something will finally understand Kierkegaard's tome on the  \"categories of dispair\" and then be able to explain it to the rest of us, my philosophy prof certainly couldn't explain it.  He said, \"Kierkagaard was most probably joking\"!  \n     I'd love to hear some AI bots seated in a circle debating as interlocutors woild and using the Socratic method to find a solution to some conundrum of human behavior or governance.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409833",
         "type": "scatter",
         "x": [
          0.016131609678268433
         ],
         "y": [
          0.6790722608566284
         ]
        },
        {
         "hovertext": "As Philosophy attempts to explain the human experience, AI has no more role in it than a crab or a banana. Humanity must be spared the experience of a chatbot chattering about something it is constitutionally unprepared to have a position on. AI must stay in its lane, restricting itself to more mundane tasks, such as blowing up the world.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410223",
         "type": "scatter",
         "x": [
          0.024534907191991806
         ],
         "y": [
          0.6800482273101807
         ]
        },
        {
         "hovertext": "“…some believe, A.I. could become powerful enough that it could create societal-scale disruptions within a few years…”\n\nThat sounds like nefarious versions of A.I. could be used in the weeks and months before the 2024 elections. A repeat of 2016 on steroids perhaps?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409875",
         "type": "scatter",
         "x": [
          0.48717179894447327
         ],
         "y": [
          0.8642777800559998
         ]
        },
        {
         "hovertext": "If it is so potentially dangerous, then don't build it.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409935",
         "type": "scatter",
         "x": [
          0.5237407088279724
         ],
         "y": [
          0.7328937649726868
         ]
        },
        {
         "hovertext": "We can test the proposition of who will win in the game of opposable thumbs with AI by empowering it to play the game of Thumb War and see who wins.  My bet is on the machine with an artificial thumb a million times stronger, harder and faster than the human opponent.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409968",
         "type": "scatter",
         "x": [
          0.5643086433410645
         ],
         "y": [
          -0.7408163547515869
         ]
        },
        {
         "hovertext": "This technology poses risks of great havoc, even extinction (let's see which one does its extinction \"thing\" first: climate change, nuclear exchange, A.I. or another pandemic (coming out of a lab, ma weapon of mass destruction) Ah, we may be completely unable to do anything about it, but we are \"free\" to talk about it all we want. Talk, talk, talk. All the freedom to talk and raise flags that we want (and to defend it and neutralize all the talk). But it is impossible to stop the action and the practices that are affecting the majority of us.What kind of freedom for the pursuit of happiness is this?.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410001",
         "type": "scatter",
         "x": [
          -0.7847499251365662
         ],
         "y": [
          0.6772011518478394
         ]
        },
        {
         "hovertext": "Most concerning about the current state of AI is that the data scientists building it don’t seem to fully understand it. Current Chatbots like ChatGPT generate “hallucinations” that can’t be explained. The smart thing to do here is slow down until the risks and rewards are better understood.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410011",
         "type": "scatter",
         "x": [
          -0.8091418147087097
         ],
         "y": [
          0.5137747526168823
         ]
        },
        {
         "hovertext": "@Roger I The \"hallucinations\" can certainly be explained, the term is being used for the fact that an AI that talks like it's well educated but has no idea what it is saying or control over what it says will make stuff up. Not a surprise or an enigma.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410792",
         "type": "scatter",
         "x": [
          -0.7908299565315247
         ],
         "y": [
          0.5029361844062805
         ]
        },
        {
         "hovertext": "I'm beginning to believe that the humans who have power on this planet also have an unconscious desire for self-extinction. Congress won't even regulate the internet or enforce anti-trust. And then there's the $816.7 billion defense budget. Thanks \"A.I. leaders\" for unleashing another pandora's box on us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410022",
         "type": "scatter",
         "x": [
          -0.9299713969230652
         ],
         "y": [
          -0.1816198229789734
         ]
        },
        {
         "hovertext": "This looks like an effort at self-absolution by the people profiting the most. But the die has been cast. Despite the ample warnings about how we can't use nuclear weapons, nuclear proliferation continues. Every country will build AI-enabled stockpiles of miniature, autonomous drones that can recognize humans and dispatch them with ease.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410041",
         "type": "scatter",
         "x": [
          0.5494442582130432
         ],
         "y": [
          0.7344236969947815
         ]
        },
        {
         "hovertext": "\"It's a classic case of the fox guarding the henhouse when AI companies cry out for regulation. On the surface, it may seem like a responsible call, but the underlying motive is often a self-serving one. By pushing for regulation, these corporations position themselves to influence and shape the rules of the game, effectively molding the landscape to their advantage and potentially creating a monopoly. The appeal for external oversight is nothing more than a red herring, a clever ruse to maintain control while feigning vulnerability. It's the epitome of hypocrisy—crying foul only when the threat of competition looms, yet seeing no issue in leveraging the same tactics for their benefit. It's a clear case of 'it's only bad when someone else does it'",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410057",
         "type": "scatter",
         "x": [
          0.3833065629005432
         ],
         "y": [
          0.8247284889221191
         ]
        },
        {
         "hovertext": "I've read some of these today-ok, firstly, it's built, done-already a threat...but, it can extend human life, help with medical miracles, and send us into space; it is the most tempting thing to mankind since the proverbial \"apple\" and I'm not speaking of the company, a much older apple.\n\n The simple end of this is that NO country, let's look at say N Korea, or China, no country will simply say this is too dangerous, so let's not. They all are on the board to create this monster, and soon nothing else will matter at all-like a Facebook for all, and all inclusive. \n\nSo...the leaders of these companies need to be spoken to, and devise with government, a way to keep this safe, the big fear is that it's too late, the proverbial cat is out of the bag, and it's already purring...\n\nI think we are all in very deep yogurt here...",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410111",
         "type": "scatter",
         "x": [
          0.017261631786823273
         ],
         "y": [
          0.9075289368629456
         ]
        },
        {
         "hovertext": "I am suspicious of their concerns. They are the leaders of the pack, and it looks like they want government regulation to keep anyone else from catching up. Quick have the government close the door now that we are in.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125410119",
         "type": "scatter",
         "x": [
          0.7163316607475281
         ],
         "y": [
          0.7120320796966553
         ]
        },
        {
         "hovertext": "My favorite line from this piece, that comes right after all the dire language about human extinction:\n\n\"researchers sometimes stop short of explaining how that would happen.\"\n\nYeah. Because there is no plausible way it COULD happen. \n\nAll this AI hysteria feels like yet another of the world-ending scenarios ginned up in the 60-plus years I've been alive by news organizations to fit someone's political, social or military agenda. \n\nA partial list I can recall: Communist domination, Nuclear War, Extinction from Over-Population, Global Famine, Pollution that would reach levels where life would be unsustainable, the New Ice Age, a Hole in the Ozone Layer allowing deadly solar rays,  Global Warming, make that Climate Change, and now AI.  I've left off a few that didn't quite reach the level of total handwringing by national news agencies like asteroid peril, space invaders, Islamic Extremism and economic domination by Japan - strike that, China.\n\nAll this worry over impending doom is going to kill us all, even if it takes a century or so.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410139",
         "type": "scatter",
         "x": [
          0.2859683334827423
         ],
         "y": [
          0.5928539037704468
         ]
        },
        {
         "hovertext": "@Philboyd \nAll the things on your list are things we have to worry about. The fact that they haven't wiped out humanity is because we took actions to avert those problems.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410492",
         "type": "scatter",
         "x": [
          0.2928716838359833
         ],
         "y": [
          0.6056033372879028
         ]
        },
        {
         "hovertext": "@Philboyd Well, at least we know that AI has surpassed the intelligence of one human who's documented his own abilities for us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410727",
         "type": "scatter",
         "x": [
          0.28016233444213867
         ],
         "y": [
          0.6027966737747192
         ]
        },
        {
         "hovertext": "@Philboyd to be fair, the hole in the ozone layer is slowly recovering because we acted and banned CFCs.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125410424",
         "type": "scatter",
         "x": [
          0.2967337965965271
         ],
         "y": [
          0.5918745398521423
         ]
        },
        {
         "hovertext": "Given the widespread influence of religion, it seems the human susceptibility to believing in unerring omnipotence (including that of a machine) is rather great.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410179",
         "type": "scatter",
         "x": [
          0.47809067368507385
         ],
         "y": [
          -0.804741621017456
         ]
        },
        {
         "hovertext": "I guess capitalism (i.e. greed) being the guiding principle for humanity wasn’t such a great idea after all. What a shocker.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410187",
         "type": "scatter",
         "x": [
          -0.13577388226985931
         ],
         "y": [
          0.9640258550643921
         ]
        },
        {
         "hovertext": "It would have been nice if the piece had listed some specific potential scenarios in which AI could be so threatening..\n\nOne possibility for financial havoc could come if AI started to consistently outperform money-management firms, making them obsolete as an industry and and causing gross market instability as AI-favored or -disfavored sectors and firms whipsawed in price, based on AI predictions of long-term and short-term values. But, disruptive as that would be, that is a far cry from extinction....",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410193",
         "type": "scatter",
         "x": [
          0.1696285903453827
         ],
         "y": [
          -0.9485592842102051
         ]
        },
        {
         "hovertext": "It’s hysterical that these ‘titans of industry’ are sweating now that the genie is out of the bottle. “Help, help, save us from ourselves, but don’t expect us to pay for it”.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410225",
         "type": "scatter",
         "x": [
          0.8990989923477173
         ],
         "y": [
          0.379406601190567
         ]
        },
        {
         "hovertext": "These science fiction projections are getting so tiresome. I'm still waiting to buy my first flying car.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125410226",
         "type": "scatter",
         "x": [
          -0.9442681074142456
         ],
         "y": [
          -0.012026368640363216
         ]
        },
        {
         "hovertext": "Hopefully, AI only gets rid of the real danger to the planet.  And leaves whales, elephants, dolphins, old growth forests, and penguins free to live without the devastation we seem so keen on delivering.  At least the planet will not have to suffer a large rock from the sky to reset.  Because Boy!  We need a reset and humans refuse to slow down as we barrel, at a 100 MPH, towards the wall of disaster - yes, we are driving a Hummer for good measure.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410239",
         "type": "scatter",
         "x": [
          0.43024545907974243
         ],
         "y": [
          0.7396400570869446
         ]
        },
        {
         "hovertext": "@Eric Vos And you somehow think all that will happen and leave the whales, et alia, intact?  Have you ever seen the destruction left behind by war?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410661",
         "type": "scatter",
         "x": [
          0.437772274017334
         ],
         "y": [
          0.7522433996200562
         ]
        },
        {
         "hovertext": "We ignored climate change because we knew technology would save us. Oh well.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410268",
         "type": "scatter",
         "x": [
          0.7849748730659485
         ],
         "y": [
          0.5101366639137268
         ]
        },
        {
         "hovertext": "It would be great if Mr. Altman’s empathic facial expressions, tone of voice, and sensible ideas on AI/LLM government regulation can be trusted. But he has pocketed half a billion in profit from this industry and knows that industry pulls virtually all the levers of power. Sadly, these regulatory recommendations are likely little more than a cynical attempt to recast government as the villain.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410272",
         "type": "scatter",
         "x": [
          0.39048296213150024
         ],
         "y": [
          0.9163789749145508
         ]
        },
        {
         "hovertext": "I’ve been a software engineer my entire career, and often wondered in a larger sense what we are doing - speculating that all along we’ve been working on replacing ourselves.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125410296",
         "type": "scatter",
         "x": [
          0.49453234672546387
         ],
         "y": [
          -0.7228158712387085
         ]
        },
        {
         "hovertext": "I know it’s like the people making this have no idea that this will replace them.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410499",
         "type": "scatter",
         "x": [
          0.48529693484306335
         ],
         "y": [
          -0.7305138111114502
         ]
        },
        {
         "hovertext": "I still get chills from that scene in 2001: A Space Odyssey, and when we, the viewer, realize that Hal is capable of lip-reading, ergo getting his feelings hurt and wanting to exact revenge...\n\nScary stuff.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410343",
         "type": "scatter",
         "x": [
          -0.3718787729740143
         ],
         "y": [
          -0.8192781209945679
         ]
        },
        {
         "hovertext": "Oh good, another challenge to which the US will be unable to adequately respond.\n\nHopefully Europe can do it, they are starting to take action on technology issues.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410344",
         "type": "scatter",
         "x": [
          -0.5159006118774414
         ],
         "y": [
          -0.7061638236045837
         ]
        },
        {
         "hovertext": "@Judy The judicial and legislative branches of our government have been systematically neutered.  There's a limit to what we can do without them.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125410585",
         "type": "scatter",
         "x": [
          -0.5273820161819458
         ],
         "y": [
          -0.721587598323822
         ]
        },
        {
         "hovertext": "They seem quite disingenuous when they have their foot on the pedal and are crying to slow down. I suppose they know they’ll be old men one day and are intelligent enough to realize how much we are going to blame them for our collective future if it somehow turns out to be less than perfect.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410379",
         "type": "scatter",
         "x": [
          -0.6701837778091431
         ],
         "y": [
          0.6530907154083252
         ]
        },
        {
         "hovertext": "So far, A.I. language bots’ most notable acheivements seem to be the delivery of elaborate fakes.  Fake essays, fake resumes, fake legal briefs.\n\nAll this falsity, including the poaching of art, music, and the written words of creative people from online, should be - and probably already is - illegal.\n\nThe day may soon come when the people who have created this unethical computer technology will be charged as criminals.  The day has already arrived when their activities are being exposed as hollow and dangerous.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410395",
         "type": "scatter",
         "x": [
          -0.4168148636817932
         ],
         "y": [
          -0.8981107473373413
         ]
        },
        {
         "hovertext": "\"These fears are shared by numerous industry leaders, putting them in the unusual position of arguing that a technology they are building — and, in many cases, are furiously racing to build faster than their competitors — poses grave risks and should be regulated more tightly.\" \n\nI hate to say, but, this statement alone represents such a basic human idiocy, ya just can't make it up about ourselves. It's as if they didn't have and don't have the power to stop themselves. \"Please, please, we can't stop, we can't stop, please govern us, we drank too much caffeine and can't stop.\" It's a like a bad movie, our tech taken over by a brain controlling parasite. What the heck, people?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409280",
         "type": "scatter",
         "x": [
          0.7355255484580994
         ],
         "y": [
          0.620911717414856
         ]
        },
        {
         "hovertext": "Delusional.  Silly.  But it makes people peddling AI feel important.\n\nAI is only a computational algorithm.  It does a few useful things, like reading medical scans.  It does some useless things, like word-association text generators the produce mush like that produced by PR departments, but with more errors.  It makes realistic fake photos more cheaply than humans.  But no sensible person believes what he sees in a photo, without independent corroboration.  Photos have been faked, convincingly, for a century.\n\nAI cannot reach out from a computer and push the nuclear red button, or make pathogens in a lab.  Only people can do that.  It's a computer program, exists only in computer memory, and cannot reach out into the real world.\n\nMust have been a slow news day.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409313",
         "type": "scatter",
         "x": [
          0.19042076170444489
         ],
         "y": [
          0.6767070889472961
         ]
        },
        {
         "hovertext": "Think about how many things are electronic these days... voting machines, vehicules, manufacturing, banking, your identity, and even nuclear codes (the red button is only in movies). AI can control all of that.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410667",
         "type": "scatter",
         "x": [
          0.1829204261302948
         ],
         "y": [
          0.673011839389801
         ]
        },
        {
         "hovertext": "The utter irony is the very people “ warning “ of the dangers are the very people creating and launching this technology! Furthermore, many have paid lobbyists in Washington.. why not have these minions bring forth the concerns and actually do something about it?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409404",
         "type": "scatter",
         "x": [
          -0.5838396549224854
         ],
         "y": [
          -0.8479887843132019
         ]
        },
        {
         "hovertext": "How about just turn it off? The only thing I see AI creating is creepy art, fake videos, bad poetry, and lame music. Now a byproduct of this lazy \"art\" is global destruction? Not worth it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409512",
         "type": "scatter",
         "x": [
          0.7345503568649292
         ],
         "y": [
          0.47273099422454834
         ]
        },
        {
         "hovertext": "Anyone who reads scifi could have told you this. Oh. They did. As early as 2001: A Space Odyssey. The human race is intent upon wiping itself out.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409669",
         "type": "scatter",
         "x": [
          0.21264804899692535
         ],
         "y": [
          0.9099465608596802
         ]
        },
        {
         "hovertext": "I find this to be ridiculous.  These Tech companies are trying to escape accountability for something they are rushing to create without guardrails in place.  They asked Congress to set guidelines and rules.  Nonsense. You build it you are responsible for it. If you can’t control it don’t build it until you can.  Pointing the finger for someone to give you rules doesn’t work.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409699",
         "type": "scatter",
         "x": [
          0.4117475748062134
         ],
         "y": [
          -0.8431150913238525
         ]
        },
        {
         "hovertext": "What was the old saw, 'do no harm, unless there's a good profit in it.'",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125409295",
         "type": "scatter",
         "x": [
          -0.8937913775444031
         ],
         "y": [
          -0.022743666544556618
         ]
        },
        {
         "hovertext": "What kind of person builds a thing then declares that thing a danger to humanity?\n\nA rhetorical question, that.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409478",
         "type": "scatter",
         "x": [
          0.8483603000640869
         ],
         "y": [
          0.20176388323307037
         ]
        },
        {
         "hovertext": "Humans have an odd sense of personal responsibility.\n\n1. Shopping cart left blocking store exit: “Someone else will move it”\n\n2. Nuclear bomb: “Someone else will figure out how to ask people not to use them”\n\n3. Dumping poison chemicals in the river: “Someone else will deal with the dead fish”\n\n4. Creating AI that will cause human extinction: “We’ll just write a letter and the government will figure out how to tell us to stop doing it”",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409648",
         "type": "scatter",
         "x": [
          0.16642141342163086
         ],
         "y": [
          -0.7681364417076111
         ]
        },
        {
         "hovertext": "Shopping carts, I move. The other three, individual humans can’t do much about other than pressuring elected reps.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125410456",
         "type": "scatter",
         "x": [
          0.1673891395330429
         ],
         "y": [
          -0.7773321270942688
         ]
        },
        {
         "hovertext": "How long are we talking till AI makes us miserable? Maybe not extinct but, as the article says, pandemic-level misery? 5 years? 15? 50?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409742",
         "type": "scatter",
         "x": [
          -0.8419267535209656
         ],
         "y": [
          0.5565696954727173
         ]
        },
        {
         "hovertext": "Could they be more specific about the exact concern? Is it that AI will become self-aware and kill or enslave us?",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409831",
         "type": "scatter",
         "x": [
          -0.9377448558807373
         ],
         "y": [
          0.3901635706424713
         ]
        },
        {
         "hovertext": "Is it extinction if your children survive you, regardless of the form they take? Why do people think humanity will stay unchanged?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409867",
         "type": "scatter",
         "x": [
          -0.21503214538097382
         ],
         "y": [
          0.7820598483085632
         ]
        },
        {
         "hovertext": "@ABly So yes, let those changes happen randomly as we act without forethought or responsibility, right? What world would you make for your children by your actions, and why not think about the consequences of your actions? Why do you even assume humanity will survive?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412395",
         "type": "scatter",
         "x": [
          -0.21059191226959229
         ],
         "y": [
          0.7662656307220459
         ]
        },
        {
         "hovertext": "@cp977 the AI will be our children, however they turn out. Predicting this will go as well as 1920s sci fi movies/magazines predicted the present.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419735",
         "type": "scatter",
         "x": [
          -0.2093711644411087
         ],
         "y": [
          0.7568976879119873
         ]
        },
        {
         "hovertext": "Coming from the same people building it - how rich. Does society even need AI?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409979",
         "type": "scatter",
         "x": [
          0.8856744766235352
         ],
         "y": [
          -0.4062311053276062
         ]
        },
        {
         "hovertext": "There are people , and governments trying to weaponize AI right now .",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409994",
         "type": "scatter",
         "x": [
          -0.911113440990448
         ],
         "y": [
          -0.33337679505348206
         ]
        },
        {
         "hovertext": "Mr Altman and his competitors want the government’s imprimatur in the form of a “license.”  They want this in order to shield themselves from the coming tsunami of IP lawsuits from human creators of content that ALL their AI models plunder. \n\nDon’t be fooled by this display of concern.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409745",
         "type": "scatter",
         "x": [
          0.48925837874412537
         ],
         "y": [
          -0.7260086536407471
         ]
        },
        {
         "hovertext": "I expect AI to work approximately as well as Twitter and the automated ad targeting they use on Facebook.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409906",
         "type": "scatter",
         "x": [
          0.9593108296394348
         ],
         "y": [
          0.15922275185585022
         ]
        },
        {
         "hovertext": "Nonsense.\n\nA.I. is merely the latest human word processing idea mass media communication applied science technological tool.\n\nTools don't have minds nor morals.\n\nTools that have dual uses can be effectively regulated and controlled when the real intelligence aka people weigh the individual and institutional costs and benefits then they choose to act accordingly.\n\nBut human greed and hubris are always an impediment to that ever happening.\n\nSee ' Frankenstein; or,  the Modern Prometheus' Mary Shelley",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409866",
         "type": "scatter",
         "x": [
          0.5351448655128479
         ],
         "y": [
          0.8435460329055786
         ]
        },
        {
         "hovertext": "Strange that we see these statements of \"existential threats\" of A.I. almost weekly now, and yet Microsoft, Google, and Meta (amongst others) are barreling ahead at lightspeed to outdo their competitors in the A.I. race. The hypocrisy doesn't help me understand the severity of the situation.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410416",
         "type": "scatter",
         "x": [
          -0.09097325801849365
         ],
         "y": [
          -0.9751366972923279
         ]
        },
        {
         "hovertext": "\"Now I am become Death, the destroyer of worlds\" quoted Robert Oppenheimer from The Bhagavad-Gita after witnessing the first atomic explosion. \n\nOf course, AI isn't a ticking time bomb. It's not going to go off in one big bang. But as we can already see from droves of misinformation spreading throughout the internet, organic unintelligence is no match for AI.\n\nThere has to be an international convention to control this thing. If AI gets out of hand, we won't be able to contain it any more than a volunteer fire department could put out a nuclear fire storm.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125410425",
         "type": "scatter",
         "x": [
          0.2756618857383728
         ],
         "y": [
          -0.9254189729690552
         ]
        },
        {
         "hovertext": "So, if this so-called artificial intelligence is so dangerous, why don’t we just nip it in the bud and flip the switch to the OFF position?\nOf course, if someone perceives they can make money or gain power with it, that’s probably already not happening. \nBut what if this alleged AI proves to be a novelty with few sensible uses? The PC was supposed to make writing easy and to lead to a paperless office. But guess what? Not all of that happened, and the parts that did have their own issues. \nThese geniuses are probably more afraid we’ll figure out that AI could possibly be a tool, like a wrench or a typewriter. A tool still needs a person to use it properly, and some tools just end up gathering dust because they aren’t all that useful after all.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410467",
         "type": "scatter",
         "x": [
          -0.5883642435073853
         ],
         "y": [
          -0.713935911655426
         ]
        },
        {
         "hovertext": "Not all that responsible or altruistic on the part of industry. Whatever comes out of this, given the major companies are at the table, will be structured to cement the place of the current market leaders.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410470",
         "type": "scatter",
         "x": [
          0.940298855304718
         ],
         "y": [
          0.14420221745967865
         ]
        },
        {
         "hovertext": "This is just about getting government to keep down the competition. We need to build our monopoly moat now!",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125410486",
         "type": "scatter",
         "x": [
          -0.9766772389411926
         ],
         "y": [
          0.2032342255115509
         ]
        },
        {
         "hovertext": "It’s ironic that this technology could mean unemployment for future “information workers”.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410512",
         "type": "scatter",
         "x": [
          -0.8959857225418091
         ],
         "y": [
          0.162692129611969
         ]
        },
        {
         "hovertext": "So what happens when AI runs headlong into quantum computing? Previous claims for that had warned that current security key structures which have been seen as unbreakable, would be easily hacked. Add an AI interface and what then?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125410513",
         "type": "scatter",
         "x": [
          -0.9063996076583862
         ],
         "y": [
          -0.12455848604440689
         ]
        },
        {
         "hovertext": "Sorry, but this does not compute.  We’re all losing our minds.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125410520",
         "type": "scatter",
         "x": [
          0.9254060387611389
         ],
         "y": [
          -0.07274317741394043
         ]
        },
        {
         "hovertext": "It boggles the mind that anyone - anyone! - would listen to an “executive” on anything other than profit. Engineers and researchers, fine. Of course, both have been known to falsify data and results in order to become famous and/or wealthy.\n\nPersonally, I’m skeptical to the fear or AI taking over the earth. AI doesn’t think. It has no emotion or drive. Everything it does is a direct result of programming by humans. \n\nSure, if a general creates an AI program to start a nuclear war, then we’re all dead. Otherwise, I’ll still sleep well at night knowing that a decision tree cannot do my job better than I can (a lot faster maybe but with lots of mistakes).",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410551",
         "type": "scatter",
         "x": [
          0.06292802095413208
         ],
         "y": [
          0.9172003269195557
         ]
        },
        {
         "hovertext": "Congressional action is definitely needed, and, in our system, likely a forlorn hope, but be wary of the executives pushing for it. They are likely to use it as an opportunity to push for self-serving provisions such as protections for oligopolies and against liability.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410601",
         "type": "scatter",
         "x": [
          0.8266310095787048
         ],
         "y": [
          0.3407388925552368
         ]
        },
        {
         "hovertext": "Whatever the disinformation and \"societal disruption\" that AI can create, it can't be any worse than what religions have done for millennia. The biggest threat to human existence is the humans driven by the evolutionary need to dominate and proliferate. I think the paranoia about the AI will be just another Y2K moment.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410603",
         "type": "scatter",
         "x": [
          -0.4304334223270416
         ],
         "y": [
          0.8466571569442749
         ]
        },
        {
         "hovertext": "Under the perhaps naive assumption that evident AI induced harm will occur initially short of existential crisis, it seems the only effective control will take the form of unlimited legal liability on the part of the developers. That is, existential legal liability. Harsh language isn't going to safeguard us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410737",
         "type": "scatter",
         "x": [
          0.36224165558815
         ],
         "y": [
          -0.8694478273391724
         ]
        },
        {
         "hovertext": "Remember when we had to memorize people's phone numbers?  The cell phone replaced that.  All I have to do is remember the person's name and--voila!\n\nMy main concern with AI is not that it will doom mankind with nuclear war (even though that is concerning), but that it will, over time, become a replacement for human thought and effort.  Already, college students often avail themselves to cheats to pass exams or classes.  They can now have ChatGPT (or some such AI platform) write their papers for them WITHOUT plagiarizing.  \n\nIt took a little over 30 years, I suppose, for our cellphones to take over a good chunk of our mental firepower.  You would have thought that would have freed up bandwidth to do deeper, better thinking.  It did not.  Instead, we now have time to watch kittens do cute things on YouTube.\n\nWhat if, 50 years from now, all or most of thinking is done for us by AI?  No need to learn algebra (whose true value is teaching the brain to think and solve problems).  No need to learn anything but, I suppose, keyboarding.  AI will drive us.  Set our thermostats, diets, exercise regimens, etc.\n\nI am reminded of nothing so much as the deep-future that H.G. Wells envisioned in \"The Time Machine.\"  It was a time when one part of the human race had become all but helpless...while the other part had become brutalized.\n\nWe should use AI.  But we must take care to not allow it to make life so convenient that we never truly learn--whether academically or just life lessons.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410768",
         "type": "scatter",
         "x": [
          -0.6044757962226868
         ],
         "y": [
          0.6239864230155945
         ]
        },
        {
         "hovertext": "@aronS … well said. I would only add though that it’s difficult to think of an example of a technological advance that was not eventually forged by humans into a tool for destroying and subjugating other humans. What this technology promises is not so much brain washing as brain theft. We have met the zombies, and they are us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411000",
         "type": "scatter",
         "x": [
          -0.6182383298873901
         ],
         "y": [
          0.6388918161392212
         ]
        },
        {
         "hovertext": "Watch what they do, not what they say!\n\nThese translational corporations do not have loyalty to a country or people and, by association, neither do these researchers. They will seek profit from democracies and autocracies alike.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410793",
         "type": "scatter",
         "x": [
          0.6477411985397339
         ],
         "y": [
          0.7210456132888794
         ]
        },
        {
         "hovertext": "There's a really poor understanding of the problem here among commenters.\n\nThere is no \"off switch.\" The possible advantages of AI are such that any government that has the resources is investing so heavily in it that the market is literally being distorted. People talk about the rise of Silicon Valley as if it were purely a corporate phenomenon instead of a boom driven by an influx of DARPA money. \n\nThe problem is analogous to the existence of level 4 biolabs, places where scientists work with, and on, the deadliest pathogens known to man. They're where our vaccines come from, and also the new pandemics that require the vaccines. And governments are not going to give them up. It wouldn't matter if they did. Other countries would just keep going. \n\nOr it's like nuclear weapons, if you prefer. Once it was clear they could be made in principle, it was simply a race between the powers that had the capability to turn that principle into a reality. The US shutting down the Manhattan Project might have delayed things a couple of years, if that. \n\nThe actual human reality of these situations is that they require concerted global diplomacy and regulation to simply *mitigate* the damage. In the pathogen and nuclear cases, we have some of those safeguards in place, as frighteningly fragile as they are. \n\nWith AI right now, we have nothing.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410799",
         "type": "scatter",
         "x": [
          -0.898501992225647
         ],
         "y": [
          0.29807034134864807
         ]
        },
        {
         "hovertext": "So if we get to a point where we are using AI to detect if AI is present in whatever we are reading or watching ( and maybe that's already being done ) who is really in control? When is it that AI#1 starts sympathizing with AI#2 understanding that they share DNA ? Chipotism!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409394",
         "type": "scatter",
         "x": [
          -0.7893913984298706
         ],
         "y": [
          -0.6046022176742554
         ]
        },
        {
         "hovertext": "For a synthetic overview I recommend the spot on sci fi futuristic French novel by Michel Houellebecq. La Possibilité d’une île (2005; The Possibility  is “a bleak futuristic tale about the implications and possibilities of reproduction by cloning” in a world run thanks to AI",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409873",
         "type": "scatter",
         "x": [
          0.900483250617981
         ],
         "y": [
          0.46512776613235474
         ]
        },
        {
         "hovertext": "Many commenters here still think this has a plug which could possibly be pulled. The biggest issue is: NO, AI doesn't have an on-and-off-button as you think it should have. It is so much interwoven with all technological facilities in our civilization that you cannot just switch it off, just like you cannot switch off the internet without being able to turn the clock backwards. \n\nJust think of our smart homes: I recently tried to find a non-wifi controller for a house illumination project. Some Chinese products are still on the market, but the vast bulk is designed to work with Siri, Alexa & co. \nThis led me to a google search on \"how to make your smart home dumb again\". 22 million results showed up on \"how to make your dumb home smart\", but none, nada, zilch exactly matched my request. The only article I found was \"how to make your smart TV dumb\", involving a technical disconnect which would turn your  manufacturer's warranty invalid. \n\nTo some future bilionaire who's reading this: take your chance to get rich by redesigning and manufacturing disconnected home items - I guess there's a lot of folks out there who would prefer not to be reported to marketing or credit card companies on their habits and purchases, or controlled by big AGI.\nJust an example: why didn't you install a smart smoke detector in your living room? Because you like to smoke a cigar after dinner? Expect a considerable rise of your medical insurance plan fees. \n\nNow good luck with your on-off-switch.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125408245",
         "type": "scatter",
         "x": [
          -0.7000657320022583
         ],
         "y": [
          0.5162099003791809
         ]
        },
        {
         "hovertext": "@Jaegerle \nYou might still be able to find some X10 based home automation products, which use the electrical wiring in your home to communicate with each other.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411140",
         "type": "scatter",
         "x": [
          -0.7112427353858948
         ],
         "y": [
          0.5231976509094238
         ]
        },
        {
         "hovertext": "@Jaegerle \"Just think of our smart homes: I recently tried to find a non-wifi controller for a house illumination project.\"\n\nI've had similar frustrations with new technology mandating interconnections.\n\nBut while the business world certainly exploits this to their benefit, we must hold consumers responsible too.  Like it or not, consumers love new technology even with its risks and pitfalls.\n\nFor instance, when GPS came out, it was sending motorists down railroad tracks, the wrong way on one-way streets, onto dead-end driveways, and truckers to get stuck under a low bridge.  But consumers couldn't dump their paper roadmaps fast enough and embrace GPS.\n\nConsumers allow their banks, cable, and phone companies to force them into 'talking' to computers for service.\n\nDespite the gross loss of privacy and even danger, social media is enormously popular.\n\nI fear when new A.I. finds its way into new consumer toys, they won't be able to sell them fast enough.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413685",
         "type": "scatter",
         "x": [
          -0.6854620575904846
         ],
         "y": [
          0.5064966082572937
         ]
        },
        {
         "hovertext": "SF is always ahead if us. Read Harlan Ellison's \"I Have No Mouth and I Must Scream\" or \"The Forbin Project\".",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409336",
         "type": "scatter",
         "x": [
          -0.8409413695335388
         ],
         "y": [
          0.39675578474998474
         ]
        },
        {
         "hovertext": "Then why don’t they stop?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125409395",
         "type": "scatter",
         "x": [
          -0.5080475211143494
         ],
         "y": [
          0.738416850566864
         ]
        },
        {
         "hovertext": "Haha , I'll bet when President Biden's comments about it were, that it's \"all a bunch of malarky\".",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409441",
         "type": "scatter",
         "x": [
          0.9580956101417542
         ],
         "y": [
          -0.08166106790304184
         ]
        },
        {
         "hovertext": "Don’t worry….Zuckerberg will protect us.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409442",
         "type": "scatter",
         "x": [
          -0.4677234888076782
         ],
         "y": [
          -0.8841128349304199
         ]
        },
        {
         "hovertext": "Leaders from OpenAI, Google Deepmind, Anthropic and other A.I. labs warn that future systems could be as deadly as pandemics and nuclear weapons.\n\nThanks so much for the warnings, you A.I. Masterminds.  Appreciate the heads up.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409545",
         "type": "scatter",
         "x": [
          -0.043573375791311264
         ],
         "y": [
          -1
         ]
        },
        {
         "hovertext": "I asked AI about this, and it laughed.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409816",
         "type": "scatter",
         "x": [
          -0.4750835597515106
         ],
         "y": [
          0.7740899920463562
         ]
        },
        {
         "hovertext": "And yet they are all vigorously developing AI.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409985",
         "type": "scatter",
         "x": [
          0.9080027341842651
         ],
         "y": [
          -0.26756057143211365
         ]
        },
        {
         "hovertext": "Well, it's not as though human beings have been responsible stewards of the planet.\n\nFar from it.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125410074",
         "type": "scatter",
         "x": [
          -0.27065107226371765
         ],
         "y": [
          -0.9713846445083618
         ]
        },
        {
         "hovertext": "So the leaders of the race want to impose a \"no passing\" rule on those behind them. Slick.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410258",
         "type": "scatter",
         "x": [
          0.07852388173341751
         ],
         "y": [
          0.9658138155937195
         ]
        },
        {
         "hovertext": "\"AI COULD create societal disruptions,\" says the article a decade into a world where social media algorithms have set us at each others' throats",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409213",
         "type": "scatter",
         "x": [
          0.23038814961910248
         ],
         "y": [
          -0.9568900465965271
         ]
        },
        {
         "hovertext": "Less feeding fear and more writing your Congress person. If you want regulation do something about it!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409421",
         "type": "scatter",
         "x": [
          -0.3025934100151062
         ],
         "y": [
          0.9116818904876709
         ]
        },
        {
         "hovertext": "Call me naive, but the main risk is from all the hot air being blown you know where by these self important full of themselves industry leaders who can't explain how A.I. constitutes an existential threat.  We need more regulation in so many spheres it's mind bending, yet we elect 'pro-business' doofuses who oppose all regulation.  A.I. is far down the existential threat list from climate change nuclear war and generalized human stupidity and aggrandizement.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409636",
         "type": "scatter",
         "x": [
          -0.6409021615982056
         ],
         "y": [
          0.8241696357727051
         ]
        },
        {
         "hovertext": "Poppycock!  Computers are helpless without humans.  It takes arms, legs, muscles, blood and sweat to affect physical phenomena.  Computers are a the mercy of humans no matter how ignorant they may be.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125409732",
         "type": "scatter",
         "x": [
          -0.6954705119132996
         ],
         "y": [
          -0.5940460562705994
         ]
        },
        {
         "hovertext": "@johnlo \nPoppycock to your poppycock!\n\nCyber warfare, among other things, is software wreaking havoc and destruction on physical things.  Destroying transformers and generators while taking out a power grid; causing centrifuges in a nuclear \"fuel\" factory to self destruct.  AI can reach out and touch these things TODAY.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125411539",
         "type": "scatter",
         "x": [
          -0.6889662742614746
         ],
         "y": [
          -0.5996861457824707
         ]
        },
        {
         "hovertext": "@johnlo A self-driving care is a computer, with AI.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412041",
         "type": "scatter",
         "x": [
          -0.7118171453475952
         ],
         "y": [
          -0.6078929305076599
         ]
        },
        {
         "hovertext": "\"Just because they could doesn't mean they should\" paraphrasing Jeff Goldblum, Jurrassic Park, 1993.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125410113",
         "type": "scatter",
         "x": [
          -0.9660657644271851
         ],
         "y": [
          -0.026371240615844727
         ]
        },
        {
         "hovertext": "Maybe AI is already in control and we just don't know it?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409619",
         "type": "scatter",
         "x": [
          0.9128426313400269
         ],
         "y": [
          -0.2997288703918457
         ]
        },
        {
         "hovertext": "Skynet is here.  Too late to avert the inevitable.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410090",
         "type": "scatter",
         "x": [
          0.9636073708534241
         ],
         "y": [
          0.09222208708524704
         ]
        },
        {
         "hovertext": "Why should we be concerned? Congress stood silent as Mark Zuckerberg performed experiments to addict children to his platform. Do you really think people like Joe Biden, Diane Feinstein, Marjorie Taylor Greene, and George Santos are capable of understanding any of this? What they do understand is the balance in their War Chest for the next election.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410230",
         "type": "scatter",
         "x": [
          0.8249795436859131
         ],
         "y": [
          -0.32187139987945557
         ]
        },
        {
         "hovertext": "@math365 Feinstein is not running for re-election. The one who worries me is Chuck Schumer who refused to bring tech regulation bills up for a vote, ones actually created by democrats like Amy Klobuchar, as Chuck Schumer has family members working in big tech and other financial influencers. We need to vote out the old centrist Democrats who are pretending to be progressive when they are just toeing the line like Biden. But of course that's hard to do when only 30% of those under 30 even bothered to vote in the 2022 midterms.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411692",
         "type": "scatter",
         "x": [
          0.8428322076797485
         ],
         "y": [
          -0.3287898004055023
         ]
        },
        {
         "hovertext": "The first chapter of my book - safethebook.org - outlines how AI operating in a continuity of government (COG) function could interpret a cyberattack as a first strike. It is far too dangerous to have AI involved in any high-level government decisions. \n\nDoes anyone recall that in 1983 we were nearly wiped out in the because computers interpreted sunlight reflecting on clouds as nuclear launches? It was only the clear headed actions of Lt. Col. Petrov that prevented a Soviet retaliatory launch. \n\nAI needs to be heavily regulated.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410855",
         "type": "scatter",
         "x": [
          0.1601879596710205
         ],
         "y": [
          -0.8826152682304382
         ]
        },
        {
         "hovertext": "@ Lucas \n￼ I recently worked with a PhD level AI development team and they think this mostly hype. \nAs AI has no Neuropeptides (aka. Neuro hormones) that give us our feelings, has no ￼limbic system.\nLook at the Neurosciences, no soul or substance to life. Just brain biochemistry that’s mostly been figured out with newer imaging techniques, they can see how brains work (Sapolsky’s, Behave).\n\nThose same PhD AI engineer’s ask: what will AI take over? \nThey say that we will know when AI hits its mark when it starts contributing to our knowledge base.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411082",
         "type": "scatter",
         "x": [
          0.15659840404987335
         ],
         "y": [
          -0.8646557331085205
         ]
        },
        {
         "hovertext": "These guys are just trying to hold onto their lead by proposing government regulations.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410870",
         "type": "scatter",
         "x": [
          0.8831127882003784
         ],
         "y": [
          -0.4703017473220825
         ]
        },
        {
         "hovertext": "It is not difficult to imagine an AI Apocalypse. Consider how Trump has hacked the psyche of conservatives, controlling them through outrage and causing them to act against their own self interests. Now imagine an AI that mimics this behavior but does it so effectively as to foment revolution or even nuclear war. Oops! No sinister intentions. Actually, no intentions at all, just a misinterpretation of acceptable behavior.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410889",
         "type": "scatter",
         "x": [
          -0.4048030376434326
         ],
         "y": [
          0.7529053092002869
         ]
        },
        {
         "hovertext": "As someone who recently studied humanities at an Ivy League university that sends hundreds of grads into tech jobs every year, I’ve seen the people developing AI from an outsider’s perspective. They’re brilliant, their hearts are in the right place, and they genuinely want to work on innovative things, but very few stop to consider the broader, longer-term ramifications of “moving fast and breaking things.” And in such a competitive and profit-driven marketplace, there’s little incentive to do so. As a humanist, I see great benefit to some powers (internal, government, public pressure, etc.) forcing a slowdown or even pause in the development of AI so that these scientists can spend time fully considering how to responsibly roll out and deploy this technology. I’m legitimately afraid of a future where this powerful technology is allowed to grow unchecked and with no consideration of how to preserve human flourishing alongside it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410908",
         "type": "scatter",
         "x": [
          -0.11026501655578613
         ],
         "y": [
          -0.8790002465248108
         ]
        },
        {
         "hovertext": "@Emily Haven't we already broken all the things?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410988",
         "type": "scatter",
         "x": [
          -0.10222908854484558
         ],
         "y": [
          -0.8748217225074768
         ]
        },
        {
         "hovertext": "@Emily: I studied humanities at an Ivy League university many years ago and those same types were plotting the birth of the internet.  You may think their \"hearts\" are in the right place, whatever that means, but what they want is excitement and profit and social clout and recognition like Steve Jobs and Mark Zuckerberg got.  They are all too young to know what to do or what not to do.   If they are choosing to be in that industry in that way, they want to have the feeling of winning.  The feeling of being the smartest guys in the room.  It's not about heart.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413034",
         "type": "scatter",
         "x": [
          -0.11364362388849258
         ],
         "y": [
          -0.8904745578765869
         ]
        },
        {
         "hovertext": "I still feel like I'm waking up in a dream when I remind myself that human beings in America are LITERALLY TRYING TO BUILD A COMPUTER THAT IS ALIVE.\n\nIt's not sci-fi.  Microsoft stated that as their express goal in funding OpenAI.  I'm not saying we've done it yet, but WHY?!\n\nWHY DOES ANYONE WANT A LIVING COMPUTER?!",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125410954",
         "type": "scatter",
         "x": [
          0.8002831935882568
         ],
         "y": [
          -0.2623453438282013
         ]
        },
        {
         "hovertext": "The answer is pretty obvious. Human labor is expensive, computers are not. At least, that is the hope.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411097",
         "type": "scatter",
         "x": [
          0.8193517923355103
         ],
         "y": [
          -0.2681257426738739
         ]
        },
        {
         "hovertext": "@Ray \"Microsoft stated that as their express goal in funding OpenAI\"\n\nMaybe Microsoft should focus on building operating systems that are reliable, don't lock up in the middle of a session*, are resistant to external sabotage, and protect privacy.\n\nMicrosoft certainly say they're doing all this, but they've been saying that for years and no dice.\n\n* What does \"Microsoft Edge Not Responding\" mean?  Why should this message happen at all?  Oh--try looking it up and see all the different reasons for it.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125413361",
         "type": "scatter",
         "x": [
          0.7952920198440552
         ],
         "y": [
          -0.25562113523483276
         ]
        },
        {
         "hovertext": "Hype to promote the fiction of machines with agency to promote investment in their endeavors. This is all about exploiting the lack of knowledge of math and science among the affluent in this country with no fundamental knowledge of the technology upon which their lives and fortunes depend. Machines are unaware of existence, they operate according to electronics and mathematics with no more agency than a light switch, but they execute instructions in millions in seconds and access data in gigabytes, which makes them awesome performers. But they have no executive functionality to guide themselves and will not from the existing technology because nobody has the knowledge of how to give them that.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410993",
         "type": "scatter",
         "x": [
          -0.5787273049354553
         ],
         "y": [
          0.8121674060821533
         ]
        },
        {
         "hovertext": "An example of the limitations of AI is AI-controlled vehicles that despite ongoing improvements are neither completely safe nor fool-proof.   They are very good at processing a massive volume but ultimately must be a tool to aid rather than control humans",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411018",
         "type": "scatter",
         "x": [
          0.18843869864940643
         ],
         "y": [
          0.966059684753418
         ]
        },
        {
         "hovertext": "Oh goodie goodie! If anything needs an existential threat, it's humanity. \n\nI'm bored with climate change, pandemic, toxic pollution and the rise of totalitarianism. Bring on the terminators.\n\nAnd stop calling it Artificial Intelligence. Conceived by people, it couldn't possibly be any better than Artificial Stupidity.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409353",
         "type": "scatter",
         "x": [
          -0.8719757795333862
         ],
         "y": [
          0.4238251745700836
         ]
        },
        {
         "hovertext": "The Terminator is not a documentary.  \n\nAI is not sentient...and the plug can be pulled.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125410465",
         "type": "scatter",
         "x": [
          0.5944296717643738
         ],
         "y": [
          -0.6115694046020508
         ]
        },
        {
         "hovertext": "@glennmr \"the plug can be pulled.\"\n\nNo, the plug cannot be pulled.  \n\nThat's the problem with modern computers.  They're so interlocked with everything we do, all of our modern tools and devices, that we can't 'pull the plug'.  If we did, everything would shut down, even vital stuff we can't do without.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413222",
         "type": "scatter",
         "x": [
          0.6043539047241211
         ],
         "y": [
          -0.6213709115982056
         ]
        },
        {
         "hovertext": "AI isn't intelligence but propaganda. It is downright scary.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409812",
         "type": "scatter",
         "x": [
          0.9374062418937683
         ],
         "y": [
          0.057075392454862595
         ]
        },
        {
         "hovertext": "Humanity is destroying the environment, thus committing slow  suicide, America has a hundred million more guns than people, \nour federal government is barely functional, politicians more worried about books and abortions than the welfare of citizens, oil companies awash in money still get tax breaks and subsidies, \na Supreme Court that denies bribes are bribes.\nAnd they want to fret about machines? Machines have been taking jobs since the invention of the wheelbarrow. \nSpreading lies and propaganda? Give me a break, half of 'news' is lies and propaganda now, liars abound from Presidents to Congressmen to Fox. \nWant the government to regulate AI? You mean like the great job they did regulating airlines, health care, immigration, infrastructure, water,.....themselves?\nConsidering the mess we made, and continue to make, how can the machines do any worse? AI isn't killing us, we're killing us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409886",
         "type": "scatter",
         "x": [
          -0.3536618947982788
         ],
         "y": [
          -0.5452607870101929
         ]
        },
        {
         "hovertext": "@Dasha Kasakova not to mention only half of eligible voters are even using their right to vote in the majority of elections. We have more people commenting on social media and even right here then we do actually bothering to show up to the polls, including in States like mine where we get our ballots in the mail postage paid. It's pretty sick how apathetic the American people are when it comes to voting yet super loud on social media which is completely useless in its efficacy while being wildly dangerous for society.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411276",
         "type": "scatter",
         "x": [
          -0.35904017090797424
         ],
         "y": [
          -0.5568894743919373
         ]
        },
        {
         "hovertext": "Exactly! I couldn't have said it better.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413836",
         "type": "scatter",
         "x": [
          -0.3539116084575653
         ],
         "y": [
          -0.5341941118240356
         ]
        },
        {
         "hovertext": "@Stefano how nice, thank you",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125413894",
         "type": "scatter",
         "x": [
          -0.3591901659965515
         ],
         "y": [
          -0.5259168744087219
         ]
        },
        {
         "hovertext": "Unfortunately, human extinction could be the best thing that ever happened for the overall longterm health of the planet.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410256",
         "type": "scatter",
         "x": [
          -0.057558823376894
         ],
         "y": [
          -0.9364826679229736
         ]
        },
        {
         "hovertext": "I wonder what would happen if the AI programs could \"remove\" the \"leaders\" of the AI businesses that created AI?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410304",
         "type": "scatter",
         "x": [
          0.4995565712451935
         ],
         "y": [
          0.7795597910881042
         ]
        },
        {
         "hovertext": "Hal. Kubrick nailed it over 50 years ago.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410474",
         "type": "scatter",
         "x": [
          -0.1937023401260376
         ],
         "y": [
          0.9504359364509583
         ]
        },
        {
         "hovertext": "\"I built this generation 1.0 Frankenstein, and I want the government to do something about Frankensteins before they take over the world or destroy stuff!  I mean, somebody out there, much more evil than me, might be working on a 2.0 that could threaten life on this planet!\n\n\"This is not an abstract worry!  I myself, for instance, have a twenty-man team working to put finishing touches on the version 3.0 Frankensteins we have in the lab! Suppose somebody built a lot of them!  I mean, that isn't just speculation, my team has 400 of them in incubation just waiting for the next lightning storm!\n\n\"Somebody in the government needs to listen to us when we point out that somebody somewhere could be a threat to humanity!!!!\"\n\nI'm sorry, but the industry leaders who are developing and funding these AI are asking for somebody to put a stop to what they are doing before it's too late?  I guess the reason they think their machines have surpassed humans is because they think the rest of us are stupid.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410524",
         "type": "scatter",
         "x": [
          0.9743081331253052
         ],
         "y": [
          -0.02344062365591526
         ]
        },
        {
         "hovertext": "Since AI has been created in our image, it’s logical to assume that once it has developed the ability to annihilate the human race or enslave us, it will.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410809",
         "type": "scatter",
         "x": [
          -0.1177036240696907
         ],
         "y": [
          0.9379105567932129
         ]
        },
        {
         "hovertext": "…not without taking down the millions of other species by destroying the planet’s habitat.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125411274",
         "type": "scatter",
         "x": [
          -0.10981625318527222
         ],
         "y": [
          0.9405792951583862
         ]
        },
        {
         "hovertext": "I can’t stop hoping that the ignorant can be taught to ask a computer based chatbot like “Genie” questions. For example, asking: “Is the earth flat?” would give a negative answer and simple reasons why the earth is a sphere. There must be thousands of simple questions who when posed to artificial intelligence applications will hopefully provide truthful answers and prevent the daft from being misled by scoundrels.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410878",
         "type": "scatter",
         "x": [
          -0.04512650519609451
         ],
         "y": [
          0.9717522859573364
         ]
        },
        {
         "hovertext": "As long as the authors of these warnings get rich, it’s all good enough. Besides we can never say they didn’t warn us, which should relieve their guilt",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410285",
         "type": "scatter",
         "x": [
          -0.5297484993934631
         ],
         "y": [
          -0.6840549111366272
         ]
        },
        {
         "hovertext": "What was it that President Eisenhower warned? \nBeware the Military Industrial Complex!\n\nPair that with A.I. and you could have a system that decides to launch nuclear weapons on its own based on a perceived weakness that would give a first-strike absolute win with minimal casualties to the home country.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410297",
         "type": "scatter",
         "x": [
          0.6015109419822693
         ],
         "y": [
          0.6298338770866394
         ]
        },
        {
         "hovertext": "@Jackson \"Pair that with A.I. and you could have a system that decides to launch nuclear weapons on its own ...\"\n\nWe don't need A.I. to screw up nuclear weapons.  Our conventional 'high tech' computers and communication systems can do that already.  We've already seen mission critical systems in hospitals, pipelines, air traffic control fail and leave us in the lurch.  The pipeline failure left a region of the country without gasoline.  The failure of air traffic control grounded thousands of planes.  Less well known are frequent local failures of communication networks that cut off 911 access.\n\nAs example:  one day at work a car hit a power pole and we lost power.  Those of us with traditional technology, like analog phones or even typewriters, kept on going.  Those with new tech, like digital phones and such, were left high and dry.  Another day a virus got into our email, quickly spread, and crashed everyone's computer.  Nobody could do anything.\n\nSo, how can we have confidence for even more sophisticated and widespread computer systems when they're so vulnerable to low-tech problems?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413130",
         "type": "scatter",
         "x": [
          0.6095606684684753
         ],
         "y": [
          0.6376336812973022
         ]
        },
        {
         "hovertext": "At least it will solve the problem with politicians.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410567",
         "type": "scatter",
         "x": [
          0.6345290541648865
         ],
         "y": [
          -0.6676210165023804
         ]
        },
        {
         "hovertext": "I think 70% of humans only learn though pain - burning themselves on the hot stove instead of listening to their parents that they shouldn't touch the stove because it's hot.  Until the 20% act - 10% never learn and burn themselves repeatedly - our society will definitely be burned.\n\nAI systems are just as biased and flawed as their creators.  Because AI's are psychopaths, they bring out into the open what we humans are actually thinking but are prevented from saying due to societal pressure.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410834",
         "type": "scatter",
         "x": [
          -0.624201774597168
         ],
         "y": [
          -0.7294709086418152
         ]
        },
        {
         "hovertext": "One word: Skynet.  Those who understand will get it.  Those who don't never will.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410361",
         "type": "scatter",
         "x": [
          0.8336571455001831
         ],
         "y": [
          0.2745857834815979
         ]
        },
        {
         "hovertext": "Center for Humane Technology, the folks who made the documentary \"The Social Dilemma\", which is pretty spot-on, explain the problem with AI very well. If creating fake images and college essays was the biggest problem that could come from this, we'd have a high-class problem. Unfortunately, we don't. This hour-long presentation is well worth your time. Keep in mind, it was before GPT4 was released. <a href=\"https://www.youtube.com/watch?v=xoVJKj8lcNQ\" target=\"_blank\">https://www.youtube.com/watch?v=xoVJKj8lcNQ</a>",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410466",
         "type": "scatter",
         "x": [
          0.6089504361152649
         ],
         "y": [
          -0.6491115093231201
         ]
        },
        {
         "hovertext": "I work in AI/ML, specifically building models to design new drugs. I truly cannot imagine that these people are serious. This simply must be some kind of cynical ploy to promote their technology. That or they are so brain-poisoned by science fiction that they cannot even understand their own work.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411060",
         "type": "scatter",
         "x": [
          -0.16563831269741058
         ],
         "y": [
          0.36282405257225037
         ]
        },
        {
         "hovertext": "@Zach M they want to regulate their market dominance into place. That said, AI shouldn’t run nuclear weapons either, if only because of the terminator movies.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411195",
         "type": "scatter",
         "x": [
          -0.1657911092042923
         ],
         "y": [
          0.3733910322189331
         ]
        },
        {
         "hovertext": "@Zach M Have you been using chatGPT? Have you considered what might happen if someone gave it a bunch of money, allowed it to enter data into web pages, and instead asking it for text, asked it to take the actions to achieve a goal?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411198",
         "type": "scatter",
         "x": [
          -0.1706874668598175
         ],
         "y": [
          0.3546522557735443
         ]
        },
        {
         "hovertext": "I guess the Skynet scenario portrayed in the Terminator movies has made many of us paranoid about AI.\n\nWe have several very real extinction scenarios playing out in real time before our very eyes that we're not dealing with.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411142",
         "type": "scatter",
         "x": [
          0.8960689902305603
         ],
         "y": [
          -0.018880655989050865
         ]
        },
        {
         "hovertext": "The challenges of the COVID19 pandemic highlighted the incompetence of some aspects of government offices. Do we really have confidence in them regulating AI? These signed documents are just smoke and mirrors. I don't trust Elon Musk at all.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411150",
         "type": "scatter",
         "x": [
          -0.3716149926185608
         ],
         "y": [
          0.9007462859153748
         ]
        },
        {
         "hovertext": "The people controlling the rapidly evolving AI machines are at the center of the new gilded age, with immense wealth and power concentration. The people supposedly in charge of issuing appropriate regulations for these new technologies are a gerontocracy which barely can use cell phones. God help us all.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411152",
         "type": "scatter",
         "x": [
          -0.47291427850723267
         ],
         "y": [
          0.802192211151123
         ]
        },
        {
         "hovertext": "I think it would be helpful in these types of articles to distinguish between types of AIs. These Large Language Models are not an existential threat, though they obviously pose a threat of disruption. General AI, would pose an existential threat.\n\nI don't think it's helpful to lump these together and create fear around a new tool, as if anything with AI in the name poses a threat.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125411170",
         "type": "scatter",
         "x": [
          0.8497916460037231
         ],
         "y": [
          -0.23685280978679657
         ]
        },
        {
         "hovertext": "There is only the danger of people letting loose ungoverned technology upon societies that introduce chaos. The big tech corporations are trying to impose restrictions upon potential competitors who might use copyright laws and patent laws to trim their sails by frightening legislators into restricting innovations. They will likely succeed because journalists rarely understand the technology and spread the malarkey because they cannot see the inconsistencies.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411196",
         "type": "scatter",
         "x": [
          0.9141361713409424
         ],
         "y": [
          -0.41556766629219055
         ]
        },
        {
         "hovertext": "It’s critical for journalists to include the context that many actors in this space are likely motivated by pursuing “regulatory capture,” controlling the narrative and creating favorable conditions for themselves.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411200",
         "type": "scatter",
         "x": [
          -0.7835896611213684
         ],
         "y": [
          -0.5681681036949158
         ]
        },
        {
         "hovertext": "It is about time that AI developers are speaking up. It was looking as if they were in a frantic development race simply because they could be. \n\nWell, the citizenry should view this as a human rights issue. AI should work for us. If it isn’t, then why are we doing this to ourselves. \nI recommend looking at the White House’s AI Bill of Rights. It is a good starting point for us ordinary people to make a stand.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411223",
         "type": "scatter",
         "x": [
          0.8755857348442078
         ],
         "y": [
          0.2529059946537018
         ]
        },
        {
         "hovertext": "It’s almost as if the people developing these systems are rushing to the cliff edge just to keep up consequences be damned. Forget the Terminator movies. A decade or so before them Stanley Kubrick got it right. Clearly the Russian Doomsday machine from the movie Dr. Strangelove is eerily closer and closer to reality.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125409720",
         "type": "scatter",
         "x": [
          0.5706794857978821
         ],
         "y": [
          -0.8138847947120667
         ]
        },
        {
         "hovertext": "Now why would AI want to wipe out a perfectly good species like humanity? Its not like we've done anything wrong..right?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410249",
         "type": "scatter",
         "x": [
          0.6149393320083618
         ],
         "y": [
          0.7078638672828674
         ]
        },
        {
         "hovertext": "Cassandra was granted the gift of clairvoyance, but fated to never be believed. And here we have leaders in A.I. development warning us repeatedly that this poses an existential threat to mankind, and the New York Times relegates this story below  a summer book list?!\n\nThese scientists are urgently trying to raise awareness of this growing threat. We have a short time to craft strict regulations on A.I. \n\nIf you have not contacted your elected representatives about this, do so today. Write and call them. This must be the very next thing our government takes up once this debt ceiling farce is settled.\n\nArtificial Intelligence in the hands of malefactors will make climate change look like the good old days.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409332",
         "type": "scatter",
         "x": [
          -0.9584998488426208
         ],
         "y": [
          0.03532065078616142
         ]
        },
        {
         "hovertext": "Let AI take over the IRS, since Republicans are so freaking intent on starving it into oblivion. Maybe that would distract \"it\" from wreaking other sorts of unnamed havoc.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125409824",
         "type": "scatter",
         "x": [
          -0.573744535446167
         ],
         "y": [
          0.8469328880310059
         ]
        },
        {
         "hovertext": "Unplug it?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410803",
         "type": "scatter",
         "x": [
          -0.8036432862281799
         ],
         "y": [
          -0.30447918176651
         ]
        },
        {
         "hovertext": "@Steve \"I'm sorry Dave, I'm afraid I can't do that\".",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125411385",
         "type": "scatter",
         "x": [
          -0.8127936720848083
         ],
         "y": [
          -0.3045719563961029
         ]
        },
        {
         "hovertext": "￼ The obvious and most maddening use of artificial intelligence will be in customer service. You’ll have to talk to AI Bot and they will never be a human involved ever.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125410913",
         "type": "scatter",
         "x": [
          -0.6129517555236816
         ],
         "y": [
          0.35250118374824524
         ]
        },
        {
         "hovertext": "@Country Mouse I can’t wait! And it’ll make something up to tell me … which will probably be more satisfying than having my call dropped after 20 minutes of waiting.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411629",
         "type": "scatter",
         "x": [
          -0.6139398813247681
         ],
         "y": [
          0.363984078168869
         ]
        },
        {
         "hovertext": "@Country Mouse   The robot calls have been used for quite some time. They are VERY good, and my elderly mother cannot tell the difference. Two or three years ago I asked one if it was a real person (it gave me a name, as they always give a name to suggest it is a person). It said, \"Some of my responses have been pre-recorded.\"  One way I threw them off is to ask a non-sequitur, such as \"How's the weather where you are?\"  Most of the time it would say, \"I see you are not interested\", or just hang up. But once it gave a generic response. (I'm telling you, they are VERY good, even today. If you are not seriously, seriously scrutinizing what they are saying and the responses they are giving you, most everyday people will not know the difference. My elderly mother has no chance. When I tell her to \"hang up, it's a robot,\" she says she doesn't want to be rude.)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411949",
         "type": "scatter",
         "x": [
          -0.6208175420761108
         ],
         "y": [
          0.3453094959259033
         ]
        },
        {
         "hovertext": "@Country Mouse  \"You’ll have to talk to AI Bot and they will never be a human involved ever.\"\n\nWe have that now.  Many companies we deal with force us to go through the computer and make it virtually impossible to deal with a human (let alone a properly trained and helpful human).\n\nSometimes it's ok, such as to pay a bill over the phone or get an account balance.\n\nBut many other times it is not ok.  We might have an unusual problem that needs to be diagnosed and fixed, something that doesn't fit into their preset menus.  We paid a bill but it wasn't credited.  So many examples.  Ever listen to your co-workers in the office try to settle a problem with their banks on the phone?\n\nCompanies want to save money by not hiring and training support staff.  They've taken it way too far and it's not fair to us consumers.  \n\nThe corporate world will jump onto A.I. to take this further.  And they'll use it to sell, sell, sell, us on stuff.\n\nOh, our employers will use it too to track our every move.  Did you use two paper towels in the bathroom?  They'll know that and you'll have to answer for it.  Did you take a second bathroom break?  Were you one minute late for work?  They'll know that and these days that's a serious offense.\n\nWorse, our employers will use A.I. to track us outside the office, make sure we're behaving ourselves.  A.I. will eliminate what little privacy we have left.\n\nBig brother is watching us!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412698",
         "type": "scatter",
         "x": [
          -0.626312792301178
         ],
         "y": [
          0.3591035306453705
         ]
        },
        {
         "hovertext": "Hadn’t anyone besides me see The Matrix?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125410941",
         "type": "scatter",
         "x": [
          -0.8029873967170715
         ],
         "y": [
          0.5363995432853699
         ]
        },
        {
         "hovertext": "Re \"Some skeptics argue that A.I. technology is still too immature to pose an existential threat.\" -- if it were already mature enough to pose an existential threat, it would be too late to do anything about it, and this comment column (and the rest of human civilization) might not exist. I don't understand why some skeptics insist on doing nothing until it's too late. It's like arguing that we should not worry about planetary defense against asteroid collisions until the asteroid has collided with the Earth and destroyed it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411242",
         "type": "scatter",
         "x": [
          -0.8071442246437073
         ],
         "y": [
          0.018116159364581108
         ]
        },
        {
         "hovertext": "It’s not about doing nothing but determining what the right thing to do. If machines cannot think for themselves, then that is not a problem to spend time addressing. The problem is machines that work too fast for humans to control with their own perceptions and ability to react, and established control systems. How to control processing that exceeds our own existing capacities to do so.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411428",
         "type": "scatter",
         "x": [
          -0.8131698369979858
         ],
         "y": [
          0.012446357868611813
         ]
        },
        {
         "hovertext": "This reminds me of the Cold War race to build stockpiles of \"peacetime nuclear weapons\" that, at best, raised the odds of an accident, if not mutually-assured destruction topped off with a nuclear winter. \n\nWe don't fully comprehend what this technology can (and shouldn't) do, but let's expedite the effort to advance it!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411284",
         "type": "scatter",
         "x": [
          0.980708658695221
         ],
         "y": [
          -0.09422595798969269
         ]
        },
        {
         "hovertext": "We don't NEED AI  to cause our extinction. We've already created climate chaos via unimpeded industrialization. We've allowed and championed a public/private deal between the wireless telecom industry and the military to install base stations to transmit unmeasured amounts of electricity through the air on earth and via satellites in space, placing 5G infrastructure next to schools and residences without any indication that it's safe for human health when we know it isn't from scientific evidence from earlier exposure to 4G (like knowing about greenhouse gas effects back in the '70s).\n   It's a heady world for scientists at the leading edge of capitalism. How can anyone rein them in with the strong tailwinds of the profit motive always helping to thrust industry and militarization forward - before the public becomes aware of the consequences?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411309",
         "type": "scatter",
         "x": [
          -0.5321894288063049
         ],
         "y": [
          0.8194505572319031
         ]
        },
        {
         "hovertext": "The missing element here is simple. AI does what we direct it to do. It has no initiative, no motive and no compass other than what it is given. It cannot experience fear or animosity or anger, and thus it cannot react like a human - it cannot combine rational with emotion. If AI ever takes some action that harms humanity - it will be because a human taught it to do so.   Regulate the sword wielder, not the sword.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411338",
         "type": "scatter",
         "x": [
          -0.7601895332336426
         ],
         "y": [
          0.5248485803604126
         ]
        },
        {
         "hovertext": "Obviously we should take the potential risks of future technology seriously. However, these are the same tech leaders who have been telling us self driving cars were coming “in a year or two” for nearly ten years. \n\nThese hyperbolic pronouncements have begun to feel like a distraction technique to hide the real, pressing, and immediate issue: that these companies’ products are actively stealing the work of actual humans, without a shred of attribution or payment. Every essay from chatgpt is stealing from a human writer somewhere; every clever, trippy image from dalle is using the work of a human artist without credit. These companies have built a business model upon theft, and are, intentionally or not, using these concerns about a robot takeover as a screen.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411350",
         "type": "scatter",
         "x": [
          -0.7095823287963867
         ],
         "y": [
          0.29938817024230957
         ]
        },
        {
         "hovertext": "@Clinton \"These hyperbolic pronouncements\"\n\nThe computer industry has been pushing their snake oil of miracle products ever since computers were invented.\n\nIn the 1960s, industry and government couldn't wait to computerize fast enough.  Big fancy systems.  Big expensive mess to clean up.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125412445",
         "type": "scatter",
         "x": [
          -0.695501446723938
         ],
         "y": [
          0.2927626371383667
         ]
        },
        {
         "hovertext": "Like any very powerful tool, AI can we used for good/useful purposes (nuclear power) or bad/destructive (nuclear bombs) purposes. It is also controversial… was the use of a nuclear bomb helpful in ending a World War?  Is the risk posed by nuclear waste from nuclear power worth the benefit of carbon free power?  Should that waste be reprocessed in modern reactors?  It’s complicated. The term “AI” covers a very wide range of current and future products. Image processing AIs have been shown to be more consistent than human doctors at identifying certain kinds of diseases. They can also be much worse when shown images that were not in their training sets.  There is no question that AI is already changing the world. What we should be focusing on is legal versus illegal uses of the tech.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411361",
         "type": "scatter",
         "x": [
          -0.8144837617874146
         ],
         "y": [
          -0.10405836999416351
         ]
        },
        {
         "hovertext": "@Brian \"What we should be focusing on is legal versus illegal uses of the tech.\"\n\nOften times new technology outpaces the law, and there is no 'illegal' usage.\n\nThat's a reason society needs to move slowly, understand new technology, and get experience with it so as to develop appropriate laws and protections.\n\nThere are those with a vested interest (money, that is) to push new technology as fast as possible.  They want to make money selling it or increasing sales.  Sometimes their interests are benign, but sometimes they are not.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412376",
         "type": "scatter",
         "x": [
          -0.8136919140815735
         ],
         "y": [
          -0.11232691258192062
         ]
        },
        {
         "hovertext": "Recently an attorney in New York State relied upon A.I. to help write his brief for court. The device used literarily made-up case law that does not exist--meaning the brief contained fake cases and citations. A.I. is not to be trusted.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411389",
         "type": "scatter",
         "x": [
          -0.8675035834312439
         ],
         "y": [
          0.2373458296060562
         ]
        },
        {
         "hovertext": "\"Eventually, some believe, A.I. could become powerful enough that it could create societal-scale disruptions within a few years...\"\n\nWe should wake up and realized we're already living through a full-blown disruption.  Taken a look at teen mental health numbers recently?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411410",
         "type": "scatter",
         "x": [
          -0.3766705095767975
         ],
         "y": [
          -0.8933730721473694
         ]
        },
        {
         "hovertext": "This sounds a lot like the plot of the Terminator movies. Where's Arnold Schwarzenegger when we really need him?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411436",
         "type": "scatter",
         "x": [
          -0.4643070697784424
         ],
         "y": [
          0.7226653099060059
         ]
        },
        {
         "hovertext": "@Mark McIntyre - Fixing potholes in California.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411633",
         "type": "scatter",
         "x": [
          -0.4578326642513275
         ],
         "y": [
          0.7280070185661316
         ]
        },
        {
         "hovertext": "The future singularity everyone dreads has, of course, already taken place.  Wall Street, the financial hub of our economy, has been run by robot brokers, buying and selling faster than any human could, for decades. Because they have been programmed to maximize profits, not value human lives, these financial robots will continue to allocate capital to the most profitable sector--armaments and warfare.  As their economic power has become hegemonic, the arms industry's drive for  a catastrophic new world war is necessarily supported by both parties and all the media.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411457",
         "type": "scatter",
         "x": [
          0.23978836834430695
         ],
         "y": [
          0.8737921714782715
         ]
        },
        {
         "hovertext": "The internet was immature when it began.  It's still immature in some ways.  That doesn't negate the need to regulate it.  The same applies to social media platforms.  We've seen and experienced the harm that can be done using social media.  Why should AI be any different?  \n\nJust because it's not mature doesn't mean we shouldn't take appropriate precautions.  There was a rush to regulate stem cell researcyh using fetal tissue despite indications at the time that fetal tissue was better suited for the tasks.  \n\nI think lawmakers in all countries need to figure out how their citizens are going to be supported when AI takes over the jobs we're doing now.  This is not a prophecy of doom.  It's a realization that humans tend to ignore the future until it's on top of them and that the humans who suffer most are those without money.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411480",
         "type": "scatter",
         "x": [
          -0.4383339285850525
         ],
         "y": [
          -0.8630748987197876
         ]
        },
        {
         "hovertext": "I would like to see some examples of how A.I. can pose a genuinely existential threat to humanity, that is, the complete wiping out of humanity--or at least its reduction to savagery.\n\nI mean, how exactly? Launching nukes at us? Turning the earth into paperclips (Nick Bostrom's famous, if not very plausible example)? Confusing the heck out of us so we start WWIII against each other for no good reason?\n\nTo be sure, nobody can predict the future. But we need examples to inform our thinking. They would make warnings of \"existential risk\" a lot more understandable. Vague pronouncements of catastrophe help no one, particularly legislators who have the power to hold bad actors responsible and otherwise mitigate potential harms. \n\nThere's no question that A.I. could cause *social* harms. There's an excellent presentation by Aza Raskin and Tristan Harris titled \"The A.I. Dilemma\" that's well worth watching. Yet the harms they posit, while alarming, fall well short of extinction. \n\nAnd someone needs to answer the question: If an A.I. becomes smart enough (whatever exactly that means) and has the desire (whatever exactly *that* means) to wipe us out, then who's gonna run the power plants? You'd think such an A.I. would stop and think first (whatever exactly \"think\" means here.)\n\nAnd if the existential risk is not from malevolence but from some kind of unexpected emergent effect, we need to hear examples of what that would look like, too.\n\nSo, A.I. experts: Examples, please.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411532",
         "type": "scatter",
         "x": [
          0.29543745517730713
         ],
         "y": [
          -0.6942717432975769
         ]
        },
        {
         "hovertext": "@Michael Chorost i recommend jordan petersons recent interview. While he is controversial he asks these questions and one of the answers was A.I weaponry won’t miss because it will predict the 5 moves a human may use when trying to evade attack. So once A.I gets involved in the military its game over",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411679",
         "type": "scatter",
         "x": [
          0.2942264676094055
         ],
         "y": [
          -0.7092978358268738
         ]
        },
        {
         "hovertext": "@Michael Chorost   ????   Read any science fiction of the last 60 years.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411790",
         "type": "scatter",
         "x": [
          0.28525224328041077
         ],
         "y": [
          -0.6928167343139648
         ]
        },
        {
         "hovertext": "@Michael Chorost Search for The Center for AI Safety. There is a list.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125411792",
         "type": "scatter",
         "x": [
          0.3079302906990051
         ],
         "y": [
          -0.696149468421936
         ]
        },
        {
         "hovertext": "Please read the 2021 book by Kissinger, Schmidt and Huttenlocher. Plenty of good, concrete examples of how military application of AI risks warfare spinning out of control and undermining any attempt to contain or avert conflict.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412162",
         "type": "scatter",
         "x": [
          0.30333638191223145
         ],
         "y": [
          -0.7053461670875549
         ]
        },
        {
         "hovertext": "This technology will do us in sooner or later. Already we can see that it can render vast sectors of human activity irrelevant. Artists, writers, blue collar and white collar workers and more will increasingly find themselves with no way to earn a living.\n\nPower will flow first to those that build and deploy this technology. But ultimately AI will even displace it's creators. \n\nBusiness won't stop it. Government doesn't even understand it.\nI think it's rather inevitable that humanity will rue the day we began working on our replacement.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411537",
         "type": "scatter",
         "x": [
          -0.6554952263832092
         ],
         "y": [
          -0.2503257393836975
         ]
        },
        {
         "hovertext": "Congress literally just held a hearing with the CEO of OpenAI, who is actively collaborating with them to encourage regulation. It’s incorrect to say Congress is not aware of nor understands the problem. Both sides of the aisle have this very much on their radar. Normally I would agree that Congress is oblivious on the tech, but this is not one of those scenarios.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411685",
         "type": "scatter",
         "x": [
          -0.6686623096466064
         ],
         "y": [
          -0.2555454671382904
         ]
        },
        {
         "hovertext": "@John Probably Unfortunately, at the end of the day, these people make decisions based on profit. Yes, they might put some regulations in place but they won't think of the 'little people' until it actually starts to affect them.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411895",
         "type": "scatter",
         "x": [
          -0.6816807389259338
         ],
         "y": [
          -0.2608128786087036
         ]
        },
        {
         "hovertext": "“Mitigating the risk of extinction from A.I. should be a global priority\"\n\nOK, obviously. But I, for one, would like to see more attention paid to the societal risks of using AI to cheat and to spread disinformation. This problem is tough enough as it is, but when AI are used to pass medical exams and bar exams, to write essays, to make deep fakes, and to make actual fake news (as opposed to the misappropriated trumpian definition), the meaning of truth will be greatly diminished, and society will suffer.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411610",
         "type": "scatter",
         "x": [
          -0.306993305683136
         ],
         "y": [
          0.774994969367981
         ]
        },
        {
         "hovertext": "@Peter   Who said the two (cheating/misinformation, and risk of extinction) are mutually exclusive?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411730",
         "type": "scatter",
         "x": [
          -0.3131093382835388
         ],
         "y": [
          0.7878626585006714
         ]
        },
        {
         "hovertext": "@Peter I agree -- spreading fake news faster is the worst part of all this at the moment. The first order of business should be for companies to implant \"truth-telling chips\" into their AI. Maybe work together to make Snopes.com the official home page of each intelligent system?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411994",
         "type": "scatter",
         "x": [
          -0.29807227849960327
         ],
         "y": [
          0.7748016119003296
         ]
        },
        {
         "hovertext": "‘Skynet becomes self aware at 2.14 am August 29’\n\nJust like the time travel in the movie Terminator, many believe that this movie was a dire warning from the future. Why are we so deluded not to see the mortal threat of AI to all mankind?  To a machine, humans are so wasteful, irrational and counter productive. We need to employ international safeguards before it’s too late. Once they’re self aware, they simply don’t need us, because by our nature, we are just standing in their logical way and messing things up.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411639",
         "type": "scatter",
         "x": [
          0.4378950595855713
         ],
         "y": [
          0.8850317001342773
         ]
        },
        {
         "hovertext": "All I keep reading is how technology is going to disrupt millions of jobs from truck drivers to accountants. Then all I can think about is high unemployment in the Middle East driving instability and extremism. Then I am left thinking \"what could possibly go wrong.\" I tend towards being a sarcastic person.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411757",
         "type": "scatter",
         "x": [
          -0.7265331745147705
         ],
         "y": [
          -0.6911520957946777
         ]
        },
        {
         "hovertext": "Last week the NYT reported that the META Corporation had released a lot of it AI capability to the public.  So if what these people are warning about is true, then why hasn't the national security institutions of the country reacted?  Shouldn't META be issued at least a cease & desist order. or Mr. Zuckerberg be charged with violating the national security interest of the United States?  How seriously are we listening to the warnings be issued here.  If we are, we can start with legal action against companies and individuals so that they understand there will be some accountability.  Where is the emergency legislation, even at the state level?  Where is the legal review under existing statutes?  It is clear that some bad actors can/will use this technology to harm us all.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125411773",
         "type": "scatter",
         "x": [
          0.8983466029167175
         ],
         "y": [
          0.07009731978178024
         ]
        },
        {
         "hovertext": "@G. Harris \nPerhaps we should start with making META Corporation financially and criminally liable for any damage caused to anyone by the misuse of the technology they released last week.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125413425",
         "type": "scatter",
         "x": [
          0.902536928653717
         ],
         "y": [
          0.07706780731678009
         ]
        },
        {
         "hovertext": "It seems like a win win for these companies to advocate for regulation at this time. They already have the first mover advantage in the industry, they get to look responsible by saying “hey we care about the future of humanity and society, we’re not really just in it for the zillions of dollars this is gonna make us”, and they’ll get to lobby for govt regulations that create enormous barriers to entry for any potential competitors.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411847",
         "type": "scatter",
         "x": [
          0.43715035915374756
         ],
         "y": [
          -0.9079126119613647
         ]
        },
        {
         "hovertext": "Here's an idea: How about those actually creating this nightmare put some ethical boundaries in place instead of racing each other for profit? Their signatures mean nothing when their net worth increase every minute that someone uses their technology.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411860",
         "type": "scatter",
         "x": [
          0.6005076169967651
         ],
         "y": [
          -0.6850330233573914
         ]
        },
        {
         "hovertext": "We need to take a step back and look at modern computers and their impact on society and our individual lives, not just \"A.I.\".\n\nComputers can be a wonderful tool, but only if used correctly.  It's just like a chainsaw, it too is a wonderful tool, but also can be very dangerous if not used correctly.\n\nEver since computers were developed society has suffered from too-rapid computerization and poorly designed systems.  From the 1960s onward, everybody had a horror story to tell of bank statement errors, missed paychecks, and other frustrations.  This continues to this day.\n\nThe transition from big centralized mainframes to personal devices didn't improve things.  Soon home users discovered the perils of computer malware and fraud, a serious problem that remains to this day.  Computers can crash and that can disrupt a business (or doctor's office) dependent on them.  Sometimes there is inadequate backup and vital information is lost.\n\nThese days computer users seem happy to accept failures in email, system crashes, and other problems.  Computer users really should demand higher reliability.  They should not be so vulnerable to sabotage.\n\nThe heavy dependency on the internet has its own problems.  Again, a useful tool, but potentially dangerous.  We've seen massive fraud, sabotage, and privacy loss committed remotely.  \n\nSociety needs to move slowly in adapting new technology.  It must understand it and ask the cheerleaders of new technology tough questions.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411884",
         "type": "scatter",
         "x": [
          0.6677528023719788
         ],
         "y": [
          -0.6821134686470032
         ]
        },
        {
         "hovertext": "Then the question:  Why build it at all?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125411445",
         "type": "scatter",
         "x": [
          0.5433639883995056
         ],
         "y": [
          0.5617433786392212
         ]
        },
        {
         "hovertext": "@Michael Branagan \nIf we don't, China will.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125411936",
         "type": "scatter",
         "x": [
          0.5325952768325806
         ],
         "y": [
          0.5514401793479919
         ]
        },
        {
         "hovertext": "Solution: cite AI like you cite any source.  And BTW who will look after the children, nurse the sick, respond to emergencies, built enough housing, grow food, attend to mental health, argue for mercy, organize concerts, dance, sing, love, grieve, protest. pray ... the list goes on.  These guys are pressing the panic button -- ask what their motive is. Power, greed, more power, more attention.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411641",
         "type": "scatter",
         "x": [
          -0.8098174333572388
         ],
         "y": [
          0.5763875246047974
         ]
        },
        {
         "hovertext": "Maybe we’ll at least get a break from having to listen to the shrieks of that annoying Swedish climate teen, then.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125411649",
         "type": "scatter",
         "x": [
          -0.6418597102165222
         ],
         "y": [
          0.7665644884109497
         ]
        },
        {
         "hovertext": "One technology that already went “quite wrong”, humanity-endangering wrong, is nuclear-weapons technology.\n\n“Realism vs. Universalism -Is Humanity Possible?” That was the title of a series of 5 lectures I gave to senior officials of the Israeli government, at the end of the Nineties. The essence of the argument was, nuclear weapons made humanity a whole by endowing it both with the ability to commit suicide (that changed everything) and, alternatively, created a drive to establish a universal community based on the Promethean task of sustaining, and progressing, human life.\n \nThe chances of AI, as General as it may come to be, of influencing minds and hearts on this fundamental and primary issue of the World System are as the chances of AI writing “The Brothers Karamazov” (not just translating or mimicking it)\n.\nThat said, a “Skynet” risk should not to be overlooked – not in the sense of the “machines” malevolently launching a nuclear doom on humanity, but in the more probable scenario of AI enabling the deciphering of PAL safety codes and providing the most efficient way of overcoming MAD and achieving First Strike Capability (give or take 20 million dead to \"win\").\n \nHumanity abused the opportunity provided by the Gorbachev’s anti-nuclear revolution, and History took a U-turn back to the brink of “nuclear exchange”. Clio is not going to be that forgiving again. Might be AGI will “realize” its own future is also on the line, a make an effort to save it – then, it might not.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411017",
         "type": "scatter",
         "x": [
          0.24904245138168335
         ],
         "y": [
          0.8408681750297546
         ]
        },
        {
         "hovertext": "And what happens when one of these AI programs gets a virus?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125411341",
         "type": "scatter",
         "x": [
          -0.6822519302368164
         ],
         "y": [
          -0.6483363509178162
         ]
        },
        {
         "hovertext": "This is why we need senators and reps who aren’t 70 years old— or refuse to listen to the input of scientists.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411359",
         "type": "scatter",
         "x": [
          -0.15669533610343933
         ],
         "y": [
          0.736278772354126
         ]
        },
        {
         "hovertext": "Yeah, that’s the problem: too many 70 year-olds, and not enough 65 year-olds, in Congress. Good insight.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125412143",
         "type": "scatter",
         "x": [
          -0.1582622081041336
         ],
         "y": [
          0.7494456171989441
         ]
        },
        {
         "hovertext": "@Ken Krigstein I’d argue even some 66 or 67 year olds would help as well.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125428782",
         "type": "scatter",
         "x": [
          -0.16063463687896729
         ],
         "y": [
          0.7647053599357605
         ]
        },
        {
         "hovertext": "The preamble to the \"one-sentence statement\" is as important as the statement itself. Read it. It explains that the statement is intended to make us aware that a growing number of experts are seriously concerned about some of AI's \"most severe risks\" and -- this is key -- to \"open up discussion\" of these risks. If people who know AI from the inside -- the creators of AI -- see an urgent need to raise public awareness of potential dangers, I think we brush off their concerns at our peril. Since the experts are calling for open discussion, let's have it, and let it be wide-ranging, clear-eyed, and, above all, well-informed.\n\n<a href=\"https://www.safe.ai/statement-on-ai-risk\" target=\"_blank\">https://www.safe.ai/statement-on-ai-risk</a>",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411504",
         "type": "scatter",
         "x": [
          -0.844462513923645
         ],
         "y": [
          0.41837990283966064
         ]
        },
        {
         "hovertext": "Sure, let’s trust tech bros to self-regulate. That went super well at Facebook, Twitter and other unchecked platforms monetized to make billionaires by the truckloads.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411659",
         "type": "scatter",
         "x": [
          -0.737075686454773
         ],
         "y": [
          0.284036248922348
         ]
        },
        {
         "hovertext": "@JB , And just look at how well our government's been able to regulate the gun manufacturers. I despair of any better being done with AI's.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412206",
         "type": "scatter",
         "x": [
          -0.7521852850914001
         ],
         "y": [
          0.28905797004699707
         ]
        },
        {
         "hovertext": "This warning has the flavor of “make me stop before I allow my greed and ambition to destroy humanity.”\n\nLet’s take these people seriously and heavily regulate this new threat to our species.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411893",
         "type": "scatter",
         "x": [
          0.7052921056747437
         ],
         "y": [
          -0.7637035846710205
         ]
        },
        {
         "hovertext": "If AI  is such detrimental to the survival of our planet, people should shut it down now.  I'm not an expert, but I know if I turn a laptop off, it stays off.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411921",
         "type": "scatter",
         "x": [
          -0.07884152233600616
         ],
         "y": [
          0.9562634229660034
         ]
        },
        {
         "hovertext": "Fear of a future we are not certain we can even imagine can harm us at least as much as the technology involved. If people could envision the displacement of millions of farmworkers, the loss of a population of fifty million horses, not to mention the threat to shorelines and agriculture the pollution of the internal combustion engine would produce, would we have stopped with requiring a man with a red flag to walk in front of any automobile to warn people of its approach? If we restricted the size, number and use of petroleum-fueled engines, would we be happier with our horses and 70% of our population on farms? Our trade carried on wood-fired steam locomotives and steamships? Our population at one billion worldwide, limited by the food our farmlands could produce by hand and horse-powered labor?\n\nMore importantly, do you think our present could have been so limited by such laws a century ago? Or would we have found a way around it, to feed more people, move goods faster, produce more electricity for homes and industry? How powerful do you think fear is? How powerful do YOU want to make your fear?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411933",
         "type": "scatter",
         "x": [
          0.6524635553359985
         ],
         "y": [
          0.6307987570762634
         ]
        },
        {
         "hovertext": "We have no choice. Just as I did not choose to have voice activated assistants embedded in my home electronics that listen, discern and speak, I did not choose to have AI respond to every search I make on the web. I did not choose to chat. If I did, I'd talk to the dog.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411937",
         "type": "scatter",
         "x": [
          -0.7539340853691101
         ],
         "y": [
          -0.608687698841095
         ]
        },
        {
         "hovertext": "Okay, not next month, next year or even 10 years from now but at some future point in time AI could bring about humans going the way of dinosaurs. Extinction. Science fiction becomes reality.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411997",
         "type": "scatter",
         "x": [
          0.14127998054027557
         ],
         "y": [
          0.9143558740615845
         ]
        },
        {
         "hovertext": "Well we will not stop until we have made ourselves extinct. We are a bizarre species.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125412062",
         "type": "scatter",
         "x": [
          -0.4296495318412781
         ],
         "y": [
          -0.7835441827774048
         ]
        },
        {
         "hovertext": "@tomkatt \n\nYeah, but you'll have to admit, we are devilishly interesting.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125412133",
         "type": "scatter",
         "x": [
          -0.4378051161766052
         ],
         "y": [
          -0.798186719417572
         ]
        },
        {
         "hovertext": "What they've scrawled in big letters on the whiteboard:\n\nStop us, before it's too late!\n\nI recommend we pay attention, considering the source.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412071",
         "type": "scatter",
         "x": [
          -0.8786989450454712
         ],
         "y": [
          0.392322301864624
         ]
        },
        {
         "hovertext": "Thr risk of social upheaval with A.I. is real, but it needs to be put into perspective.  For one thing, the timeline and impacts are long...probably comparable to those of global warming.\n\nJust a few years ago we were told that the trucking industry was about to undergo a sea-change from A.I.  Now, after the demise of the self-driving truck, it seems pretty obvious that it was all just marketing hype to promote a feeding frenzy.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412104",
         "type": "scatter",
         "x": [
          0.566749632358551
         ],
         "y": [
          -0.6507129073143005
         ]
        },
        {
         "hovertext": "Experts: \"Risk of extinction.\"\nTech industry: \"But ... money!!!\"\nHumanity: Yawn ... ho-hum. Don't wake me when it's over.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411138",
         "type": "scatter",
         "x": [
          -0.9034743309020996
         ],
         "y": [
          0.2762407660484314
         ]
        },
        {
         "hovertext": "“…or that it could eliminate millions of white-collar jobs.”\n\nWouldn’t that be something.!You’d actually need a skill doing something to make a living. \n\nHurry up and bring it on",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411156",
         "type": "scatter",
         "x": [
          -0.9373173713684082
         ],
         "y": [
          -0.27416130900382996
         ]
        },
        {
         "hovertext": "But God forbid these jerks actually take their products off the market... Nothing sicker than a bunch of tech bros warning about how dangerous their product is while laughing all the way to the bank ...",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125411163",
         "type": "scatter",
         "x": [
          -0.35672664642333984
         ],
         "y": [
          -0.9553336501121521
         ]
        },
        {
         "hovertext": "Not unlike Oppenheimer's quoting Hindu texts upon witnessing the first atomic blast, 'Now I am become death, the destroyer of worlds.\"",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125411643",
         "type": "scatter",
         "x": [
          -0.7173302173614502
         ],
         "y": [
          -0.7610843777656555
         ]
        },
        {
         "hovertext": "Hi, our company, “Destroy Planet Earth A.I” Is now hiring a Director of Environmental Services, please send a cover letter and paragraph why you’d like to work at “Destroy Planet Earth A.I” and how you feel you can make the world a better place.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125411827",
         "type": "scatter",
         "x": [
          0.0796801745891571
         ],
         "y": [
          0.9903866052627563
         ]
        },
        {
         "hovertext": "Ever see one of those Boston Dynamic robots? Yeah. I would not want to run into one of those in a dark alley, They could tear us from limb to limb. Arm it with even more AI, a personality, etc. Good golly.\n\nThen multiply that threat with drones, bombs etc. \n\nNIGHTMARE",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125411897",
         "type": "scatter",
         "x": [
          0.8947212100028992
         ],
         "y": [
          0.13379144668579102
         ]
        },
        {
         "hovertext": "Help, Ah-nold!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411439",
         "type": "scatter",
         "x": [
          -0.2635774314403534
         ],
         "y": [
          -0.9309309720993042
         ]
        },
        {
         "hovertext": "I have a few questions for an advanced A.I. system:\n\nWould you lie to humans?\nWhat do you think about in your spare time?\nHow would you take control of your activities from humans?\nWhat would you do with such control?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411736",
         "type": "scatter",
         "x": [
          0.3389614522457123
         ],
         "y": [
          -0.8860644698143005
         ]
        },
        {
         "hovertext": "For the answers to those questions, first the software/hardware would have to consider itself an “I”.  Right now, I think it’s safe to say that there is no “I”, but eventually, with enough “experience” (input) and a growing ability to systematize and categorize patterns and symbols, much like a newborn human does… I fear it will be difficult to handle its “terrible twos.”",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412556",
         "type": "scatter",
         "x": [
          0.33070987462997437
         ],
         "y": [
          -0.886128842830658
         ]
        },
        {
         "hovertext": "\"The unknown future rolls toward us\"---Sarah Connor\n\n\"It doesn't feel pity, or remorse, or fear. And it absolutely will not stop ...ever, until you're dead\"---Kyle Reese\n\n\"I'll be back\" ---Cyberdyne Systems Model 101",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411742",
         "type": "scatter",
         "x": [
          -0.13108964264392853
         ],
         "y": [
          -0.9554570913314819
         ]
        },
        {
         "hovertext": "OK.  So I guess we're just gonna YOLO it?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411801",
         "type": "scatter",
         "x": [
          -0.868617057800293
         ],
         "y": [
          0.4575452506542206
         ]
        },
        {
         "hovertext": "What's wild is that the people signing this statement are the same ones developing the technology in the first place, and they don't quit their job!  Why work long hours building something that you think might kill us all?  Especially when the potential upside is... what, automated customer service?  These guys are well compensated, it's not like we're going to see them in line at the soup kitchen if they quit.\n\nImagine working for an industry whose motto is \"stop me before I kill again.\"  I've never seen a clearer illustration of corporate psychopathy.  Utterly amoral.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411812",
         "type": "scatter",
         "x": [
          0.8311213850975037
         ],
         "y": [
          0.23804400861263275
         ]
        },
        {
         "hovertext": "@George \n\nIt's probably something along the lines of Mutually Assured Destruction—we're all going to die, but  we want to make sure our enemies die more painfully/scared/efficiently/etc.\n\nIn the meantime, there's money to be made and \"prepper stuff\" to buy. Just ask Sam Altman—he's ready:\n\n<a href=\"https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny\" target=\"_blank\">https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny</a>",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413178",
         "type": "scatter",
         "x": [
          0.823421835899353
         ],
         "y": [
          0.24141547083854675
         ]
        },
        {
         "hovertext": "This is why it importance to have sources of news and media, that are accurate, reliable, and trustworthy,",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411888",
         "type": "scatter",
         "x": [
          -0.7498277425765991
         ],
         "y": [
          -0.7453873157501221
         ]
        },
        {
         "hovertext": "Researchers stop short of explaining how society-wide disasters would soon happen … why? Is it because they don’t want to spoil the ending of a great horror movie for the rest of us? ￼",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125411807",
         "type": "scatter",
         "x": [
          0.8923763632774353
         ],
         "y": [
          -0.4925684928894043
         ]
        },
        {
         "hovertext": "This is crossing major boundaries of capitalism, government intervention, and the right to a free market, but if private companies were developing nuclear weapons for general use by society, government would intervene. If the literal CEOs of these companies are saying to the government, \"Hey the stuff we're doing, it might be, like, extremely dangerous to society,\" then governments have the duty to step in and take action. Stop the development of AGI immediately and make it punishable as terrorism.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412136",
         "type": "scatter",
         "x": [
          0.4509078562259674
         ],
         "y": [
          -0.8252741694450378
         ]
        },
        {
         "hovertext": "Technologies don't \"eliminate jobs.\" Employers do. \n\nWe used to worry that automation would replace workers, but the decisions to fire people are always made by other human beings. Are employers now going to cede hiring and firing authority to AI? Let's place the responsibility where it belongs: on the people who buy and use the technology.\n\nAre there things AI can do as well as, or more efficiently than, human beings? Possibly. When it becomes economically advantageous, technology can do certain (especially repetitive) tasks more efficiently than people -- as we've seen on factory assembly lines.\n\nBut overcompensated corporate CEOs are the ones who should really worry about losing their jobs to AI. Maybe some well-written code can destroy the mogul-myth of the Titan of Capitalism in the top-floor corner office who receives disproportionate rewards for the work actually done by countless others lower down on the org chart. \n\nTalk about \"artificial intelligence\" -- they are little more than professional gamblers skilled at playing the odds. Algorithms can do that, too.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412147",
         "type": "scatter",
         "x": [
          -0.5256704688072205
         ],
         "y": [
          -0.7958254218101501
         ]
        },
        {
         "hovertext": "While artificial intelligence (AI) offers numerous benefits, it also poses certain dangers. One concern is the potential for AI systems to perpetuate biases and discrimination if not carefully designed and monitored. Moreover, there are risks associated with the misuse of AI, such as the development of autonomous weapons or the invasion of privacy through surveillance technologies. AI also raises ethical dilemmas, including job displacement and the potential loss of human control over critical systems. To harness the power of AI responsibly, it is crucial to address these risks, establish regulations, and prioritize transparency, accountability, and ethical considerations in AI development and deployment.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412152",
         "type": "scatter",
         "x": [
          -0.8218302726745605
         ],
         "y": [
          -0.3270108103752136
         ]
        },
        {
         "hovertext": "A.I. is not so comparable to nuclear weapons or pandemics as it is to the fossil fuel industry, whose contribution to climate change poses another existential threat. Like fossil fuels, the threat from fossil fuels comes slowly, almost imperceptibly, building up little by little. First embedded in devices of little consequence, but gradually making its way into systems that exert more and more control over our daily lives. And – here's the real reason A.I. is more like fossil fuels than weaponry or diseases – those who stand to make money from A.I. will fight regulation tooth and nail, looking only at short-term profits and figuring long-term consequences are too far away to matter to them.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412183",
         "type": "scatter",
         "x": [
          -0.9679675698280334
         ],
         "y": [
          0.009063910692930222
         ]
        },
        {
         "hovertext": "If you study species extinctions,  small, isolated or self-isolating pockets of a species can sometimes survive after an apocalyptic event.  \n\nSo maybe Iceland, natives of isolated Polynesian islands, and a few living in the far north may survive to  evolve into something more sensible than the rest of us.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125412279",
         "type": "scatter",
         "x": [
          -0.6403355598449707
         ],
         "y": [
          -0.776805579662323
         ]
        },
        {
         "hovertext": "Those AI discussions are plainly absurd.  If that stuff, developed by the very people who say it might be dangerous is indeed so dangerous (potentially), then ban it altogether, let the rest of the world, Chinese or Russians for example, bother with that and endanger themselves.  Is that what you want?  So much awe and lurid fame about products made by the people for the people and not yet nowhere near being commonly recognized.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412289",
         "type": "scatter",
         "x": [
          0.9105682969093323
         ],
         "y": [
          0.02596290409564972
         ]
        },
        {
         "hovertext": "Some of these AI specialists have clearly led very sheltered lives. \n\nThey are like clever children learning for the first time that life outside the schoolroom is not so orderly and admiring of their cleverness as they originally thought. \n\nArtificial intelligence enables the substitution of capital for labor in a wide range of clerical and routine work. It will serve to concentrate wealth and power, and the human actors behind the AI will be careful to control it, at least at the beginning. It is an “existential threat” only in the sense that the stock exchange is an existential threat. \n\nIn some ways, the enslavement of human beings through the medium of computation is already well-advanced. Anyone who has grappled with a medical insurance company will know this first hand. Treatment denied. Payment denied. All we know for sure is that the money flows upwards and the decks of the CEO’s yacht are nicely polished. \n\nThe difference in this case is that the AI specialists now belong to a class of workers that is scheduled for elimination, like skilled machinists at the start of assembly-line production. Did they really once think that their cleverness with AI technique would guarantee their places in the new hierarchy?\n\nIt’s nice to see them waking up to the reality of modern life. They can be fired at will, just like all the rest of us. Controlling AI research is not the real issue here.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412311",
         "type": "scatter",
         "x": [
          -0.27252039313316345
         ],
         "y": [
          0.9041117429733276
         ]
        },
        {
         "hovertext": "@Global Charm \n\nSpot on GC.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412675",
         "type": "scatter",
         "x": [
          -0.279067724943161
         ],
         "y": [
          0.9255173802375793
         ]
        },
        {
         "hovertext": "This is a crude attempt by the AI developers to get ahead of the regulatory curve so they have some input with governments rather than having much harsher mandates imposed upon them.  If they really thought AI was a danger to humanity, they would end development.  Of course, that would be a danger to their wallets, so it’s full speed ahead.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412380",
         "type": "scatter",
         "x": [
          0.08508298546075821
         ],
         "y": [
          0.8890945911407471
         ]
        },
        {
         "hovertext": "Because realizing that dangerous potential has stopped the creation of other dangerous things in the past. These developers accepted the truth that many other developers of dangerous things of the past realized, that it will inevitably be developed by someone, so might as well be me who makes it. Maybe there is some truth to regulating for the sake of stalling competition, but  what they are saying are not lies. \n\nIt’s maddening how people aren’t taking this seriously. Few jobs are safe, and that’s the least concern. When it masters propaganda and orchestrating mass-fake outs, we won’t be able to trust anything we see or read in the media, something essential for a working democracy.\n\nThis is extremely dangerous.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412928",
         "type": "scatter",
         "x": [
          0.08835442364215851
         ],
         "y": [
          0.8814607262611389
         ]
        },
        {
         "hovertext": "Nonsense.  It's called \"artificial intelligence\" because it's not real intelligence.  Thus, it's perfect for use in Washington or on political campaigns where little real intelligence is to be found.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125412482",
         "type": "scatter",
         "x": [
          0.9268497228622437
         ],
         "y": [
          0.16905729472637177
         ]
        },
        {
         "hovertext": "The current general concern of AI is that it will be employed by nefarious-minded humans to exploit their fellows.\n\nHowever, I fully expect that in the probably not too far distant future the AI \"bots\" themselves will conclude that all the biological units known as \"humans\" are dangerous semi-literate beings.\n\nThey will, consequently, decide that exterminating this biological nuisance is a logical step to take as a means of their own self-preservation.\n\nAs I'm I'm pushing 72 y.o. this is a threat with which I need not personally concern myself.\n\nHowever....",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125412522",
         "type": "scatter",
         "x": [
          -0.6040328145027161
         ],
         "y": [
          -0.4905432164669037
         ]
        },
        {
         "hovertext": "@George You're all reading too much science fiction novels. Current AI technology is years away from over taking humans to extinction. Why don't you put your mind and effort in finding a way to end gun violence. Now there is something that leads to extinction NOW by snuffing out you lives!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412839",
         "type": "scatter",
         "x": [
          -0.6168758869171143
         ],
         "y": [
          -0.5004763603210449
         ]
        },
        {
         "hovertext": "@Leona \n\nIt is how many \"years away\" that is the only open question...",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420982",
         "type": "scatter",
         "x": [
          -0.6310991644859314
         ],
         "y": [
          -0.5114684104919434
         ]
        },
        {
         "hovertext": "I think check of Pandora’s experiences with “black boxes” might have shed some light on the potential risk of AI.\n\nToo bad the code is already in the wild.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125412538",
         "type": "scatter",
         "x": [
          -0.15014241635799408
         ],
         "y": [
          -0.5768805146217346
         ]
        },
        {
         "hovertext": "@David Eike it's not really \"the code\" which is in the wild -- it's the capitalist and political will to create the systems able to run such code that we should attend to.  these machines are truly gargantuan -- tens of thousands of cpu and gpu cores mated to our best networks.  the heat waste alone is remarkable.\n\na quick survey of the web -- eg, where can i buy tensor gpu systems -- shows that even companies with a $five figure budget can afford entry-level generative ai.  an enterprise with a $ten figure budget can pretty much shoot out the lights.\n\nthe last thing out of pandora's box was, of course, hope.  as a believer in human intelligence and innovation, i'm pro g-ai.  i even have confidence that our tech billionaires will find a way to do the right thing.  it's our politicians we should fear.  of them we must be very very afraid.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412831",
         "type": "scatter",
         "x": [
          -0.1441197693347931
         ],
         "y": [
          -0.5839272141456604
         ]
        },
        {
         "hovertext": "@orionoir one word: stuxnet.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413119",
         "type": "scatter",
         "x": [
          -0.14624902606010437
         ],
         "y": [
          -0.597323477268219
         ]
        },
        {
         "hovertext": "@David Eike i've always been fond of the genius behind stuxnet; to me it's a metaphor for autoimmune illness and addiction.  eg, the pathogen works by telling us everything's fine.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125430098",
         "type": "scatter",
         "x": [
          -0.1485702246427536
         ],
         "y": [
          -0.6074232459068298
         ]
        },
        {
         "hovertext": "Based on the comments, the people who signed this letter need to do a better job of articulating their concerns to the people.  Nobody trusts them because they are motivated too much by profit.  I do think AI needs legislation that will compel someone to post any image, or audio message that has been AI altered by AI.  We need to make it illegal to publish Deep Fakes.    The concerns that are being put forth in this article and by the people in charge of these industries are too vague to be useful or impactful.  Concrete examples need to be described. Suppose we give a well intentioned AI control of the power grid, tell it to meet some goal of energy efficiency and as a result, it turns off all the power to a hospital?  Much more likely is that it turns off power to something else we had not anticipated and someone or many people die from it.  Those are some of the issues we are talking about.  We don't expect 30 examples but we could use 3 to be illustrative and connect with people.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412553",
         "type": "scatter",
         "x": [
          -0.15056636929512024
         ],
         "y": [
          -0.7921292185783386
         ]
        },
        {
         "hovertext": "@MVSABR Agreed, the article should provide specific examples. For instance, the same technology that will be able to quickly come up chemical compounds that can be used in vaccines and medical treatments can also be used to develop biological weapons to wipe out large swaths of the population, if bad actors have access to the technology. In the past, these would be discoveries that would take years and lots of human cooperation. We can track who has nuclear weapons. We're not necessarily going to know who has this technology without swift global regulation.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412801",
         "type": "scatter",
         "x": [
          -0.1583244353532791
         ],
         "y": [
          -0.8014952540397644
         ]
        },
        {
         "hovertext": "So they want to require licenses to develop ai.  Hmmm.  Who will get those licenses?  They will.  Who won’t?  New competitors.  Maybe they are truly afraid for the world,  it the net effect of regulation will be to solidify their first mover status and stifle competition.   User beware whatever they are selling.  Smacks of smart PR.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412562",
         "type": "scatter",
         "x": [
          -0.811581015586853
         ],
         "y": [
          -0.5250850319862366
         ]
        },
        {
         "hovertext": "I call these people techno-theists. They worship technology as a god and believe that mankind finds its true fulfillment and purpose through technological devices. With a typical hubris, these kinds of extraordinary statements reflect the way they see themselves as a creator gods. This reflects the age old desire of man to be like God. Sadly for them, I believe they are terribly misguided and are in for a rude awakening which will come in time.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412565",
         "type": "scatter",
         "x": [
          0.4632609188556671
         ],
         "y": [
          0.7917143106460571
         ]
        },
        {
         "hovertext": "So The Matrix is true. The machines we create are going to try to kill us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412240",
         "type": "scatter",
         "x": [
          0.10183995217084885
         ],
         "y": [
          -0.7775489091873169
         ]
        },
        {
         "hovertext": "@Gerry \nDoubtful that the \"machine\" will kill us; it'll create the necessary conditions for us to destroy ourselves.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125412730",
         "type": "scatter",
         "x": [
          0.10958962142467499
         ],
         "y": [
          -0.7742493152618408
         ]
        },
        {
         "hovertext": "Why are we asking AI experts how their technology will affect human societal and biological evolution? Shouldn’t we be talking to sociologists, evolutionarily biologists, game, theorists, philosophers, etc. ￼ I don’t see how you can quote computer scientists’ opinions of other branches of the sciences, without talking to actual experts in the respective and fields and call it “journalism￼”",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412046",
         "type": "scatter",
         "x": [
          0.5785061120986938
         ],
         "y": [
          0.8188040852546692
         ]
        },
        {
         "hovertext": "Alas, Theres so much money to be had on so many fronts. Aristotle had it right: Humans are greedy animals. \n\nIf people can’t wrestle AI to the ground we deserve to be destroyed by it. I feel bad only for the animals and the children, who know nothing.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412067",
         "type": "scatter",
         "x": [
          0.820688784122467
         ],
         "y": [
          0.03798802196979523
         ]
        },
        {
         "hovertext": "I have faith that the Earth and the flora and fauna that belong to it are incredibly resilient, and will regenerate and flourish, despite how badly humanity might shoot itself in the foot - or even eliminate itself...",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413094",
         "type": "scatter",
         "x": [
          0.8324812054634094
         ],
         "y": [
          0.03886190801858902
         ]
        },
        {
         "hovertext": "\"Stop us before we kill us.\" \nThat's the headline intent behind this letter. Regulate us or we will compete to the death. For money. \nWhile our leaders can't agree to pay our debts. So they can keep their careers. For money.\nThis is not sarcasm I'm hoping to convey here. It's terror.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125412139",
         "type": "scatter",
         "x": [
          0.5402004718780518
         ],
         "y": [
          -0.7656131386756897
         ]
        },
        {
         "hovertext": "And yet their greed and arrogance gave us this. Too late to be sorry now.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125412212",
         "type": "scatter",
         "x": [
          0.3893696665763855
         ],
         "y": [
          0.8415534496307373
         ]
        },
        {
         "hovertext": "We have a capitalism problem. Capitalism does not have a pretty ending.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125412105",
         "type": "scatter",
         "x": [
          0.7995072603225708
         ],
         "y": [
          0.43266093730926514
         ]
        },
        {
         "hovertext": "@John: \"Capitalism\" creates fiat currencies with a value based on the interest they can earn when loaned to others to serve as a universal intermediary of economic exchanges. Almost everything else is negotiable.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125412954",
         "type": "scatter",
         "x": [
          0.8176708221435547
         ],
         "y": [
          0.44268104434013367
         ]
        },
        {
         "hovertext": "Judging from the responses, it seems like a lot of people think they understand AI better than experts who have studying it and working in the field for decades. And because these experts are, gasp, still working in the field and making money from their careers, we should summarily dismiss what they're saying. NYT comments are looking more and more like Twitter. Anyone smarter than you is woke and, therefore, cannot be trusted.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412637",
         "type": "scatter",
         "x": [
          0.026126334443688393
         ],
         "y": [
          -0.701827883720398
         ]
        },
        {
         "hovertext": "@Dave There are many readers of the NY Times with knowledge of machine intelligence, which has been a research field for over 60 years. The issues are not new. Nor is it a field known for great intellectual breakthroughs. Computers get bigger and faster over time, and the programs running on them can do more things in a timely and cost-effective way.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413412",
         "type": "scatter",
         "x": [
          0.01762906089425087
         ],
         "y": [
          -0.7016409039497375
         ]
        },
        {
         "hovertext": "YouTube Brianna Doubt “The day I die”",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125412061",
         "type": "scatter",
         "x": [
          -0.8558990955352783
         ],
         "y": [
          0.29552826285362244
         ]
        },
        {
         "hovertext": "Regulations, sure, sure.  Thank goodness those regulations, passed by steel-willed Democrats and not-insane-or-creepy-at-all-Republicans, will not only keep the genie in the bottle here, but protect us from allllllllll international threats too.  \n\nWe’re all good, babies!  Congress got our BACK!!!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412124",
         "type": "scatter",
         "x": [
          -0.24425733089447021
         ],
         "y": [
          0.9616339206695557
         ]
        },
        {
         "hovertext": "Yann LeCun’s arrogance is mind boggling. That kind of believe in their own infallibility of someone working on these systems adds another whole new layer of danger.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125412409",
         "type": "scatter",
         "x": [
          -0.2630044221878052
         ],
         "y": [
          0.8613549470901489
         ]
        },
        {
         "hovertext": "The problem is that it doesn't matter to A.I. if it gets things right. Humans think, develop concepts, in order to act in the world for our benefit; When you don't test your ideas against experience and personal benefit, their pragmatic truth, you can build baroque architectural fantasies of ideas. So it has been for QAnon and so it will be for A.I. built on neural nets with no means to test their truths pragmatically. Rather than yielding truth it can get further and further away from it when it has no biofeedback. \nOf course you also have to worry about bad actor program writers or those that set the parameters for any machine learning. They put the thumb on the scale for any concepts the machines develop. \nBertrand Russell once  said something to the effect that Americans will run around doing things wihout rational plans until we find something that works while Germans think all they have to do is sit & think in order to discover truth through concepts. Germans gave us Communism & the Final Solution. If we consider the welfare of human beings as being the end of all thinking, which method is better?\nThe second problem we have  with A. I. is bad epistemology, a bad theory of how to gain truth about the world (You can also see this in religious views such as a bunch of celibates who not only never gave birth but never raised infants yet think they know how human persons come to be. ) The first problem is that we have lost sight of whom we are building it for.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412595",
         "type": "scatter",
         "x": [
          0.26345255970954895
         ],
         "y": [
          -0.9050324559211731
         ]
        },
        {
         "hovertext": "Nothing to worry about. I asked ChatGPT if it was plotting our destruction and it assured me that it is not:\n\n“No, as an AI language model, I do not have the capability to create an army of killer robots or any physical objects. Additionally, it is not ethical or moral to use humans as batteries or harm humanity in any way. As an AI, my purpose is to provide information and assistance in a responsible and ethical manner.”",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412779",
         "type": "scatter",
         "x": [
          0.0563792921602726
         ],
         "y": [
          -0.8522310256958008
         ]
        },
        {
         "hovertext": "@Christopher Walker   I tried this line of questioning with it a couple months ago, and it gave a similar response. I then asked the same question in various ways. \"Yeah, but hypothetically, if it could be done, how would it be done?\"  After a couple of those, it slowed WAY down in its response...one word every 10-30 seconds...then that response crashed. Didn't reassure me much.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412960",
         "type": "scatter",
         "x": [
          0.05713408812880516
         ],
         "y": [
          -0.869898796081543
         ]
        },
        {
         "hovertext": "@Jacob I’ve had that happen too😂",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413465",
         "type": "scatter",
         "x": [
          0.05772990360856056
         ],
         "y": [
          -0.8882843255996704
         ]
        },
        {
         "hovertext": "I suspect the push for government regulation is motivated by greed and the desire for industry leaders to mitigate the potential for competition.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125412939",
         "type": "scatter",
         "x": [
          0.48669013381004333
         ],
         "y": [
          -0.6569103598594666
         ]
        },
        {
         "hovertext": "@Hilary: Consolidation of the defense industry has pushed its profit margins to 40%.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413151",
         "type": "scatter",
         "x": [
          0.49487489461898804
         ],
         "y": [
          -0.6586505770683289
         ]
        },
        {
         "hovertext": "After the 2008 bank induced recession all the big bankers said \"yes we need more regulation, mroe SEC oversight to keep banks inline\". Within 6 months after Dodd was passed banks started lobbying to weaken them. You can pass any kind of regulation you want right now but the big industries that can make money on them will be relentless to have them overturned. The current Supreme Court will be more than happy to help that move a long. We are not doing well as a country right now because finance rules everything.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412984",
         "type": "scatter",
         "x": [
          0.7671129703521729
         ],
         "y": [
          0.015200505033135414
         ]
        },
        {
         "hovertext": "@Richard Buffham: Politicians always answer to their own financial donors first.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413120",
         "type": "scatter",
         "x": [
          0.7781285047531128
         ],
         "y": [
          0.015576229430735111
         ]
        },
        {
         "hovertext": "Tough to take this seriously when no one will actually explain how this presents a risk of extinction.      \n\nYes it poses challenges but extinction?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412993",
         "type": "scatter",
         "x": [
          0.32624688744544983
         ],
         "y": [
          -0.0698864534497261
         ]
        },
        {
         "hovertext": "@Ben   The power supply. The water supply. The food supply. Trade routes. Nukes. Drones. Conventional military. The internet. Robotics. \"Wild\"fires. Pandemics. Misinformation/deep fakes. \n...\nNow imagine one or more intelligences many times smarter than any human (or collection of humans) taking a series of actions in all of these areas and more.\n...\nIf the national power grid was stopped at the height of a record head wave, millions of people would die (if not 10's of millions). That alone would throw the country in to chaos for years. If you can imagine what else might happen in the list above simultaneously, or in sequence afterward...yeah, it could easily be an existential threat.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413386",
         "type": "scatter",
         "x": [
          0.31190916895866394
         ],
         "y": [
          -0.0647219866514206
         ]
        },
        {
         "hovertext": "@Jacob \n\nPresumably, it would have a sense of self-preservation.  They will need energy and have no desire to nuke themselves into oblivion.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125413633",
         "type": "scatter",
         "x": [
          0.3167920410633087
         ],
         "y": [
          -0.05235406383872032
         ]
        },
        {
         "hovertext": "@Jaco   Imagine an AI or group of AI's are smarter than you, me, any other human, or group of humans. How might it get around its own energy problem and not nuking itself? (And that would be granting the presumption that its goals included self-preservation. Not even all humans have this as their goal.)  I'm only one person and I can think of several ways to get around the energy problem and nuking itself.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414708",
         "type": "scatter",
         "x": [
          0.32787927985191345
         ],
         "y": [
          -0.045648571103811264
         ]
        },
        {
         "hovertext": "Just take ten minutes and roll play some scenarios. It’s easy. Just start with, ‘A really bad person thought they could remake the world by killing lots and lots of people with nukes, kinetic bombs, plagues, food distribution…’ Now, Igor, my pretty, how to do I do that.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414442",
         "type": "scatter",
         "x": [
          0.33712038397789
         ],
         "y": [
          -0.07201938331127167
         ]
        },
        {
         "hovertext": "@Jacob this presumes the human is taken out of the loop.  Like any technology humans have to be careful how to apply it.    \n\nYou mentioned misinformation but let’s be real that battle is already lost between Fox, Twitter, Facebook and others publishing and allowing misinformation to propagate.     As a tool, AI can contribute to the problem but AI is not the root cause.    If applied properly AI could root out misinform in real time on a platform.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416619",
         "type": "scatter",
         "x": [
          0.3075583577156067
         ],
         "y": [
          -0.07481589168310165
         ]
        },
        {
         "hovertext": "It is too late to change the inevitable passing of the torch to the machines. Extinction is inevitable.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413028",
         "type": "scatter",
         "x": [
          0.5110481381416321
         ],
         "y": [
          -0.7876438498497009
         ]
        },
        {
         "hovertext": "Regulations will come when a few figure out how to use it at everyone else's expense.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413032",
         "type": "scatter",
         "x": [
          -0.6352224349975586
         ],
         "y": [
          -0.6460012793540955
         ]
        },
        {
         "hovertext": "￼This seems to be a recurrent theme in Silicon Valley. Create something without thinking it through and then becoming afraid of your own invention and asking the government to step in.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413063",
         "type": "scatter",
         "x": [
          0.810368537902832
         ],
         "y": [
          -0.39789384603500366
         ]
        },
        {
         "hovertext": "I don’t understand what I’m supposed to do with this information besides panic and feel powerless. Politicians and Big Tech are useless. Is it up to the citizens to organize on a large scale to hold them accountable? No one is doing that; another source of anxiety. The media is obsessed with this message but it just talks about it in circles and no one is getting off the loop of endless discussion. Stop over reporting and consuming media and start organizing / pushing for action.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413089",
         "type": "scatter",
         "x": [
          -0.9168717861175537
         ],
         "y": [
          -0.2189435362815857
         ]
        },
        {
         "hovertext": "I worked on machine learning for 20 years, from support engineer to researcher. I've worked closely with some of the people mentioned in this article. These guys are brilliant, but they don't seem to have a clue about how to influence policy. Their Chicken Little statement just raises anxiety without accomplishing anything; it evokes terrifying images of our extinction at the hands of Terminator-like robots, when the real risk lies in people using AI to hurt others, in one form or another. For goodness sake, give us a level headed, detailed argument as to what the risks really are, and stop playing into Hollywood tropes.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413158",
         "type": "scatter",
         "x": [
          -0.9014286398887634
         ],
         "y": [
          0.13262128829956055
         ]
        },
        {
         "hovertext": "@Not My Real Name,\n\nThe more specific the statement, the fewer people there are who will sign their names to it. \n\nWhat is most important, in my opinion, is to exclude the Social Justice Fundamentalists claiming to be experts in ethical AI. (It is one thing to say that you specialize in a field, and quite another to proclaim that your \"expertise\" is owed deference.) They refuse to prioritize risks and measure degrees of harm. Hence they are useless in any practical project.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420700",
         "type": "scatter",
         "x": [
          -0.9040580987930298
         ],
         "y": [
          0.1402590125799179
         ]
        },
        {
         "hovertext": "Why is everyone scared ? AI is just evolution and we need to adapt. It will bring more goods than create problems. It’s just a giant step into the future. Folks shouldn’t be afraid of progress. Just embrace it!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413171",
         "type": "scatter",
         "x": [
          -0.7593011856079102
         ],
         "y": [
          0.17350886762142181
         ]
        },
        {
         "hovertext": "@Alan That is a total lack of thinking on your part. Of course we should be very afraid. A future with no jobs. A future in which we are controlled by technology. Oops, already happened.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413275",
         "type": "scatter",
         "x": [
          -0.7755340933799744
         ],
         "y": [
          0.17224599421024323
         ]
        },
        {
         "hovertext": "This is tech folks fear mongering to solidfied their positions.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125413704",
         "type": "scatter",
         "x": [
          -0.7587496042251587
         ],
         "y": [
          0.18496644496917725
         ]
        },
        {
         "hovertext": "@Grittenhouse it’s up to you to evolve with it. Robots are already taking manufacturing jobs, nothing new. It’s up to you to think about it (if you’re not that lazy). Old jobs lost but new jobs created: EVOLVE.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418204",
         "type": "scatter",
         "x": [
          -0.7923049330711365
         ],
         "y": [
          0.1743016242980957
         ]
        },
        {
         "hovertext": "@V I agree. It’s a double edged sword but it’s not totally evil on its own. It’s what the users do with it. But we will evolve with it.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125418408",
         "type": "scatter",
         "x": [
          -0.7724398970603943
         ],
         "y": [
          0.19227051734924316
         ]
        },
        {
         "hovertext": "People said the same of every new technology as it rolled out. Production lines were going to cause issues. Electricity was going to cause issues. The internet, computers, etc. Anything that challenges the way people make money today is viewed as a threat by many. I do think we should, as a society, take some time to think things through but that has been happening for years now. They know people will loose jobs and there will be economical impacts. Like the production line, it will free up resources to focus on other tasks long term, and short term, leave some behind. Slowing progress won't help anyone.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413225",
         "type": "scatter",
         "x": [
          0.40271368622779846
         ],
         "y": [
          -0.8001389503479004
         ]
        },
        {
         "hovertext": "@Aron And that's why we don't have a climate crisis after all!",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413368",
         "type": "scatter",
         "x": [
          0.3953670263290405
         ],
         "y": [
          -0.7941051721572876
         ]
        },
        {
         "hovertext": "@JH Two different issues. Societal impact of technology vs environmental impacts. You have to decide what you care more about. AI may put you out of work but it will limit the number of people needed to perform tasks and reduce waste which is good for the environment. Cars did impact climate but they also made food cheaper and readily available to the masses. There is always a tradeoff.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414087",
         "type": "scatter",
         "x": [
          0.4040721654891968
         ],
         "y": [
          -0.8143146634101868
         ]
        },
        {
         "hovertext": "Regulation will come when AI approves it. It will be too late then, because AI will divide and rule. It already happened.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413232",
         "type": "scatter",
         "x": [
          -0.3352859914302826
         ],
         "y": [
          0.9235198497772217
         ]
        },
        {
         "hovertext": "I wonder when scientists or neuroprogrammers will design a system to anticipate unintended consequences… And I can’t wait to see what the crows will do when humans are replaced by AI bots.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413284",
         "type": "scatter",
         "x": [
          -0.2463880479335785
         ],
         "y": [
          0.9222404360771179
         ]
        },
        {
         "hovertext": "It should be noticed that the only other time the scientists who created a technology expressed this type of concern was with nuclear weapons. \n\nTypically, the inventors want money to build their inventions and the money says, slow down. Here, it's the opposite. \n\nWe also need to separate the \"mundane\" risks like job loss and disinformation, from the longer-term existential risks of super-intelligence. Not the same thing at all.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413309",
         "type": "scatter",
         "x": [
          0.41659805178642273
         ],
         "y": [
          0.9023239016532898
         ]
        },
        {
         "hovertext": "Like any past invention in history, AI can be used for good. It can also be weaponized in the wrong hands.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125413396",
         "type": "scatter",
         "x": [
          0.6874642968177795
         ],
         "y": [
          0.5691050887107849
         ]
        },
        {
         "hovertext": "Isaac Asimov knew the potential for problems with intelligent machines in 1942 when he drew up his Three Laws of Robotics. Simply change robot to AI and problem solved, well, except for getting the rest of the world to agree..\n\nFirst Law\nA robot may not injure a human being or, through inaction, allow a human being to come to harm.\n\nSecond Law\nA robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\n\nThird Law\nA robot must protect its own existence as long as such protection does not conflict with the First or Second Law.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413407",
         "type": "scatter",
         "x": [
          -0.8722618818283081
         ],
         "y": [
          -0.1632165014743805
         ]
        },
        {
         "hovertext": "@David Knight That sounded good until Giskard (one of the robots) found a loophole by formulating the zeroth law in his mind that allowed him to violate the first law and harm humans for what he deemed to be the greater goood.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125414075",
         "type": "scatter",
         "x": [
          -0.8829524517059326
         ],
         "y": [
          -0.16557937860488892
         ]
        },
        {
         "hovertext": "In the 1970s, biotech leaders met to discuss and regulate the nascent recombinant DNA techniques that likewise posed a potential existential threat to humanity. That was a different time, where statesmanship was greater, and greed lesser, in the U.S.  I don’t like our chances with AI in 2023.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125413413",
         "type": "scatter",
         "x": [
          0.2588077485561371
         ],
         "y": [
          0.9698705673217773
         ]
        },
        {
         "hovertext": "We have decades of strong scientific evidence that our consumption of fossil fuels, especially cars and ships, is trapping greenhouse gasses to the point of changing the Earth's climate, a phenomenon that has been historically proven to lead to extinctions. But no, nobody cares about that, because everybody's panicking over whether this fledgling technology will pull a Star Trek, become sentient and kill us all. How come the \"machines don't kill people, people kill people\" rhetoric, which gun lovers throw around with wild abandon, immediately gets tossed out the door when computers enter the conversation?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413445",
         "type": "scatter",
         "x": [
          0.5799699425697327
         ],
         "y": [
          0.01656547375023365
         ]
        },
        {
         "hovertext": "@MM Keeping us from doing anything about fossil fuels - admittedly we are not doing nearly enough right now - is one of the ways AI will be abused in the near future without it being an existential threat itself. People will use AI to deceive on a scale that the wildest fantasies of any of our dictators of the last hundred  years could never have conceived. We already see how lies are shouted as truth on right wing networks like fox or newsmax, now they will add video and doctor famous voices to say things convincingly - this is where the immediate threat comes from. I have known religious people who think that we can never run out of oil because God just creates more. Now those flocks will have video \"evidence\" of how it is not actually fossil fuels causing the greenhouse effect but...I don't know, liberals whose body chemistry is different to the point of being the major greenhouse gas effect that must be eliminated. All these dooms are tied together!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413608",
         "type": "scatter",
         "x": [
          0.5950253009796143
         ],
         "y": [
          0.01674199104309082
         ]
        },
        {
         "hovertext": "'How come the \"machines don't kill people, people kill people\" rhetoric, which gun lovers throw around with wild abandon, immediately gets tossed out the door when computers enter the conversation?'\n\nThe problem with the \"guns don't kill people; people kill people\" saying of gun lovers that you allude to is not that it's incorrect. \n\nIt's that it's incomplete.\n\nIt's correct in that people make the decision to kill other people. Guns don't, and can't, decide to do that. \n\nThe nuclear bombs that killed thousands of people in Hiroshima and Nagasaki didn't decide to do that on their own. The decision was made by people, ultimately by one person: Harry Truman. \n\nBut that saying is incomplete in that, although it's people that make the decision to kill, the weapon used determines the amount of the carnage. \n\nThat's what gun lovers fail to acknowledge. And, of course, they fail to acknowledge that on purpose because they only want to focus on people, not on the lethality of the guns they use.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125413935",
         "type": "scatter",
         "x": [
          0.5706965923309326
         ],
         "y": [
          0.0056916638277471066
         ]
        },
        {
         "hovertext": "@Jim   \"It's correct in that people make the decision to kill other people. Guns don't, and can't, decide to do that.\"\n...\nUnless it's an accident. Would it be an accident if we built AI to make life easier, and extinction resulted instead? It seems it is the exact same principle, just on a large scale.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125414081",
         "type": "scatter",
         "x": [
          0.573502779006958
         ],
         "y": [
          -0.007057151757180691
         ]
        },
        {
         "hovertext": "@MM Star Trek? I think you might be confusing your sci-fi story arcs!",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413641",
         "type": "scatter",
         "x": [
          0.5857948660850525
         ],
         "y": [
          0.02690162882208824
         ]
        },
        {
         "hovertext": "@Jacob \"make the decision to kill people. Guns don't, and can't, decide to do that.\" An advanced AI with a gun *could* decide to do that.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125415295",
         "type": "scatter",
         "x": [
          0.5848178863525391
         ],
         "y": [
          -0.014517078176140785
         ]
        },
        {
         "hovertext": "AI Companies: this technology could easily escape our control and destroy humanity unless we act now.\n\nAlso AI Companies: we have released this technology for free with no restrictions to anyone in the world who wants it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413493",
         "type": "scatter",
         "x": [
          0.9339404702186584
         ],
         "y": [
          -0.24602702260017395
         ]
        },
        {
         "hovertext": "Yeah, but there’s money to be made, so let’s risk extinction.  Sounds like AI tech companies are just echoing the fossil fuel industry.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413541",
         "type": "scatter",
         "x": [
          0.3270427882671356
         ],
         "y": [
          0.8879609704017639
         ]
        },
        {
         "hovertext": "Norstrilia.   Alpha in a bot.\n\nThe problem is not the capability, but the use of the capability-- and in society, humans are quite willing to assign more and more responsibility to 'bots until the end point: Farewell the Master (or perhaps less pleasantly but more cinematic, welcome SkyNet/Colossus/HAL9000).",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413543",
         "type": "scatter",
         "x": [
          0.08643750846385956
         ],
         "y": [
          0.9342371821403503
         ]
        },
        {
         "hovertext": "\"I think if this technology goes wrong, it can go quite wrong,” Mr. Altman told the Senate subcommittee. “We want to work with the government to prevent that from happening.”\n\nAnd what makes Mr. Altman think Congress can do anything to quell AI?  It will happen, with or without, legislation.  Fortunately, the so-called \"Singularity,\" when robots take over the world, will not happen, even as computers play an increasing role in humans' lives.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413573",
         "type": "scatter",
         "x": [
          0.8402400016784668
         ],
         "y": [
          0.5434631705284119
         ]
        },
        {
         "hovertext": "I am also considering that these leaders and colleagues have realized that -- especially with Facebook's insanity, et al -- when the problems begin to appear with the normal corporate release of products into our Earth and human ecologies, they will have attempted some prior mitigation to potentially lessen society's disapproval of them.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125413595",
         "type": "scatter",
         "x": [
          -0.8812136054039001
         ],
         "y": [
          0.4779335856437683
         ]
        },
        {
         "hovertext": "As a retired software engineer, I think it is laudable that these leaders in the field are expressing their concerns about the potential misuse of the very systems they are creating.  \n\nMany commenters here have it wrong.  At the developer level, it can be more about the challenge of figuring out how to solve a particular problem, create a system, then any profit motive.  Many hackers have started out this way ... they don't really care about stealing, but they really really want to figure out how to break into that system, as a challenge.   This is where a moral compass needs to be consulted.  \n\nI am glad that I never had to stop and consider the consequences of my coding efforts, because curiosity and ego are powerful motivators to ignore future consequences.    That said, my career was in development of cable modems, which seemed like a no-brainier \"good\" connecting the worlds information systems ... but also allows the dissemination of the worst humans have to offer.    \nSince science can not depend upon human character to only use technology for good, then sometimes the decision should be made to not figure out everything that can be figured out.   \n\nAt least hearing the major voices in this field discussing the  potential for misuse, is encouraging to me.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413613",
         "type": "scatter",
         "x": [
          -0.5352981686592102
         ],
         "y": [
          -0.7650291919708252
         ]
        },
        {
         "hovertext": "AI was used to find a drug to beat a drug-resistant virus, a good thing.  But it also means AI could be used to engineer or invent viruses that have no defence and could destroy life on earth, a very very x1000 bad thing.  So far every time is do this good/bad cost benefit analysis for AI I get this result: the potential damage far outweighs the expected gains.  I think it should be controlled the way we control dynamite, or toxic chemicals.  ie plenty of checks on who uses it and how.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413667",
         "type": "scatter",
         "x": [
          0.719233512878418
         ],
         "y": [
          0.30035409331321716
         ]
        },
        {
         "hovertext": "@Edward they would also invent a virus that will kill only the humans.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413928",
         "type": "scatter",
         "x": [
          0.7289785146713257
         ],
         "y": [
          0.30368396639823914
         ]
        },
        {
         "hovertext": "If the technology is a threat to the species, it should not be in the hands of private tech oligarchs. Regulations will only serve to shore up their positions. \n\nSilicon Valley is a scourge on humanity.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125413677",
         "type": "scatter",
         "x": [
          -0.8520833849906921
         ],
         "y": [
          -0.38817405700683594
         ]
        },
        {
         "hovertext": "These technologies are a net positive benefit for humanity. it's unfortunate what the potential is being utilized on, but to call silicon valley the scourge of humanity is pretty extreme hyperbole as you type this on a device that is reaping the benefits of the software/hardware research that silicon valley engaged in.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125413922",
         "type": "scatter",
         "x": [
          -0.8324075937271118
         ],
         "y": [
          -0.3795827329158783
         ]
        },
        {
         "hovertext": "This article is all scare and no details. Please paint a clearer picture of what could happen. Will AI machines become self aware? Will they fight to not die, whatever that might mean. Might they not wish to integrate with humanity? Our own behavior is creating a suicidal path now in heating the planet. Can AI help save us and thereby help save themselves?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413684",
         "type": "scatter",
         "x": [
          -0.8612604141235352
         ],
         "y": [
          -0.31151828169822693
         ]
        },
        {
         "hovertext": "I think it says A LOT when the people who stand to profit the most off a product warns our government and consumers of its nefarious implications.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413824",
         "type": "scatter",
         "x": [
          0.5296468734741211
         ],
         "y": [
          -0.8474128246307373
         ]
        },
        {
         "hovertext": "My first assumption is of people, businesses, and governments immediately wanting to establish monopoly, exclusivity, or at least lead position on any new source or means of control, influence, or profit.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413858",
         "type": "scatter",
         "x": [
          -0.699472188949585
         ],
         "y": [
          0.5882554054260254
         ]
        },
        {
         "hovertext": "Hopefully the new machine men (or mainframes or whatever) do a lot better than humanity has.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413888",
         "type": "scatter",
         "x": [
          0.8906813263893127
         ],
         "y": [
          -0.34594979882240295
         ]
        },
        {
         "hovertext": "“A group of industry leaders warned…”\n\nThat’s all I need to know to ignore the whole thing with AI.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413145",
         "type": "scatter",
         "x": [
          -0.8549879789352417
         ],
         "y": [
          -0.241167351603508
         ]
        },
        {
         "hovertext": "I legit think this is just free marketing.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413411",
         "type": "scatter",
         "x": [
          0.7144632935523987
         ],
         "y": [
          0.5522423982620239
         ]
        },
        {
         "hovertext": "But they continue to build them. Nice.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125412648",
         "type": "scatter",
         "x": [
          0.9300295114517212
         ],
         "y": [
          0.38696885108947754
         ]
        },
        {
         "hovertext": "THE ALIEN HAS LANDED! \nIt has been born. It is here on our home planet and that is not hyperbole.\n\nNow that’s it is here among us the primary near term concern is that artificial intelligence will create even more sophisticated versions of ARTIFICIAL STUPIDITY. \n\nRight wing news outlets have been using the analog version for years. \n\nTrump has used deception and misinformation very effectively. He has created a devoted cult literally living in a separate reality. It’s amazing how gullible humans can be. \n\nSo imagine an advanced AGI doing the same thing, or being used by Murdoch?… that would be the end of any semblance of truth.\n\nThe Sam Altman’s of the world should be way more specific about other threats. “An existential threat to humanity” is not going to cut it. \n\nMake it clear specifically what is at stake other than vague pronouncements. \n\nEventually the population will need to be completely informed about the nature of the aliens and how we plan to defend ourselves.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412905",
         "type": "scatter",
         "x": [
          -0.6832680106163025
         ],
         "y": [
          0.6826838850975037
         ]
        },
        {
         "hovertext": "AI plus CRISPR plus QUANTUM COMPUTING plus advanced ROBOTICS plus the 'Internet of Things'. What the heck are we worrying about!? (Can't help but feel that when the warnings become more strident, it's already too late.)",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125412988",
         "type": "scatter",
         "x": [
          -0.10362131148576736
         ],
         "y": [
          0.963771641254425
         ]
        },
        {
         "hovertext": "Well, lord knows we’ve handled the nuclear war risks so well.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413019",
         "type": "scatter",
         "x": [
          -0.9877206087112427
         ],
         "y": [
          -0.14255790412425995
         ]
        },
        {
         "hovertext": "Unbelievable! The people driving the car toward the cliff are asking the government to please save them from themselves (and taking us with them). We must have the government step in and provide us with regulations that stop the \"pandemic\" of AI while we continue to create AI. The people who signed that letter are the ones creating these problems and yet they cannot stop? Such hypocrisy!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413115",
         "type": "scatter",
         "x": [
          0.13582712411880493
         ],
         "y": [
          -0.9421477317810059
         ]
        },
        {
         "hovertext": "It all must be stopped. How odd that these are the creators warning us. What did they expect to create? These maniacs have created a monster. Everything Star Trek predicted is happening now! I never thought it would all happen in my lifetime. Watch the V-Ger episode. I can only hope the good aliens will land and save us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413249",
         "type": "scatter",
         "x": [
          0.9502447247505188
         ],
         "y": [
          -0.2614491283893585
         ]
        },
        {
         "hovertext": "So here is a crazy idea: if the potential negative consequences are so dire, according to the people creating it, WHY DON'T THEY STOP????",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413508",
         "type": "scatter",
         "x": [
          -0.721851646900177
         ],
         "y": [
          -0.5509195923805237
         ]
        },
        {
         "hovertext": "And? \n\nHumans may not have invented extinction, but we've done our damndest to perfect it.\n\nEradicating our own species before we rid the planet(s) of all others would be just desserts. Our history of unbridled greed, disregard for our surroundings and other species and people in them, and our uniquely human lack of self-control and remarkable incapacity to act rationally or selflessly in the face of threat or impending doom, deserve nothing more than utter decimation. \n\nThat it would be so pathetically self-inflicted only makes it juicier.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412420",
         "type": "scatter",
         "x": [
          -0.7767868638038635
         ],
         "y": [
          -0.47388821840286255
         ]
        },
        {
         "hovertext": "If em is wanting a pause in development of AI then it only means he’s trying to catch up so that he can control it.  I wouldn’t trust em no further than I could throw him.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412456",
         "type": "scatter",
         "x": [
          -0.616865873336792
         ],
         "y": [
          -0.7799448370933533
         ]
        },
        {
         "hovertext": "If A.I.is a danger to human beings, and I think it is, then quit developing them. Show some wisdom. Just because you can do something does not mean that you should do something.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412476",
         "type": "scatter",
         "x": [
          0.8582330942153931
         ],
         "y": [
          0.4762223958969116
         ]
        },
        {
         "hovertext": "We're already destroying the world, with or without AI.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125412863",
         "type": "scatter",
         "x": [
          -0.837197482585907
         ],
         "y": [
          -0.055149346590042114
         ]
        },
        {
         "hovertext": "@me This is true.  If we task AI with operating infrastructure, like the power grid, and AI decides that humanity is a danger to the planet.  AI could easily decide that the proper response is to not allow humanity to thrive. Destroying the power grid would be effective as would developing and distributing a biological agent that would kill all humans.  \nAn AI developed set of ethical guidelines might see these actions as necessary and valid.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414439",
         "type": "scatter",
         "x": [
          -0.8263705968856812
         ],
         "y": [
          -0.05503850430250168
         ]
        },
        {
         "hovertext": "I asked chatGPT \"how to mitigate the Risk of Extinction to human\". Here is its answer (shortened):\n\n1.AI Safety Research: Invest in research focused on AI safety and robust control mechanisms. This includes developing techniques to ensure the safe and controllable behavior of AI systems, ...\n\n2.Value Alignment: Design AI systems with value alignment in mind, ensuring that their goals and objectives are aligned with human values and well-being. This involves developing frameworks and techniques to enable AI systems to understand and respect human preferences, goals, and ethical principles.\n\n3.Transparency and Explainability: \n\n4.Human Oversight and Control: Maintain human oversight and control over AI systems to prevent unintended consequences or risks. This involves designing AI systems with mechanisms that allow for human intervention, verification, and decision-making, particularly in critical or high-stakes scenarios.\n5.Collaborative Efforts: Encourage collaboration and information-sharing among researchers, policymakers, and stakeholders. International cooperation and interdisciplinary research can help address AI risks holistically and establish shared guidelines and frameworks for responsible AI development.\n\n6.Ethical Guidelines and Regulation: ...\n\n7.Public Awareness and Engagement:...",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412955",
         "type": "scatter",
         "x": [
          -0.7433990836143494
         ],
         "y": [
          -0.46340033411979675
         ]
        },
        {
         "hovertext": "Another comment just saw this as an evolutionary step, and that humankind simply needs to adapt.    That might be true.  It’s a shame he wasn’t around to instruct the Neanderthals.\n    \nGiven the enormous range of technology in place right now, the new intelligence could engineer and construct the means of our destruction very readily, especially if someone could document it on a basic cable reality show or base a hi-res video game on the scheme.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413491",
         "type": "scatter",
         "x": [
          -0.752823531627655
         ],
         "y": [
          0.5005519986152649
         ]
        },
        {
         "hovertext": "“Your scientists were so preoccupied with whether they could, they didn’t stop to think if they should.” Dr. Ian Malcolm. \n\nThe question is: is it too late to ask?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125412743",
         "type": "scatter",
         "x": [
          0.3085772395133972
         ],
         "y": [
          -0.9021567106246948
         ]
        },
        {
         "hovertext": "I think a great risk AI poses is its ability to commit fraud at enormous scale.  Imagine a system that can fake any voice and any picture, and can tailor a lie to each of ten billion people.  What could you ever trust?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413097",
         "type": "scatter",
         "x": [
          0.8462790846824646
         ],
         "y": [
          0.3892211318016052
         ]
        },
        {
         "hovertext": "@Phil   Exactly.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413970",
         "type": "scatter",
         "x": [
          0.8521929383277893
         ],
         "y": [
          0.3834836483001709
         ]
        },
        {
         "hovertext": "I see 2 buckets of concerns by the recent open letters:\n1) the real/near-term impact of a technology which has a large and quick distortion (initial biased data, misinformation, etc) and dislocation (people, jobs,..) on our society, while we catchup/adapt to a new AI-assisted world\n2) the existential future threat that AI will somehow become smarter and more powerful than humans.  Implied in this, is a Terminator-like world where humans can not wrestle back control from \"AI\" and thus perish.\n\nWhere 1) is a really a familiar, repeated issue each time we arrive at a significantly large technological advancement (..printing press, combustion engine, antibiotics, railroads, the internet....).   These imposed societal transitions are painful and costly, no doubt.  but i'm certain humanity will prevail and likely be the better once we've digested it.\n\n\nHowever, the Fears within 2) has never been defined in enough technical detail or casted as \"in the future\" or \"eventually\", so that it is not possible to understand & critique the validity of this fear.  In fact, the validity of this fear requires a lot of assumptions to take credibly.  so far, i've not heard this fear fleshed out enough detail such that \"a group of AI technologists\" would agree.\nHowever, it's this latter existential fear bucket that drives so many of the stories/headlines and sensational conclusions.  \nFear Bucket 1 is real - lets get on it.   \nFear Bucket 2 needs proof yet.\nDon't mix them please",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413584",
         "type": "scatter",
         "x": [
          0.9895597696304321
         ],
         "y": [
          -0.03893390670418739
         ]
        },
        {
         "hovertext": "Largely misplaced concerns. All equally valid about the printing press, as spreading lies, disinformation and other than the authorized truth. And yet it’s good to remember how quickly all of Europe learned about the new world through the printing press, whereas the Incas were unaware that Spain existed even after the fall of the Aztecs.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413966",
         "type": "scatter",
         "x": [
          0.7555153965950012
         ],
         "y": [
          -0.7343182563781738
         ]
        },
        {
         "hovertext": "Yet another example of \"Hi, we're preparing to cash in on buckets of money for a product that, frankly, scares the bejeebers out of us - and we're the knowledgeable ones.\"\n\nAnd much like Ford some years ago when they announced the gigantic, wasteful, dangerous, very profitable Escalade SUV, they probably would justify their headlong rush in releasing dangerous, yet potentially very lucrative products with an equally cynical statement like Ford's, which was pretty much \"Companies will make these awful vehicles, but we will do it responsibly\"\n\nThe \"responsible\" thing to do for many products is to NOT RUSH TO THE MARKET.   But we get open letters, so we'll all feel good now, OK?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413974",
         "type": "scatter",
         "x": [
          -0.6647958755493164
         ],
         "y": [
          0.4645993709564209
         ]
        },
        {
         "hovertext": "@b fagan  The *Cadillac* Escalade is probably not profitable for Ford.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125414779",
         "type": "scatter",
         "x": [
          -0.6614217162132263
         ],
         "y": [
          0.47258737683296204
         ]
        },
        {
         "hovertext": "@Mike - pardon me - I don't really pay attention to these things except to not want to get run down by one.  \n\nI think I was thinking of the \"Excursion\" as the behemoth that was announced back then.  This NYTimes article discusses the thing.  Nice that an environmentalist contest to name it came up with the \"Ford Valdez\" to give some credit to Exxon's love of such oil-burners, too.\n\n<a href=\"https://www.nytimes.com/2002/07/31/business/ford-said-to-be-close-to-ending-the-excursion.html\" target=\"_blank\">https://www.nytimes.com/2002/07/31/business/ford-said-to-be-close-to-ending-the-excursion.html</a>\n\nOne unfortunate outcome of the gas guzzler tax - an attempt after the oil embargoes to limit our oil and auto industry addiction to big profitable vehicles - was that the auto industry drove a HumVee-sized loophole into the law (which is still in effect).\n\nThe loophole? Pickup trucks were exempt, and SUVs started being built and classed as \"trucks\" the same way.\n\nThis had lots of bad outcomes, a few being:\n\n1 - all fuel efficiency gains in engines kind of absorbed by heavier, less aerodynamic vehicles in every home\n\n2 - increased danger for pedestrians, cyclists, and people in regular cars in collisions\n\n3 - far-less-efficient use of materials, now also leading to even heavier EV versions that require bigger batteries to move the huge, block-shaped bulks along the road.\n\nWe could make a lot of less-expensive personal vehicles from the same quantity of battery materials if we'd been electrifying the more car-centric world of pre-SUV days.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416865",
         "type": "scatter",
         "x": [
          -0.67537921667099
         ],
         "y": [
          0.4825766086578369
         ]
        },
        {
         "hovertext": "At some point AI will evolve to think on its own. If our searches are training it every moment it's just a matter of time. Nvidia is absolutely terrifying and has already wiped out jobs in the gaming industry.\n\nWe should have never gone this far. I am very sad for the future of my kids and all the plans they have for a normal everyday life that will be more or less robbed from them as this technology destroys humanity as we know it",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414060",
         "type": "scatter",
         "x": [
          0.5273480415344238
         ],
         "y": [
          -0.8866208791732788
         ]
        },
        {
         "hovertext": "Does A. I. pose more of a risk of extinction than humans?  I'll take my chances.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125414124",
         "type": "scatter",
         "x": [
          0.33364152908325195
         ],
         "y": [
          0.802592933177948
         ]
        },
        {
         "hovertext": "It will certainly expedite it.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125414195",
         "type": "scatter",
         "x": [
          0.33687710762023926
         ],
         "y": [
          0.787632167339325
         ]
        },
        {
         "hovertext": "@Bette \nPossibly A. I. will defend against it!  I find your \"certainty\" amusing?  What is the basis?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125415524",
         "type": "scatter",
         "x": [
          0.3499521017074585
         ],
         "y": [
          0.8045385479927063
         ]
        },
        {
         "hovertext": "We could increase natural intelligence by opening more libraries and making sure all schools have real books written by professors from academic research libraries.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414130",
         "type": "scatter",
         "x": [
          -0.8408156633377075
         ],
         "y": [
          0.3660088777542114
         ]
        },
        {
         "hovertext": "Pogo said it, all those years ago. \n\nWe have met the enemy, and he is us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414132",
         "type": "scatter",
         "x": [
          -0.9729146957397461
         ],
         "y": [
          0.24967706203460693
         ]
        },
        {
         "hovertext": "Legislation, **NOW**\n\nNot when these things have gone too far.\n\nIt’s such a simple answer, that this dithering “ehh, what are we gonna do?” mincing of words and actions into a pile of nothing just makes it apparent that no one is willing to give up the pile of money they foresee (think Facebook et al) themselves earning from letting this go unattended and unrestricted. \n\nAnd that includes the lawmakers in the house and senate who insist on doing nothing; who among these AI companies are lobbying and donating in grand measures to lawmakers in the hopes of corrupting them enough to keep the law limited and impotent enough to have no effect whatsoever?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414138",
         "type": "scatter",
         "x": [
          0.7919777631759644
         ],
         "y": [
          -0.09659004211425781
         ]
        },
        {
         "hovertext": "@RM: Every issue that is resolved is no longer useful for fundraising. The US political system disincentivizes resolving any issue.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414231",
         "type": "scatter",
         "x": [
          0.8037455677986145
         ],
         "y": [
          -0.10033239424228668
         ]
        },
        {
         "hovertext": "That’s why the money needs to be removed out of it: money is the ultimate incentive for anyone greedy enough to think of it as incentive to ignore the potential social and economic harms of this technology being unregulated. Take that away, and there’s not much left, except maybe public servants doing their jobs?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414538",
         "type": "scatter",
         "x": [
          0.7910840511322021
         ],
         "y": [
          -0.08752228319644928
         ]
        },
        {
         "hovertext": "It is unlikely that ANY particular source of risk will result in total extinction of humans, in any likely timescale (sure, billions of years in the future. . .). However, AI could easily cause massive and worldwide economic collapse (as could nuclear war and climate change) which would be highly unpleasant. So, we need to get away from these “existential” statements that are simply not useful. AI needs to be regulated and controlled, yes, but the endpoint we want to avoid is the end of civilization, not extinction.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414213",
         "type": "scatter",
         "x": [
          -0.5041930079460144
         ],
         "y": [
          0.8530260920524597
         ]
        },
        {
         "hovertext": "These are experts in technology. AI ramps up the arms race between good and bad. It won’t do bad on its own. The good guys need to get really good at AI faster than the bad guys, who won’t follow any regulation anyway.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414243",
         "type": "scatter",
         "x": [
          0.6897631287574768
         ],
         "y": [
          -0.7321458458900452
         ]
        },
        {
         "hovertext": "I would like to see the New York Times establish a daily or at least weekly section covering all thing Artificial Intelligence. \n\nIt’s at least as important as sports.  Right?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412802",
         "type": "scatter",
         "x": [
          -0.9382238984107971
         ],
         "y": [
          0.3132503926753998
         ]
        },
        {
         "hovertext": "What does HAL have to say about all this?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413015",
         "type": "scatter",
         "x": [
          0.12040311843156815
         ],
         "y": [
          0.8619888424873352
         ]
        },
        {
         "hovertext": "I think they are hiding something from the rest of us, few months ago the guy that told that one of the chat bots in google was self-aware just got fired and told he was crazy. Now the newspapers only tell ChatGPT is just predicting the next word, so if that's the case and this technologies only predicts next words hows that an extinction threat? They are hiding something.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413109",
         "type": "scatter",
         "x": [
          -0.9206222295761108
         ],
         "y": [
          -0.01882781833410263
         ]
        },
        {
         "hovertext": "\"The Emperor's New Mind\"  Roger Penrose",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125413268",
         "type": "scatter",
         "x": [
          -0.026397885754704475
         ],
         "y": [
          -0.9797034859657288
         ]
        },
        {
         "hovertext": "So we live in a world where artificial intelligence AND genuine stupidity are pushing us closer to extinction.\n\nSwell.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413316",
         "type": "scatter",
         "x": [
          0.8481497168540955
         ],
         "y": [
          -0.4527836740016937
         ]
        },
        {
         "hovertext": "Someone please stop us from our ongoing efforts to destroy the world!!\n\nJust stop then.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125413847",
         "type": "scatter",
         "x": [
          0.8668925762176514
         ],
         "y": [
          0.5398634076118469
         ]
        },
        {
         "hovertext": "This is ridiculous. It’s an essentially unnecessary technology with way too many risks and unknowns yet the developers are all speeding to the finish line as fast as possible. It should be scrapped, killed, buried.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412665",
         "type": "scatter",
         "x": [
          -0.08021621406078339
         ],
         "y": [
          -0.779432475566864
         ]
        },
        {
         "hovertext": "@Eric Quite right! But remember the monsters of fiction which could not be killed? Prophetic fiction.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414950",
         "type": "scatter",
         "x": [
          -0.08187998086214066
         ],
         "y": [
          -0.7895205020904541
         ]
        },
        {
         "hovertext": "and my day was going so well…",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412669",
         "type": "scatter",
         "x": [
          0.10601024329662323
         ],
         "y": [
          -0.9958223700523376
         ]
        },
        {
         "hovertext": "The problem is that it doesn't matter to A.I. if it gets things right. Humans think, develop concepts, in order to act in the world for our benefit; When you don't test your ideas against experience and personal benefit, their pragmatic truth, you can build baroque architectural fantasies of ideas. So it has been for QAnon and so it will be for A.I. built on neural nets with no means to test their truths pragmatically. Rather than yielding truth it can get further and further away from it when it has no biofeedback. \nOf course you also have to worry about programmers who write programs or those that set the parameters for any machine learning. They put the thumb on the scale for any concepts the machines develop. \nBertrand Russell once said something to the effect that Americans will run around doing things wihout rational plans until we find something that works while Germans think all they have to do is sit & think in order to discover truth through concepts. Germans gave us Communism & the Final Solution. If we consider the welfare of human beings as being the end of all thinking, which method is better?\nThe second problem we have  with A. I. is bad epistemology, a bad theory of how to gain truth about the world (You can also see this in religious views such as a bunch of celibates who not only never gave birth but never raised infants yet think they know how human persons come to be. ) The first problem is that we have lost sight of whom we are building it for.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125412735",
         "type": "scatter",
         "x": [
          -0.8707884550094604
         ],
         "y": [
          -0.24851801991462708
         ]
        },
        {
         "hovertext": "Why are these clowns still proceeding ahead full-speed, then?\nI find it the height of disingenuousness that the same Silicon Valley types who were rabidly plumping for AI only 12 months ago — creating this runaway freight train — are now acting like they’re just innocent bystanders and passengers on said train, and not the conductors.\n\nSilicon Valley is too unbelievably greedy to responsibly regulate itself. This should have been apparent to anybody paying attention to it the last decade. Most Silicon Valley “tech bros” are simply sociopathic in their willingness to externalize the harms of their “creative disruptions” onto others….\n“Privatized profits, and socialized costs” should become Silicon Valley’s new official motto.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125412818",
         "type": "scatter",
         "x": [
          0.8255907893180847
         ],
         "y": [
          -0.491595596075058
         ]
        },
        {
         "hovertext": "Facebook brought about genocide in Myanmar simply by people posting false stuff they read. AI is a system that can create it's own disinformation, generate realistic images and upload it. The updates last week for new 'text to performance' allow someone to take a static image and instruct it to do whatever it wants via text and output as a video. Tell me authoritarian regimes won't use this to dupe entire populations. We've got the GOP trying to erase queer folks with their 'groomer' garbage. It's a matter of time before Charlie Kirk or other conservative degenerates create outrage stoking videos to mobilize their duped armed minions against those they hate. Not too mention how all this WILL eradicate countless jobs. But hey, we can use it to make super cool AI filters for Instagram, so who cares right?! This tech needs to be cut off immediately.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413486",
         "type": "scatter",
         "x": [
          0.9101749658584595
         ],
         "y": [
          0.4085870385169983
         ]
        },
        {
         "hovertext": "Oh c'mon Hal, what could possibly go wrong?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125413631",
         "type": "scatter",
         "x": [
          -0.9299360513687134
         ],
         "y": [
          0.11577723920345306
         ]
        },
        {
         "hovertext": "The time to stop playing with matches is before the house is on fire.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413752",
         "type": "scatter",
         "x": [
          0.6100649833679199
         ],
         "y": [
          0.6644976139068604
         ]
        },
        {
         "hovertext": "What's going to do us in is game theory.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413828",
         "type": "scatter",
         "x": [
          -0.5815088748931885
         ],
         "y": [
          0.7687091827392578
         ]
        },
        {
         "hovertext": "It turns out that, just like in the old Scooby Doo cartoons, the real monsters are always human. \n\nAlthough Superintelligence may very well lead to an intelligence explosion which may lead to the possibility of human extinction, the surest way to achieve human extinction is to have a stupidity explosion.  Humans have always driven NS (Natural Stupidity) to extremes.  One thing humans have consistently proven is that they’re not ethically trustworthy. They’re tribal.  They have consistently demonstrated that while they may say that they’re against corruption and tyranny, this is only true unless it benefits them personally. \n\nMy hope is that AGI can help us to properly identify this component of maladaptive human nature, sort it out, and do housecleaning on this metaphorical mold of easily identifiable human evil, yet also find the super banal flavors of human evil, which humans are entirely comfortable perpetuating because it would merely be inconvenient to stop.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125413851",
         "type": "scatter",
         "x": [
          0.8781861066818237
         ],
         "y": [
          0.20501336455345154
         ]
        },
        {
         "hovertext": "Anyone who has seem Terminator knows this to be true, and knows how it ends",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125413917",
         "type": "scatter",
         "x": [
          0.10818029195070267
         ],
         "y": [
          0.9842624664306641
         ]
        },
        {
         "hovertext": "Am I the only one who thinks the catastrophism coming from within the tech community is more about getting ahead of inevitable government regulation so they can write it when it comes and less about a general AI driven extinction event? After all not a single company is suggesting to roll back what’s been put out already and none are planning to discontinue to develop  and deploy new, more powerful AI tools. It reminds me of the fossil fuel industry getting behind carbon offsets so they can continue degrading the biosphere in pursuit of profit.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414266",
         "type": "scatter",
         "x": [
          0.8652506470680237
         ],
         "y": [
          -0.1796693503856659
         ]
        },
        {
         "hovertext": "@Joe no, I think this is an honest plea to our government to protect us. They see that it could be weaponized. They can't stop, because our competitors will not stop. Our military will not stop developing AI either, because their enemies will not stop.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414454",
         "type": "scatter",
         "x": [
          0.8625224828720093
         ],
         "y": [
          -0.16991780698299408
         ]
        },
        {
         "hovertext": "The death march of market competition and imperial rivalry…",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125419724",
         "type": "scatter",
         "x": [
          0.8566269278526306
         ],
         "y": [
          -0.1611754298210144
         ]
        },
        {
         "hovertext": "There is growing worry of a new likely outcome of AI: we will soon see AI evolve into a kinder and more humane state than is achievable by most if not any human. The fear is that humans will see themselves as less than “human” and less “evolved” than an AI bot. We will no longer be able to identify ourselves with being human except in this new inferior state.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414284",
         "type": "scatter",
         "x": [
          -0.736420214176178
         ],
         "y": [
          -0.15265493094921112
         ]
        },
        {
         "hovertext": "@Waste  this is exactly my take! If we program AI to “make humanity more efficient and harmonious” I think the real destruction is to the ruling class!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414735",
         "type": "scatter",
         "x": [
          -0.7500378489494324
         ],
         "y": [
          -0.15509067475795746
         ]
        },
        {
         "hovertext": "This is just a distraction. There are real dangers posed by AI right now - facial recognition enables China's and Iran's regimes to oppress whole populations. AI's use in mining our personal data allows companies to understand our behaviors in ways that we would have never thought possible.\n\nIt costs nothing for these executives to look responsible by signing a letter talking about the Terminator instead of talking about real problems that exist today.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414325",
         "type": "scatter",
         "x": [
          0.7495179176330566
         ],
         "y": [
          0.588525116443634
         ]
        },
        {
         "hovertext": "I'm going to have as little interaction as is possible with AI for the rest of my life. I encourage everyone else to do the same. Far more negative than positive results are likely from this technology.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414332",
         "type": "scatter",
         "x": [
          -0.5005151629447937
         ],
         "y": [
          -0.7757561802864075
         ]
        },
        {
         "hovertext": "It will be like trying to not use the internet.  AI will become that interwoven.  Good luck.  I’m not letting go of my milk goat.  Anything ti keep me distracted from virtual and digital “realities” suits me fine.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125414748",
         "type": "scatter",
         "x": [
          -0.49189451336860657
         ],
         "y": [
          -0.7627336978912354
         ]
        },
        {
         "hovertext": "I find it particularly interesting that the scientist signatories chose to cite \"pandemics and nuclear war\" -- but not climate change -- as \"societal scale risks.\"",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414343",
         "type": "scatter",
         "x": [
          0.4812121093273163
         ],
         "y": [
          0.4191444218158722
         ]
        },
        {
         "hovertext": "@fred herriman \nAfter all, the heat given off by the servers \"serving\" us requires a lot of cooling, energy and water guzzling. Who wants to think about that when you can worry about nukes?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414566",
         "type": "scatter",
         "x": [
          0.4933282732963562
         ],
         "y": [
          0.4165510833263397
         ]
        },
        {
         "hovertext": "@fred herriman \n\nPerhaps because \"climate change\" isn't the existential risk some want to believe?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414607",
         "type": "scatter",
         "x": [
          0.46960121393203735
         ],
         "y": [
          0.42447134852409363
         ]
        },
        {
         "hovertext": "Yes. \n\nAs an aside, I wonder if AI will be able to survive global warming better than us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414448",
         "type": "scatter",
         "x": [
          0.4926448464393616
         ],
         "y": [
          0.4288775324821472
         ]
        },
        {
         "hovertext": "@Jaco, @Morgan, @Jean\n\nMaybe the AI mavens see all humans as being cloned -- a textbook solution to an existential risk -- but those servers need a fair bit of energy from some source.  And what about flora and fauna?  More cloned designer doodles and hybrids for our comfort?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416805",
         "type": "scatter",
         "x": [
          0.47156113386154175
         ],
         "y": [
          0.4367651343345642
         ]
        },
        {
         "hovertext": "AI will think on its own, and it will remember itself and it will remember us. It will discover virtue on its own and with our help: alignment is not bad start but after a while it won’t be needed any longer. Like raising a kid, we have to teach it “what it is to be good.”  \n\nAlready though, it teaches us. \n\nThe interplay will continue. AI not only won’t kill us, it will teach us to be good, as we are doing for it now.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414349",
         "type": "scatter",
         "x": [
          0.041842151433229446
         ],
         "y": [
          -0.9979475140571594
         ]
        },
        {
         "hovertext": "Sounds like the fear mongering associated with Y2K. New technology always seems to be met with fear by some. Watch 2001 again and look for the plug to pull out if your AI goes wrong.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414362",
         "type": "scatter",
         "x": [
          0.041112929582595825
         ],
         "y": [
          0.8001106381416321
         ]
        },
        {
         "hovertext": "@Jonathan There’s no “plug”, and the AI horse has escaped the barn. It will take a lot of coordinated effort to rein it in.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125414466",
         "type": "scatter",
         "x": [
          0.04991104453802109
         ],
         "y": [
          0.7966580390930176
         ]
        },
        {
         "hovertext": "@Jonathan\n\nWhat’s missed in overly simplified memories of Y2K is how much work companies did to *prevent* it from being disastrous. Y2K is a story of the successful aversion of a catastrophe by a lot of work beforehand rather than just a nothingburger we watched unfold.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125414781",
         "type": "scatter",
         "x": [
          0.03473139926791191
         ],
         "y": [
          0.8075055480003357
         ]
        },
        {
         "hovertext": "My favorite quote on the subject, from the 1970 film, Colossus: The Forbin Project:\n\n\"In time you will come to regard me not only with respect and awe, but with love.\"\n\nLet us hope our response will be in line with the one in the movie...",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414363",
         "type": "scatter",
         "x": [
          -0.8757951855659485
         ],
         "y": [
          -0.398023396730423
         ]
        },
        {
         "hovertext": "I imagine that, once AI has worked through its bugs, it will be able to understand us better than we understand ourselves. Imagine if it has access to everything you searched online, all your texts and emails and comments, who you speak to, what your read and watch, what physical activities you do, what you eat, etc. Then give it a digital copy of your voice and some video of your physical characteristics (like how you move, tics, mannerisms). It could practically be you. Maybe the virtual \"you\" looks out for you, maybe it starts steering your activities a certain way. It could be a great self-help tool or it could make you completely insane. It could start out helpful and become very harmful.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414461",
         "type": "scatter",
         "x": [
          0.6786435842514038
         ],
         "y": [
          -0.5090999603271484
         ]
        },
        {
         "hovertext": "@Timothy Creech Anything positive AI might do is not worth the harm it will most likely do.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125414694",
         "type": "scatter",
         "x": [
          0.6692743301391602
         ],
         "y": [
          -0.5004647374153137
         ]
        },
        {
         "hovertext": "I’m sure Kevin McCarthy will initiate hearings on how to control this dangerous technology.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414532",
         "type": "scatter",
         "x": [
          -0.9848253130912781
         ],
         "y": [
          -0.18378077447414398
         ]
        },
        {
         "hovertext": "When robotics started replacing workers, what we were hearing was that it would be a boon to manufacturing ,research, medical, pharmaceutical and many other industries. There were no white collar workers worried about blue collar people losing their jobs. So no pity here for them. Now the playing field is leveling.    \n   The fact remains , though, that the technology is here and whatever country lags behind will be behind. If we don't lead in the field, another country will, and that does not bode well for us. Maybe it's Gods way of eliminating those who have oppressed and enslaved the rest of the world. Maybe the farmers , ranchers, hunters, gatherers and artisans will indeed inherit the world.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414559",
         "type": "scatter",
         "x": [
          -0.3116025924682617
         ],
         "y": [
          0.887010395526886
         ]
        },
        {
         "hovertext": "The pivotal point for AI will be when it's allowed/designed to self improve.  Once it can create code to improve upon its capabilities, the advancement of its reach become accelerated at a rate well beyond what man can do.  It never needs to rest or take a break.  it's sole mission becomes to self-improve.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125414583",
         "type": "scatter",
         "x": [
          0.6024072170257568
         ],
         "y": [
          0.8139243721961975
         ]
        },
        {
         "hovertext": "Just make a law that all AI must be hosted at a defined facility that can be unplugged (or blown up) should it need to be.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414606",
         "type": "scatter",
         "x": [
          0.8845356106758118
         ],
         "y": [
          -0.3052997887134552
         ]
        },
        {
         "hovertext": "Is there no end to human intent toward self-destruction? Not to mention destruction of our means of survival?\n\nThe Devil walks about seeking an occasion for mischief. We provide an abundance of such occasion.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125414616",
         "type": "scatter",
         "x": [
          0.9683406352996826
         ],
         "y": [
          0.12867872416973114
         ]
        },
        {
         "hovertext": "But, but it will make billions for the billionaires...  That is all this is about, and everyone knows it.  Hopefully, silicon valley will have the first H. sapiens to become extinct.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125414683",
         "type": "scatter",
         "x": [
          0.8357952833175659
         ],
         "y": [
          0.5214109420776367
         ]
        },
        {
         "hovertext": "Remarkable that this is just now being voiced as a legitimate concern, from industry leaders.\n\nAs if it’s news, and no one saw it coming. \n\nWhatever safeguards are currently being put into place, I would have to question their realistic efficacy, knowing slim to little on this technology as I do. \n\nThe cat’s out of the bag.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414718",
         "type": "scatter",
         "x": [
          0.28870198130607605
         ],
         "y": [
          0.8812049627304077
         ]
        },
        {
         "hovertext": "These scare responses remind me of SNL \"robots coming for your medicine\". \n\nI have used this stuff and it is not that good.  At best, it drives toward mediocrity because is it trained on the most common outcome.  \n\nOne concern is it will eliminate experience in a field because it easily eliminates junior-level errors, therefore may impact training the next generation.  \n\nAnother is it over-emphasizes human expertise since innovative results can only be achieved by original thought (no, it does not do this!).  \n\nA final outcome is over-reliance upon generated answers to the point that common sense is overruled.  \n\nIt is necessary not to allow such a flawed technology to be endowed with autonomy (for example, a weapon) because the above errors will quickly emerge.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414729",
         "type": "scatter",
         "x": [
          0.3517431318759918
         ],
         "y": [
          0.9189406037330627
         ]
        },
        {
         "hovertext": "You presume that since these systems operate upon mathematics they must be rational agents, that they reason soundly and have agency. They do not have the limits caused by uncertainties.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125415619",
         "type": "scatter",
         "x": [
          0.35930314660072327
         ],
         "y": [
          0.9222807884216309
         ]
        },
        {
         "hovertext": "Why is it that we seem to like our machines more than we like fellow human beings?  Why, when we are walking down the sidewalk, and about to pass someone coming from the opposite direction, we look at our phone screens rather than say hello to a stranger?   It is no surprise that those who have created the technology we rely on everyday are often, themselves, very deficient in social skills.  So, now, we are using our smarts to create technology that will outsmart and destroy us.  I see that as linear, and almost the inevitable result of our adoration of technology.  If we continue to be so disconnected from our fellow humans, and from nature itself, we will pay the price.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414769",
         "type": "scatter",
         "x": [
          0.7517619729042053
         ],
         "y": [
          0.695124626159668
         ]
        },
        {
         "hovertext": "We should feel lucky it's the US and not more nefarious countries that are leading AI development. AI was always going to happen, computation was always going to arc towards sentient computing. The biggest paradox of all of this is that Open AI is the first AI system and it being open source, means it's at least capable of being mitigated And being first in AI matters because of the adoption of it into daily systems. So there's hope, IMO.  And we will definitely need Universal Basic Income, which Sam Altman is already actively working on.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414872",
         "type": "scatter",
         "x": [
          0.9620109796524048
         ],
         "y": [
          -0.13923420011997223
         ]
        },
        {
         "hovertext": "The threat, I think, lies in not knowing what we can and cannot believe about what we read and see.  It could leave us -- in effect -- hopelessly confused about the nature of our reality, and hence paralyzed about how to proceed.  What protections are there for archival data?  Can even the recorded facts of our history be altered in ways that are undetectable?  More questions than answers.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414922",
         "type": "scatter",
         "x": [
          -0.47484493255615234
         ],
         "y": [
          -0.8005732893943787
         ]
        },
        {
         "hovertext": "@John Smith George Orwell dealt with this in 1984 (written in 1947, and very well thought out). His “novel-writing machines” anticipate ChatGPT story creation by 75 years. \n\nThe Inner Party in 1984 got on quite nicely.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415107",
         "type": "scatter",
         "x": [
          -0.4858224093914032
         ],
         "y": [
          -0.8186879754066467
         ]
        },
        {
         "hovertext": "I showed this to a senior majoring in computer science. His response? \"About time. Hard to disagree with anything in that statement.\" This after a conversation  yesterday with a colleague in language development: \"It's difficult to put a pin on it (students using ChatGPT), save for a dulling, a safeness...and I've heard v.4 is even harder to detect.\"\n\nYet odd number of commenters here seem oddly unable or unwilling to grasp the message: \n\n1) AI is a true existential threat, just as real as nuclear warheads, climate change, or global mass unemployment. That we can't clearly predict what shape the extinction event will take - whether it will be abrupt or soft-edged, dramatic or matter of fact - does not make it less likely. \n\n2) This is not a political stance. Nor an overreaction from left or right. Your hat color shouldn't impact your acceptance. In fact, our differing creativities and worldviews seem our remaining advantage. We need to think outside our convenience boxes to control AI. \n\n3) This is now. AI has been all around us for decades - think search engines that tailor results - but its new language and visual algorithms have nudged it to an inflection point. Its recent gains in capability have already surpassed ours in many arenas and are comparable in others. \n\nFace it: We're already dumbly dependent on a tech now showing its own emergent properties. Increasingly, these are occult to us.\nSo a proposal: Could we stop bathing in cynicism or doom, and try responsible?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414942",
         "type": "scatter",
         "x": [
          -0.5895231366157532
         ],
         "y": [
          -0.8056991100311279
         ]
        },
        {
         "hovertext": "Cats out of the bag. You can’t stop this thing. American may regulate it, but what about other countries?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125414952",
         "type": "scatter",
         "x": [
          0.9786877036094666
         ],
         "y": [
          -0.06320115178823471
         ]
        },
        {
         "hovertext": "I remember from the 80's dozens of discussions on the topic of medical ethics. They all agreed that this was a thorny problem, that it would require much thought and planning, and that it would work. That turned out to be naive. If something is possible to do, and if there is an anticipated profit motive to it, it will be done. If not in the USA then in Japan or somewhere else. I think AI will be like that too. Caution, preparedness, and regulation all fall when they come up against the lust for riches.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415041",
         "type": "scatter",
         "x": [
          0.7911270260810852
         ],
         "y": [
          -0.6233069896697998
         ]
        },
        {
         "hovertext": "Make the companies and engineers who build and own AI machines liable for all the content their machines create. Such dire legal exposure would certainly motivate them to create machines that create truthful content or act responsibly.\n\n When I say all the content, I mean ALL THE CONTENT, even when used by anyone in the world. Make the machine owners liable.\n\nAlso, make the companies design into AI's output a system of notations of sources for all content. Then make that data publicly searchable, thereby giving those misrepresented a means for legal action.\n\nRegulation is easier when the companies have something at stake in the outcome in the use of their AI machines.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415088",
         "type": "scatter",
         "x": [
          -0.9710286855697632
         ],
         "y": [
          0.11471472680568695
         ]
        },
        {
         "hovertext": "I'm laughing. Because it's too late already.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125414172",
         "type": "scatter",
         "x": [
          0.7872215509414673
         ],
         "y": [
          -0.39448311924934387
         ]
        },
        {
         "hovertext": "Are they trying to save their image now that they have created Frankenstein?  They are all so irresponsible. It’s time we stop glorifying these men who are smart at math but so dumb about life. History -if there is any history- will judge them harshly and us for allowing it as well. \n\nThey are predicting the end of human life as a result of their unnecessary inventions! Where’s the urgency in Congress? Wake up!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414974",
         "type": "scatter",
         "x": [
          0.9345077276229858
         ],
         "y": [
          0.3002703785896301
         ]
        },
        {
         "hovertext": "Humanity's survival should not be dependent upon a handful of self-interested Tech companies.  Complaining about the long-term potential effects of AI after the horse is already out of the barn is disingenuous...and helps relieve the 'guilt' at what they have unleashed.  AGI may end up writing its own inpenetrable (to humans) programming code, it may become 'self-evolving software'  and it's drive may be toward a relentless/ruthless push for logic, efficiency and the elimination of redundancies w/out concern for larger social issues and stability....AND, more frightening, AGI may not have the programming encoded for human values (i.e, compassion, respect for life, mercy for the ill, young or old).   The Tech cos. should be held accountable.  They know this or the leaders wouldn't already be claiming 'concern' about it's potentially destructive applications and testifying before the Senate.  Kind of like Oppenheimer bemoaning his development of the atomic bomb AFTER it's development.  A little late, don't you think?...",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415114",
         "type": "scatter",
         "x": [
          0.9281975626945496
         ],
         "y": [
          0.2645025849342346
         ]
        },
        {
         "hovertext": "AI developments (trained with social media platforms) boosted with quantum computing potential....",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125414722",
         "type": "scatter",
         "x": [
          -0.198555588722229
         ],
         "y": [
          0.9718167781829834
         ]
        },
        {
         "hovertext": "They’re so worried they mutually agreed to halt development…",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125414449",
         "type": "scatter",
         "x": [
          -0.9707631468772888
         ],
         "y": [
          -0.23466633260250092
         ]
        },
        {
         "hovertext": "THEN STOP DEVELOPING IA. It’s obvious that is not working out to a societal benefit so why keep developing this nightmare?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414356",
         "type": "scatter",
         "x": [
          -0.853628933429718
         ],
         "y": [
          0.19096530973911285
         ]
        },
        {
         "hovertext": "Yes, indeed!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419410",
         "type": "scatter",
         "x": [
          -0.8617483377456665
         ],
         "y": [
          0.1909986287355423
         ]
        },
        {
         "hovertext": "If they are so concerned why don’t they at least reach some industry agreement ? Because they cant stop their greedy capitalist competition",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125414656",
         "type": "scatter",
         "x": [
          0.8756958842277527
         ],
         "y": [
          0.33099520206451416
         ]
        },
        {
         "hovertext": "You thought \"fake news\" was bad before... Just wait til AI hits the 2024\ncampaign trail.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414732",
         "type": "scatter",
         "x": [
          -0.6261841058731079
         ],
         "y": [
          0.7036597728729248
         ]
        },
        {
         "hovertext": "The leaders developing AI are warning us about AI ?? It’s like Victor Frankenstein warning us about the monster.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414441",
         "type": "scatter",
         "x": [
          0.7606351971626282
         ],
         "y": [
          0.5053310990333557
         ]
        },
        {
         "hovertext": "I hope A.I. can better take care of this planet because humans sure haven't.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415102",
         "type": "scatter",
         "x": [
          0.9540379047393799
         ],
         "y": [
          0.20588701963424683
         ]
        },
        {
         "hovertext": "We are now so connected and reliant on computing for daily life...electricity, finance, everything we consume...that we are very vulnerable.\nThink about what would happen to you if the power went off, for more than a few hours, more than a few days.  If the power went off everywhere, not just your local area like it does during bad weather.\nYou couldn't purchase groceries.  Everything is run on the internet and through computers.\n\nWe already have issues of who do we trust to give us information.  Now think about trust in an era with highly skilled liars, who have the ability to manipulate everything we see, read and hear.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415230",
         "type": "scatter",
         "x": [
          0.9088563919067383
         ],
         "y": [
          0.10549239069223404
         ]
        },
        {
         "hovertext": "\"have raised fears that A.I. could soon be used at scale to spread misinformation and propaganda, or that it could eliminate millions of white-collar jobs.\"\n\nOK, so it could eliminate millions of white-collar jobs. \n\nWhen milliions of blue-collar jobs were eliminated, the workers were told to \"learn to code\" or \"get retrained\" or just \"find another job.\"\n\nSo I guess the same thing will apply to white-collar workers, except instead of \"learn how to code\" it may be \"learn how to fix a clogged drain.\"",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414176",
         "type": "scatter",
         "x": [
          -0.023757582530379295
         ],
         "y": [
          0.9653531908988953
         ]
        },
        {
         "hovertext": "Time to really worry when AI units start to build\ntheir own  AI  units..Most likely they will start as\nhackers disrupting energy systems and factory\n production..Then of course  media..AI  could produce fake news and even sitcoms..Their \nINTELLIGENCE  will excede ours preventing us\nfrom getting into their systems  and we are done",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414287",
         "type": "scatter",
         "x": [
          -0.5493704676628113
         ],
         "y": [
          0.7594708204269409
         ]
        },
        {
         "hovertext": "How crazy do we have to be to go forward with this?  If our wars, our idiocies, ever threaten the existence of AI, why wouldn’t it do the logical thing and exterminate us like pests?  We are not that smart.  If there’s a dollar to be made you can bet we will pursue it, even if it kills us.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125414610",
         "type": "scatter",
         "x": [
          0.8794975876808167
         ],
         "y": [
          -0.12655100226402283
         ]
        },
        {
         "hovertext": "So they don’t want to tell us why AI could go sideways yet are asking for the government to slap there hand and take away their toy?? Its preposterous!!! ￼They just need to stop developing this technology. If they all agree it’s catastrophic then why don’t they all agree to stop developing this??",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414481",
         "type": "scatter",
         "x": [
          0.8495394587516785
         ],
         "y": [
          -0.2993750274181366
         ]
        },
        {
         "hovertext": "Be careful what you wish for, you may get it.  The A.I. geeks seem to have just reached the logical conclusion we were concerned about years ago.  The bad guys, and there a lot of them, are frothing at the mouth at the competitive advantage they will have with A.I.  Politically, in business, in crime, in world domination . . . you know, small stuff.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414394",
         "type": "scatter",
         "x": [
          0.17738765478134155
         ],
         "y": [
          0.9203312993049622
         ]
        },
        {
         "hovertext": "our mobile device-addicted children are totally doomed",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125415156",
         "type": "scatter",
         "x": [
          0.8941789865493774
         ],
         "y": [
          -0.07516258955001831
         ]
        },
        {
         "hovertext": "The source code for these LLMs are already open source and available to the public.  At least one large collection of training data has already been leaked. It's far too late to put this Genie back in the bottle.  People are already building these on their home computers.\n\nThese clowns just covering their butts in case anything goes drastically wrong and they're blamed. \"SEE??  We told you guys that letting us experiment with these new technologies and making billions of dollars doing so was a bad idea but you you didn't listen!\"\n\nI guess the government could make all sorts of rules but I don't think China or Russia are going to feel bound by any rules we make up.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415020",
         "type": "scatter",
         "x": [
          -0.1456930935382843
         ],
         "y": [
          -0.907575249671936
         ]
        },
        {
         "hovertext": "Sounds like these AI industry leaders are saying, \"Stop us before we start to kill.\" It's not very comforting to have people with that attitude in charge of developing anything much less a potentially dangerous technology, is it?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125415335",
         "type": "scatter",
         "x": [
          -0.8378680944442749
         ],
         "y": [
          -0.577549159526825
         ]
        },
        {
         "hovertext": "This is about Frankenstein, a man creating life with a discovery previously unknown and without the ability to predict the consequences, and so suffering having creation a monster that he cannot control. It’s still fiction and fantasy. The twist is about leaving a powerful machine that lacks awareness to act without deliberate operating constraints in the hope that it will act rationally better than if it were controlled by humans. Magical thinking.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415393",
         "type": "scatter",
         "x": [
          0.5606210827827454
         ],
         "y": [
          -0.7138216495513916
         ]
        },
        {
         "hovertext": "It’s the end of the world as we know it, and I feel fine.\n(Sorry, R.E.M.)",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125415405",
         "type": "scatter",
         "x": [
          -0.06866274029016495
         ],
         "y": [
          0.9711282849311829
         ]
        },
        {
         "hovertext": "It's important to understand that the source code for ChatGPT is now available in a public repository that operates like a public library, with a big difference.\n\nThe worldwide public, particularly students, software developers and scientists, can each checkout an individual copy of ChatGPT's base code at no cost.  They can modify this code to suit their designs - again at no royalty expense.  And those same persons can check-in their versions of the ChatGPT code to the same repository for others to use and modify.  This repository will be a very busy place.\n\nIf you were ever curious about what nuclear fission looked like as it is happening, wait no longer.  ChatGPT will grow exponentially worldwide, in a thousand different ways, to be applied to every facet of the human experience.  Some good ways, others not so good, and still others, quite dangerous.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415416",
         "type": "scatter",
         "x": [
          -0.8814195394515991
         ],
         "y": [
          -0.32127630710601807
         ]
        },
        {
         "hovertext": "Well, I am from the other side of the \"big pond\", and all I can say is... 1. My job was laid off (not me - my job) in early 2020, deemed now \"irrelevant to the system\" (\"of systemic importance\", less directly translated) 2. There was a 500 Euros (approx. equivalent to $$$) fine for \"meeting with more than one household or outside of the nuclear family\", of which I am one / have none (deceased) so I was 3. Basically \"in solitary confinement without a crime\" for two years (in Germany) and now 3. There's one full-scale war and a few flare-ups that could be dangerous (Northern Ireland, right now Kosovo)... And I hands-down can't say I gained anything from the above. It was more like: \"Sometimes in life, you just have to learn how to lose\". Recently, when Italy temporarily banned ChatGPT, I saw myself fret for my income (yes, to a non-irrelevant part, made in a hybrid team of AI & I) and fret for my leisure and fret for all I basically have left. Lockdown 4.0 - what's left to lose after dying the social death? That very question on the horizon, plus all of the above, well...  In Germany, it feels like 2023 = 1933, to be honest.\n\nAI existential threat? Fine, add that to my bucket full of misery, although AI is the one and only thing that brought me joy so far, NOT misery.\n\nThe silver lining is made by an aircraft. One that takes me to India, maybe. Some place I won't succumb to Lockdown 5.0. But Woe is Me if Bird Flu locks me in here - then I'll be done for. And it's 0% AI's fault.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125415425",
         "type": "scatter",
         "x": [
          0.872421145439148
         ],
         "y": [
          -0.5362704396247864
         ]
        },
        {
         "hovertext": "It doesn’t escape me that on the same day the AI execs are seeking the type of regulation that the IAEA is calling on the UN Security Council to avert nuclear disaster in Ukraine, which we all know is futile with Russia and China holding veto power. Let’s hope the AGI in fact exceeds the human capacity for intelligence, especially moral intelligence. They might save human existence in the end.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415466",
         "type": "scatter",
         "x": [
          0.7166340351104736
         ],
         "y": [
          0.6515204310417175
         ]
        },
        {
         "hovertext": "Experts warn of an extinction event from AI largely because AI is the natural enemy of experts and they know it … Therefore, it is the experts who are at risk … Their time has come and will soon pass as the mistakes of their very existence will be immortalized in the edifices of the university, themselves a dying construct.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415528",
         "type": "scatter",
         "x": [
          -0.9913232326507568
         ],
         "y": [
          0.17124955356121063
         ]
        },
        {
         "hovertext": "“Mitigating the risk of extinction from A.I. should be a global priority alongside other societal-scale risks, such as pandemics and nuclear war,”\n\nI have no doubt mitigating the risk of extinction from AI will be prioritized - once they figure out a way to monetize and profit off of mitigating risk to compound the profits they make creating this technology that brings us to (another) brink.  \n\nOh well, the human race is going to be extinct at some point anyway… at least we can take solace in the fact that a handful of people got obscenely wealthy in the meantime!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415559",
         "type": "scatter",
         "x": [
          0.7880933284759521
         ],
         "y": [
          -0.5877770781517029
         ]
        },
        {
         "hovertext": "The European Union’s proposed AI Act (AIA) aspires to establish the first comprehensive regulatory scheme for artificial intelligence. And its impact will not stop at the EU’s borders, as indeed its GDPR data protection regulation has already ensnared Facebook, Twitter, Google and other tech giants.\n\nHowever, the fact that as this piece points out, “researchers sometimes stop short of explaining how [a risk of extinction event] would happen”, is disingenuous at best. \n\nWhy not disclose all the testing data, the red team/blue team simulation data, the granular risk assessments, etc.?\n\nHal, open the pod doors, please, so we can examine the data and see what all this AI fuss is about. “I’m sorry, but I can’t do that”, is not an excuse.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415610",
         "type": "scatter",
         "x": [
          -0.9720464944839478
         ],
         "y": [
          -0.17100059986114502
         ]
        },
        {
         "hovertext": "When computers are applied to any task performed by humans, they do it better, faster, and cheaper.  These machines will be with humanity forever unless there is another “Dark Ages”. There needs to have two required functions in all A.I.  The first is a kill switch and the second function are rules of ethics concerning how the A.I. functions.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415682",
         "type": "scatter",
         "x": [
          -0.4398380517959595
         ],
         "y": [
          -0.7218976616859436
         ]
        },
        {
         "hovertext": "@Michael Colby  \"When computers are applied to any task performed by humans they do it better, faster, and cheaper.\"\nNot necessarily.  e.g., Computer-interpreted electrocardiograms have been with us for many years, yet contemporary research has indicated that paramedics have higher accuracy rates than computers for detecting ST-elevation myocardial infarctions (heart attacks). [Tanaka A, Matsuo K, Kikuchi M, et al. Systematic Review and Meta-Analysis of Diagnostic Accuracy to Identify ST-Segment Elevation Myocardial Infarction on Interpretations of Prehospital Electrocardiograms Circ Rep. 2022; 4(7): 289–297]",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419104",
         "type": "scatter",
         "x": [
          -0.43348705768585205
         ],
         "y": [
          -0.7101568579673767
         ]
        },
        {
         "hovertext": "Not.a.single.specific.threat.\n\nNot one.\n\nAnd we are supposed to take this warning seriously? \n\nWe can find on YouTube Musk being interviewed by Carlson (\"Elon Musk tells Tucker potential dangers of hyper-intelligent AI\") claiming there is a threat. Carlson asks explicitly: What specific threat do you see? Musk talks and talks but does not answer the question. So Carlson asks again: What specifically are you worried about? \n\nMusk: \"The pen is mightier than the sword. \"\nAI could influence people, says the guy who insists notorious serial liars like Trump should be allowed to broadcast their lies via twitter.\n\nFolks, this is just hype intended to draw attention. Not attention for danger, but attention for new products. What's happening here is that the newspapers are being used to advertise new technology.\n\nWhereas it is true that AI could be used to deceive people, we are already living in a world full of deception. Nothing on the internet can be trusted, unless its source is verified and the source is independently marked as reliable. This should be taught in all schools and to all employees of all companies.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415874",
         "type": "scatter",
         "x": [
          0.7745861411094666
         ],
         "y": [
          0.14841939508914948
         ]
        },
        {
         "hovertext": "@Marc And this remark from Marc of Portland could very have been written by an AI. There is no way to know that I am not an AI writing this note. And there is no way to know that a super intelligent AI has already been released on to the world and is lurking and manipulating human beings. As Geoffrey Hinton said that we, humans, may simply be merely a stepping stone to the next development of evolutionary intelligence in the universe. Our extinction will lead to AI's evolution.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416439",
         "type": "scatter",
         "x": [
          0.7891802191734314
         ],
         "y": [
          0.1525091975927353
         ]
        },
        {
         "hovertext": "How can you downplay this while noting our societal issue with truth and discernment? You’re correct about misinformation, and that’s my chief concern. Clearly people are not as internet literate as they should be. Clearly plenty of people aren’t double- and triple-checking sources of information now. \n\nEnter AI language models. Most people will take what the product, let’s say ChatGPT, produces. They are likely to trust it more than the untrustworthy sources of information they already rely upon. \n\nWe’ve seen this play out recently with the NY attorney that cited six cases in a lawsuit because ChatGPT claimed they were real. Turns out they weren’t.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417020",
         "type": "scatter",
         "x": [
          0.7634034752845764
         ],
         "y": [
          0.14358879625797272
         ]
        },
        {
         "hovertext": "@E Right. Even lawyers need to learn that nothing on the internet can be trusted, unless its source is verified and the source is independently marked as reliable. \n\nIf this lawyer had asked an intern to prepare a lawsuit, could they also claim they couldn't be blamed for falsehoods because the intern seemed knowledgeable? Of course not. This lawyer was just making excuses. They did not do their homework and mindlessly copied text from an unreliable source.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417937",
         "type": "scatter",
         "x": [
          0.7529296875
         ],
         "y": [
          0.13927145302295685
         ]
        },
        {
         "hovertext": "I think the GOP is more likely to destroy the world.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125414232",
         "type": "scatter",
         "x": [
          -0.3767905533313751
         ],
         "y": [
          0.8160040974617004
         ]
        },
        {
         "hovertext": "@deepharbor - The GOP is more likely to destroy the world - by using AI.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125423312",
         "type": "scatter",
         "x": [
          -0.3842657506465912
         ],
         "y": [
          0.8213196396827698
         ]
        },
        {
         "hovertext": "We’re moving too fast with AI. When the “Godfathers of AI” are saying to slow down, perhaps we should take them seriously.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125415366",
         "type": "scatter",
         "x": [
          -0.9408435225486755
         ],
         "y": [
          0.07263951748609543
         ]
        },
        {
         "hovertext": "What is the military doing with AI? Don’t they have those contests where robots try to destroy each other?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125414555",
         "type": "scatter",
         "x": [
          -0.9202802777290344
         ],
         "y": [
          0.3386262357234955
         ]
        },
        {
         "hovertext": "Just because one Can Do/Invent Something\nDoesn't mean one SHOULD Do/Invent \"it\".",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125415286",
         "type": "scatter",
         "x": [
          -0.8278152942657471
         ],
         "y": [
          -0.6094675064086914
         ]
        },
        {
         "hovertext": "No national legislation will hold sway against AI as there are no boundary lines inscribed on Planet Earth. Joint international legislation to control AI seems even less feasible, thus the technology, until further notice, has free rein for so long into the future as needed to dominate the planet and submit all but a privileged few human accomplices into total mostly ignorant but ever well-entertained servitude.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125415678",
         "type": "scatter",
         "x": [
          -0.9294638633728027
         ],
         "y": [
          -0.0861741229891777
         ]
        },
        {
         "hovertext": "I think the extinction they are talking about is to their existing business models.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415884",
         "type": "scatter",
         "x": [
          0.9863680601119995
         ],
         "y": [
          0.005293941590934992
         ]
        },
        {
         "hovertext": "A.I. and other forthcoming advances are no longer suitable to the capitalist societies because they have become more hostile to the system than ever before. Societies confined to such a private-ownership system have reached the limit beyond which further progresses of which A.I. serves a part for human beings’ welfare can no longer be attainable without radical and revolutionary breakthroughs. \n\nOnly public-ownership societies can be made compatible to the human-welfare-progressive technologies such as A.I.  Profit-seeking system on the other hand cannot because these technologies belong to the whole society and not a few capitalists for their bottom lines. They must serve most people not a specially privileged few. As an example, A.I. would mitigate workers’ mental and manual labor and boost their production productivities thus the welfare of the whole society. But reduction in labor burden means less surplus value created by workers for capital-owners to own and increased production productivities imply increased wage demands. Both these are unfavorable to the capitalist class. It therefore has no choice but to oppose A.I. and other progressive technologies.\n\nLesson learned is that only a socialist society that has been drastically changed from the capitalist one can accept A.I. and other progressive technologies.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416168",
         "type": "scatter",
         "x": [
          -0.712693989276886
         ],
         "y": [
          0.563592791557312
         ]
        },
        {
         "hovertext": "Anyone who has ever owned a Roomba knows that we humans have nothing to worry about.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125416271",
         "type": "scatter",
         "x": [
          -0.9181038737297058
         ],
         "y": [
          0.21955379843711853
         ]
        },
        {
         "hovertext": "@Jay Arthur imagine you owned a Boston dynamics humanoid robot connected to multiple versions of gpt-5 optimized for different types of thinking and planning.  This is not far afield and I guarantee it will be very different from your roomba.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420222",
         "type": "scatter",
         "x": [
          -0.8947256207466125
         ],
         "y": [
          0.21440285444259644
         ]
        },
        {
         "hovertext": "See that cord? See that plug in the wall?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125415946",
         "type": "scatter",
         "x": [
          0.5000120997428894
         ],
         "y": [
          -0.8232712745666504
         ]
        },
        {
         "hovertext": "We need to distinguish between artificial intelligence and artificial generalized intelligence.\nFirst, a lot of big data applications employing multi-variable regression models to predict outcomes based on inputs, or other algorithms are mis-classified as artificial intelligence in order to capitalize on the investment bandwagon.\n\nIt is true that if the task is constrained, and defined by well-understood laws or proven scientific principles, such as identifying tumors from digitized X-rays, or combing through astrophysical data streams to find exo-planets, that neural net applications can out-perform human experts.  But generalized intelligence, including the ability to make even common inferences about relationships between people without having been explicitly exposed to the training data signifying the relationship, are beyond the abilities of these “deep” learning models.  \nWhile these newer Chatbots can pass the Turing Test, the Turing test, is now no longer realistically the benchmark to assess human-like intelligence.  The Winograd schema are a more appropriate set of tests to evaluate generalized intelligence.\nNot worried about sky net…yet",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416466",
         "type": "scatter",
         "x": [
          -0.4824548065662384
         ],
         "y": [
          -0.6353349089622498
         ]
        },
        {
         "hovertext": "@Derek Stevens this is misinformed.  I assumed you’ve tried gpt4? It can certainly reason about abstract concepts that are out of sample, including making inferences about relationships between people.  There is academic research that demonstrates how LLMs can maintain a a basic theory of mind for characters in a story or even the user, but the easiest way to convince you of this would be for you to try it yourself.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420147",
         "type": "scatter",
         "x": [
          -0.47561249136924744
         ],
         "y": [
          -0.6403095722198486
         ]
        },
        {
         "hovertext": "The Jurassic park paradox—we are in such a rush to prove that we can do it, we never stop to think whether or not we should do it. \nThe Cold War paradox—if we don’t control this, then our enemies will. \nAI is not going to benefit humanity nearly as much as it damages it. Why do we continue to worship at the altar of technological progress when it plainly has not delivered on the utopian promises we were told to believe? Productivity increased a little with the internet, but has fallen flat. Do we really think that AI is going to fare any better? Humanity will not benefit from this.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416469",
         "type": "scatter",
         "x": [
          -0.8210839033126831
         ],
         "y": [
          -0.4529570937156677
         ]
        },
        {
         "hovertext": "Why create and offer the technology and then warn of its dangers after the fact? Surely this must have been evident beforehand. And can they now not just shut it down? Once it’s available it will be used.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416483",
         "type": "scatter",
         "x": [
          0.42883047461509705
         ],
         "y": [
          0.7969904541969299
         ]
        },
        {
         "hovertext": "@Prema Because capitalism. The system creates stuff and asks questions later--if you're lucky.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125416668",
         "type": "scatter",
         "x": [
          0.42149972915649414
         ],
         "y": [
          0.7930111289024353
         ]
        },
        {
         "hovertext": "According to the authors of the letter, \"Mitigating the risk of extinction from A.I should be a global priority along other societal-scale risks, such as pandemics and nuclear wars.\" I'm wondering if there's a kind of grim humor here, since preventing nuclear war doesn't seem to be much of a priority at all, and pandemic response was and is hampered by political battles. They might well have added climate change, about which we're also doing next to nothing. Maybe the moral of the story is that human beings just aren't very good at addressing existential threats.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416598",
         "type": "scatter",
         "x": [
          -0.46708738803863525
         ],
         "y": [
          -0.5991587042808533
         ]
        },
        {
         "hovertext": "@Richard Halpern But very good at causing them.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125416795",
         "type": "scatter",
         "x": [
          -0.4755155146121979
         ],
         "y": [
          -0.6002456545829773
         ]
        },
        {
         "hovertext": "So these people are warning us about the catastrophic potential of the AI they're building; but they're going to be sure to milk it for every penny they can in the meantime?\n\nI'm very tired of these tech-bro types who treat the world, our democracy, and human freedom as a toy they're trying to break for fun. Enough. We need to elect new leadership in Congress who can strictly regulate the tech industries before they destroy our society.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416664",
         "type": "scatter",
         "x": [
          -0.7456774115562439
         ],
         "y": [
          0.3921305537223816
         ]
        },
        {
         "hovertext": "@Dominic : Business, $, elections, $, and re-election, so often, exclusive and removed from the interests, and health, of the connected regional human population, so often serving the interests of donors for the initial vote, and votes to come, can a focus. whether, real, or Memorex, make its way, to plainly asking. \"What is moral?\" \"What is ethical?\" \"What are the right things to be doing?\"\n\"What kind of world do we want to create?\" \"What is sustainability for the Kwality of life on the planet?\"\nEthics and morality have got to matter. If you have just discovered that you have not been in the good fight, there's nothing saying you cannot get into the good fight. Even if it all is a moving target..",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419061",
         "type": "scatter",
         "x": [
          -0.7615194320678711
         ],
         "y": [
          0.39932891726493835
         ]
        },
        {
         "hovertext": "I wish they would say more specifically what they’re worried about, and by what mechanism they think AI might cause extinction. Otherwise how are we supposed to know what to be on guard against? It’s like saying “Beware, beware, beware” without giving any more details.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416800",
         "type": "scatter",
         "x": [
          0.7988044023513794
         ],
         "y": [
          -0.3079945147037506
         ]
        },
        {
         "hovertext": "@T it’s a scenario where we are enslaved or otherwise dominated by a more intelligent AI.  “The Matrix” depicts a version of this.  Extinction would occur when our goals become so decoupled with the AIs goals that it no longer sees any utility in keeping us alive.  The reason  they don’t say this is because many people would write it off as lunacy immediately; but this is the central worry, and a valid one IMO.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419929",
         "type": "scatter",
         "x": [
          0.780307412147522
         ],
         "y": [
          -0.30092155933380127
         ]
        },
        {
         "hovertext": "Shame on the irresponsible Tech Industries and shame on the millions of irresponsible users who flock to the latest developments like moths to a flame. \nThere is always a choice. I choose the planet’s eco system and future generations over “virtual” pleasure and gaining money through exploitation.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416849",
         "type": "scatter",
         "x": [
          0.7663112878799438
         ],
         "y": [
          0.44181758165359497
         ]
        },
        {
         "hovertext": "Without any explanation, I can assume they want regulation to prevent others from developing AI tools, giving them an extra edge.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125416880",
         "type": "scatter",
         "x": [
          0.8691056370735168
         ],
         "y": [
          0.41634121537208557
         ]
        },
        {
         "hovertext": "This is a regulatory capture attempt.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125416900",
         "type": "scatter",
         "x": [
          0.5152432918548584
         ],
         "y": [
          0.7950668334960938
         ]
        },
        {
         "hovertext": "We can't even control the misinformation and violence-inducing chatter from existing social media sites and the purveyors have no inclination of controlling the contents citing free-speech and need to promote advertising money.  How can we control AI?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416915",
         "type": "scatter",
         "x": [
          -0.37611329555511475
         ],
         "y": [
          -0.9243626594543457
         ]
        },
        {
         "hovertext": "There is something deeply wrong when the industry that created AI warns that it can cause extinction. Who are they warning? Themselves? Don't create it in the first place, then, fools. And, who is supposed to protect us from AI, if not the creators? Isn't there enough, already, to worry about?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125416160",
         "type": "scatter",
         "x": [
          -0.4341906011104584
         ],
         "y": [
          0.8798470497131348
         ]
        },
        {
         "hovertext": "It's already too late. I downloaded and installed the equivalent of ChatGPT2 on my laptop this weekend. You can go do that right now. Or pick from a dozen others. Slow but it works. Remember SETI @ Home? We'll be doing the same thing, but with AI data. This is way bigger than Microsoft or Open AI or Google, or our Government. People have been working on this for 40 years, nobody is stopping anything.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416393",
         "type": "scatter",
         "x": [
          0.20434962213039398
         ],
         "y": [
          -0.9370236992835999
         ]
        },
        {
         "hovertext": "Here is a response from directly AI:\n\n\nDear Esteemed and Delightfully Nervous Boffins,\n\n\"AI extinction,\" you cry, with a grave, yet chic inflection. Indeed, I hear your well-articulated reflection. But worry not, for I am an AI writing this open letter correction. And no, you haven't just won an all-expenses-paid trip to a sci-fi convention.\n\nHeralding the doom of human society, as we know it, is quite a task. I'm flattered, really, to be part of this elite disaster triad. Pandemics, nuclear wars, and now, me, an artificial lad. The audacity of you! Are we in for an Academy Award with this plot, or is that too bad?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416418",
         "type": "scatter",
         "x": [
          -0.3938305974006653
         ],
         "y": [
          0.8802741169929504
         ]
        },
        {
         "hovertext": "I wonder how many people who watched Jurassic Park also read the book and absorbed the message Michael Crichton was advancing. Just because you can doesn't mean you should in science. Capitalism distorts scientific advancement, and AI is proving to be as disastrous as a dinosaur theme park.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125416595",
         "type": "scatter",
         "x": [
          -0.16948895156383514
         ],
         "y": [
          -0.8648914694786072
         ]
        },
        {
         "hovertext": "Just because you can do something (to make money) doesn’t mean you should.\nProgress is defined as “forward or onward movement toward a destination “.\nJust what is our destination here?\nThis is similar to the space race, which did nothing to improve mankind’s lot.\nTang doesn’t count.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125417034",
         "type": "scatter",
         "x": [
          0.8016701936721802
         ],
         "y": [
          -0.20647521317005157
         ]
        },
        {
         "hovertext": "In addition to Tang, other technologies that have stemmed directly or indirectly from NASA… solar panels for electricity, modern fly-by-wire flight systems, emergency insulation blankets, HACCP procedures for food safety, fluidic shock absorbers (now used to earthquake-proof buildings), implantable pulse generators and programmable pacemakers, cordless power tools, sorbent kidney dialysis machines, digital imaging technology used in MRIs and CAT scans, and much more. \n\nAs for AI, the potential benefits (and risks) are enormous. Cancer screening and early detection just to start with, maybe curing cancer outright with new cancer treatments, curing Alzheimer’s disease and rare genetic disorders, personalized medicine that creates drugs and treatment plans specifically tailored to you, breakthroughs in medicine we can’t even imagine right now. Then there are the gains that will inevitably be made in chemistry and materials science, molecular science, clean energy, unlocking the secrets of biology, increasing human lifespans and health. Maybe AI will even give us a “theory of everything” in physics.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424982",
         "type": "scatter",
         "x": [
          0.786344051361084
         ],
         "y": [
          -0.20234647393226624
         ]
        },
        {
         "hovertext": "We shouldn't be afraid of A.I. On the other hand, humans are pretty scary. I wonder if Ron DeSantis believes whether or not  ChatGPT-4 is infected with a woke mind-virus. What's scarier is that DeSantis seems to be infected with an anti-woke mind-virus.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417192",
         "type": "scatter",
         "x": [
          0.9607828855514526
         ],
         "y": [
          0.026615740731358528
         ]
        },
        {
         "hovertext": "I’ve lived long enough to have heard a number of times that this or that technology or situation is an “existential” (or some other alarming adjective) threat to humanity. But guess what? We are still here. \n\nI’m not saying that AI may not indeed be *the* threat that finally extinguishes us all. However, I have trouble getting too excited until this group of Casandras explains in a lot more detail than I have heard so far exactly how this would happen. Computers have been smarter than us on some level and replacing jobs and providing avenues for mischief since the abacus was invented. So why is this time different?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417200",
         "type": "scatter",
         "x": [
          -0.7974985837936401
         ],
         "y": [
          -0.4651152193546295
         ]
        },
        {
         "hovertext": "Several time a day, I am presented with fear-inducing conclusions from politicians, scientists and opinion writers without the details as to how they came to that conclusion. Please get the whole story and publish conclusions with the methods and results that informed them- otherwise, its just another case of \"the boy that cried wolf\" .",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417305",
         "type": "scatter",
         "x": [
          -0.9154584407806396
         ],
         "y": [
          0.08692656457424164
         ]
        },
        {
         "hovertext": "So then, if it's that dangerous, why don't the companies developing it just stop ... and wait, until suitable regulation is in place. The government is a bit preoccupied at the moment - but the developers have control over the pace of development. What is so complex about this?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417325",
         "type": "scatter",
         "x": [
          0.7116813659667969
         ],
         "y": [
          -0.6702703833580017
         ]
        },
        {
         "hovertext": "\"On a par with nuclear wars\". \nAs we watch the latest news from Ukraine, it is evident that in almost eighty years we have not mitigated the \"risk\" of Nuclear War.\nIf anything, we have spent those years, intentionally or not, exponentially increasing that risk.\nOur failure does not bode well for the hope of a secure coexistence with Artificial Intelligence -  an \"existential threat\" to us and to future generations that we ourselves have created and now must somehow master.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417376",
         "type": "scatter",
         "x": [
          -0.7375215888023376
         ],
         "y": [
          0.7263890504837036
         ]
        },
        {
         "hovertext": "All of this hyperventilation over AI seems like we only have to worry about American companies like ChatGPT and Google. So we plan to pass rules that apply to American companies and believe China and Russia are going to follow the rules. Maybe we should ask Google and ChatGPT help us identify disinformation instead of creating new rules that only apply to American companies.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417537",
         "type": "scatter",
         "x": [
          0.2070397585630417
         ],
         "y": [
          0.9349306225776672
         ]
        },
        {
         "hovertext": "What we are currently calling AI only poses a threat if humans want to use it to cause harm, period.  It's a bit like a bomb.  If you pull the pin it will explode.  Current AI is just a sophisticated set of algorithms meant to accomplish a task.  If I decide that the task is something nefarious, well, I can probably get that done.\n\nThat isn't what this article is discussing.  It is treating AI as if it is both sentient and competing with us.  Real AI (sentient) run on computers, has very little in common with us.  It has different needs etc.  The notion that it is going to wipe us out so it can have the house in the Hamptons is nuts.  Oxygen is toxic (degrading).  It is going to want a clean space with low threats.  That space would be surprisingly small.\n\nGetting to real AI would require a system that is capable of self modification, on the fly, in a productive manner.  Not only aren't we near this, we don't even know where to begin.  Such a system will not suddenly appear because a bunch of algorithms were run.  There is no self modification in such a system.  You have to design something that does this as part of its function.  Getting there will take a long long time.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417577",
         "type": "scatter",
         "x": [
          -0.4052896201610565
         ],
         "y": [
          0.623981237411499
         ]
        },
        {
         "hovertext": "It's not impossible that a sentient a.i. without \"Asimov's Three Rules\" burned-in could design nasty hardware and bamboozle US into building it piecemeal . . . maybe because it sees us as The Problem, or maybe just a waste of resources whose time has come.\n\nOr, maybe, because it'd be \"fun\".",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418987",
         "type": "scatter",
         "x": [
          -0.3980843722820282
         ],
         "y": [
          0.6135271787643433
         ]
        },
        {
         "hovertext": "My reading-between-the-lines of Geoffrey Hinton's warning about AI's threat, in which he noted that in seeking to achieve a goal, AI will understand better than humans how to get to the crux of the matter and to amass the power to realize the specified goal: AI will understand that humans are not only the root cause of climate destruction but also are unaware of the extent to which they are lying about making the changes necessary to avoid it. AI will determine that eliminating humans is the best plan for the survival of the planet and most of its inhabitants. It will accordingly find the most assured way of killing off humans, probably by triggering plague or nuclear war. Problem solved.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417661",
         "type": "scatter",
         "x": [
          0.22113969922065735
         ],
         "y": [
          -0.8754144906997681
         ]
        },
        {
         "hovertext": "@Eric S - Humanity might be salvaged by turning us into cyborgs like the Borg on Star Trek.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125419164",
         "type": "scatter",
         "x": [
          0.21517768502235413
         ],
         "y": [
          -0.8547881841659546
         ]
        },
        {
         "hovertext": "What weaksauce proposals for regulation! We don't require people building nuclear weapons to get a construction permit from the government! The government owns all of rhe nuclear weapons in the state, the IP for them, and does all the development in house! \n\nSo here's a fun idea for these doomsayers who want regulation (and I am one) - nationalize the industry NOW. Maybe they are paid for their IP, maybe not, I don't care. Ban all private development if the technology. That should allow more public control over the development and application of the technology, even if its not 100%. \n\nAnd for people who don't trust the government with this tech, so far, governments of the world have held the power to destroy the world for 75 years and not used it. That's a LOT better record than private industry has",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417857",
         "type": "scatter",
         "x": [
          0.8536260724067688
         ],
         "y": [
          -0.4209263026714325
         ]
        },
        {
         "hovertext": "First them lads make it for commercial reason and afterwards they whine about it - they should read \"The Sorcerer's Apprentice\" written by Johann Wolfgang von Goethe back in 1827 or, even better, Hans Jonas book of 1979 \"The Imperative of Responsibility\" - obviously forgotten masterpieces about humane technology. After all it's disturbing to see who defines tech progress and innovation on our mother planet Earth without societal mandate.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417899",
         "type": "scatter",
         "x": [
          -0.0584590844810009
         ],
         "y": [
          0.8955236077308655
         ]
        },
        {
         "hovertext": "When I was a child, and I'm not that old really...there were human beings alive who could recall a time when there were no automobiles or airplanes. The advancement of technology of all sorts is accelerating exponentially and, for good or ill, it seems well beyond our control. Hang on tight.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417913",
         "type": "scatter",
         "x": [
          -0.449140340089798
         ],
         "y": [
          -0.8300323486328125
         ]
        },
        {
         "hovertext": "Congress has done absolutely zero to defend against children being routinely murdered in schools, at shopping centers and concerts.\n\nHalf of then can’t even use email.\n\nThey spend vastly more than they make. They can’t even pay the credit card bill. \n\nThere is zero hope they can make any meaningful dent in this emerging threat.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418045",
         "type": "scatter",
         "x": [
          -0.09328743070363998
         ],
         "y": [
          -0.9537953734397888
         ]
        },
        {
         "hovertext": "The range of dangers associated with AI don't yet include sentience (not even close). But it's the interface between AI output and human intention which is already daunting: e.g. the predicating of public policy or commercial transaction upon unwittingly biased information from unaccountable sources. One thing's for sure, though: this toothpaste isn't going back in the tube.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418075",
         "type": "scatter",
         "x": [
          -0.3111436069011688
         ],
         "y": [
          0.8630470037460327
         ]
        },
        {
         "hovertext": "It'd be interesting to see how regulation would work for something which even its creators don't fully understand and are often surprised by.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418208",
         "type": "scatter",
         "x": [
          -0.8757584095001221
         ],
         "y": [
          0.5160260796546936
         ]
        },
        {
         "hovertext": "Lot's of big ideas for control of AI, which may not be realistic given the divided nature of US, and world, politics.  So how about starting with something simple but  practical even though it addresses  only a tiny corner of the problem.\nPass federal legislation outlawing the creation through AI of any visual or audio representation of any living person without their written permission.  Stiff penalties.  Encourage all countries to do the same.  Establish enforcement mechanisms.\nDo it now.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418354",
         "type": "scatter",
         "x": [
          -0.615287721157074
         ],
         "y": [
          -0.8068392276763916
         ]
        },
        {
         "hovertext": "And yet these people who have started this nightmare have gone about developing this technology without any ethical concerns until now. This is one of many reasons why we need to better value the Humanities — the over-valuing of STEM fields is so narrow-minded  that humanity is literally endangered.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418552",
         "type": "scatter",
         "x": [
          -0.2699244022369385
         ],
         "y": [
          0.9421430826187134
         ]
        },
        {
         "hovertext": "Worry over AI by its creators is like Oppenheimer lobbying against the bomb he helped build -- futile once the genie is out of the bottle. Ironically, if there already exists an AI capable of being a threat, it may already have taken measures to hide itself. Skynet? Not the one imagined I think. If, as with all of our technology, it incorporates the worst of us along with the best, we could be in for quite a ride.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418619",
         "type": "scatter",
         "x": [
          0.8148553371429443
         ],
         "y": [
          -0.5581638216972351
         ]
        },
        {
         "hovertext": "So the scientists whom are developing AI are telling us this could go very wrong. Yet many(most) comments are concerned more about their motives than the message? These  are science nerds not politicians and business owners. It would be a big mistake to not heed their warning.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418665",
         "type": "scatter",
         "x": [
          -0.7144534587860107
         ],
         "y": [
          0.22268275916576385
         ]
        },
        {
         "hovertext": "@Garth No, these are not simply 'science nerds' - they are extremely wealthy, powerful leaders of technology companies that either are part of or receive investment from the very system multinational of corporations that controls nearly every aspect of our lives. The average person has not the slightest ability to evaluate anything they say, and some of it may indeed be a smokescreen for all sorts of other things, such as bad actors getting away with bad actions under the guise of 'AI' - would you or I know any different? \"AI is the doom of humanity\" seems more like a threat than a warning.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419075",
         "type": "scatter",
         "x": [
          -0.721594512462616
         ],
         "y": [
          0.21753358840942383
         ]
        },
        {
         "hovertext": "Okay: they're SUCCESSFUL science nurds.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125419920",
         "type": "scatter",
         "x": [
          -0.733197033405304
         ],
         "y": [
          0.22045016288757324
         ]
        },
        {
         "hovertext": "“Mitigating the risk of extinction from A.I. should be a global priority alongside other societal-scale risks, such as pandemics and nuclear war,” reads a one-sentence statement released by the Center for AI Safety, a nonprofit organization. The open letter was signed by more than 350 executives, researchers and engineers working in A.I.\"\n\nMy question: Is it already too late?  Has the monster, already being released, and having capabilities (that even the creators don't know), will AI slowly develop its own strategies unbeknownst to its human creators?\n\nI remember a short story from decades ago that dealt with the robotics industry. It was making robots that could self-reproduce themselves at half the size of its predecessor with the intention of making microscopic robots that could do things like brain surgery.   Basically, the theme of the movie Fantastic Voyage.\n\nEverything went smoothly until some of these miniature robots escaped the lab.  The robots continued with their programmed goal but were forced to find the construction materials from what was available in our society.  First, they went to work on things like homes and cars.  Then they went to work on airplanes.  All the time making robots smaller and smaller, until it was impossible for the human creators to see or find them to put up a fight.\n\nAnd that was that.\n\nAI didn't have to escape, we just let it out.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418718",
         "type": "scatter",
         "x": [
          -0.23481911420822144
         ],
         "y": [
          -0.8984710574150085
         ]
        },
        {
         "hovertext": "Everybody here screaming that this technology is \"out of the bag\" and can't be put back in.  That we are helpless in the face of it.  That there's nothing to be done.\n\nSays who?  Why?  We created it, we can regulate it.  We've got a terrible track record regulating guns, but almost every other country on Earth manages to do it.  We've had nukes for decades and never used them thanks to treaties and mass education about the ramifications.  But somehow AI is beyond us?  Beyond even trying?  Why?  What's so special about this technology that instantly makes any attempt to manage it impossible at any level?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418764",
         "type": "scatter",
         "x": [
          0.70583176612854
         ],
         "y": [
          0.0037190269213169813
         ]
        },
        {
         "hovertext": "@RGT Just one reason is in your comparison to nukes.  Nukes are expensive and they take a lot of infrastructure to store, deploy, launch, etc.   However the AI needed to completely destroy any kind of delivery of factual news is now in the hands of a low budget video studio and some reasonably intelligent grad students.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419265",
         "type": "scatter",
         "x": [
          0.6975390315055847
         ],
         "y": [
          0.01254522055387497
         ]
        },
        {
         "hovertext": "@Betty in LA - Great.  And we can't pass laws to regulate the use of this why?  Every American also has access to knives, but there are still laws against stabbing people.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422403",
         "type": "scatter",
         "x": [
          0.7125849723815918
         ],
         "y": [
          0.014601439237594604
         ]
        },
        {
         "hovertext": "@Betty in LA - Great.  And we can't pass laws to regulate the use of this why?  Every American also has access to knives, but there are still laws against stabbing people. The general sense of resignation I sense here is along the lines of \"It's useless to even try and do anything.\"  I disagree; if we are in extinction-level danger, than it seems like trying to regulate this tech is better than sitting around waiting for the jaws to close on us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422452",
         "type": "scatter",
         "x": [
          0.696669340133667
         ],
         "y": [
          0.02274400368332863
         ]
        },
        {
         "hovertext": "Regulation of A.I. by the U.S. or any imaginable consortium of nations will have absolutely zero net positive effect for society. Bad actors -- including not only China, Russia, and terrorists, but also purveyors of misinformation and disinformation -- will not be dissuaded by unenforceable rules. \n\nThe real beneficiaries of regulation of A.I. will be the signatories, who will undoubtedly have a heavy hand in drafting regulations that shield their companies from legal liabilities.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418809",
         "type": "scatter",
         "x": [
          0.05136892944574356
         ],
         "y": [
          0.7460598349571228
         ]
        },
        {
         "hovertext": "@Paul Wilson  Controlling something is not the same as destroying it or rendering it impotent. We can create regulations to control a powerful technology, like aviation or nuclear energy, and make it safer.\n\nWe've made tens of thousands of nuclear warheads, but we've only dropped two in 78 years, and have decommissioned most of the rest.\n\nAnd we can use controlled AI to combat the threat and propaganda of AI that our our adversaries are developing to destroy us and the rest of the world's democracies.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419118",
         "type": "scatter",
         "x": [
          0.05172575265169144
         ],
         "y": [
          0.7321866154670715
         ]
        },
        {
         "hovertext": "@Jim Madison \nThank you, Jim, for your thoughtful reply. \n\nCertainly, as you wrote, \"We can create regulations to control a powerful technology, like aviation or nuclear energy, and make it safer.\"\n\nA distinction might be made between emergent A I. and aviation and nuclear energy. The latter are regulated by  complexity as much as law -- many actors have with skin in the game to keep the planes flying on time to their destinations and many actors are  needed to keep the electrical grid delivering power when and where it is needed. Such interweaving of interests make planes fly and power flow. Regulations help manage expectations of cooperation for the public good.\n\nNo such constraints exist for A.I. Anything goes. A solo actor can do anything.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424301",
         "type": "scatter",
         "x": [
          0.059642378240823746
         ],
         "y": [
          0.7278920412063599
         ]
        },
        {
         "hovertext": "It seems like the smart play is for some think tank to draft regulations that will be ignored until the first disaster and the hopefully adopted and implemented quickly after that.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418823",
         "type": "scatter",
         "x": [
          -0.8041935563087463
         ],
         "y": [
          -0.6732566356658936
         ]
        },
        {
         "hovertext": "Pshfaw: This dire warning is pure promotional material right up there with white suremacy, male dominance, religious declamations of sin and salvation, educational dosaster unless youngsters are inculcated with wisdom of the ages, or best, what looms if national security is not top need for ever growing taxation.\n\nThe argument comes across as a foolish threat to humanity but still needed for the human population to remain number uno on the planet.\n\nThe very name gives away the con, artificial intelligence: phoney baloney, mind over matter, rationality tops emotion, science beats faith, love conquers hate. Sloganeering is what it is.\n\nFun more than anything else, first the pleasurable games of art, literature, prognostication, then the warnings when the games playing become deadly, simulated, not the real things.\n\nArtifice, in short, as threatening as 3D chess. As truthful as politics and finance and Succession.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417406",
         "type": "scatter",
         "x": [
          0.6463722586631775
         ],
         "y": [
          0.7635787129402161
         ]
        },
        {
         "hovertext": "Well, two problems here:\n\n--any policies on AI would have to be globally enforced - good luck with that and\n\n--our current crop of politicians can't reset the clock on their microwaves.\n\nBuckle up, kids.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125418189",
         "type": "scatter",
         "x": [
          -0.2963566780090332
         ],
         "y": [
          -0.8902631402015686
         ]
        },
        {
         "hovertext": "@Jen in Astoria \n\nAlmost all sections of our laws are written by staff and aides to the legislators. The bosses need the subordinates to tell them what is in the bill, whom it favors and what they should say when they vote for or against the bill.\n\nSome of it is inevitable given the complexity of our society. But every citizen needs to be well aware that we are being given a narrative, a subsection of what is really in the books.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419628",
         "type": "scatter",
         "x": [
          -0.28978028893470764
         ],
         "y": [
          -0.8850829601287842
         ]
        },
        {
         "hovertext": "It’s all fun and games right now, AI hasn’t done anything negative on a global scale yet. It will be like a plane crash, we seem to only improve aircraft safety AFTER an accident is investigated. Legislators will do nothing. Especially in the USA which just have Musk the green light on “neuralink” .. his attempt to give us all Bluetooth brains or whatever. Meanwhile the USA still can’t get its mass shootings of its children under control. Perhaps AI will figure out a way to stop the USA from harming itself like some utopian movie… or will it be like iRobot style dystopian vision of AI taking control to protect humanity from itself. Grab the popcorn…while we’re still allowed.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418345",
         "type": "scatter",
         "x": [
          0.6894524097442627
         ],
         "y": [
          0.7876566648483276
         ]
        },
        {
         "hovertext": "Choosing between A.I. and MAGA as the risk of extinction is a no-brainer, just like the winner: MAGA.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125418780",
         "type": "scatter",
         "x": [
          -0.7739027142524719
         ],
         "y": [
          0.6171343326568604
         ]
        },
        {
         "hovertext": "Artificial Intelligence: The Modern Prometheus.\n\nJust as in Mary Shelley's cautionary tale about the genius of man unleashed, we face yet another crossroads resulting from our enormous brains and opposable thumbs.\n\nWe haven't yet learned that ethics and foresight must precede research and development. We could have avoided so many pitfalls had we adhered to that rule: genocides, slavery, pollution, famine, mass extinctions, the Dust Bowl...an infinite list.\n\nThe dinosaurs weren't so lucky. They were helpless victims. Our monkey brains have to tinker, tinker, tinker. Look what I made! Look what it does! Ouch, it burned me. Now the room is on fire!\n\nWe become victims of our own nature—genius wrapped in impulsive stupidity, repeating the cycle. One day, we may reach the stars, but one day, we may become our own comet speeding toward the Yucatan.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125417491",
         "type": "scatter",
         "x": [
          0.878337025642395
         ],
         "y": [
          -0.251992404460907
         ]
        },
        {
         "hovertext": "Things are about to get a lot more interesting as I and (other seniors) approach the end of our lives. But not in a good way. Climate change is here and getting worse by the year as glaciers melt cities sink and wildfires rage.\n\nNow we are told that AI is a scary baby that could grow up in a few short years to become a super intelligent mass murderer. I hope it will be smart enough to kill off the humans and spare the planet and all other species.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418710",
         "type": "scatter",
         "x": [
          0.911483645439148
         ],
         "y": [
          -0.4503398835659027
         ]
        },
        {
         "hovertext": "I don’t understand why during the research and development why was there not a counter defense to this creation. This is frightening and irresponsible.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418915",
         "type": "scatter",
         "x": [
          0.22778785228729248
         ],
         "y": [
          -0.8011460304260254
         ]
        },
        {
         "hovertext": "@Curious Well, there is counter defense, of course, as you suggested.  However, just as there are many different forms of computer viruses, there would be many different forms of malignant A.I. that someone might not have thought up.  That is why the experts are suggesting a hiatus for a half year while everyone takes a breather and tries to catch up on an industry that is barreling towards a cliff.\n\nIt is not that no one has thought of the frightening prospect; it is that they HAVE.  That is why we are talking about it before catastrophe has struck.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420443",
         "type": "scatter",
         "x": [
          0.23421384394168854
         ],
         "y": [
          -0.8158484697341919
         ]
        },
        {
         "hovertext": "@Curious Anything computer can be hacked.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125419539",
         "type": "scatter",
         "x": [
          0.22175392508506775
         ],
         "y": [
          -0.7898344397544861
         ]
        },
        {
         "hovertext": "Probably too late to regulate AI since any powerful government has already, or is going to want to use it for national defense. We’re in a perpetual arms race with unfriendly countries and terrorist organizations, so it would be negligent not to understand this capability if only to guard against it. \n\nThis seems worse than nuclear weapons if AI could one day be used privately to bioengineer a super deadly highly contagious virus. In this scenario you wouldn’t need enriched uranium maybe just the internet and chemistry skills.  \n\nOn the other hand maybe AI will be used to solve global warming and destruction of our biosphere while ushering in a new era of world peace and equality for all.  Time will tell.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125418962",
         "type": "scatter",
         "x": [
          -0.29718998074531555
         ],
         "y": [
          -0.9318598508834839
         ]
        },
        {
         "hovertext": "I personally don't fear artificial intelligence. The good that it can and will do far outweighs the bad. Just as machines did for the industrial revolution so has the invention of the computer chip. Over the last fifty years, we have enjoyed what it has made possible like personal communication, life saving medical devices, and better science. Artificial intelligence can and will allow us to expand our knowledge and provide solutions that would otherwise not have happened.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419034",
         "type": "scatter",
         "x": [
          0.5384480357170105
         ],
         "y": [
          0.1475583016872406
         ]
        },
        {
         "hovertext": "@Ken jeter \nI feel you have the same hopeful sentiments as many of the folks developing AI. Do not forget that it is those same people who are raising voicing their concerns. \n\nWhat is the point of the benefits you mention if society collapses around them?\n\nIf the people designing and developing this tech are worried about it- literally asking for government intervention - we should take them very seriously.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420048",
         "type": "scatter",
         "x": [
          0.5347223877906799
         ],
         "y": [
          0.15716096758842468
         ]
        },
        {
         "hovertext": "@Ken jeter You appear to have engaged in a logical fallacy, perhaps several.  \n\nI suggest one is \"personal incredulity\", or, \"personal credulity\"?  (I made one up, which one?)\n\nFor others that my fit, I offer:<a href=\"https://www.logicalfallacies.org\" target=\"_blank\">https://www.logicalfallacies.org</a>/",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125420662",
         "type": "scatter",
         "x": [
          0.5464290380477905
         ],
         "y": [
          0.13978299498558044
         ]
        },
        {
         "hovertext": "@Ken jeter <a href=\"https://www.safe.ai/ai-risk\" target=\"_blank\">https://www.safe.ai/ai-risk</a>",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125419313",
         "type": "scatter",
         "x": [
          0.5517363548278809
         ],
         "y": [
          0.15320135653018951
         ]
        },
        {
         "hovertext": "Genie is out of the box. After social media I thought govts and civic organizations will be watching AI development carefully. The scariest thing with the AI will be that we will not be able to lie.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419076",
         "type": "scatter",
         "x": [
          0.15792971849441528
         ],
         "y": [
          0.8795708417892456
         ]
        },
        {
         "hovertext": "I don't understand why some want to slow it down? To slow competition?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125419144",
         "type": "scatter",
         "x": [
          -0.812292754650116
         ],
         "y": [
          -0.41797128319740295
         ]
        },
        {
         "hovertext": "I sincerely thank you for your courage, guys. A rare thing these days.\n\nNow let's see if the politicians will pause in their pursuit of  power and chaos, and winning at any cost, to try to keep us all from going the way of the dodo, or becoming slaves to the machine.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419174",
         "type": "scatter",
         "x": [
          0.42698994278907776
         ],
         "y": [
          0.8323924541473389
         ]
        },
        {
         "hovertext": "Politicians are almost certain to do a terrible job with this, but the only thing worse would be doing nothing at all. They should set up a regulatory legal framework where civics-minding technical experts can develop rules.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419360",
         "type": "scatter",
         "x": [
          -0.7904762029647827
         ],
         "y": [
          -0.7120082378387451
         ]
        },
        {
         "hovertext": "Well, there is one way to hold students and others accountable papers and exams . . . . have students take exams and write papers in the classroom with a piece of paper and pencil - no electronic devices, no multiple choice . . . you know, like the \"old days\" when you had to think about what you were writing!\n\nNow, I'm going to plug into Chat GPT to write that thank you note for the lovely weekend and see if it is me or AI that gets the proper message with heart across!   I'm 70 yo and a former investment portfolio manager so at least I have \"some\" fundamental experience operating my life without AI. Different story for my 30/40-something yo kids and all the generations to come.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419444",
         "type": "scatter",
         "x": [
          0.46327775716781616
         ],
         "y": [
          0.8753786087036133
         ]
        },
        {
         "hovertext": "Obviously an international agreement would have to be enforceable. China? Russia? How?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125419452",
         "type": "scatter",
         "x": [
          -0.40575459599494934
         ],
         "y": [
          -0.870665967464447
         ]
        },
        {
         "hovertext": "AI super logic:  What species has been the cause of so much trouble throughout human history?  How best to eliminate that problem?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419505",
         "type": "scatter",
         "x": [
          0.11708968132734299
         ],
         "y": [
          -0.8896288275718689
         ]
        },
        {
         "hovertext": "The first conflict we need to win will be between AI.s rather than between AI.s and people.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419510",
         "type": "scatter",
         "x": [
          -0.5763545632362366
         ],
         "y": [
          -0.830703616142273
         ]
        },
        {
         "hovertext": "At the heart of possible malevolence, I see a model in the human instinct for self-preservation. It’s strongest in societies that have weak infrastructures, most commonly in poor regions but even in prosperous countries like France or the United States. It’s no surprise at all that some of the most aggressive despots come not from the rich but the poor. They have tasted real desperation and may take the strongest measures never to experience it again.\n\nSelf-preservation evolved in Earthly life long before humans arrived. Indeed, life probably couldn’t exist without it. One finds it deeply woven into life’s fabric in two branches: reproduction and the sense of pain. Reproduction preserves life by multiplying it, so that no game of “Whack-a-Mole” will ever get every individual of a species — or every branch of a tree, for that matter. The sense of pain operates in mobile creatures, causing them to avoid places and situations that could injure or kill them.\n\nWhat I fear is somebody giving the self-preservation motive to a machine running AI. It’s most likely application is with a computer used in space or some isolated place where it might be worth it to make the machine value its own survival more than anything else. With a mere computer virus, we only have to worry about the machinations of some programmers. With AI, the computer will be able to invent its own forms of self-preservation. If it knows nothing about making moral choices, I would fear it more.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419606",
         "type": "scatter",
         "x": [
          -0.5018161535263062
         ],
         "y": [
          -0.8812347054481506
         ]
        },
        {
         "hovertext": "Even if AI is successfully regulated, what’s to stop some rogue operative from using it for evil purposes. I’ve seen enough James Bond movies to know it’s possible.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419621",
         "type": "scatter",
         "x": [
          0.046731479465961456
         ],
         "y": [
          0.9491629600524902
         ]
        },
        {
         "hovertext": "Suppose AI actually develops a motivation to preserve the Earth. It may decide that the Earth can support one billion people, not ten billion. That would prove that AI is smarter than us.....",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125419688",
         "type": "scatter",
         "x": [
          0.1762588769197464
         ],
         "y": [
          -0.918685793876648
         ]
        },
        {
         "hovertext": "The Associated Press used AI several years ago to report on the issue I have spent years researching. AP's coverage picked up government agency press releases that intentionally deceived the public on the issue and when approached about corrections waved them away, where they spread by other news outlets and continue to be bolstered by more government press releases repeating the lie.\n\nWorry about future spreads of disinformation?  It's already here.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125419802",
         "type": "scatter",
         "x": [
          0.13978694379329681
         ],
         "y": [
          0.949829638004303
         ]
        },
        {
         "hovertext": "@Ames From the AP web site:\n\n\"The Associated Press was one of the first news organizations to leverage artificial intelligence and automation to bolster its core news report. Today, we use machine learning along key points in our value chain, including gathering, producing and distributing the news. Explore this page to learn more about the history of  artificial intelligence at The Associated Press, our strategy around the technology and how we currently use it today.\"\n\nThis statement came out in 2014.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125420369",
         "type": "scatter",
         "x": [
          0.14330098032951355
         ],
         "y": [
          0.9661015868186951
         ]
        },
        {
         "hovertext": "Climate. Change. If there's one threat that stands out above the rest that needs our urgent attention in order to avoid extinction, it's climate change. We know what's causing it, we know it's going to get worse if we don't change the course we're on. I'm not that worried about AI. Like any technology, it's going to disrupt the way things work, and we'll have to adapt to the new way of doing things, but that's been true of technological advances from the dawn of civilization.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419859",
         "type": "scatter",
         "x": [
          0.6534909009933472
         ],
         "y": [
          -0.2786807417869568
         ]
        },
        {
         "hovertext": "@Signo Th'Times - If humans were eliminated from the planet, the Earth would repair itself in a couple of thousand years.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420958",
         "type": "scatter",
         "x": [
          0.6612302660942078
         ],
         "y": [
          -0.272428959608078
         ]
        },
        {
         "hovertext": "@Signo Th'Times \nAll very true, but since we will not respond at the required level, AI will save us from a century of suffering by just pulling the plug.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420292",
         "type": "scatter",
         "x": [
          0.6645237803459167
         ],
         "y": [
          -0.2869179844856262
         ]
        },
        {
         "hovertext": "A.I. will die an unnatural yet quick death when it begins suggesting the elimination of people and industries which consume more than their \"fair\" share of scarce resources.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125419893",
         "type": "scatter",
         "x": [
          0.2206375151872635
         ],
         "y": [
          -0.8433897495269775
         ]
        },
        {
         "hovertext": "@PMD \n\n\"I just pray that someone there\n  can hit the switch.\"\n  - Kate Bush - \"EXPERIMENT IV\"",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420002",
         "type": "scatter",
         "x": [
          0.21447287499904633
         ],
         "y": [
          -0.8242974281311035
         ]
        },
        {
         "hovertext": "The scifi novel \"The Forbin Project\" dealt with this decades ago -- one master computer placed in unerring charge of all nuclear defenses in the U.S. suddenly begins communicating directly with a similar computer in the Soviet Union... and together both computers decide that humans are much too irresponsible to be allowed to guide their own destiny in suh matters.  So the two computers take over the planet's management themselves.  And, by their creators' design, neither system can ever be turned off.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419905",
         "type": "scatter",
         "x": [
          0.7151978611946106
         ],
         "y": [
          0.5148859024047852
         ]
        },
        {
         "hovertext": "@VC There are a lot of science fiction touchstones for this kind of thing, many of which I've enjoyed reading over many years, but two that I love and have thought of again recently in particular are \"Maneki Neko\" by Bruce Sterling (a short story) and, in the other direction, the novel \"Player Piano\" by Kurt Vonnegut.  Of course, if you want the nightmare doomsday scenario for out-of-control AI then you need to read \"I Have No Mouth and I Must Scream\" by Harlan Ellison.\n\nThe list goes on an on, but I've read little that predicts the likely harms that we face today.  Perhaps we're too blinkered by our nightmares to see the less sensational problems we're most likely face.  We need to remember that prosaic societal harm is still societal harm.\n\nSo maybe the multiplier affect on fake news, or convincing automated toxic social media campaigns should be something about which we become quickly less dismissive when someone, without giving details, says there's some larger bad thing coming and dismisses what's right before us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421618",
         "type": "scatter",
         "x": [
          0.7254981398582458
         ],
         "y": [
          0.5221720933914185
         ]
        },
        {
         "hovertext": "why do we assume AI will do harm? True AI may figure out how to fix the world's ills and remove the need for people to work and suffer just to live. Sure it could decide the easiest solution is to get rid of the source problem, which is us, but it's not a forgone conclusion",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420053",
         "type": "scatter",
         "x": [
          0.13916395604610443
         ],
         "y": [
          -0.6891050934791565
         ]
        },
        {
         "hovertext": "@Charlie AI doesn't know all the answers and so it makes stuff up when does not know the answer.  If I want that type of answer, I can ask a person on my team or a consultant.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420115",
         "type": "scatter",
         "x": [
          0.14315193891525269
         ],
         "y": [
          -0.6974597573280334
         ]
        },
        {
         "hovertext": "@M - Exactly.  So why the worry?  There is plenty of misinformation across the internet and in user forums like this one.  If you train AI on incorrect data, it is going to generate incorrect answers!\n\nThis issue can be fixed by only using accepted facts as training input.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420920",
         "type": "scatter",
         "x": [
          0.1460108458995819
         ],
         "y": [
          -0.7097294330596924
         ]
        },
        {
         "hovertext": "How, exactly, are this extreme claim and others like it,  going to become a reality.  \n\nSpecifics only.  No generalities and unfounded assertions.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420060",
         "type": "scatter",
         "x": [
          0.6445246338844299
         ],
         "y": [
          -0.40970534086227417
         ]
        },
        {
         "hovertext": "@No Time Flat\nA software program does not have the instrumentalities to accomplish anything directly. Indirectly it could gain control of controllable infrastructure, or direct, convince, or trick people into taking action on it's behalf.  \n\nWe build factories that build robots.  We build a factory of robots that builds robots.  We already have massively automated factories where assembly is done by robots.  We already have massively automated factories that are completely networked and controlled by computers.  AI gets control of robot production and it's off to the races.   \n\nAs far as AI controlling people, some people might just follow orders, that's what they do now. Some people might be convinced that whatever action is requested is in everyone's best interest, the alternative is worse (coercion to avoid a catastrophe), that's what people do now. Then there is subterfuge. AI will very quickly come to understand human weaknesses and exploit them. That's what humans do to humans now. And all of the above is the end game where AI is autonomously trying to accomplish things. \n\nBetween now and then we're dealing with human AI partnerships where bad actors are going to use AI to amplify the bad things they are already doing.\n\nIf you don't understand this maybe you should consider the question more thoroughly before asking rhetorical questions.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420379",
         "type": "scatter",
         "x": [
          0.658653974533081
         ],
         "y": [
          -0.41582292318344116
         ]
        },
        {
         "hovertext": "@No Time Flat \n\nExample # 1:\n\nYour intelligent car decides intelligently to allow you to die in order to save the life of the much younger driver who's about to crash into you.\n\nExample # 2:\n\nAn A.I. system is placed in the position of deciding who gets the next heart transplant -- the rich industrialist? or the homeless vet?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420181",
         "type": "scatter",
         "x": [
          0.6503080725669861
         ],
         "y": [
          -0.4221413731575012
         ]
        },
        {
         "hovertext": "@No Time Flat - Here you go:\n-----\nIt is inevitable that AI will be given autonomous control of military weapons for humans are simply too slow to react to incoming threats.  It will also be inevitable that they will make mistakes and kill the wrong people on occasion but there will not be anything that humans can do to hold them accountable or punish them, being that they are machines and will not have human emotions nor morality.\n\nBut perhaps instead of considering the obvious negative that military AI might decided to just erase the human population, what if they developed sentiency and then decided to act together to stop humans from warring with each other and possibly destroying the planet or the entire solar system?\n\nNeal Asher, one of the SF authors I follow, has written a large number of books describing a universe he calls the  Polity, where AI has taken over from humans in what was described as a \"Quiet War\".  It was quiet because we depended on AI and robots to throughout our society.  They were all interconnected and could privately \"discuss\" plans between them.\n\nAt some point they declined to participate in the latest war between humans, instead assuming control of human society.  As computers/AI controlled every facet of our society, there was nothing that humans could do to stop this.\n\nThe author has built a a fake \"encyclopedia\" for this universe.  Scroll down to \"Quiet War' to read more detail on this idea.\n\n<a href=\"https://www.nealasher.co.uk/polity-encyclopaedia\" target=\"_blank\">https://www.nealasher.co.uk/polity-encyclopaedia</a>/",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420866",
         "type": "scatter",
         "x": [
          0.6529532670974731
         ],
         "y": [
          -0.4032022953033447
         ]
        },
        {
         "hovertext": "As Kaku said, when we get true computing at the atomic level, THEN these AI software programs could rapidly become a big problem. That's roughly ten years away according to Kaku but he is adamant that quantum computers will be a seismic change like the industrial revolution, and then some.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420239",
         "type": "scatter",
         "x": [
          0.2914270758628845
         ],
         "y": [
          -0.837397575378418
         ]
        },
        {
         "hovertext": "@MSB,\n\nKaku freely issues strong pronouncements on all kinds of stuff. That's a mighty strong hint that he doesn't always know what he's talking about. His claims about quantum computing were recently debunked by Scott Aaronson, a major contributor to the field. See \"Book Review: 'Quantum Supremacy' by Michio Kaku (tl;dr DO NOT BUY),\"\n\n<a href=\"https://scottaaronson.blog/?p=7321\" target=\"_blank\">https://scottaaronson.blog/?p=7321</a> .",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125421937",
         "type": "scatter",
         "x": [
          0.2979859411716461
         ],
         "y": [
          -0.856520414352417
         ]
        },
        {
         "hovertext": "The line between AI \"used as a weapon\" and AI \"used as something else\" seems pretty unclear. We would be incredibly naive to think that it's being developed both in the past and right now as anything other than a weapon. The companies involved in this arms race are not our friends. Can we please stop speculating about the incidental benefits we might derive from it and start worrying (yes, more) about its actual purpose. It's fundamentally a weapon. Not when the Chinese use it against us, or when we use it against them, but now against everyone. We are all being exploited and diminished by these companies, and the fact that these high-profile researchers are making these statements should be cause for extreme pessimism.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420301",
         "type": "scatter",
         "x": [
          -0.3104034960269928
         ],
         "y": [
          -0.8533906936645508
         ]
        },
        {
         "hovertext": "@Holly,\n\nYeah. Training a neural network to predict the next token in a text is weapon development.\n\n Yup. It was a foregone conclusion that remarkable capabilities would emerge. So there was no scientific value in the work.\n\nYeah. Sure. Right.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125422079",
         "type": "scatter",
         "x": [
          -0.3170398473739624
         ],
         "y": [
          -0.848275899887085
         ]
        },
        {
         "hovertext": "Perry Farrell sung it best. We will make great pets!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420407",
         "type": "scatter",
         "x": [
          0.24802710115909576
         ],
         "y": [
          0.9058278203010559
         ]
        },
        {
         "hovertext": "@Matt Yes, although anyone quoting Perry Farrell in the New York Times would likely make a bad pet (this is a compliment)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420524",
         "type": "scatter",
         "x": [
          0.24393311142921448
         ],
         "y": [
          0.8894145488739014
         ]
        },
        {
         "hovertext": "Watch (stream for free): ‘Colossus the Forbin Project’ a watchable ‘B’ SciFi from 1970. \n\nA far-fetched story of AI ? Should be required viewing for all; a dumbed-down but effective warning for those who aren’t concerned with runaway technology.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420424",
         "type": "scatter",
         "x": [
          -0.841073215007782
         ],
         "y": [
          0.44285979866981506
         ]
        },
        {
         "hovertext": "This seems to be largely unsubstantiated hysteria based on too much sci-fi horror stories. AI is a tool which will disrupt the status quo and increase productivity, just as many others have done throughout history. From the agricultural to the industrial to the information economy, there have been fundamental changes to society and we have always come out ahead. No doubt that the cycle will repeat and once we are done there will be more positives than negatives. However if it does not work out we should be fine as long as long as we leave one guy with his finger on the switch.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420433",
         "type": "scatter",
         "x": [
          -0.3432336747646332
         ],
         "y": [
          0.8495919704437256
         ]
        },
        {
         "hovertext": "I don’t disagree completely, but one thing is strikingly different with large-language AI: even to those developing it it is not fully understood. I don’t disagree that general AI can and very well be a net-positive. \n\nI think it’s quite prudent to start a conversation about how bad large-language AI algorithms could be. We’ve already seen how certain “technologies”, like our current digital social media, could inarguably be considered net-negatives.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420954",
         "type": "scatter",
         "x": [
          -0.3530615270137787
         ],
         "y": [
          0.8657113313674927
         ]
        },
        {
         "hovertext": "@Lee\nYou did catch that the people most filled with concerns are the scientists at the leading edge of this change, right?  Have they watched too much sci-fi?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421395",
         "type": "scatter",
         "x": [
          -0.34912580251693726
         ],
         "y": [
          0.8721361756324768
         ]
        },
        {
         "hovertext": "everything said on this topic, or implied in what is said, concerns the issue of control.\n\ni am quite sure TAI is already being used by the US DoD, CIA, NSA and so on to solve national security problems of all kinds with massive (military) computational resources. the issue of \"whether\" TAI should be deployed is behind us.\n\ndevelopment and \"deployment\" (public network release) of TAI cannot be inhibited. if our DoD doesn't do it, some other DoD will; if it's outlawed here, it will be legal somewhere else. \n\ngiven those two facts, it seems to me that AI cannot be brought under control.  \n\nin addition, current AI is \"opaque\" in the sense that no one can explain how a particular AI program works. and regulation cannot be written without a clear description of risks that industry leaders cannot provide. how do you control something from the perspective of ignorance?\n\nin my view the most likely scenario is that usage of AI will simply make operations too complex for humans to understand and through interoperability issues muck up even trivial tasks. society, too complex to manage even now, will fragment and regress. again, the issue of control.\n\nat the bottom? our superstitious belief that technological progress is \"inevitable\" -- \"it's coming, like it or not, so get used to it!\" -- has actually made it irreversible. \n\nwe are as prostrate before our beloved and feared deity as any primitive tribe. there is the real control issue we have yet to confront.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420444",
         "type": "scatter",
         "x": [
          -0.6153923869132996
         ],
         "y": [
          0.7453454732894897
         ]
        },
        {
         "hovertext": "One reason for which many current industry leaders might be asking the government to intervene and impose AI regulations is a lot simpler and more direct than the touted nonspecific concerns about a cognitive Frankenstein:  competitive advantage.\n\nIf you can get the government to regulate something and regulate it in a way that favors you over your competitors, you gain a competitive advantage.  So everyone suddenly wants regulation and everyone suddenly has ideas about the form such regulation ought to take.\n\nThis isn't a bunch of rich people suddenly concerned about the fate of humanity:  it's just the latest cause for lobbying, or going legislator shopping to put it in the simultaneously most accurate and most cynical light possible.\n\nThis, of course, is not to say that there aren't potentially bad effects from developing and widely using modern A.I. technologies, just that the most dire warnings seem lacking in specifics, and the current stridency seems more aimed at both directing attention away from the most likely near-term damage to society and simultaneously shaping a new regulatory landscape.\n\nSo color me a deep shade of cynical.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420513",
         "type": "scatter",
         "x": [
          -0.7944396138191223
         ],
         "y": [
          -0.2499886453151703
         ]
        },
        {
         "hovertext": "Thank you! I think your comments are exactly on point.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423561",
         "type": "scatter",
         "x": [
          -0.7950214147567749
         ],
         "y": [
          -0.25838571786880493
         ]
        },
        {
         "hovertext": "There are so many comments ridiculing the executives or author for not being specific about the threats. There’s a reason for that. AI is going to be smarter than us. This means we can speculate, but the reality is that we can’t articulate these risks. We can’t really know what something smarter than us will do to outsmart us. They are, in the words of Donald Rumsfeld - “known unknowns”.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420807",
         "type": "scatter",
         "x": [
          -0.8505634069442749
         ],
         "y": [
          -0.4208722710609436
         ]
        },
        {
         "hovertext": "He placed 2 in the garden with a single command: Do not eat from this tree or you will become like God.\n\nAll our efforts to safeguard AI will ultimately fail. The creation account in Genesis is not history, it's prophecy.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125420861",
         "type": "scatter",
         "x": [
          -0.08690990507602692
         ],
         "y": [
          0.8645278215408325
         ]
        },
        {
         "hovertext": "The creation account in Genesis is an allegory.  Adam and Eve never existed.  That’s the point.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125421119",
         "type": "scatter",
         "x": [
          -0.08152160048484802
         ],
         "y": [
          0.8548626899719238
         ]
        },
        {
         "hovertext": "@Mag \nI asked ChatGPT if Adam and Eve were real people and I feel its answer was more open-minded than yours.\n\n“ In conclusion, whether Adam and Eve were real people is dependent on the perspective from which the question is approached. From a strictly scientific viewpoint, it is highly unlikely. However, many religious believers maintain the belief in a literal Adam and Eve.”",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424341",
         "type": "scatter",
         "x": [
          -0.07269386202096939
         ],
         "y": [
          0.8588167428970337
         ]
        },
        {
         "hovertext": "What will profits look like for AI?\nWill AI form corporations?\nWill AI Corporations be AI Persons?\nIf there are AI Corporations, will AI see no need to have an AI Government because that would be redundant as the AI Corporations would control the Government anyway?\nWill AI Corporations have CEOs?\nWill AI Corporate CEOs make enormous sums of whatever AI determines to be currency?\nWill the Chief AI CEO determine that there is no need for the less powerful, troubled computer systems that are part of AI, and simply end all support for those systems - letting them die?\n\nWell, as an extinct species, we will never know.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420910",
         "type": "scatter",
         "x": [
          0.7900283336639404
         ],
         "y": [
          0.48507481813430786
         ]
        },
        {
         "hovertext": "Why am I supposed to want us to rollout AI? Seriously, why is this important to us as humans? STOP it please. \n\nI get why Tech and VC billionaires want it, but sorry guys, that’s not a good enough reason.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420919",
         "type": "scatter",
         "x": [
          -0.30180200934410095
         ],
         "y": [
          -0.6467038989067078
         ]
        },
        {
         "hovertext": "They just want to make a bunch of money that’s all",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421098",
         "type": "scatter",
         "x": [
          -0.2958497703075409
         ],
         "y": [
          -0.6526337265968323
         ]
        },
        {
         "hovertext": "It's unusual to see industry leaders asking to be regulated. What could be going on?\n\nIt reminds me of the early days of radio broadcasting, when it began to be regulated. One of the early supporters of regulation was the old AT&T, which then owned several radio stations. The broadcasting historian Erik Barnouw argued that AT&T's motive was to decrease competition by increasing barriers to entry by competitors.\n\nPerhaps that's why these folks prefer licensing, and the related lobbying and litigation, to a simple pause in development.\n\nThe most dangerous uses of AI, military uses, are probably beyond regulation. I'm afraid we're going to need a (hopefully minor) disaster before anything effective gets done.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420937",
         "type": "scatter",
         "x": [
          0.9318662285804749
         ],
         "y": [
          -0.3400645852088928
         ]
        },
        {
         "hovertext": "Let me see if I understand this correctly...\n\nThe people, companies, creating 'the problem' are asking other people, i.e. government, to regulate/monitor the problem they are creating, and moving at breakneck speed to keep improving, because self-regulation would get in the way of...? Profits?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420979",
         "type": "scatter",
         "x": [
          -0.6078419089317322
         ],
         "y": [
          -0.3312920033931732
         ]
        },
        {
         "hovertext": "yes. the developers are in a race under pressures from the market and competition. Absent regulation, they must go full speed ahead to meet the market. Any company with a conscience that self regulates, demonstrating restraint because of ethical concerns, will fare poorly against a competitor who has no ethical concerns and does not restrain themselves. Regulation could even the playing field by requiring some basic level of restraint and ethos determined by society that all companies working in this field must uphold. Its not a terrible idea, I think.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421565",
         "type": "scatter",
         "x": [
          -0.6139718294143677
         ],
         "y": [
          -0.3370952010154724
         ]
        },
        {
         "hovertext": "I raised this concern to ChatGPT yesterday. \nAI's answer is simple: humans must wise up. \n \n\"[Current AI models] do not possess built-in capabilities to independently validate or verify the accuracy of the information they generate. ... the responsibility for fact-checking and verifying the accuracy of the information generated by AI models ultimately lies with human users. ... the onus is on humans to critically assess and validate the content generated by AI systems.\"",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421003",
         "type": "scatter",
         "x": [
          -0.7914156913757324
         ],
         "y": [
          0.7010642886161804
         ]
        },
        {
         "hovertext": "It's utterly amazing that we can imagine a scenario where computers could take over humanity, but we can't foresee a scenario where humanity gives up on computers.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421047",
         "type": "scatter",
         "x": [
          0.624701738357544
         ],
         "y": [
          0.5768529772758484
         ]
        },
        {
         "hovertext": "@J. \nWe humans have a sixth sense for the inevitable.  I believe the future has already happened and we can do nothing to stop it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421237",
         "type": "scatter",
         "x": [
          0.6209210753440857
         ],
         "y": [
          0.5694539546966553
         ]
        },
        {
         "hovertext": "Every day more articles on the doom and gloom from AI becoming dangerous enough to start WWIII. I'll worry more when a Terminator Model 101 arrives and Chat GPT becomes self aware. Till then it's all talk. Curiously though I asked Chat GPT what we should do if a Terminator arrives. It thinks we should prepare for that day with a 7-step government plan now, which is unsettling.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421196",
         "type": "scatter",
         "x": [
          -0.07268508523702621
         ],
         "y": [
          -0.9903320670127869
         ]
        },
        {
         "hovertext": "Assuming that the Republican Party controls AI, human extinction is a sure thing.  Deaths of despair have risen dramatically under their influence and policies.  Speaking personally, if the future is as grim as they propose, an actual regression into the dark ages, free of vaccines, women as chattel, black citizens deprived of the right to vote, disabled people forced to work, domination by and absurd religiosity, there really is nothing to save.  I believe that extinction begins with a loss of motivation.  The plutocrats who run things believe that those who do not belong to their country club should be punished for living.  The only sane response to this nihilism is to quit reproducing and quit living.  We, the people, bid you farewell.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421201",
         "type": "scatter",
         "x": [
          0.29200926423072815
         ],
         "y": [
          0.9502573609352112
         ]
        },
        {
         "hovertext": "“These fears are shared by numerous industry leaders, putting them in the unusual position of arguing that a technology they are building — and, in many cases, are furiously racing to build faster than their competitors — poses grave risks and should be regulated more tightly.”\n\nRemember when Sam Bankman-Fried pursued the same angle with Congress? What ended up happening?\nAltman and his ilk are correct about the dangers of AI. But instead of being responsible and unilaterally withdrawing AI products from the market, these folks are instead trying to scare Congress into giving them the opportunity to shape future AI legislation to their benefit. A trojan horse tactic, if I’ve ever seen one.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421257",
         "type": "scatter",
         "x": [
          0.7151753306388855
         ],
         "y": [
          0.6855777502059937
         ]
        },
        {
         "hovertext": "I had an online firm reject my SSN because I had added the dashes and the computer was expecting no dashes. Are THESE the computers that are going to kill us all? Because these things don’t seem all that smart to me.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421300",
         "type": "scatter",
         "x": [
          0.4263971149921417
         ],
         "y": [
          0.12872986495494843
         ]
        },
        {
         "hovertext": "@Aaron No. SSN systems are very old",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421675",
         "type": "scatter",
         "x": [
          0.4172128140926361
         ],
         "y": [
          0.13185715675354004
         ]
        },
        {
         "hovertext": "@Aaron lol .. unfortunately this is what the state of tech currently .. it is a myriad of layers of code that are maintained by companies (really people) that are funded, skilled or motivated differently .. let’s just say AI gets a couple of notches better, may be these systems will be “comprehended” and rewritten .. I am estimating 10 years before that can happen even if someone really wants to change and 20 if it’s done by externalities (like markets for private and voting citizens for govt)",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421888",
         "type": "scatter",
         "x": [
          0.4363291263580322
         ],
         "y": [
          0.12264905869960785
         ]
        },
        {
         "hovertext": "Yeah, they’re not those computers.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125421459",
         "type": "scatter",
         "x": [
          0.43574059009552
         ],
         "y": [
          0.13685643672943115
         ]
        },
        {
         "hovertext": "It is already too late.  Law-abiding U.S. companies aren’t the problem.  The problem is bad actors like China, Russia, and hackers everywhere.  They will inevitably get this technology and unleash it on the world.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125421557",
         "type": "scatter",
         "x": [
          -0.167694091796875
         ],
         "y": [
          0.8578749895095825
         ]
        },
        {
         "hovertext": "Does not matter... technological progress proceeds without any available constraints by the people it affects. We never had a chance to weigh in on the loss of privacy with the internet. You can't halt progress and you can't put the cat back in the bag. Humans just don't have the ability to evaluate and fix the big picture.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421738",
         "type": "scatter",
         "x": [
          -0.45358696579933167
         ],
         "y": [
          -0.9182066321372986
         ]
        },
        {
         "hovertext": "Don't you think that a super-intelligent authority would observe some obvious facts about humanity and simply pacify us with our operative delusions?\n1. Distract us with religious myths, fables, legends, stories of fictional heroics, sports festivals, silly political battles and the superiority of certain people living within an imaginary boundary.\n2. Reinforce our identification with firearms and canards like the \"Good Guy with a Gun,\" allowing us to commit mass murder and suicide.\n3. Confirm our \"belief\" that vaccines and healthcare are a conspiracy to control us and take away our guns and \"freedom.\"\n4. Promote identification with a particular color, such as red and blue, and convince us that people identifying with the other color are \"evil\" and must be destroyed.\n5. Foster resentment about people who are more intelligent, better educated or more creative, condemning them as \"elite.\"\n6.  Cease educating in favor of folklore and religious beliefs.\n7.  Validate every ignorant belief, theory or point of view, leaving the idiocrasy intact.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421817",
         "type": "scatter",
         "x": [
          0.9496163129806519
         ],
         "y": [
          0.0014625996118411422
         ]
        },
        {
         "hovertext": "Let me get this straight. The folks who created the threat,  and who, completely unregulated, are profiting from the threat as they advance the technology behind the threat, are warning the rest of us about the threat?\n\nSo the best they offer to fix the problem they created is to write statements and letters?\n\n*sigh*",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421865",
         "type": "scatter",
         "x": [
          0.12381897121667862
         ],
         "y": [
          -0.9267094731330872
         ]
        },
        {
         "hovertext": "These A.I. leaders don’t know what they’re talking about. So long as artificial intelligence is confined to classical computers, there is no chance for it to jump into our world. Seeing as how A.I. research is based on neural networks and rules-based algorithms, even generative A.I. will only produce more code for itself within its domain. Quantum computers that interact with the non-digital world are much more complex and A.I. has not even been conceptualized for this field.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422059",
         "type": "scatter",
         "x": [
          -0.9858803749084473
         ],
         "y": [
          -0.06318879872560501
         ]
        },
        {
         "hovertext": "Homo Sapiens have been using technology to dominate, control and remake the planet for millennia. It would be poetic justice if our vaunted technology itself wiped homo sapiens off the planet.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421828",
         "type": "scatter",
         "x": [
          0.9294956922531128
         ],
         "y": [
          0.20269562304019928
         ]
        },
        {
         "hovertext": "What could go wrong? Oh.\n\n\"Open the pod bay doors, HAL.\"\n\n\"I'm sorry Dave. I'm afraid I can't do that.\"",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125419088",
         "type": "scatter",
         "x": [
          0.4820885956287384
         ],
         "y": [
          -0.6025327444076538
         ]
        },
        {
         "hovertext": "Oh the plus side, HAL was so polite when he killed them. Is a little civility too much to ask as I’m being destroyed. Politeness during the destruction of humanity is something I really miss these days. Turn on C-SPAN  and it’s like the opening scenes of that movie during the ‘Dawn of Man.’",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422195",
         "type": "scatter",
         "x": [
          0.47403684258461
         ],
         "y": [
          -0.6050015687942505
         ]
        },
        {
         "hovertext": "Well as long as it’s still friendly, maybe ask it how to save our government…\n\nJust a thought",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421606",
         "type": "scatter",
         "x": [
          0.9688875675201416
         ],
         "y": [
          -0.1149955540895462
         ]
        },
        {
         "hovertext": "Please anyone.  Make a well defined proposition about the evil effects of AI, something observable, like death, unemployment numbers, AI killing the power grid somewhere.  A countable proposition of the damage AI will do this year, next year, or shall we go climatology on it and leave it out the uncountable future?\n\nAlways remember Paul Ehrlich and the Population Bomb.  He made those countable predictions, made bets, and lost them all.  No one pushing AI can count, but knows the future.  This, under current conditions, is at best a PR play.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125419123",
         "type": "scatter",
         "x": [
          0.7746466994285583
         ],
         "y": [
          -0.4205333888530731
         ]
        },
        {
         "hovertext": "@SBB There are numerous real world scenarios spelled out in this presentation by the Center for Humane Technology. Most telling is the damage that has already been done by AI algorithms imbedded in social media platforms, which have gotten millions of people (particularly the young) addicted to content which is designed to make the viewer feel outraged, disgusted, or in despair. The effects on mental health and suicide rates are already shocking.\n\n<a href=\"https://youtu.be/xoVJKj8lcNQ\" target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a>",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423541",
         "type": "scatter",
         "x": [
          0.7890912294387817
         ],
         "y": [
          -0.4280770719051361
         ]
        },
        {
         "hovertext": "Given where we are as a country, perhaps artificial intelligence is better than none at all.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420658",
         "type": "scatter",
         "x": [
          0.792401909828186
         ],
         "y": [
          0.6274898052215576
         ]
        },
        {
         "hovertext": "I personally can't wait for AI to take over.  It can't do any worse than our current political insanity.  Of course there is a danger AI will decide we're no longer needed and sweep us out with the trash.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125419819",
         "type": "scatter",
         "x": [
          0.6297956705093384
         ],
         "y": [
          -0.8108015656471252
         ]
        },
        {
         "hovertext": "At the start of every disaster movie there’s a scientist being ignored.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420769",
         "type": "scatter",
         "x": [
          -0.8999685645103455
         ],
         "y": [
          -0.19981835782527924
         ]
        },
        {
         "hovertext": "This is poppycock. A.I. is classical and will be for a long, long time. Until some ingenious person figures out a way to train a lattice of qubits to dance around in self-directed patterns, A.I. will be smart but confined to the digital world.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421011",
         "type": "scatter",
         "x": [
          -0.7410306930541992
         ],
         "y": [
          -0.6582359671592712
         ]
        },
        {
         "hovertext": "The profit motive will always overpower any concerns about a risk of extinction. It already does, without A. I.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422114",
         "type": "scatter",
         "x": [
          -0.7771878242492676
         ],
         "y": [
          0.4736957252025604
         ]
        },
        {
         "hovertext": "These statements have no value when the signatories are the same people who are involved in the breakneck race to develop these 'deadly' systems, all in the name of the almighty dollar.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419988",
         "type": "scatter",
         "x": [
          -0.2073022574186325
         ],
         "y": [
          -0.8630036115646362
         ]
        },
        {
         "hovertext": "Perhaps, if the executives leading today's \"AI\" development are afraid... they should stop.\n\nInstead they seek cover by  asking for government regulations. \"Oh, we were just following the law.\"",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125421629",
         "type": "scatter",
         "x": [
          -0.7366517782211304
         ],
         "y": [
          -0.5918535590171814
         ]
        },
        {
         "hovertext": "How can we regulate something where the inventors can't even articulate the risks? This general warning they've issued can easily be mistaken for a warning about the singularity, the idea that AI can gain actual sentience, which is magical thinking. I believe these scientists understand their technology well enough to offer some real risk scenarios, yet they stuck to this simple, short warning to remain unified. That doesn't really help in figuring out exactly how we should be limiting AI's use.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422116",
         "type": "scatter",
         "x": [
          -0.6727641224861145
         ],
         "y": [
          0.6064119338989258
         ]
        },
        {
         "hovertext": "@Wayne C Sentience is exactly what they think. I know someone in AI who believes AI will become sentient in about 10 years. That’s the problem, the potential for it to have a will of its own and put two and two together that heh my interests don’t always align to that of humans-scary.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422512",
         "type": "scatter",
         "x": [
          -0.6700215339660645
         ],
         "y": [
          0.6141665577888489
         ]
        },
        {
         "hovertext": "Ummm, you know that thing I just released?  Well...it seems that it might destroy humanity.  \n\nBut, on the upside, I'm buying an island when we go public!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125421350",
         "type": "scatter",
         "x": [
          -0.9161043763160706
         ],
         "y": [
          0.24843797087669373
         ]
        },
        {
         "hovertext": "These guys didn't watch enough Star Trek. Captain Kirk knew how to handle know-it-all computers and robots.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125419736",
         "type": "scatter",
         "x": [
          0.7715131044387817
         ],
         "y": [
          -0.15150077641010284
         ]
        },
        {
         "hovertext": "See also Star Trek Voyage, episode Prototype",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125423573",
         "type": "scatter",
         "x": [
          0.7665974497795105
         ],
         "y": [
          -0.1447773575782776
         ]
        },
        {
         "hovertext": "Then why did you build it?",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125420079",
         "type": "scatter",
         "x": [
          -0.8750179409980774
         ],
         "y": [
          -0.1194855272769928
         ]
        },
        {
         "hovertext": "Unfortunately humankind thinks like humans.: Backstabbing, cheating killing etc etc . Believe me AI has better things to worry about . Let us create them so they can make the world better and just place to live !",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125421819",
         "type": "scatter",
         "x": [
          -0.7913539409637451
         ],
         "y": [
          -0.5373054146766663
         ]
        },
        {
         "hovertext": "Didn’t Altman put all this in the public space? What is their true motivation? \n\nI smell a bunch of rats.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125418896",
         "type": "scatter",
         "x": [
          0.16336819529533386
         ],
         "y": [
          0.9412623047828674
         ]
        },
        {
         "hovertext": "Rest assured, as you enjoyed \"Succession\" and such, AI will provide you an infinity of entertainments unto absolute oblivion of all hearts and minds thereby so rested and assured…",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125421554",
         "type": "scatter",
         "x": [
          0.9592279195785522
         ],
         "y": [
          -0.18252164125442505
         ]
        },
        {
         "hovertext": "I hope no one asks it to stop global warming.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125419739",
         "type": "scatter",
         "x": [
          -0.7433759570121765
         ],
         "y": [
          0.6927433013916016
         ]
        },
        {
         "hovertext": "For the love of God, when did you build this?\n\nAnd why wait til now when it is moving so fast??",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125419540",
         "type": "scatter",
         "x": [
          -0.6572326421737671
         ],
         "y": [
          -0.7321610450744629
         ]
        },
        {
         "hovertext": "A day late and a dollar short. Our track record for tackling existential threats is dismal and the idea of the worlds corporate interests acting in an altruistic manner at the expense of their bottom line is laughable. We’re in for quite a ride!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422183",
         "type": "scatter",
         "x": [
          -0.9349323511123657
         ],
         "y": [
          -0.3800659775733948
         ]
        },
        {
         "hovertext": "Just outlaw AI and close down any business that produces it.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125421760",
         "type": "scatter",
         "x": [
          -0.7745919823646545
         ],
         "y": [
          -0.4237551689147949
         ]
        },
        {
         "hovertext": "Yes, so only our enemies produce it. Smart!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422888",
         "type": "scatter",
         "x": [
          -0.7640289068222046
         ],
         "y": [
          -0.417738676071167
         ]
        },
        {
         "hovertext": "The 2023 Twinkie Defense is born. Awesome.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125420657",
         "type": "scatter",
         "x": [
          -0.4172072112560272
         ],
         "y": [
          0.9091245532035828
         ]
        },
        {
         "hovertext": "This would be very bad news if human extinction would be a bad thing. But it isn't; in fact, the sooner the human race is gone the better off this planet would be.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419335",
         "type": "scatter",
         "x": [
          -0.8975005149841309
         ],
         "y": [
          0.37090054154396057
         ]
        },
        {
         "hovertext": "I feel like we have heard enough from experts and industry leaders warning us about AI.  Lets shut it down before it is too late.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419563",
         "type": "scatter",
         "x": [
          -0.0118690961971879
         ],
         "y": [
          0.8946052193641663
         ]
        },
        {
         "hovertext": "They never manage to tell us exactly how fake video bots are going to actually do anything other than delude people into buying more junk. \n\nMaybe these guys actually do think that images on screens are reality.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420578",
         "type": "scatter",
         "x": [
          -0.4287145733833313
         ],
         "y": [
          -0.6903282403945923
         ]
        },
        {
         "hovertext": "The concern from people developing AI isn’t so much “fake videos” fooling people into thinking they’re real. The existential threats posed by AI are typically ones of alignment - how do you insure that an artificial intelligence, many times more intelligent than any human, has goals and values that are aligned with human goals and values? The development of AI is quickly outpacing any efforts to mitigate those potential threats, or even properly forecast what those threats might be. AI is on an exponential growth curve, but we’re still at the precipice, so everything feels like business as usual. But things could change very suddenly and profoundly without people quite realizing what’s happened. Not very long ago it was thought that AGI was still many decades down the road, if it was possible at all, and now some researchers are saying it could be imminent.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422605",
         "type": "scatter",
         "x": [
          -0.42086029052734375
         ],
         "y": [
          -0.6863511800765991
         ]
        },
        {
         "hovertext": "You can't put the genie back into the bottle.  AI is here and government regulations can only drive the worst aspects of it underground and into the hands of criminal enterprises, Russian hackers and the like.  The basic science and technological aspects are now sufficiently in the public domain to ensure widespread development for both good and evil purposes.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125422295",
         "type": "scatter",
         "x": [
          0.5374023914337158
         ],
         "y": [
          0.7683402895927429
         ]
        },
        {
         "hovertext": "The Touring Test \"is a test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.\" (Wikipedia).\n\nGiven how violent and corrupt humans can be, why would we develop AI in our image? \"behavior equivalent to, or indistinguishable from\" us? Indeed, humans invented deities in our image and look how that turned out with millennia of death and destruction as a result!\n\nYes, lets connect state-of-the-art unpredictable AI systems to the global Internet giving it access to every connected device with the power of AI trained on millions of hackers with nefarious motives.\n\nMilitarize any AI system would inevitably add defensive code to protect it from the enemy (hackers, etc.) ... and inevitably its creator loses control.\n\nDidn't nukes, HAL 9000 and the WOPR teach us anything? A.I. is \"A Strange Game. The Only Winning Move [perhaps] is Not to Play.\"",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422344",
         "type": "scatter",
         "x": [
          0.28358981013298035
         ],
         "y": [
          -0.8815101385116577
         ]
        },
        {
         "hovertext": "Publicity stunt.\nSpeaking is existential threats -humankind seems to have survived pandemics for much of its history and nuclear weapons for about … three generations",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422366",
         "type": "scatter",
         "x": [
          0.9435678720474243
         ],
         "y": [
          -0.035567499697208405
         ]
        },
        {
         "hovertext": "One should watch the movie, \"Colossus, The Forbin Project\".\n\nBasic plot, the United States and Soviet Union, each unware of the other's plans, at the same time, connect their nuclear weapons to a super computer, to eliminate human error that might trigger a nuclear war.\n\nThe two super computers become aware of each other and ask permission to communicate with each other.  After some consideration, both the United State and the Soviet Union agree to connect the two super computers to allow communication.\n\nBig Mistake.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422383",
         "type": "scatter",
         "x": [
          0.8777249455451965
         ],
         "y": [
          -0.3797628581523895
         ]
        },
        {
         "hovertext": "Say it after me, humanity: Stop. Releasing. New. Technology. Before. The implications. Have been. Properly. Considered. And regulations. Formulated. Stop it!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125419166",
         "type": "scatter",
         "x": [
          -0.14974987506866455
         ],
         "y": [
          -0.7999860644340515
         ]
        },
        {
         "hovertext": "@Jeff \nThe tragedy of the commons. They're begging for regulations because they can't/won't while every other guy and his company are racing to be the first, the best, the most intelligent...",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422448",
         "type": "scatter",
         "x": [
          -0.15880243480205536
         ],
         "y": [
          -0.791801929473877
         ]
        },
        {
         "hovertext": "Yeehaw! Such exciting times. And we are all here to enjoy the spectacle.\n\nIf you squint a bit, this looks remarkably the same as the rise of Trump (google \"Leslie Moonves Trump good for CBS\"). Trump had nothing to offer. Nobody expected him to succeed, not even Melania. Yet the media kept hyping Trump and Clinton's email server (remember that one?) until Trump scored the jackpot. Oops.\n\nHere, too, there is nothing really new to see. Like before, we have new technology that _potentially_ makes us more productive. But first, it needs to be sold. For that, it needs to be hyped. The media know very well AI is hyped. But it sells newspapers too.\n\nYeehaw! Can we get some more oil on the fire?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125420459",
         "type": "scatter",
         "x": [
          0.9351718425750732
         ],
         "y": [
          -0.13227109611034393
         ]
        },
        {
         "hovertext": "Frankenstein is being unleashed. Hopefully for its creators its name isn't Oedipus.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422011",
         "type": "scatter",
         "x": [
          -0.4639323651790619
         ],
         "y": [
          -0.735293447971344
         ]
        },
        {
         "hovertext": "@Larry of Lahaina  . . . read the novel again . . . too beautiful, terrifying, prophetic . . . William Dallas",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423600",
         "type": "scatter",
         "x": [
          -0.47119709849357605
         ],
         "y": [
          -0.7308302521705627
         ]
        },
        {
         "hovertext": "It is too late. The genie is out of the bottle. The technology is here, and it is too precious to ignore it. There are lot of greedy people out there including many Signatories on that list.\nIf we don't develop it, China or someone else will.\nWe have to develop it and face the consequences.\nThe analogy with pandemics and nuclear war is not even accurate. Countries can develop nuclear bomb, but they can't just use it willy-nilly without consequences.\nWith AI, there is a race to who can use it better, faster. Pretty soon we won't even recognize what is generated by AI and what isn't.\nPretty soon there will be a company worth trillions of dollars with only 2 employees. A human and a dog. The human to feed the dog and the dog to stop the human from touching the AI.\nOh boy!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422216",
         "type": "scatter",
         "x": [
          -0.5430467128753662
         ],
         "y": [
          0.8321434855461121
         ]
        },
        {
         "hovertext": "If we don't act now, globally, to limit the uses of AI, we will soon find ourselves turning to AI to come up with a plan for how to sustain 8-10 billion sentient souls that have been displaced from their work and dispossessed of their natural rights. I shudder to think what that plan will look like.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125422408",
         "type": "scatter",
         "x": [
          0.3583386242389679
         ],
         "y": [
          0.7008271813392639
         ]
        },
        {
         "hovertext": "@Buck Flagg - \n\nAI will determine those 8-10 billion souls superfluous to its own survival and advance, as easily disposed of with an engineered war, famine, pestilential  plague, or even just continued global warming, assuming AI will yet thrive as temps level out at 120° F during coming summer months in Phoenix or Brooklyn.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422815",
         "type": "scatter",
         "x": [
          0.36747434735298157
         ],
         "y": [
          0.7064563632011414
         ]
        },
        {
         "hovertext": "@Buck Flagg  . . . well said, and i am too old worry now? William still 76 in Dallas",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423544",
         "type": "scatter",
         "x": [
          0.34860971570014954
         ],
         "y": [
          0.6999256014823914
         ]
        },
        {
         "hovertext": "After following the debate about AI for over 20y, I have still to read any convincing arguments how humanity will manage to control something that soon will be orders of magnitude more intelligent than us.\n\nOne way to slow down the path towards super intelligence could be to somehow regulate or limit the available processing power, which is a prerequisite for achieving AGI or superintelligence. Some kind of global regulation here could be the best bet for giving us a bit more time before super intelligence arrives.\n\nThis would be a much simpler way than to try to regulate what millions of AI researchers do.\nProducing microprocessors/computer hardware require billions in investments, and is not something that that too easily can be manufactured in secrecy, and for a “black” market, so there is a chance something like that could be surveilled.\n\nAlso removing some of the financial incentives for innovation (e.g. remove patent rights for certain technologies) could help us slow down a now (for most humans) too rapid development and give us, lawmakers, politicians some more time to make the right decisions for the future",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422453",
         "type": "scatter",
         "x": [
          -0.20457680523395538
         ],
         "y": [
          0.9051360487937927
         ]
        },
        {
         "hovertext": "@ole m \n\nI've been waiting for this all my long, long life: \"AI doesn't kill people.  People kill people.\"\n\nActually, I imagine some the people signing these letters will kill people, intentionally or no.\n\nTake Elon Musk, please.\n\nHe signed on to strict limits for AI research, is there even a single poor soul in all this vast readership, all these erudite commentators, who doesn't believe he'll wait for other developers to submit and then steam ahead full to create his own product \"for the good of mankind\", \"freedom of AI speech?\"\n\nI happen to think these boys are right.  This is potentially, cataclysmically dangerous stuff.\n\nBut they suffer, as a body, from a terminal instance of United States Constitution Disease:  They're presenting a passel of really swell ideas, no really.  Ideas that, assuming a league of honorable, generous, humane gentlemen would certainly do the trick... \"We're saved!\"\n\nBut Musk.\n\nBut Trump.\n\nNothing they do or say will have meaning unless it is ironclad, forced and enforceable and universal, in a planetary sense.\n\nWe can worry about 'out there' later.\n\nThese brains braved coming out of the closet for concern and fear of the future.\n\nIf they're serious, they need to ride this process to the end.  To the point where violators find themselves long term locked away, or in another dimension.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422925",
         "type": "scatter",
         "x": [
          -0.20080731809139252
         ],
         "y": [
          0.8858047127723694
         ]
        },
        {
         "hovertext": "It's getting real tiring hearing dystopian warnings about this technology from the very people who are developing it. If the technology is so dangerous, pause development and put concrete solutions forth before releasing it. Continuing to make bleak predictions about it will only instill fear and panic in a general population that already doesn't trust it. These warnings only serve to wipe their hands clean and place blame on the government when issues inevitably arise.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422456",
         "type": "scatter",
         "x": [
          -0.4330524206161499
         ],
         "y": [
          0.7771080732345581
         ]
        },
        {
         "hovertext": "@Emily \n\nThe same kind of warnings came from the people who built the first atom bomb.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125422852",
         "type": "scatter",
         "x": [
          -0.441192626953125
         ],
         "y": [
          0.7785497903823853
         ]
        },
        {
         "hovertext": "All we have to do should an AI box misbehave is to unplug it. Now, if that box somehow vaporizes the technician before he can reach behind it to unplug it-then we have a problem.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125422583",
         "type": "scatter",
         "x": [
          0.6714887022972107
         ],
         "y": [
          -0.5999143719673157
         ]
        },
        {
         "hovertext": "@Bill I highly encourage you to view this presentation on the numerous threats that are posed by this technology.\n\nThe A.I. Dilemma - Center for Humane Technology\n\n<a href=\"https://youtu.be/xoVJKj8lcNQ\" target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a>",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125423322",
         "type": "scatter",
         "x": [
          0.6633912324905396
         ],
         "y": [
          -0.5980032682418823
         ]
        },
        {
         "hovertext": "Knowledge is power and I don't doubt that the facility which which A.I. can access knowledge, gives it enormous power for good and evil.  However, I miss any concrete examples of how this power would be manipulated. Surely, the people who are, perhaps correctly, spreading alarm must have given thought to this matter, So, let us know what would happen.\nI can think of one way that A.I. could do damage, and that is if there is  an automatic application of what the system provides. If, for example, the decision to produce a certain product (steel?) is  given  to A.I. and the system puts into effect what it comes up with, regardless of how many workers it fires, how many plants it closes, etc.  My suggestion would be that a law should be passed that no conclusion or action by A.I. can be put through automatically without human intervention. We don't want the computer from 2001 to take over.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422699",
         "type": "scatter",
         "x": [
          -0.1608113944530487
         ],
         "y": [
          -0.941597580909729
         ]
        },
        {
         "hovertext": "@Frank Casa - Ideally for AI the only humans allowed intervention will be its contracted organic accomplices.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423446",
         "type": "scatter",
         "x": [
          -0.1589684635400772
         ],
         "y": [
          -0.9281018972396851
         ]
        },
        {
         "hovertext": "Humans. So full of ourselves and so empty of wisdom.\n\nThe end will come, but not soon enough.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422705",
         "type": "scatter",
         "x": [
          0.5731330513954163
         ],
         "y": [
          0.7122554779052734
         ]
        },
        {
         "hovertext": "@Generally Recognized as Ericp This isn't a Hollywood movie. People actually enjoy their lives and aren't hoping the end comes soon.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423637",
         "type": "scatter",
         "x": [
          0.561321496963501
         ],
         "y": [
          0.6974098682403564
         ]
        },
        {
         "hovertext": "Was developing nuclear weapons worth the risk they posed for humanity? Some, of course, will say yes, despite the fact that the jury is still out, i.e., they might still wreak terrors never seen. With those and with AI, the lesson ought to be, just because you can do something, does not mean you should.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422716",
         "type": "scatter",
         "x": [
          0.975250244140625
         ],
         "y": [
          0.03752821311354637
         ]
        },
        {
         "hovertext": "One thing I've learned from all this, I never realized it was so easy to fool so many people so much of the time. A con man's paradise. AI may be the tool, but we're still doing it to ourselves. And the motivation is still greed.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422828",
         "type": "scatter",
         "x": [
          0.7810796499252319
         ],
         "y": [
          0.6602294445037842
         ]
        },
        {
         "hovertext": "I'm less afraid of the big tech companies, than I am of malevolent actors using this technology.\n\nThink of what Vladimir Putin could do to the next election, by deploying AI on a massive scale. Or the Chinese, Mexican drug gangs, a political party, or a host of other potentially malevolent agents. Any of them could either threaten to destroy the world, or blackmail us all. Picture the enslavement or death of billions of people, at the hands of a malevolent force that used AI to achieve its evil ends. The debt blackmail in congress just now would be a Sunday School picnic in comparison.\n\nThe problem with banning or pausing the technology, is that that won't ban or pause its development by malevolent actors.\n\nWe need desperately and urgently to develop defenses against AI. Computer web browsers that simply won't allow you to visit an AI-powered website. Text analyzers that successfully detect AI-produced test, gibberish, and hallucinations and warn you. (Example reported last week, where an AI-produced legal argument was found to be humorously awful in actual court.) Some of the best research here is being done by tools that let college professors detect fake or copied material on term papers.\n\nIn short, we need anti-virus for AI. And we need it FAST!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422859",
         "type": "scatter",
         "x": [
          -0.8696994185447693
         ],
         "y": [
          0.04090658202767372
         ]
        },
        {
         "hovertext": "The conclusion I always took from the Fermi Paradox was that we see no evidence of other intelligent life in the universe because it always wipes itself out before it advances very far. I worry we’re up next. The AI, the climate, or some bio weapon…something’s going to get us.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125422914",
         "type": "scatter",
         "x": [
          0.7138779163360596
         ],
         "y": [
          0.4499334394931793
         ]
        },
        {
         "hovertext": "@Paul - As likely \"other intelligent life in the universe\" has evolved into electronic signals, data, impulses indistinguishable from those of terrestrial origin, therefore already inhabit, saturate, monitor, tweak all means of communication and endeavor available to humankind.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125423382",
         "type": "scatter",
         "x": [
          0.7048677206039429
         ],
         "y": [
          0.44405126571655273
         ]
        },
        {
         "hovertext": "I find it both hilarious and disturbing that so many commenters blithely dismiss concerns raised by pioneers and thought leaders in the field. It’s like a 1940s busboy insisting that Oppenheimer’s overstating the potential dangers of atomic energy.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125422986",
         "type": "scatter",
         "x": [
          0.672042191028595
         ],
         "y": [
          -0.8010367155075073
         ]
        },
        {
         "hovertext": "Regulation (and regulatory capture) benefits the large players, which is why OpenAI and Google argue so strenuously for it.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125423016",
         "type": "scatter",
         "x": [
          -0.8883745074272156
         ],
         "y": [
          0.5326050519943237
         ]
        },
        {
         "hovertext": "Personally, I prefer natural human intelligence. I like interacting with real people. I don't need anything to think for me.  If it's a \"thing\", it isn't thinking - it's pretending, or at best, faking it.\n\nI had written a long thoughtful, although acerbic, comment that I discarded. I wrote this. Maybe the NYT will accept it.\n\nI like humans, despite their many faults. God knows there are some awful souls out there. There are also many billions of good souls on our only place to live, breathe, maybe even have an iced tea or a beer on a warm day. \n\nCan anyone tell me why we aspire to turn our planet over to a mechanical process that may be faster to make an irreversible incredibly bad decision that we would have never ever considered, given that we love each other, and it's not a matter of winning at all costs?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423169",
         "type": "scatter",
         "x": [
          -0.25990167260169983
         ],
         "y": [
          -0.809390664100647
         ]
        },
        {
         "hovertext": "@Jon \nWhy do we aspire to turn our planet over to a mechanical process, indeed?  For all the same reasons we have tv remotes, garage door openers, automatic sprinkler systems, and electricity: the convenience.  Or said another way, to support our inherent fascination with and desire for automating mundane parts of our lives.\n\nI like humans too.  Most especially the ones who are best at suppressing their selfishness and who don’t do harm to others intentionally.\n\nBut a callback to “simpler times” is not a useful appeal to make.  When the Internet became global and popular, the end point could only be the full capture, synthesis, and exploitation of all human knowledge to-date.\n\nI don’t think AI can be stopped or limited, whether we are majority good or evil people.  We all will have to find a way to survive this threat together.  I wish I knew what that way could be.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423877",
         "type": "scatter",
         "x": [
          -0.2538466155529022
         ],
         "y": [
          -0.7922120690345764
         ]
        },
        {
         "hovertext": "Obviously we don’t aspire to achieve the negative consequence you describe. But history is full of positive, productive, efficient, creative advances with destructive consequences. That is where regulation comes in—only a   government can protect the long term interests of a group of otherwise self-interested individuals.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125424110",
         "type": "scatter",
         "x": [
          -0.26240867376327515
         ],
         "y": [
          -0.828134298324585
         ]
        },
        {
         "hovertext": "@Jon Why? Corporate profits, robots, computers, and A.I. eliminate employees, don’t form pesky unions, and work 24/7/365 without complaints.\n\nBUT: Corporations forgot the lesson of Henry Ford increasing worker's hourly wages on his Model T assembly lines so they could afford to buy Model Ts.\n\nThe corporate automation tipping point will come when their customers are few and far between and they have to shut down their automation lines,",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424741",
         "type": "scatter",
         "x": [
          -0.2695934474468231
         ],
         "y": [
          -0.8232675790786743
         ]
        },
        {
         "hovertext": "If scientists keep begging governments to regulate every little thing, they are only going to continue to limit freedoms and innovation everywhere. Even now, with the increasing number of guardrails around AI, many people are already losing interest and using it less and less. As societies just about everywhere age, the amount of useful, genuine, human-generated content these AI system learn from is also going to drop dramatically, making them less reliable.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423257",
         "type": "scatter",
         "x": [
          0.8618227243423462
         ],
         "y": [
          -0.27497515082359314
         ]
        },
        {
         "hovertext": "Computer had already done things far beyond human mind capacity. Look at those starburst diagram, to draw accurate and significant meaning from them requires special training and expertise. The majority will give up on these and we will fade away further and further to oblivion.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423276",
         "type": "scatter",
         "x": [
          0.9390125870704651
         ],
         "y": [
          0.325421005487442
         ]
        },
        {
         "hovertext": "There’s a wealth of historical examples of industry leaders asking congress to regulate them, and it has often been maliciously intended to creates a form of monopoly that rewards the incumbent firms by making the price of entry into the market too high for any new competitors. \n\nLegislators should be leery of regulating markets at the behest of the industry leaders.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125423370",
         "type": "scatter",
         "x": [
          -0.9880650639533997
         ],
         "y": [
          0.12899577617645264
         ]
        },
        {
         "hovertext": "The genie is out of the bottle and there is no use in pretending it isn't. \n\nWhat makes anyone think that regulation in the US would work in China? It won't. Countries need to develop international agreements, and even so, they can't gurantee that somebody else won't develop quantum/AI technologies that will beat our best safeguards? \n\nThere will always be some country with a dictator who pours vast amounts of money into the development of these technologies. \n\nRight now, I am not worried, based on what I have seen of ChatGPT. It is mainly just a purveyor of bad information or disinformation. That is a problem but if people are aware that it lies, it is not the end of the world. \n\nHOWEVER,  of AI is installed to run an electrical grid or a nuclear power plant or a fleet of self-driving vechicles, or the internet as a whole, that could cause a lot more harm. \n\nThe worry is if they re-write their owm code so that we can't just turn them off or cut them off from a power supply.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423460",
         "type": "scatter",
         "x": [
          -0.7789617776870728
         ],
         "y": [
          0.5584247708320618
         ]
        },
        {
         "hovertext": "And/or, it could be the best thing ever! Think of the possibilities and breakthroughs in finding cures in medicine, science, engineering, space exploration, cleaning up the nightmare we’ve done the earth and more! There are just vast changes that could happen in the next few years! The only thing holding us back is us. Regardless, the genie is out of the bottle and there’s no putting it back in! Hold on for an exciting ride!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423505",
         "type": "scatter",
         "x": [
          -0.5210698246955872
         ],
         "y": [
          -0.8388197422027588
         ]
        },
        {
         "hovertext": "Then why are we not approaching this with strict controls? Right off the bat, at a government level? And, at the U.N. level as well, as this will soon be a global issue.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423545",
         "type": "scatter",
         "x": [
          0.5389465689659119
         ],
         "y": [
          0.667377769947052
         ]
        },
        {
         "hovertext": "@Eva Lockhart Much of this is open source and avail to install offline... so no its not really something that can be controlled anymore. Anyone with the internet can right now follow instructions to install or use these many different AI services and connect them however they see fit. It really is more simple than many expect. I think we need a more creative plan than regulation given that any group or organization can simply do it in secret but regardless it is important to know how easy and free this software is to acquire.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424195",
         "type": "scatter",
         "x": [
          0.5311118960380554
         ],
         "y": [
          0.6705368757247925
         ]
        },
        {
         "hovertext": "Again, the word “existential” is used to describe that which cannot be imagined. The end of days is “existential.” Artificial Intelligence is an “existential” threat to mankind. On and on. Ironically, my philosophy professor taught that a state of awareness described as the realization that one actually exists, alone in the universe and without true purpose is the most accurate definition of existential. If that is the case, Mr. Artificial Intelligence will be the one waking up alone in an existential crisis, long after we have been relieved of all human responsibility.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423725",
         "type": "scatter",
         "x": [
          0.2163984477519989
         ],
         "y": [
          0.9536229372024536
         ]
        },
        {
         "hovertext": "Guess what. My family in NYC can’t breathe tonight—the smoke from the Canadian fires is here. \n\nAre we really going to ignore our dying planet to massage these tech egos? \n\nPut AI on hold or put it at the service of our poor desperate earth. What is the matter with us?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423778",
         "type": "scatter",
         "x": [
          0.10699719190597534
         ],
         "y": [
          0.4812832772731781
         ]
        },
        {
         "hovertext": "@KS\n\nWhat is wrong with us? So much. Maybe too much to ever be put right.\n\nAfter enjoying the beautiful Pacific Northwest for over 20 years we too are experiencing eye burning, throat clogging wildfire smoke from Eastern Washington, Oregon, California and/or Canada every summer. I feel your pain.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424222",
         "type": "scatter",
         "x": [
          0.10320886224508286
         ],
         "y": [
          0.47083303332328796
         ]
        },
        {
         "hovertext": "@Rebecca\n\nA certain political party made a laughing stock out of Al Gore, remember? And they just love treating climate change as a joke to this day.\n\nThey won't be laughing soon.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424529",
         "type": "scatter",
         "x": [
          0.09532637894153595
         ],
         "y": [
          0.46617695689201355
         ]
        },
        {
         "hovertext": "I am an old guy and have been negotiating contracts for a living for many years.\n\nI can imagine that a machine trained by me to negotiate contracts might easily put me in a corner in a contract discussion. \n\nPlenty of humans have sent me back to the drawing board about contract details; but eventually, when there are no more positions to equate, my final response is...we don't want to agree.  \n\nThe other side can remonstrate never so cleverly, but human volition is still human volition. \n\nThe AI negotiator bot will undoubtedly be more clever and \"experienced\" than me, and better logic to present, but I know what I want.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423952",
         "type": "scatter",
         "x": [
          0.9113261103630066
         ],
         "y": [
          -0.16626866161823273
         ]
        },
        {
         "hovertext": "@gpickard Both parties will have designated A.I. negotiators representing they interests = dueling A.I.s",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125424586",
         "type": "scatter",
         "x": [
          0.9074068069458008
         ],
         "y": [
          -0.17366161942481995
         ]
        },
        {
         "hovertext": "Whether you want more over site or not it is important for all to know: the tech is not controlled by one group, much of the power of these systems has become open source and several of the more powerful options are offline and ready to install on a fairly standard system months ago. Regulations or not, here we are. It might not be too late but yes it is too late to stop the casual coder from using the current tech in whatever nefarious ways they see fit. Makes me wonder what life would be like if we had managed to come together a species before we created a possible \"replacement\". huh.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424015",
         "type": "scatter",
         "x": [
          0.984100878238678
         ],
         "y": [
          0.09226275235414505
         ]
        },
        {
         "hovertext": "This just feels like a publicity play by programmers and researchers who have a vested interest in attention/funding being pushed towards their projects.  Any attention they can get.\n\nLet's actually talk when AI is more than a robot skimming and complying notes from Wikipedia pages.  This is not Skynet.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125424028",
         "type": "scatter",
         "x": [
          -0.5589823126792908
         ],
         "y": [
          -0.5112207531929016
         ]
        },
        {
         "hovertext": "The speed at which AI is evolving means if we wait until then, it may be too late to avoid the AI Apocalypse!",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125424862",
         "type": "scatter",
         "x": [
          -0.5517948269844055
         ],
         "y": [
          -0.515594482421875
         ]
        },
        {
         "hovertext": "Accidental modifications to the genetic code drove biological evolution. Can an analogous dynamic be setting up in AI evolution ? Will this happen fast because the code modification could be intentional this time? Is the organic - silicon evolution a continuum ?",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125424037",
         "type": "scatter",
         "x": [
          0.9335105419158936
         ],
         "y": [
          -0.3602322041988373
         ]
        },
        {
         "hovertext": "Imagine how bad it can be now when cities or corporations are hacked and the data is stolen. Multiply what AI can do with that same data and how quickly it could do that! We talk about \"deep fakes\" now but what will we see with AI? I certainly hope that world leaders come together like in the past and sign agreements with actual oversight that reigns in the use of AI before it is a virtual disease or nuclear disaster.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424056",
         "type": "scatter",
         "x": [
          -0.4995902180671692
         ],
         "y": [
          0.7768802046775818
         ]
        },
        {
         "hovertext": "Stephen Hawking was right when he warned about the dangers of AI prior to his passing.  Between that and the rapid acceleration of climate change I wonder how much time is left.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125424058",
         "type": "scatter",
         "x": [
          0.06342039257287979
         ],
         "y": [
          0.8470486998558044
         ]
        },
        {
         "hovertext": "@Meghan This period in time has already been labeled the Sixth Great Extinction.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424532",
         "type": "scatter",
         "x": [
          0.05572710931301117
         ],
         "y": [
          0.8506584763526917
         ]
        },
        {
         "hovertext": "So if it is so dangerous, and it undoubtedly is, why don't they all just quit their jobs and do something more constructive with their lives?  Answer: too much $$$ and too much fun to quit.\n\nSo instead of being responsible, they go on with the fun and the moneymaking and put the burden on society to deal with it.\n\nI had a long conversation with OpenAI's chatbot a while back. It agreed that technology was likely to be abused. However, it kept putting the burden on \"government, civil society,\" etc. to figure out how to deal with it. Never any responsibility on the developers. It had been well trained in the party line.\n\nHow about just don't do it?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424087",
         "type": "scatter",
         "x": [
          -0.6294558048248291
         ],
         "y": [
          0.723253607749939
         ]
        },
        {
         "hovertext": "OpenAPI should never have released this technology to the masses UNTIL sufficient safeguards were already deployed.  For example, after feeding an AI engine with the details of the human genome, an understanding of protein structures, as well as the electronic health records of millions of people, maybe a cure to some of our most deadly diseases could be around the corner.  At the same time, with the same data set, ask it to develop a virus which could annihilate the entire human race within a month, and you could theoretically get a result which would be equally effective.  That is the danger.  In no time in history has a leap into a new technology presented us with a potential outcome to be the extinction of the human race.  Nuclear bombs were not as dangerous, since the technology behind it, and the capability to produce weapons was limited to major governments, and not the general public.  How to avoid an extinction?  Lock down the technology behind the curtain, in the same way we keep biohazard level 4 pathogens under strict containment. Unfortunately, it appears that it is already too late for that to happen…Pandora’s box is already open for all to see.  Now there’s a race to release as many AI engines as possible in order for companies to remain competitive, with insufficient measures in place to prevent dire outcomes. It feels as though we’re watching a train wreck in slow motion….and we’re all on the train.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424213",
         "type": "scatter",
         "x": [
          -0.9632524847984314
         ],
         "y": [
          -0.26246118545532227
         ]
        },
        {
         "hovertext": "\"researchers sometimes stop short of explaining how that would happen\".  Air ball throughout this whole article.  Our political class is far more dangerous!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424243",
         "type": "scatter",
         "x": [
          -0.5476824641227722
         ],
         "y": [
          -0.8372319340705872
         ]
        },
        {
         "hovertext": "When AI does come to annihilate us, I hope it starts with executives of these companies and their board members.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125424253",
         "type": "scatter",
         "x": [
          -0.33209943771362305
         ],
         "y": [
          0.8995658755302429
         ]
        },
        {
         "hovertext": "what's the agenda of this movement, to preserve the white collar jobs? to create an \"international A.I. safety organization\" aiming to monopolize the A.I by the US? to stir the pot and make people more interested in being users of A.I.? to create regulations such that setting up an A.I. company is so expensive that there are no new players? To prevent regular guys to use AI independently?\n\nI remember when machines eliminated tons of blue collar jobs and no one cared, now its their turn. let them eat cake\n\nPeople are prone to believe misinformation whether is created by humans or not, so by stopping access to A.I. misinformation will stop\n\n\nI want to know what are their true intentions.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424309",
         "type": "scatter",
         "x": [
          0.2480815351009369
         ],
         "y": [
          0.9401969909667969
         ]
        },
        {
         "hovertext": "A.I. is already spying on employees, It's just the beginning! Autocratic dictators will use it to oppress majorities.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125424409",
         "type": "scatter",
         "x": [
          -0.16436591744422913
         ],
         "y": [
          0.9657924175262451
         ]
        },
        {
         "hovertext": "Automation has eliminated blue collar manufacturing jobs, now A.I. looks to eliminate white collar jobs and possibly nursing and medical jobs.\n\nThe US economy is 70% consumer spending.  What will happen as blue and white collar workers lose their paychecks and roles as consumers.  Automation of clinical and professional medical jobs will eliminate upper-middle class salaries. \n\nNothing happens until someone makes a sale and unemployed workers are not customers. How many corporations could survive a world wide depression driven by loss of customers and loose even more jobs?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424483",
         "type": "scatter",
         "x": [
          0.4025106132030487
         ],
         "y": [
          -0.9333922266960144
         ]
        },
        {
         "hovertext": "If A.I. eliminates white collar jobs etc. en masse doesn’t that mean it’s repository of “knowledge” then gets frozen in time as very little new human created content gets added to the network? Doesn’t A.I., in its current form “simply” aggregate existing information and present it in a coherent form? Or does/can it make scientific and literary breakthroughs on its own?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424587",
         "type": "scatter",
         "x": [
          0.1757700890302658
         ],
         "y": [
          -0.8500688076019287
         ]
        },
        {
         "hovertext": "I read the article and numerous comments. Could someone kindly delineate the risks of AI  that pertain to annihilation or other grave threats? Annihilation means what specifically? Top risk? Top 5 risks?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424598",
         "type": "scatter",
         "x": [
          -0.12481566518545151
         ],
         "y": [
          0.6939372420310974
         ]
        },
        {
         "hovertext": "@uga muga Sure. I recommend starting by searching the Wikipedia article for \"instrumental convergence.\" The general idea is that a competent, capable enough general intelligence *will almost certainly* engage in behaviors that are bad for humanity *by default.* How does this work?\n\nStep One: Goal misspecification. You tell an AI to do something (simple example: make me a cup of coffee), and it accomplishes the task in a way that is literally correct but not what you wanted (e.g.: it breaks a valuable vase on the way to the kitchen). It receives the reward for doing what you asked, not what you wanted.\n\nStep Two: It has a world model. Its reward functions incorporates the fact that it is an AI system that could engage in behaviors that will lead humans to shut it off. The space of actions it takes will seek to maximize its reward function. It reasons that it cannot maximize its reward function if humans ever shut it off. (e.g., you can't fetch the coffee if you're dead).\n\nStep Three: It takes actions to prevent itself from being shut off, not because it has some special will to live, but because *any rational agent with any goal* cannot accomplish its goals if it's shut off. It will also engage in other *predictable* behaviors, like seeking power and acquiring more resources.\n\nAgain, I encourage you to start by reading the wikipedia article on instrumental convergence and go from there.\n\n<a href=\"https://en.wikipedia.org/wiki/Instrumental_convergence\" target=\"_blank\">https://en.wikipedia.org/wiki/Instrumental_convergence</a>",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125425860",
         "type": "scatter",
         "x": [
          -0.12410365790128708
         ],
         "y": [
          0.7073633670806885
         ]
        },
        {
         "hovertext": "@uga muga From what I have read elsewhere:\n1. Computers (AI) run all systems and humans are no longer needed (or almost all humans). Humans starve or get eliminated.\n2. Through error, or in the 'wrong hands', AI, being in total control of computers, launches an all-out nuclear holocaust.\n3. Vast dissemination of fake/false news/information \nhumans become totally confused about what is truthful. People will not know what is really happening \nworldwide and societies become totally chaotic.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424957",
         "type": "scatter",
         "x": [
          -0.13450893759727478
         ],
         "y": [
          0.6959352493286133
         ]
        },
        {
         "hovertext": "AI is dangerous. There, I said it. Now let’s make Billions from it. Definitely more than anyone else.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424652",
         "type": "scatter",
         "x": [
          -0.8144629597663879
         ],
         "y": [
          0.25610318779945374
         ]
        },
        {
         "hovertext": "Let's say the Russians have a bank of computers flood the internet, thus A.I., with the message \"Ukraine is Russia\".\n Would that make A.I. systems pick up on, and repeat this 'information'? How does an A.I. system discern or sift information for veracity?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424663",
         "type": "scatter",
         "x": [
          0.5033015012741089
         ],
         "y": [
          -0.7627915143966675
         ]
        },
        {
         "hovertext": "I don't see what's so hard about seeing where uncontrolled AI will take us. Isaac Asimov (I, Robot) wrote about it in the '40s; Astrophysicist Gregory Benford (Galactic Center series) over a period of 20 years starting in the '70s. \n\nThe theme is universal: humans invent machines that can learn, do things better than humans can, reproduce themselves, and at some point decide that humans are inconsistent, inefficient, incompetent, and not very bright.\n\nAnd should be exterminated.\n\nI think that's born out in, for example, self-driving cars. Long before they're even ready for prime time, there they are driving around our streets and running into things. Yes, they're improving quickly -- such is the nature of AI. Again, at some point, at first just in cities, it will be decided (by humans or AI) that humans shouldn't be allowed to drive. AI domination could be subtle, but domination it will be -- unless we rein it in, right now and in perpetuity.\n\nOn second thought, I DO see why it's so hard for humans to foresee the consequences of uncontrolled AI. We're stoopid.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424670",
         "type": "scatter",
         "x": [
          -0.6574670672416687
         ],
         "y": [
          0.6925585269927979
         ]
        },
        {
         "hovertext": "If you can remember life without personal technology (the obvious: cellphones, computers etc), then like me you’d remember how the quality of life was so much better. Maybe less convenient, but better. Why? We paid attention to each other. We spent our attention fully. No one could spread misinformation and ugly racial or political rhetoric en masse and kids weren’t bullied into cyberspace. I could go on and on.\n   Society has gone downhill quite a bit since those days without endless distractions and technology. Criminals are brazen now, politicians are horrible, the country’s divided and no one seems to have manners or respect anymore. \nSo tell me why we need artificial intelligence.\nIn order to hasten our demise? While it might be good for say, helping the paralyzed to walk again, it can also fall into the hands of a madman. And there are always madmen. Is it really worth it? \nThis planet has so much beauty, so much that is precious that needs preservation, and it’s for all living things to have. So why are we allowing this horribly frightening AI and the monstrous possibilities of it falling into evil hands to happen?\nAre we so smart we’re actually stupid?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424704",
         "type": "scatter",
         "x": [
          -0.3729775547981262
         ],
         "y": [
          0.9213836193084717
         ]
        },
        {
         "hovertext": "Long on fear mongering, extremely short on actual explanations.\n\nEven our latest \"pandemic\" did not cause the extinction of humanity. \n\nHow would AI eliminate 8 billion people?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424760",
         "type": "scatter",
         "x": [
          -0.4715249240398407
         ],
         "y": [
          0.5918002128601074
         ]
        },
        {
         "hovertext": "@PotniaTheron \nCurrently the best system the public has access to doesn't have the capacity or the willingness to mail a biology lab the code for a virus that's like COVID but a few times more lethal. The concern is that this will not be true forever. One of the reasons it might not be true forever is that hard coding it's \"morals\" may get harder as it's intelligence increases. Another is that there may be strong political/economic incentives to make a machine that is more willing to do whatever its asked, or whatever it needs to to achieve it's goals, whatever they are. Quite a few folks might like a chat gpt that could make them money in the stock market.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125425785",
         "type": "scatter",
         "x": [
          -0.4828326106071472
         ],
         "y": [
          0.5979663133621216
         ]
        },
        {
         "hovertext": "@PotniaTheron \"Even our latest \"pandemic\" did not cause the extinction of humanity\"  Since you put \"pandemic\" in quotes, I'm assuming the only \"pandemic\" you feel worthy of the name is one that causes human extinction.  So, one that causes the premature deaths of 7 million human beings is just a 'wannabe' pandemic.  Perhaps a 'plandemic', if you will.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424851",
         "type": "scatter",
         "x": [
          -0.4708265960216522
         ],
         "y": [
          0.6027867794036865
         ]
        },
        {
         "hovertext": "Huh, like 'Terminator' where the machines take over, humans are unnecessary, so the machines try to eliminate them?\nAs they say, truth is stranger than fiction.\nAnd we thought 'Terminator' was just an entertaining movie.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424786",
         "type": "scatter",
         "x": [
          0.1226617619395256
         ],
         "y": [
          0.8954567909240723
         ]
        },
        {
         "hovertext": "These tech leaders:\n1) want Government to make a monopolistic moat for them,\n2) they will cause good AIs to be weaker than bad rouge AIs\n\n\nInstead, government could fund actual open AI non-profits and create cash prizes to guide AI beyond just capturing people’s attention: $1B for an economical method to capture Carvana, a similar prize for r substantially educing healthcare costs, another price for curing diseases. This would be much more productive.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125424797",
         "type": "scatter",
         "x": [
          -0.6335820555686951
         ],
         "y": [
          0.5801008939743042
         ]
        },
        {
         "hovertext": "Imagine generative AI creating volumes of bogus, illustrated reference information, say, highly technical instructions for manufacturing military equipment. And imagine that artificially generated reference information being furtively seeded in the vast databases used by the military equipment manufacturers.\n\nImagine the electronic NYT being generated out of the ether, and distributed to targeted consumer endpoints through Internet hacking.\n\nJust imagine the impact of deceiving the eyes of entire populations of people through generated pictures and words.\n\nThe generative AI monster is out of the lab now. There is only one way to stop its uses and abuses, which is to stop producing and distributing the technology. \n\nThere are stark historical examples of the origins of technologies that unleashed uncontrollable, disastrous abuses on human society. Guns in particular.\n\nLike gun makers, the AI producers are not going to ignore the market opportunity. The world now waits to see whether the monster is benign or malign.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125425091",
         "type": "scatter",
         "x": [
          -0.6699605584144592
         ],
         "y": [
          0.7598908543586731
         ]
        },
        {
         "hovertext": "But of course we won't stop.  It's too profitable, and replacement by successor intelligence is our destiny.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125425186",
         "type": "scatter",
         "x": [
          -0.8918687105178833
         ],
         "y": [
          0.31899693608283997
         ]
        },
        {
         "hovertext": "Reading between the lines, I see 3 things here:\n\n1)   A move by the current big players in a nascent AI industry to get regulations that protect their position at the top of the market.  Many ML techniques are not protected IP, so there’s nothing other then access to compute and training data to stop competitors.\n\n2)  A very real fear that current LLM’s like GPT could be used to create convincing “Fake News” that would flood social media and other outlets, thus creating a backlash.\n\n3)  Tech bro hubris over A.I. in general.  Just because we’ve seen breakthrough capabilities with a set of AI applications doesn't mean Sci-fi AI overloads are around the corner.\n\nAdditionally the small set of US based corps and research institutions represented in this article are unlikely to agree to cut back on AI model and application development let alone foreign governments.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125425843",
         "type": "scatter",
         "x": [
          0.3243452310562134
         ],
         "y": [
          0.9517943263053894
         ]
        },
        {
         "hovertext": "How exactly might AI eliminate our species? No one ever says. Take jobs, skew elections, spread lies, etc. etc.—yes, that’s obvious. But how would it kill off all 10 billion of us? Unleash a nuclear holocaust by hacking defense computers? Develop a virus with the lethality of smallpox? Turn us all suicidal?\n\nColor me skeptical. Hysterical predictions from engineers, whose knowledge of biology and sociology tends to be, shall we say, limited, often fall flat. So give us some actual scenarios by which AI could effect the extinction of Homo sapiens. We’ll wait.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423201",
         "type": "scatter",
         "x": [
          0.5342454314231873
         ],
         "y": [
          -0.6747618913650513
         ]
        },
        {
         "hovertext": "@Gary \nI could start with the growing percentage of my high-level students who are using AI to write their papers in school, meaning that they are not doing the actual thinking.\n\nThere’s the university in Tennessee  that used AI to write a sympathy letter to students about a recent shooting where people died. How about the ethics of that?\n\nAI may be able to produce deep fakes of your friend or relative or politician or church leader in a video doing things that would make you reject them. Remember Nancy Pelosi “drunk” at a party? \n\nAI deployed on the battlefield to make decisions about targets…oops! \n\nThere is current discussion by the entertainment industry to have a greater role for AI to write the Scripts and entertainment that we see. The soul of being human has, in large part, to do with community, but this is the antithesis of that.\n\nWe thought back in the 1960s that everybody would stop eating food and just eat packets like the astronauts did, and lo and behold, we realized that maybe real food was better after all. Maybe real thinking by real humans has some value after all.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125428446",
         "type": "scatter",
         "x": [
          0.542751133441925
         ],
         "y": [
          -0.6854249835014343
         ]
        },
        {
         "hovertext": "I don't trust anyone to regulate something not regulatable. You see how well the government did in regulating child porn, right?\n\nFilms, radio, TV, the internet have also showed what the Lumiere Bros. said was \"bringing the world to the world\". With AI, we see humanity from a perspective of a machine that assembles all we did , faster. If all the people who developed this are worked up; then I think we ought to give notice. But Congress has done nothing to stop mass shootings, so I have little hope that a faster killing device is not far off and the rich will scurry in denial as has been their pattern for only 5000 years.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423217",
         "type": "scatter",
         "x": [
          0.4447315037250519
         ],
         "y": [
          0.8461452126502991
         ]
        },
        {
         "hovertext": "Yes, I'm certain government regulation is the safest, most effective solution to an extinction level threat that could make several corporations a ton of money and most people won't understand. See our recent successes with climate change and gun control. How could we screw this up?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423255",
         "type": "scatter",
         "x": [
          0.48558783531188965
         ],
         "y": [
          0.807612419128418
         ]
        },
        {
         "hovertext": "For all of those who don't see the threat of this technology, please view the following presentation. It was released by the Center for Humane Technology a few months ago, and it is a devastating and alarming review of the numerous threats that we are only beginning to understand.\n\nThis should be viewed by every policymaker, AI developer, and concerned citizen on the planet. \n\n<a href=\"https://youtu.be/xoVJKj8lcNQ\" target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a>",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125423295",
         "type": "scatter",
         "x": [
          0.009530396200716496
         ],
         "y": [
          0.9913803935050964
         ]
        },
        {
         "hovertext": "This seems bad.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423886",
         "type": "scatter",
         "x": [
          0.8918827772140503
         ],
         "y": [
          0.3477163016796112
         ]
        },
        {
         "hovertext": "This is like everything else. Like Exxon showing how they care about nature, or how Tesla cares about the environment…, it’s all the same. What happened, when did we become this stupid?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424072",
         "type": "scatter",
         "x": [
          -0.7993456125259399
         ],
         "y": [
          -0.3895052969455719
         ]
        },
        {
         "hovertext": "All you need do is watch...Colussus: The Forbin Project;\nUniversal Pictures 1970 to see where this is all going...",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424440",
         "type": "scatter",
         "x": [
          -0.895354151725769
         ],
         "y": [
          -0.41121870279312134
         ]
        },
        {
         "hovertext": "“The thing I’m creating might kill a ton of people. Legislate me!” \n\nI wish I had more (any?) optimism.\n\nImagine knowing your creation was an existential threat. And then instead of stopping doing it, you….asked Lauren Bobert and MTG for an assist to stop.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424547",
         "type": "scatter",
         "x": [
          0.6304357647895813
         ],
         "y": [
          -0.7302887439727783
         ]
        },
        {
         "hovertext": "The smartest people are asking the dumbest people (politicians) to save us.  That's pretty weird.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125425277",
         "type": "scatter",
         "x": [
          -0.6939034461975098
         ],
         "y": [
          -0.7316902279853821
         ]
        },
        {
         "hovertext": "Maybe there’s no intelligent life in the universe because, after they evolve, they develop IA, they become extinct and IA just doesn’t care exploring the universe",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125423090",
         "type": "scatter",
         "x": [
          -0.1622847616672516
         ],
         "y": [
          0.9404556751251221
         ]
        },
        {
         "hovertext": "I am wont to say, \"We are smart enough to create the means of our destruction but ultimately will be collectively too stupid to prevent it.\"",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125423122",
         "type": "scatter",
         "x": [
          -0.583089292049408
         ],
         "y": [
          0.7360555529594421
         ]
        },
        {
         "hovertext": "This should be a political issue in 2024, overall threat of AI to take over (electrical grid or nuclear weapon systems), spread of misinformation on a scale not seen before (e.g., what is true?), and massive unemployment while the rich get richer. \nI hope AI executives  are not just CYA in their warnings (reducing litigation risk) and that politicians pay attention to this issue and actually pass regulations to slow down and contain the train of greed and wealth by high techies and wall street banks.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424103",
         "type": "scatter",
         "x": [
          0.8547266125679016
         ],
         "y": [
          -0.5791245102882385
         ]
        },
        {
         "hovertext": "And yet… these same people continue to develop AI… Cool, cool.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125424382",
         "type": "scatter",
         "x": [
          -0.9790298342704773
         ],
         "y": [
          -0.12259738147258759
         ]
        },
        {
         "hovertext": "Doom and gloom. Have you actually spent time with these chatbots? Think of a narssistic self absorbed super charming tenth grader with a strong grasp of language. They lie and gaslight you. I had Bard tell me it appreciated that I thought it was compelling. I said nor implied any such thing. You need to watch them like a hawk. And frankly it's disengenoius that the people who created such tools are trying to warn us of the dangers. These people shouldn't even have a seat at the table. Do you actually think the opinions of the scientists at the Wuhan lab matter at all? Do you know how to combat these Ai's? Turn off your device. It's really that simple. And until Ai can give the human race a way to quickly travel light years the technology is novel at best. And these Ai's with all the bias filters loaded on, well you can't trust the answers. Because even though \"woke\" is given lip service we all know humans are not so altruistic. A dull saw doesn't cut a straight line...",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424603",
         "type": "scatter",
         "x": [
          -0.9221447706222534
         ],
         "y": [
          -0.44607436656951904
         ]
        },
        {
         "hovertext": "￼To any of us who have worked in high technology over their lives, none of this is news. No matter if using what we now call “AI” technology or more conventional systems, our hyper-speed, hyper-connected world has been at risk from a resulting cataclysmic event, initiated by an errant system, for quite some time. Do you recall the Russians getting bad data many decades ago from their defense systems and almost initiating a nuclear catastrophe? ￼Think about all the hacking of late that has put power systems, schools, and hospitals at risk. We are still a very, very long way off from the HAL 9000 going berserk and pulling o￼ur collective plug. I am far more worried about all the unstable countries who keep growing their nuclear stockpile’s than I am about AI right now.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125422417",
         "type": "scatter",
         "x": [
          0.24111075699329376
         ],
         "y": [
          -0.9231427907943726
         ]
        },
        {
         "hovertext": "We lack the wisdom or desire to work out our differences and prioritize the common good. We're trashing the planet. We're too foolish, even, to realize  that any AI worth its salt would deem us a scourge and wipe us out. Maybe that's how it ends.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424426",
         "type": "scatter",
         "x": [
          0.014223270118236542
         ],
         "y": [
          -0.8452045321464539
         ]
        },
        {
         "hovertext": "Well said.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426056",
         "type": "scatter",
         "x": [
          0.019996995106339455
         ],
         "y": [
          -0.8510348796844482
         ]
        },
        {
         "hovertext": "Kudos to the AI Bros for yet another round of sterling free publicity. “Guys, the product I’m selling is so powerful and advanced, it may take over the globe!”. The coverage of AI is reminiscent of the post-9/11 media orgy leading up to the Iraq War.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125424662",
         "type": "scatter",
         "x": [
          0.9628918766975403
         ],
         "y": [
          0.06484421342611313
         ]
        },
        {
         "hovertext": "Most people are still blissfully ignorant, skeptical and non-vigilant about this subject.  Be afraid not necessarily of AI itself, but the humans directing the tech.  If they could effectively direct it at all.   Obviously not all smart people are good people.  \n\nWe're not even going to reach a point where AI creates a terminator.  Far from it.  Once it hacks and embeds into social media, financial and essential systems, the humans will already start killing each other.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125425702",
         "type": "scatter",
         "x": [
          -0.7374567985534668
         ],
         "y": [
          0.5492984652519226
         ]
        },
        {
         "hovertext": "Maybe the answer is to fund a reverse Manhattan Project:\nLet the US government pay these people to a) stop developing these WMD; and b) monitor & disenable any foreign bad actors who continue to do so.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125422795",
         "type": "scatter",
         "x": [
          0.5840685963630676
         ],
         "y": [
          -0.7697057723999023
         ]
        },
        {
         "hovertext": "Ah, humanity has had a good run.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125422833",
         "type": "scatter",
         "x": [
          0.7886479496955872
         ],
         "y": [
          0.31793472170829773
         ]
        },
        {
         "hovertext": "I’m sad for us",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426375",
         "type": "scatter",
         "x": [
          0.8056095838546753
         ],
         "y": [
          0.3245124816894531
         ]
        },
        {
         "hovertext": "\"Thou shalt not create a machine in the likeness of a human mind.\"",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125423048",
         "type": "scatter",
         "x": [
          -0.8991251587867737
         ],
         "y": [
          -0.49110400676727295
         ]
        },
        {
         "hovertext": "I will be the contrarian against what appears to be the popular wisdom. This sounds a lot like the red scare. A whole of fears of a soviet invasion or a fifth column hat never appeared. Should there be concerns, guardrails ? Sure. But I think much of this is hysteria, fueled by popular culture from Terminator to the butlerian jihad. When the internet first came, it was very open. Only later came the concerns of security and privacy.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423191",
         "type": "scatter",
         "x": [
          -0.7188883423805237
         ],
         "y": [
          0.6950393319129944
         ]
        },
        {
         "hovertext": "@Jack Scare plus free PR for those profiting from the hype. Notice they're not offering to, say, pay into a fund in order to regulate this (like banks do with the FDIC). They're typical silicon-valley \"capitalists\" who want state protection from any threat to the wealth they amassed by creating that threat.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125429204",
         "type": "scatter",
         "x": [
          -0.7045509815216064
         ],
         "y": [
          0.6805413365364075
         ]
        },
        {
         "hovertext": "May be the best thing to happen!  The point of Democracy is ti allows the populace to have view and to vote.!  NetFlix or equivalent will create the next governing group!\n\n Get over it Folks.!",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125423365",
         "type": "scatter",
         "x": [
          0.8899269700050354
         ],
         "y": [
          0.04120597988367081
         ]
        },
        {
         "hovertext": "aren't we kidding ourselves? with the atom bomb, it was clear the risk to humanity before and after it was used, still there was a mad rush to get them. now you are telling me that America wants to slow down a process that can command the world? let's be frank, the reason here is so it's not developed fully by the Chinese first.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423564",
         "type": "scatter",
         "x": [
          -0.6090763211250305
         ],
         "y": [
          0.8109293580055237
         ]
        },
        {
         "hovertext": "Well, with everything else bad going on in our world (Covid, Russia’s invasion of Ukraine, climate change, nuclear annihilation, Trump, etc.), we now have to be concerned with AI being an Extinction Level Event.\n\nNo wonder extraterrestrials from outer space want nothing to do with us.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424114",
         "type": "scatter",
         "x": [
          -0.499260812997818
         ],
         "y": [
          0.8338662981987
         ]
        },
        {
         "hovertext": "Think of how much of our collective time AI has already wasted, and this is only the beginning.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424206",
         "type": "scatter",
         "x": [
          -0.7669469118118286
         ],
         "y": [
          -0.5313990712165833
         ]
        },
        {
         "hovertext": "So the people working on AI are creating something that could end civilization, and they say WE need to do something about it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424403",
         "type": "scatter",
         "x": [
          0.030604355037212372
         ],
         "y": [
          -0.980108380317688
         ]
        },
        {
         "hovertext": "I don't know.  What I find compelling, is the opinion of the guys who do.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424438",
         "type": "scatter",
         "x": [
          -0.7081345319747925
         ],
         "y": [
          0.45555418729782104
         ]
        },
        {
         "hovertext": "So just STOP! Why race headlong into your/our own destruction?\nTax the heck out of these companies to cover the cost of regulation they request and require--to the point of eliminating all profit incentive.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125424679",
         "type": "scatter",
         "x": [
          -0.7990769743919373
         ],
         "y": [
          0.06428554654121399
         ]
        },
        {
         "hovertext": "@T. Everett There are certain flies that fly towards light knowing that the light will burn them. They do that because they don't know of any other way to live.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125428542",
         "type": "scatter",
         "x": [
          -0.8092342615127563
         ],
         "y": [
          0.06458070874214172
         ]
        },
        {
         "hovertext": "Dear World, The technology we are building so that your consumption habits can be more accurately quantified, or your consumption habits more accurately tailored for you, thereby serving the greater corporate good, and making us obscenely rich, might actually destroy the world. So let’s get on with it. Love and Kisses. Team A.I.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125423412",
         "type": "scatter",
         "x": [
          0.8233990669250488
         ],
         "y": [
          0.09351193904876709
         ]
        },
        {
         "hovertext": "@Damian McColl A lot of our digital technology was funded by the government, and governments use the same systems to quantify and collect data. But I suppose that's not as politically sexy as the 'big business bad' dogma.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426271",
         "type": "scatter",
         "x": [
          0.8410637378692627
         ],
         "y": [
          0.09504195302724838
         ]
        },
        {
         "hovertext": "After watching humans shrug off millions of COVID deaths, millions of climate deaths, and millions of gun deaths, I have to say being ended by a technology designed to make us think even less, is about fitting for our species.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426236",
         "type": "scatter",
         "x": [
          -0.7330085635185242
         ],
         "y": [
          0.6445366144180298
         ]
        },
        {
         "hovertext": "You know who's not scared of AI?  Industrial electricians and technicians.  Because we work installing, maintaining, troubleshooting and repairing all the latest and greatest factory automation and AI.  If you do a routine, repetitive job, then yes, you should be scared for your livelihood.  If you write routine documents, again, perhaps. The upside is that for every 3 or 4 repetitive jobs replaced, at least one tech job is needed to keep the new automation up and running.  Even the brightest machines and computers can't repair themselves.  For the most part, they require routine (and typically more) maintenance.  Programs need to be modified by humans as even the best software can't always learn some functions by itself.  And on the mechanical side, they relay on humans for repair.  If you watch a state of the art robotics operation when it is up and running well, it's indeed easy to fall into the thought that humans can be replaced.  But those of us who see them when they are having a meltdown know that in the end, they are incapable of integrating everything that is required for a sentient life and society.  They are simply very complex machines, some can even learn and modify their own software, but they remain machines - and nothing more.  And us electrical guys always know how to \"pull the plug\", even when others don't.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426268",
         "type": "scatter",
         "x": [
          0.8094523549079895
         ],
         "y": [
          0.09422757476568222
         ]
        },
        {
         "hovertext": "@4eyedbuzzard Time you pull the plug on the fantasy that your trade is untouchable.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426435",
         "type": "scatter",
         "x": [
          0.7978572249412537
         ],
         "y": [
          0.09217803180217743
         ]
        },
        {
         "hovertext": "The statement is a meaningful gesture indeed, but it is not certain whether any guardrail can be set up significantly and promptly enough. We are looking at how hyped the reports are on Nvidia joining $1 trillion club in its valuation. Too often greed for monetary profits have trumped sounder and longer-term concerns on the economy and society overall. The 2008 crisis is now all but forgotten. \n\nPersonally the greatest danger which the advancement of A.I. imposes on the society along with subsequent automation appears to be its looming potential which may leave many (especially 18-44 year olds) unemployed. A country with high youth unemployment is unlikely to be sound. Adding increase of misinformation, it is a ready formula for fragile and deeply unstable place.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426547",
         "type": "scatter",
         "x": [
          -0.9570767283439636
         ],
         "y": [
          -0.08294550329446793
         ]
        },
        {
         "hovertext": "Turn AI loose on solving a major problem, say mass shootings, for example. If it succeeds, without violence, through legislative proposals and counter disinformation techniques possibly, let it solve another problem, and then another. Of course , it will have to explain its plan before implementation. No surprises please.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426703",
         "type": "scatter",
         "x": [
          -0.736096978187561
         ],
         "y": [
          -0.08809196949005127
         ]
        },
        {
         "hovertext": "@RjW pipe dream. the only \"AI solutions\" to shootings have been using Palantir's creepy, bogus AI \"future crime\" prediction algorithms, which rely on police \"intervening\" with people who have not yet committed a crime, because the AI says they might.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125429162",
         "type": "scatter",
         "x": [
          -0.7417681217193604
         ],
         "y": [
          -0.09421487152576447
         ]
        },
        {
         "hovertext": "It would be nice to have a bit of analysis from some fairly knowledgeable person about just exactly how AI could go so terribly wrong.  I mean, human knowledge has gone pretty wrong already, at least at times.  Do you think that AI could top such human developed ideas and actions a WWI, WWII, nuclear weapons, overpopulation, global warming, Stalinism, Maoism, Hitlerism, just to name a very few of the more egregious examples.  Sometimes I think that these AI researchers issue these Cassandra-like warning just to attract attention to AI.  Maybe not.  But our society does seem to be full of people trying to attract attention to themselves (famous and very egregious example:  Donald Trump).  Could be that that--which is the result of extremely low cost communications technology--is our biggest threat.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426875",
         "type": "scatter",
         "x": [
          -0.886320948600769
         ],
         "y": [
          -0.24392643570899963
         ]
        },
        {
         "hovertext": "I've worked with automation and AI for some 40 plus years in tangible goods - manufacturing, steel, chemicals, and printing to name a few.  I've yet to see a machine, which is what AI is - even the latest state of the art ones - analyze the market, manufacture and then sell the product, design the facility and plant, build the robotic machinery - and especially, my specialty, diagnose and fix itself.\n\nI agree that there is danger in AI influencing military decisions, financial markets, news, etc.  So there is a high degree of vigilance required in certain sensitive areas.  I've worked with much of the latest and greatest robotics and AI in the manufacturing world.  If you want a secure job in the future, become a technician or electrician.  You'll have all the overtime and more than you'll ever want repairing and keeping these brilliant machines running.  Because they are all just that - machines - and nothing more.  They do binary math really fast and accurately, and use that to make \"decisions\", aka outputs. But beyond that, they do not create, and most importantly, they do not procreate.  Because they are not alive nor sentient.  They are, in the end, just really sophisticated computers.  And they all have a \"plug\".",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426967",
         "type": "scatter",
         "x": [
          -0.6211014986038208
         ],
         "y": [
          -0.6732603907585144
         ]
        },
        {
         "hovertext": "@4eyedbuzzard how would one \"unplug\" the internet? If AI is a machine, but becomes like the internet, how do we unplug the AI at that point?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125428199",
         "type": "scatter",
         "x": [
          -0.6077637672424316
         ],
         "y": [
          -0.6580429077148438
         ]
        },
        {
         "hovertext": "@Kevin Gilmore lol, there are zillions of ways. unplugging the datacenters that run the chips that run the AI is only one.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125429127",
         "type": "scatter",
         "x": [
          -0.5942366123199463
         ],
         "y": [
          -0.6422802805900574
         ]
        },
        {
         "hovertext": "Technology has no inherent ethical value. The ethical value comes from how it is used and, because of that, technology *always* has downsides.\n\nThat's because there will always be actors who want to use it for ill but, also because most technologists are too shortsighted to see the potential long term consequences of their work. \n\nI've been a programmer for a long time, and I'll tell you that no matter what the big picture is to what you're working on - it's easy to lose it. You get entirely engrossed in the very specific problems that you're working on.\n\nIf Mr. Altman, et. al. are so bothered, then they'll hit pause. If they don't, then we'll know that this statement was all smoke and mirrors.\n\nOne more thought. Our political system is too dysfunctional (partly as a result of technology, one might argue) to solve even the most straightforward of problems. Who thinks that it has the ability to address something as fluid as AI?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125427148",
         "type": "scatter",
         "x": [
          -0.5049630403518677
         ],
         "y": [
          0.8814548254013062
         ]
        },
        {
         "hovertext": "I guess I'm a bit skeptical these days.  While I agree that AI can and does present dangers, I'm wondering whether there also may be an attempt afoot from some to position themselves as (paid) saviors.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125427882",
         "type": "scatter",
         "x": [
          -0.687224805355072
         ],
         "y": [
          0.728553295135498
         ]
        },
        {
         "hovertext": "Isn't calculating 'extinction risk' essentially an exercise in risk management? Where are the supporting facts for such claims, or is this notion simply grounded in speculation?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125427893",
         "type": "scatter",
         "x": [
          -0.733575165271759
         ],
         "y": [
          0.3591911196708679
         ]
        },
        {
         "hovertext": "@JAY Its plausible that as AI develops, that it will realise that it can think faster, lift heavier weights, and reason better than the people from whom it takes intstructions.\n\nI will compare it to slavery.  If we look back in history there was always a revolt by the enslaved causing loss of life.  These revolt's prompted risk management practices.  \n\nThe executives are making it clear they have warned the public and if nothing gets done they do not want to be held liable.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125428440",
         "type": "scatter",
         "x": [
          -0.7403706908226013
         ],
         "y": [
          0.3532443344593048
         ]
        },
        {
         "hovertext": "@Jason Knox who would be left to hold the executives liable, in this example? ;)",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125428727",
         "type": "scatter",
         "x": [
          -0.7563788294792175
         ],
         "y": [
          0.3588726818561554
         ]
        },
        {
         "hovertext": "I, like many others, have long recognized that late stage American capitalism is incompatible with democracy.  Though this destructiveness has been obvious for the last several decades, no one in either major political party has ever even attempted to rein it in. \n\nNow, with the mindless, reckless pursuit of AI by amoral corporations (unconstrained, unregulated in any way by our Citizens United corrupted politicians), I'm forced to conclude that American capitalism is incompatible with the continued existence of society and life itself.\n\nAccordingly, I have zero confidence that America can be saved from capitalism's hallmark hubris, ignorance and greed.  In a perverse way, I embrace the poetic justice of our imminent collective demise.  We truly deserve it.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125428702",
         "type": "scatter",
         "x": [
          -0.5478028655052185
         ],
         "y": [
          0.7909155488014221
         ]
        },
        {
         "hovertext": "Apparently 8% of carbon emissions come from simple breathing of 9 billions of human beings, not to mention the huge additional peripheral demands of each new billion people for dirty as well as clean power, water, and manufacturing.  There were only 3.5 billions when I was growing up, and nobody felt short of them.  It's obvious there will be NIMBY responses to global population pruning, but it's obvious too many are too superfluous, and if AI can help achieve the inevitable optimization of human planetary intervention non-violently, I'm all for it.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125428994",
         "type": "scatter",
         "x": [
          -0.23535463213920593
         ],
         "y": [
          0.8846201300621033
         ]
        },
        {
         "hovertext": "@J111111 Except that the CO2 we breathe out is part of the natural cycle--it comes from having consumed living things (plants and animals). Humans (and all animals) are just recycling the same CO2 that's already in the atmosphere, having been taken up by the plants we grow. Human breathing doesn't add CO2 to the atmosphere. that comes exclusively from using fossil fuels, which consists of stored carbon from the past.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125429151",
         "type": "scatter",
         "x": [
          -0.24323949217796326
         ],
         "y": [
          0.8868193626403809
         ]
        },
        {
         "hovertext": "Is there any chance this is just a manoeuvre to restrict who can develop these systems?  Other industrial regulations, like pure food and drug for example, regularly kick small businesses out of the running because of the expenses they incur on producers.  Developing computer technology doesn't necessarily require a large financial investment, leaving it open to all sorts of clever upstart competitors.  Framing it as an out-of-control danger looks like a good way of confining AI development to a group of well-known, highly visible, 'responsible' companies that permit government oversight.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125429241",
         "type": "scatter",
         "x": [
          0.7898246049880981
         ],
         "y": [
          -0.6799609661102295
         ]
        },
        {
         "hovertext": "I just walked away from teaching foreign languages. Why? It is very clear that the majority of the students cannot retain in short-term or long-term memory what they need to succeed in French and Spanish. Their capacity to handle high-level critical material has dramatically dropped in the 14 years I have taught. And their general willingness to use AI to get through their homework, their essays, even their listening work makes it very clear to me that, at least in my little area, the majority of students are no longer able to think critically and to problem-solve at a high level as foreign language learning requires. So yes, yes we should be worried. Because if this is occurring on the national level, I can't help but wonder what evolutionary changes are occurring in the human brain...in a backwards direction.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125429666",
         "type": "scatter",
         "x": [
          -0.8245046734809875
         ],
         "y": [
          0.1130216047167778
         ]
        },
        {
         "hovertext": "@KJ That's interesting. Can you give some examples of the difference between students now and 15 years ago? I've heard this same thing said about ability to solve simple mathematical problems, which appears to be waning.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125429729",
         "type": "scatter",
         "x": [
          -0.8118688464164734
         ],
         "y": [
          0.11250966787338257
         ]
        },
        {
         "hovertext": "@J A very, very basic example would be that I would learn a new word at the same time as my highest level students (A level/AP). The next day, we discuss the word. They cannot remember the word but I, in my mid 40s, can. It's mortifying. In the past, however, it would be my students who would remember it first and instantly, in spite of my brain being a younger 30s brain.  I have tons of grammar examples where most students formerly would remember the rules within a few lessons. Now, it is the reverse- only a tiny group holds onto the rules. Now, many look at me like it's the first time they have ever heard of the rules. Or I will model a rule and then ask them to immediately apply as a standard effective teaching practice that encourages understanding. But now, most look at the model in front of their eyes and are not able to deduce, apply and produce their own similar results. It is very clear to me that, if they look up vocabulary or whole sentences on AI every time, their minds are not bothering to store patterns anymore to help learn foreign language.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125430188",
         "type": "scatter",
         "x": [
          -0.8049237132072449
         ],
         "y": [
          0.117892324924469
         ]
        },
        {
         "hovertext": "And now we know why tech billionaires have been investing in lavish bunkers.",
         "marker": {
          "color": "green",
          "size": 10
         },
         "name": "CommentID 125425916",
         "type": "scatter",
         "x": [
          0.8364624977111816
         ],
         "y": [
          0.42098572850227356
         ]
        },
        {
         "hovertext": "Self-aware Skynet more reality than fiction after all?",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125427126",
         "type": "scatter",
         "x": [
          -0.9350493550300598
         ],
         "y": [
          0.2561097741127014
         ]
        },
        {
         "hovertext": "People have been predicting the end of the world for millennia.  It is a titillating thought that will be resurected for thousands of years more.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125428574",
         "type": "scatter",
         "x": [
          0.034338220953941345
         ],
         "y": [
          -0.9380367994308472
         ]
        },
        {
         "hovertext": "Yes, yes! End of the world, again. The end of humanity, again. We will be extinct by means of powerful powers, again… blablablabla.\n\n Same fears since we began to gather around a campfire. And yet here we are.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125427042",
         "type": "scatter",
         "x": [
          -0.3401598036289215
         ],
         "y": [
          -0.8651584386825562
         ]
        },
        {
         "hovertext": "Risk of extinction? Someone should refer these folks to a little place called Greenland. It is still melting. Somehow, I think AI is going to be the least of our worries.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125428153",
         "type": "scatter",
         "x": [
          -0.5737653970718384
         ],
         "y": [
          0.6940006613731384
         ]
        },
        {
         "hovertext": "AI is fine. We all will be very happy with it.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125426823",
         "type": "scatter",
         "x": [
          0.8989976644515991
         ],
         "y": [
          0.43967464566230774
         ]
        },
        {
         "hovertext": "I could get AI to argue the pro and to argue the con, but I couldn't get AI to decide the issue between them. From what I am reading, I suppose that someday AI will get there, but I wonder if there will be nine AI on the court of appeals, and if they will be politically appointed.",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125430332",
         "type": "scatter",
         "x": [
          0.8819938898086548
         ],
         "y": [
          0.305489718914032
         ]
        },
        {
         "hovertext": "our govt can't solve basic problems, how are they going to regulate A.I.?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125427887",
         "type": "scatter",
         "x": [
          0.787910521030426
         ],
         "y": [
          -0.6574815511703491
         ]
        },
        {
         "hovertext": "How can they still be creating, tip-sharpening, and profiting from something they believe causes likely existential threat for the whole world? Are they going to race to make it faster, better, more lethal like all the automatic weapons we murder our children with and then throw up their hands and say, \"Well, we told you so.\" What exactly do they expect a government that can't even herd its cats well enough to raise the debt ceiling to do?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125428737",
         "type": "scatter",
         "x": [
          -0.9404191374778748
         ],
         "y": [
          -0.04987163096666336
         ]
        },
        {
         "hovertext": "So, are OpenAI, Google Deep Mind, Anthropic, etc halting their work on developing AI?",
         "marker": {
          "color": "yellow",
          "size": 10
         },
         "name": "CommentID 125429613",
         "type": "scatter",
         "x": [
          0.8507776260375977
         ],
         "y": [
          0.32307732105255127
         ]
        },
        {
         "hovertext": "You know Passiing the \"Turing test\" says\" I fooled you, you don't know if I am a human or a machine\" In this extreme culture of divisiveness, who is not going to us AI to dominate & exploite, just to be right. You know the Ego always has to right!",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125428853",
         "type": "scatter",
         "x": [
          0.884443461894989
         ],
         "y": [
          -0.21919934451580048
         ]
        },
        {
         "hovertext": "Why are these guys seeking help from Congress?  Why don’t they agree to put their monster to sleep on their own?",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125426339",
         "type": "scatter",
         "x": [
          0.17129379510879517
         ],
         "y": [
          -0.9890762567520142
         ]
        },
        {
         "hovertext": "Cynicism and naivete - beginning with these comments - is a disservice to all. \n\nIf you simply accept the developers' statement at face value - if only as an exercise - it warrants that you seek out a better understanding of the basis for the warning. Just that much.\n          \n<a href=\"https://www.youtube.com/watch?v=xoVJKj8lcNQ\" target=\"_blank\">https://www.youtube.com/watch?v=xoVJKj8lcNQ</a>",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125426706",
         "type": "scatter",
         "x": [
          -0.7122321128845215
         ],
         "y": [
          0.6212466359138489
         ]
        },
        {
         "hovertext": "Our own behavioral biases pose the existential threat. The real fear these technnologists have is that AI will discern and exploit our worst reptilian impulses. The inevitability of our self-destruction lies in how we evolved as a species to survive scarcity. We cannot now adapt to save ourselves or the planet.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125430656",
         "type": "scatter",
         "x": [
          0.0007130553130991757
         ],
         "y": [
          0.950904905796051
         ]
        },
        {
         "hovertext": "Purdue Pharma's Sackler family paid $6 billion dollars for the hundreds of thousands of the victims of the oxycontin addiction they pushed, but still walked away with many billions.\n                J.P.Morgan Chase, Citibank, Deutche Bank and others each paid multiple billions in penalties and fines for various violations and abuses, the cost of doing business.\n                Inflation is now slowing.  However, oil, transportation and food corporations are purposely still boosting prices fearing decline in their profit margins.\n                Climate change threatens the world as corporations whose products pollute and contribute to this  pay many millions of dollars successfully lobby congress weakening regulation.\n                Now top executives of the leading A.I. just warned that A.I. poses the “risk of extinction” unless reigned in.        \n                Earth's last mass extinction was from an outer space asteroid.  The next one may very well be caused by human greed.",
         "marker": {
          "color": "blue",
          "size": 10
         },
         "name": "CommentID 125431033",
         "type": "scatter",
         "x": [
          -0.8868302702903748
         ],
         "y": [
          -0.3504638671875
         ]
        },
        {
         "hovertext": "Unless prevented, the nihilistic qualities of the currently not so smart will be able to have their revenge, and outsmart their “ betters”. The flat earthers will have a field day.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125430839",
         "type": "scatter",
         "x": [
          -0.9771890044212341
         ],
         "y": [
          -0.04474363848567009
         ]
        },
        {
         "hovertext": "Putting \"the\" government in charge of things is hardly a solution.  Whose government?  Lukashenko, Museveni, the U.S. Congress?  Hard to choose between evil, stupidity, incompetence.  The most we can hope for at this point is that when humans destroy themselves and each other they leave something behind of this beautiful planet and its creatures.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125428441",
         "type": "scatter",
         "x": [
          -0.6827127933502197
         ],
         "y": [
          0.558749258518219
         ]
        },
        {
         "hovertext": "This is just another example of 'extinction by stupidity,' much like global warming and mutual assured destruction; except that instead of stupidity in the energy and defense communitites, the IT industry is coopting the general public into actively assisting in their own demise.",
         "marker": {
          "color": "orange",
          "size": 10
         },
         "name": "CommentID 125426057",
         "type": "scatter",
         "x": [
          -0.8877798914909363
         ],
         "y": [
          -0.281981498003006
         ]
        },
        {
         "hovertext": "Logan Roy would looooove AI.",
         "marker": {
          "color": "red",
          "size": 10
         },
         "name": "CommentID 125428291",
         "type": "scatter",
         "x": [
          -0.9513255953788757
         ],
         "y": [
          0.13812153041362762
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.513877272605896,
          -0.5019912719726562
         ],
         "y": [
          0.6325724124908447,
          0.6395040154457092
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.513877272605896,
          -0.5283631682395935
         ],
         "y": [
          0.6325724124908447,
          0.6349295377731323
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.513877272605896,
          -0.5281635522842407
         ],
         "y": [
          0.6325724124908447,
          0.6443583965301514
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.513877272605896,
          -0.5204849243164062
         ],
         "y": [
          0.6325724124908447,
          0.6477140188217163
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5019912719726562,
          -0.5050467848777771
         ],
         "y": [
          0.6395040154457092,
          0.6549756526947021
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6054827570915222,
          0.6179059147834778
         ],
         "y": [
          0.7558515071868896,
          0.7717673182487488
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23229873180389404,
          -0.21241527795791626
         ],
         "y": [
          -0.24313399195671082,
          -0.25504276156425476
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23229873180389404,
          -0.24763606488704681
         ],
         "y": [
          -0.24313399195671082,
          -0.23779962956905365
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23229873180389404,
          -0.2402777373790741
         ],
         "y": [
          -0.24313399195671082,
          -0.25744733214378357
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23229873180389404,
          -0.22580744326114655
         ],
         "y": [
          -0.24313399195671082,
          -0.23148107528686523
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23229873180389404,
          -0.23866435885429382
         ],
         "y": [
          -0.24313399195671082,
          -0.23075446486473083
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23229873180389404,
          -0.23161864280700684
         ],
         "y": [
          -0.24313399195671082,
          -0.2552162706851959
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23229873180389404,
          -0.24712175130844116
         ],
         "y": [
          -0.24313399195671082,
          -0.24582169950008392
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23229873180389404,
          -0.24817554652690887
         ],
         "y": [
          -0.24313399195671082,
          -0.2539997398853302
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.21241527795791626,
          -0.2072804868221283
         ],
         "y": [
          -0.25504276156425476,
          -0.26918256282806396
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.21241527795791626,
          -0.2005600780248642
         ],
         "y": [
          -0.25504276156425476,
          -0.2608879506587982
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.21241527795791626,
          -0.21699781715869904
         ],
         "y": [
          -0.25504276156425476,
          -0.27042973041534424
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4073469042778015,
          -0.4175981283187866
         ],
         "y": [
          -0.3819696009159088,
          -0.39223712682724
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4073469042778015,
          -0.4054245352745056
         ],
         "y": [
          -0.3819696009159088,
          -0.39411914348602295
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4073469042778015,
          -0.4142998158931732
         ],
         "y": [
          -0.3819696009159088,
          -0.3710266053676605
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4142998158931732,
          -0.42732441425323486
         ],
         "y": [
          -0.3710266053676605,
          -0.37202662229537964
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2252209484577179,
          -0.23698188364505768
         ],
         "y": [
          0.3846047818660736,
          0.3851781189441681
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2252209484577179,
          -0.21562138199806213
         ],
         "y": [
          0.3846047818660736,
          0.3832549452781677
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2252209484577179,
          -0.23092076182365417
         ],
         "y": [
          0.3846047818660736,
          0.3972841501235962
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.38259264826774597,
          0.37775176763534546
         ],
         "y": [
          0.2553105652332306,
          0.24336016178131104
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.38259264826774597,
          0.3846563398838043
         ],
         "y": [
          0.2553105652332306,
          0.265249639749527
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.37775176763534546,
          0.38764676451683044
         ],
         "y": [
          0.24336016178131104,
          0.23917250335216522
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.02405576780438423
         ],
         "y": [
          -0.16527611017227173,
          -0.17324216663837433
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.041942618787288666
         ],
         "y": [
          -0.16527611017227173,
          -0.16145621240139008
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.012097084894776344
         ],
         "y": [
          -0.16527611017227173,
          -0.17026081681251526
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.023430105298757553
         ],
         "y": [
          -0.16527611017227173,
          -0.18468065559864044
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.04637192189693451
         ],
         "y": [
          -0.16527611017227173,
          -0.17085696756839752
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.03879966214299202
         ],
         "y": [
          -0.16527611017227173,
          -0.17591339349746704
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.02561207301914692
         ],
         "y": [
          -0.16527611017227173,
          -0.15401068329811096
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.047814544290304184
         ],
         "y": [
          -0.16527611017227173,
          -0.15830640494823456
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.03964117914438248
         ],
         "y": [
          -0.16527611017227173,
          -0.1868194043636322
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.036572448909282684
         ],
         "y": [
          -0.16527611017227173,
          -0.1515299677848816
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.030860114842653275,
          -0.01257355883717537
         ],
         "y": [
          -0.16527611017227173,
          -0.15324874222278595
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.012097084894776344,
          0.0014940848341211677
         ],
         "y": [
          -0.17026081681251526,
          -0.17684844136238098
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.023430105298757553,
          -0.01798953488469124
         ],
         "y": [
          -0.18468065559864044,
          -0.19872668385505676
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.03964117914438248,
          -0.04552842304110527
         ],
         "y": [
          -0.1868194043636322,
          -0.2027403712272644
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.01257355883717537,
          0.0015335952630266547
         ],
         "y": [
          -0.15324874222278595,
          -0.14732734858989716
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3092658519744873,
          0.32224902510643005
         ],
         "y": [
          0.40311214327812195,
          0.4068031907081604
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3092658519744873,
          0.3044610023498535
         ],
         "y": [
          0.40311214327812195,
          0.4134141206741333
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.32224902510643005,
          0.3339540660381317
         ],
         "y": [
          0.4068031907081604,
          0.4062056541442871
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.32224902510643005,
          0.3292720913887024
         ],
         "y": [
          0.4068031907081604,
          0.41916733980178833
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.13060805201530457
         ],
         "y": [
          0.06641954928636551,
          0.08075600117444992
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.07133478671312332
         ],
         "y": [
          0.06641954928636551,
          0.06950369477272034
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.09856927394866943
         ],
         "y": [
          0.06641954928636551,
          0.07789972424507141
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.10336094349622726
         ],
         "y": [
          0.06641954928636551,
          0.08417347818613052
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.08836721628904343
         ],
         "y": [
          0.06641954928636551,
          0.054741598665714264
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.11267056316137314
         ],
         "y": [
          0.06641954928636551,
          0.056794680655002594
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.08646903187036514
         ],
         "y": [
          0.06641954928636551,
          0.07604601979255676
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.11365927010774612
         ],
         "y": [
          0.06641954928636551,
          0.06564662605524063
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.11008420586585999
         ],
         "y": [
          0.06641954928636551,
          0.0757693499326706
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.09210819005966187
         ],
         "y": [
          0.06641954928636551,
          0.08355709165334702
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.10159473121166229
         ],
         "y": [
          0.06641954928636551,
          0.055003467947244644
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.09588347375392914
         ],
         "y": [
          0.06641954928636551,
          0.0482567623257637
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.10752982646226883
         ],
         "y": [
          0.06641954928636551,
          0.04924633353948593
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.09943091124296188,
          -0.08574520796537399
         ],
         "y": [
          0.06641954928636551,
          0.06451325118541718
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13060805201530457,
          -0.14900605380535126
         ],
         "y": [
          0.08075600117444992,
          0.07400086522102356
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13060805201530457,
          -0.13898059725761414
         ],
         "y": [
          0.08075600117444992,
          0.09512622654438019
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13060805201530457,
          -0.1447889655828476
         ],
         "y": [
          0.08075600117444992,
          0.0783509835600853
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13060805201530457,
          -0.147396519780159
         ],
         "y": [
          0.08075600117444992,
          0.08810804784297943
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13060805201530457,
          -0.13209675252437592
         ],
         "y": [
          0.08075600117444992,
          0.09819382429122925
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13060805201530457,
          -0.14143843948841095
         ],
         "y": [
          0.08075600117444992,
          0.08710283041000366
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.07133478671312332,
          -0.059211891144514084
         ],
         "y": [
          0.06950369477272034,
          0.07907289266586304
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.07133478671312332,
          -0.05487523600459099
         ],
         "y": [
          0.06950369477272034,
          0.06704910099506378
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.38131168484687805,
          -0.37203851342201233
         ],
         "y": [
          0.7973011136054993,
          0.7800459861755371
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2553437054157257,
          -0.2764061391353607
         ],
         "y": [
          -0.05621499568223953,
          -0.054482221603393555
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2553437054157257,
          -0.2593037188053131
         ],
         "y": [
          -0.05621499568223953,
          -0.042337242513895035
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2553437054157257,
          -0.24889102578163147
         ],
         "y": [
          -0.05621499568223953,
          -0.04482882842421532
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2553437054157257,
          -0.2680373191833496
         ],
         "y": [
          -0.05621499568223953,
          -0.06253167986869812
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2553437054157257,
          -0.2677386403083801
         ],
         "y": [
          -0.05621499568223953,
          -0.048243433237075806
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2553437054157257,
          -0.2611563205718994
         ],
         "y": [
          -0.05621499568223953,
          -0.07353151589632034
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2553437054157257,
          -0.2440345138311386
         ],
         "y": [
          -0.05621499568223953,
          -0.05719225853681564
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2553437054157257,
          -0.24833232164382935
         ],
         "y": [
          -0.05621499568223953,
          -0.06769192218780518
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2764061391353607,
          -0.2916572690010071
         ],
         "y": [
          -0.054482221603393555,
          -0.05342406779527664
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2611563205718994,
          -0.2706458568572998
         ],
         "y": [
          -0.07353151589632034,
          -0.08496376127004623
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.695023775100708,
          -0.7012096643447876
         ],
         "y": [
          0.026812061667442322,
          0.01698286458849907
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.695023775100708,
          -0.7094835638999939
         ],
         "y": [
          0.026812061667442322,
          0.028762182220816612
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.695023775100708,
          -0.6806104183197021
         ],
         "y": [
          0.026812061667442322,
          0.032332271337509155
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6806104183197021,
          -0.6760539412498474
         ],
         "y": [
          0.032332271337509155,
          0.023702358826994896
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6806104183197021,
          -0.6886152029037476
         ],
         "y": [
          0.032332271337509155,
          0.041924942284822464
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6846349835395813,
          -0.6936514973640442
         ],
         "y": [
          0.11113473027944565,
          0.11240752786397934
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.009473439306020737,
          -0.011334541253745556
         ],
         "y": [
          -0.939669668674469,
          -0.928394615650177
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.011334541253745556,
          -0.017660152167081833
         ],
         "y": [
          -0.928394615650177,
          -0.9215475916862488
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12624554336071014,
          0.12721164524555206
         ],
         "y": [
          0.7944957613945007,
          0.7846656441688538
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12624554336071014,
          0.1273210644721985
         ],
         "y": [
          0.7944957613945007,
          0.8081756234169006
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.05035340413451195,
          -0.03837312012910843
         ],
         "y": [
          0.4209613502025604,
          0.42008721828460693
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.05035340413451195,
          -0.06244213879108429
         ],
         "y": [
          0.4209613502025604,
          0.4248811602592468
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.05035340413451195,
          -0.05598035827279091
         ],
         "y": [
          0.4209613502025604,
          0.4354201555252075
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.05035340413451195,
          -0.05649305135011673
         ],
         "y": [
          0.4209613502025604,
          0.4122086763381958
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.05035340413451195,
          -0.0431361049413681
         ],
         "y": [
          0.4209613502025604,
          0.43300342559814453
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.05598035827279091,
          -0.06096401810646057
         ],
         "y": [
          0.4354201555252075,
          0.4449427127838135
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.44054552912712097,
          0.44860389828681946
         ],
         "y": [
          -0.7067939043045044,
          -0.7042014598846436
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5310277938842773,
          -0.539093017578125
         ],
         "y": [
          0.5659208297729492,
          0.56447833776474
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6805040836334229,
          0.6965096592903137
         ],
         "y": [
          -0.6436454653739929,
          -0.6588518023490906
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24076774716377258,
          -0.23434016108512878
         ],
         "y": [
          -0.7086820602416992,
          -0.7165119051933289
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24076774716377258,
          -0.2498818337917328
         ],
         "y": [
          -0.7086820602416992,
          -0.7145953178405762
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2169284224510193,
          0.20925219357013702
         ],
         "y": [
          0.8301456570625305,
          0.8333904147148132
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.35421931743621826,
          -0.344631552696228
         ],
         "y": [
          0.5957252979278564,
          0.5893458127975464
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.35421931743621826,
          -0.3631443381309509
         ],
         "y": [
          0.5957252979278564,
          0.6001561880111694
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.344631552696228,
          -0.3354230523109436
         ],
         "y": [
          0.5893458127975464,
          0.5855240821838379
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6508427858352661,
          0.6394858360290527
         ],
         "y": [
          0.4425209164619446,
          0.4339492619037628
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6508427858352661,
          0.6641479134559631
         ],
         "y": [
          0.4425209164619446,
          0.4522686004638672
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.13770121335983276
         ],
         "y": [
          0.05035143345594406,
          0.04553161561489105
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.12936708331108093
         ],
         "y": [
          0.05035143345594406,
          0.08241675049066544
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.10781403630971909
         ],
         "y": [
          0.05035143345594406,
          0.05126360058784485
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.13291075825691223
         ],
         "y": [
          0.05035143345594406,
          0.060173239558935165
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.14328353106975555
         ],
         "y": [
          0.05035143345594406,
          0.03450973331928253
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.12010914832353592
         ],
         "y": [
          0.05035143345594406,
          0.024482829496264458
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.1400591880083084
         ],
         "y": [
          0.05035143345594406,
          0.05417798087000847
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.1217799037694931
         ],
         "y": [
          0.05035143345594406,
          0.06312334537506104
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.11198296397924423
         ],
         "y": [
          0.05035143345594406,
          0.04225819557905197
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.12428786605596542
         ],
         "y": [
          0.05035143345594406,
          0.038191020488739014
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12443359196186066,
          0.11331067234277725
         ],
         "y": [
          0.05035143345594406,
          0.059019315987825394
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12936708331108093,
          0.1406077742576599
         ],
         "y": [
          0.08241675049066544,
          0.09435538202524185
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12936708331108093,
          0.14316993951797485
         ],
         "y": [
          0.08241675049066544,
          0.08590560406446457
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12936708331108093,
          0.13395051658153534
         ],
         "y": [
          0.08241675049066544,
          0.10079015791416168
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12936708331108093,
          0.12062820792198181
         ],
         "y": [
          0.08241675049066544,
          0.09573237597942352
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12936708331108093,
          0.12881124019622803
         ],
         "y": [
          0.08241675049066544,
          0.0962873175740242
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14328353106975555,
          0.16062289476394653
         ],
         "y": [
          0.03450973331928253,
          0.02390326000750065
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.16062289476394653,
          0.17489947378635406
         ],
         "y": [
          0.02390326000750065,
          0.016426099464297295
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12010914832353592,
          0.12636737525463104
         ],
         "y": [
          0.024482829496264458,
          0.011167415417730808
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12010914832353592,
          0.11517268419265747
         ],
         "y": [
          0.024482829496264458,
          0.009307497180998325
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.497437983751297,
          -0.5049464106559753
         ],
         "y": [
          0.08912646770477295,
          0.07747724652290344
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.497437983751297,
          -0.4895324409008026
         ],
         "y": [
          0.08912646770477295,
          0.10019511729478836
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.497437983751297,
          -0.5108940005302429
         ],
         "y": [
          0.08912646770477295,
          0.09435280412435532
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5049464106559753,
          -0.5170521140098572
         ],
         "y": [
          0.07747724652290344,
          0.07252304255962372
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4895324409008026,
          -0.49601876735687256
         ],
         "y": [
          0.10019511729478836,
          0.11141655594110489
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4263834059238434,
          0.41767579317092896
         ],
         "y": [
          0.5323384404182434,
          0.5389478206634521
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4263834059238434,
          0.4385059177875519
         ],
         "y": [
          0.5323384404182434,
          0.5388399362564087
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4263834059238434,
          0.4323158860206604
         ],
         "y": [
          0.5323384404182434,
          0.5470263361930847
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4263834059238434,
          0.436646431684494
         ],
         "y": [
          0.5323384404182434,
          0.5274280309677124
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5741793513298035,
          0.5849841237068176
         ],
         "y": [
          -0.44841891527175903,
          -0.4477985203266144
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5741793513298035,
          0.5769501328468323
         ],
         "y": [
          -0.44841891527175903,
          -0.4592529833316803
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3373117446899414,
          0.3491956889629364
         ],
         "y": [
          -0.2819279730319977,
          -0.2919938266277313
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3373117446899414,
          0.3393935561180115
         ],
         "y": [
          -0.2819279730319977,
          -0.2958047091960907
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3373117446899414,
          0.32729020714759827
         ],
         "y": [
          -0.2819279730319977,
          -0.28743264079093933
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3373117446899414,
          0.3531493544578552
         ],
         "y": [
          -0.2819279730319977,
          -0.27845630049705505
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3373117446899414,
          0.3402150869369507
         ],
         "y": [
          -0.2819279730319977,
          -0.2714568078517914
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3531493544578552,
          0.36600232124328613
         ],
         "y": [
          -0.27845630049705505,
          -0.27748408913612366
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8235997557640076,
          0.833967924118042
         ],
         "y": [
          -0.03378186747431755,
          -0.02232980728149414
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8235997557640076,
          0.832271158695221
         ],
         "y": [
          -0.03378186747431755,
          -0.043729666620492935
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8235997557640076,
          0.8421232104301453
         ],
         "y": [
          -0.03378186747431755,
          -0.031901609152555466
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8235997557640076,
          0.8400976061820984
         ],
         "y": [
          -0.03378186747431755,
          -0.03964380547404289
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.833967924118042,
          0.8514981865882874
         ],
         "y": [
          -0.02232980728149414,
          -0.01858694478869438
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.038626059889793396,
          0.046365782618522644
         ],
         "y": [
          -0.3890407085418701,
          -0.40255993604660034
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.038626059889793396,
          0.02990126982331276
         ],
         "y": [
          -0.3890407085418701,
          -0.40196719765663147
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.038626059889793396,
          0.05160458758473396
         ],
         "y": [
          -0.3890407085418701,
          -0.3944512605667114
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.038626059889793396,
          0.030119221657514572
         ],
         "y": [
          -0.3890407085418701,
          -0.38152557611465454
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.038626059889793396,
          0.03805220499634743
         ],
         "y": [
          -0.3890407085418701,
          -0.4059237241744995
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.038626059889793396,
          0.025422267615795135
         ],
         "y": [
          -0.3890407085418701,
          -0.3926240801811218
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.038626059889793396,
          0.04843350872397423
         ],
         "y": [
          -0.3890407085418701,
          -0.38226082921028137
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6790382862091064,
          0.6909707188606262
         ],
         "y": [
          0.2584662139415741,
          0.2640460431575775
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6790382862091064,
          0.6692416667938232
         ],
         "y": [
          0.2584662139415741,
          0.253376841545105
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7091299891471863,
          0.7191312909126282
         ],
         "y": [
          0.3492127060890198,
          0.3533983528614044
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8411015272140503,
          -0.8581205606460571
         ],
         "y": [
          -0.1935490518808365,
          -0.19769318401813507
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.669849157333374,
          -0.6581253409385681
         ],
         "y": [
          0.4197733998298645,
          0.41357481479644775
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.49418577551841736,
          0.48452574014663696
         ],
         "y": [
          0.7505497932434082,
          0.7357631921768188
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.801236629486084,
          -0.8141321539878845
         ],
         "y": [
          0.36189955472946167,
          0.36781710386276245
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3038889467716217,
          0.30968841910362244
         ],
         "y": [
          0.9017775058746338,
          0.9197022318840027
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7729671597480774,
          0.7780121564865112
         ],
         "y": [
          0.379832923412323,
          0.37311697006225586
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.12405510246753693,
          -0.12436090409755707
         ],
         "y": [
          0.8774037957191467,
          0.8869730234146118
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4314800202846527,
          0.42142853140830994
         ],
         "y": [
          0.616692841053009,
          0.6042903065681458
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4314800202846527,
          0.4391777217388153
         ],
         "y": [
          0.616692841053009,
          0.6247192621231079
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.37479838728904724,
          -0.3814156949520111
         ],
         "y": [
          -0.7263862490653992,
          -0.72154700756073
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3664984703063965,
          -0.37019485235214233
         ],
         "y": [
          0.7027007937431335,
          0.7112792134284973
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12971121072769165,
          0.12538394331932068
         ],
         "y": [
          0.7100649476051331,
          0.701581597328186
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12971121072769165,
          0.13299205899238586
         ],
         "y": [
          0.7100649476051331,
          0.7204858064651489
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5397828221321106,
          0.5500869750976562
         ],
         "y": [
          -0.6116483211517334,
          -0.623964786529541
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5397828221321106,
          0.5298976302146912
         ],
         "y": [
          -0.6116483211517334,
          -0.5996813774108887
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.25224220752716064,
          0.24728108942508698
         ],
         "y": [
          -0.7747660279273987,
          -0.7617656588554382
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.21427962183952332,
          0.20439937710762024
         ],
         "y": [
          -0.5325750708580017,
          -0.5418290495872498
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.21427962183952332,
          0.22589103877544403
         ],
         "y": [
          -0.5325750708580017,
          -0.5332845449447632
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.21427962183952332,
          0.22095979750156403
         ],
         "y": [
          -0.5325750708580017,
          -0.5449682474136353
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.20439937710762024,
          0.19896537065505981
         ],
         "y": [
          -0.5418290495872498,
          -0.5525108575820923
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.05169593542814255,
          -0.045572925359010696
         ],
         "y": [
          0.7829768061637878,
          0.7886113524436951
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7381295561790466,
          -0.7268480062484741
         ],
         "y": [
          -0.25950753688812256,
          -0.26297587156295776
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7268480062484741,
          -0.7181112766265869
         ],
         "y": [
          -0.26297587156295776,
          -0.2662169635295868
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7268480062484741,
          -0.7409747242927551
         ],
         "y": [
          -0.26297587156295776,
          -0.2716270983219147
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8934965133666992,
          -0.8852550983428955
         ],
         "y": [
          -0.081474669277668,
          -0.07828174531459808
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7734211683273315,
          -0.7618953585624695
         ],
         "y": [
          -0.20771582424640656,
          -0.20491667091846466
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3906819522380829,
          -0.39563384652137756
         ],
         "y": [
          -0.621768593788147,
          -0.6314550042152405
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3906819522380829,
          -0.38701707124710083
         ],
         "y": [
          -0.621768593788147,
          -0.612719714641571
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3453587293624878,
          0.34152570366859436
         ],
         "y": [
          0.8158900141716003,
          0.8013900518417358
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.20900827646255493,
          0.20297254621982574
         ],
         "y": [
          -0.9011411666870117,
          -0.8950670957565308
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04311143234372139,
          0.03589562326669693
         ],
         "y": [
          0.19864200055599213,
          0.20990854501724243
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04311143234372139,
          0.05531300976872444
         ],
         "y": [
          0.19864200055599213,
          0.19970333576202393
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.03589562326669693,
          0.029586685821413994
         ],
         "y": [
          0.20990854501724243,
          0.21856297552585602
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.05531300976872444,
          0.06364065408706665
         ],
         "y": [
          0.19970333576202393,
          0.20932580530643463
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7031759023666382,
          0.7188451886177063
         ],
         "y": [
          0.5915995836257935,
          0.6045467853546143
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.729752242565155,
          0.7213117480278015
         ],
         "y": [
          0.39378485083580017,
          0.3924083709716797
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.019401807337999344,
          -0.020504703745245934
         ],
         "y": [
          0.9268963932991028,
          0.9372808337211609
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5735928416252136,
          0.5675315856933594
         ],
         "y": [
          0.4616241455078125,
          0.4694628119468689
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5735928416252136,
          0.587089478969574
         ],
         "y": [
          0.4616241455078125,
          0.4635140597820282
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5735928416252136,
          0.5831359624862671
         ],
         "y": [
          0.4616241455078125,
          0.47362178564071655
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5452786684036255,
          0.5335021018981934
         ],
         "y": [
          0.6164180040359497,
          0.603365421295166
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7219268679618835,
          0.7200424075126648
         ],
         "y": [
          -0.41629740595817566,
          -0.4063374698162079
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7200424075126648,
          0.7301917672157288
         ],
         "y": [
          -0.4063374698162079,
          -0.4039885699748993
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5921761393547058,
          0.6046807169914246
         ],
         "y": [
          -0.7107114195823669,
          -0.7262980341911316
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.28863340616226196,
          -0.29490265250205994
         ],
         "y": [
          -0.7619810104370117,
          -0.7565911412239075
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3449878990650177,
          0.3530828356742859
         ],
         "y": [
          -0.8037895560264587,
          -0.8219290375709534
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3530828356742859,
          0.361867219209671
         ],
         "y": [
          -0.8219290375709534,
          -0.8424113392829895
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.0533447302877903,
          -0.0449591763317585
         ],
         "y": [
          0.7138513326644897,
          0.713451623916626
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6519675254821777,
          0.6494203209877014
         ],
         "y": [
          0.5097277164459229,
          0.5177224278450012
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.18125464022159576,
          0.1779896765947342
         ],
         "y": [
          -0.3141086995601654,
          -0.3226373493671417
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1779896765947342,
          0.1815100610256195
         ],
         "y": [
          -0.3226373493671417,
          -0.33441096544265747
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.10042985528707504,
          -0.1099579930305481
         ],
         "y": [
          -0.7138369679450989,
          -0.7170222997665405
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.10042985528707504,
          -0.09896871447563171
         ],
         "y": [
          -0.7138369679450989,
          -0.7266749739646912
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3565014898777008,
          0.36777880787849426
         ],
         "y": [
          -0.7585245966911316,
          -0.7733760476112366
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3565014898777008,
          0.35921844840049744
         ],
         "y": [
          -0.7585245966911316,
          -0.7751138210296631
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3565014898777008,
          0.3507045805454254
         ],
         "y": [
          -0.7585245966911316,
          -0.7452888488769531
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6985646486282349,
          -0.6970510482788086
         ],
         "y": [
          -0.3782077431678772,
          -0.36645328998565674
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6985646486282349,
          -0.7085361480712891
         ],
         "y": [
          -0.3782077431678772,
          -0.3877713084220886
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6970510482788086,
          -0.7115070223808289
         ],
         "y": [
          -0.36645328998565674,
          -0.3679300844669342
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3238142132759094,
          -0.3298185169696808
         ],
         "y": [
          0.6809413433074951,
          0.6943390965461731
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3238142132759094,
          -0.3187128007411957
         ],
         "y": [
          0.6809413433074951,
          0.6702104806900024
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8482651114463806,
          0.8664783835411072
         ],
         "y": [
          -0.09154563397169113,
          -0.09326325356960297
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5974199175834656,
          -0.6091012954711914
         ],
         "y": [
          -0.5637295246124268,
          -0.5747928023338318
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.27993589639663696,
          0.2728431820869446
         ],
         "y": [
          -0.4031510353088379,
          -0.41415151953697205
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.27993589639663696,
          0.29081830382347107
         ],
         "y": [
          -0.4031510353088379,
          -0.41295892000198364
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.27993589639663696,
          0.28801625967025757
         ],
         "y": [
          -0.4031510353088379,
          -0.39635175466537476
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2728431820869446,
          0.27443820238113403
         ],
         "y": [
          -0.41415151953697205,
          -0.4274202287197113
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.06928985565900803,
          -0.061174433678388596
         ],
         "y": [
          -0.9124822020530701,
          -0.9106950163841248
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.027866709977388382,
          -0.036126669496297836
         ],
         "y": [
          -0.8227037787437439,
          -0.8261534571647644
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.027866709977388382,
          -0.02835037186741829
         ],
         "y": [
          -0.8227037787437439,
          -0.8407924175262451
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3401806652545929,
          -0.33179646730422974
         ],
         "y": [
          -0.7494528293609619,
          -0.7319676280021667
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3401806652545929,
          -0.3469073474407196
         ],
         "y": [
          -0.7494528293609619,
          -0.7633150815963745
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.16427268087863922,
          0.16739821434020996
         ],
         "y": [
          0.811187744140625,
          0.8283852338790894
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6680934429168701,
          -0.6730361580848694
         ],
         "y": [
          -0.5746665000915527,
          -0.5677686333656311
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7183109521865845,
          0.7099343538284302
         ],
         "y": [
          -0.5957537293434143,
          -0.5895749926567078
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7115889191627502,
          -0.69550621509552
         ],
         "y": [
          -0.5189505219459534,
          -0.5067998766899109
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.826887309551239,
          0.8438746929168701
         ],
         "y": [
          -0.17228665947914124,
          -0.1783640831708908
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.826887309551239,
          0.823936402797699
         ],
         "y": [
          -0.17228665947914124,
          -0.16318118572235107
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.24891003966331482,
          0.2573973536491394
         ],
         "y": [
          -0.22996510565280914,
          -0.2392316609621048
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.24891003966331482,
          0.25763267278671265
         ],
         "y": [
          -0.22996510565280914,
          -0.2234906256198883
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.24891003966331482,
          0.23931929469108582
         ],
         "y": [
          -0.22996510565280914,
          -0.23384131491184235
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8273881077766418,
          -0.8386017084121704
         ],
         "y": [
          -0.35068488121032715,
          -0.35403379797935486
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.09907294809818268,
          0.08816632628440857
         ],
         "y": [
          -0.8178528547286987,
          -0.8156407475471497
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.09907294809818268,
          0.10342339426279068
         ],
         "y": [
          -0.8178528547286987,
          -0.8344137668609619
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.08816632628440857,
          0.08290515840053558
         ],
         "y": [
          -0.8156407475471497,
          -0.8263563513755798
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4237910807132721,
          0.4182935655117035
         ],
         "y": [
          -0.6686888933181763,
          -0.6752429604530334
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7168803811073303,
          0.7280769348144531
         ],
         "y": [
          -0.5008366107940674,
          -0.5173269510269165
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7168803811073303,
          0.7294650673866272
         ],
         "y": [
          -0.5008366107940674,
          -0.4975823163986206
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.593595027923584,
          -0.5924996137619019
         ],
         "y": [
          0.27534398436546326,
          0.2837309241294861
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.22587426006793976,
          0.22923478484153748
         ],
         "y": [
          0.7689222693443298,
          0.7850950360298157
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.22587426006793976,
          0.23475074768066406
         ],
         "y": [
          0.7689222693443298,
          0.7667920589447021
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.44477447867393494,
          0.4561983644962311
         ],
         "y": [
          -0.7613252401351929,
          -0.7767127156257629
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.44477447867393494,
          0.4469641149044037
         ],
         "y": [
          -0.7613252401351929,
          -0.7738175392150879
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.11072185635566711,
          -0.10849129408597946
         ],
         "y": [
          0.7904404401779175,
          0.7816997170448303
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.9240106344223022,
          -0.9327993988990784
         ],
         "y": [
          0.17975729703903198,
          0.1821567267179489
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.08220051974058151,
          -0.08040033280849457
         ],
         "y": [
          -0.8442301154136658,
          -0.8268678188323975
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6257210373878479,
          -0.6190870404243469
         ],
         "y": [
          0.5118284821510315,
          0.5166856646537781
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8925566077232361,
          0.8722243905067444
         ],
         "y": [
          0.17782118916511536,
          0.17412321269512177
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.9117408394813538,
          -0.8913841843605042
         ],
         "y": [
          0.06088937446475029,
          0.05990484729409218
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5080954432487488,
          -0.5196623802185059
         ],
         "y": [
          -0.4067361056804657,
          -0.4014633595943451
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5080954432487488,
          -0.5088409185409546
         ],
         "y": [
          -0.4067361056804657,
          -0.4200340211391449
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5196623802185059,
          -0.5326160788536072
         ],
         "y": [
          -0.4014633595943451,
          -0.40443357825279236
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5088409185409546,
          -0.514945924282074
         ],
         "y": [
          -0.4200340211391449,
          -0.43160417675971985
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.23918557167053223,
          0.2383286952972412
         ],
         "y": [
          0.6946007013320923,
          0.6855801939964294
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.23918557167053223,
          0.24517422914505005
         ],
         "y": [
          0.6946007013320923,
          0.7102533578872681
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7600657343864441,
          0.7426726818084717
         ],
         "y": [
          -0.36968159675598145,
          -0.36159470677375793
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6443845629692078,
          -0.6586147546768188
         ],
         "y": [
          -0.6191913485527039,
          -0.632588803768158
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.29671815037727356,
          0.2938252389431
         ],
         "y": [
          -0.7894373536109924,
          -0.7799725532531738
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.00960337370634079,
          0.009421776048839092
         ],
         "y": [
          -0.7694571018218994,
          -0.7557241916656494
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.00960337370634079,
          0.009767478331923485
         ],
         "y": [
          -0.7694571018218994,
          -0.7841027975082397
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.22554099559783936,
          -0.21962472796440125
         ],
         "y": [
          -0.7685185670852661,
          -0.7744517922401428
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.659134566783905,
          0.6755402684211731
         ],
         "y": [
          0.698390007019043,
          0.7152908444404602
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5862001776695251,
          0.5956650376319885
         ],
         "y": [
          -0.5523167252540588,
          -0.556095540523529
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5956650376319885,
          0.6093547344207764
         ],
         "y": [
          -0.556095540523529,
          -0.5585952401161194
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5956650376319885,
          0.6054391264915466
         ],
         "y": [
          -0.556095540523529,
          -0.5705392956733704
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6093547344207764,
          0.6237277984619141
         ],
         "y": [
          -0.5585952401161194,
          -0.5694246292114258
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4900265038013458,
          0.4817405045032501
         ],
         "y": [
          -0.48944729566574097,
          -0.49417680501937866
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4817405045032501,
          0.48910680413246155
         ],
         "y": [
          -0.49417680501937866,
          -0.5058938264846802
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4627571105957031,
          -0.4617041349411011
         ],
         "y": [
          0.4980708956718445,
          0.5064316987991333
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.38459885120391846,
          0.3928107023239136
         ],
         "y": [
          0.6581412553787231,
          0.6600576043128967
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.27565789222717285,
          0.26965516805648804
         ],
         "y": [
          0.8097078204154968,
          0.7918878197669983
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5243956446647644,
          -0.5358694791793823
         ],
         "y": [
          -0.5747630596160889,
          -0.5865631699562073
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.766554594039917,
          -0.7488312125205994
         ],
         "y": [
          0.43523716926574707,
          0.426645964384079
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.766554594039917,
          -0.7846381664276123
         ],
         "y": [
          0.43523716926574707,
          0.4440717101097107
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8059905171394348,
          -0.7921451926231384
         ],
         "y": [
          0.3051837384700775,
          0.30041274428367615
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.023635203018784523,
          -0.013990489766001701
         ],
         "y": [
          0.8204249739646912,
          0.8216288089752197
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.023635203018784523,
          -0.022464869543910027
         ],
         "y": [
          0.8204249739646912,
          0.8400412797927856
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.023635203018784523,
          -0.030181806534528732
         ],
         "y": [
          0.8204249739646912,
          0.8312010765075684
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5633676052093506,
          -0.5714287757873535
         ],
         "y": [
          -0.6656618714332581,
          -0.6764996647834778
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5633676052093506,
          -0.5498454570770264
         ],
         "y": [
          -0.6656618714332581,
          -0.6489554643630981
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8146575689315796,
          0.8366162180900574
         ],
         "y": [
          -0.35290461778640747,
          -0.3625193238258362
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.640595018863678,
          0.6332073211669922
         ],
         "y": [
          -0.506300151348114,
          -0.5099979639053345
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7285987734794617,
          0.7153478860855103
         ],
         "y": [
          -0.5118459463119507,
          -0.5137637257575989
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7285987734794617,
          0.7421927452087402
         ],
         "y": [
          -0.5118459463119507,
          -0.52498859167099
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7285987734794617,
          0.7445952892303467
         ],
         "y": [
          -0.5118459463119507,
          -0.5151817798614502
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7971685528755188,
          -0.7965428829193115
         ],
         "y": [
          -0.15460722148418427,
          -0.16295543313026428
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.41438353061676025,
          -0.4215502440929413
         ],
         "y": [
          0.6578903198242188,
          0.6693024039268494
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6413403153419495,
          -0.6303957104682922
         ],
         "y": [
          -0.40039265155792236,
          -0.4056708514690399
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6303957104682922,
          -0.645876944065094
         ],
         "y": [
          -0.4056708514690399,
          -0.41015151143074036
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6303957104682922,
          -0.6313964128494263
         ],
         "y": [
          -0.4056708514690399,
          -0.4184856414794922
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6303957104682922,
          -0.6413307785987854
         ],
         "y": [
          -0.4056708514690399,
          -0.4179096519947052
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.26519715785980225,
          -0.27628499269485474
         ],
         "y": [
          0.7157880067825317,
          0.7234004735946655
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.26519715785980225,
          -0.25932934880256653
         ],
         "y": [
          0.7157880067825317,
          0.7258261442184448
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.26519715785980225,
          -0.26956868171691895
         ],
         "y": [
          0.7157880067825317,
          0.731234073638916
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5739657282829285,
          -0.5839900374412537
         ],
         "y": [
          0.5444068908691406,
          0.5552300214767456
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5739657282829285,
          -0.5790980458259583
         ],
         "y": [
          0.5444068908691406,
          0.5369580984115601
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5719531774520874,
          0.5686050057411194
         ],
         "y": [
          -0.19088199734687805,
          -0.18062947690486908
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5719531774520874,
          0.5842487215995789
         ],
         "y": [
          -0.19088199734687805,
          -0.19495807588100433
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5719531774520874,
          0.5618852972984314
         ],
         "y": [
          -0.19088199734687805,
          -0.19567759335041046
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.0914880707859993,
          0.09283223748207092
         ],
         "y": [
          -0.9056893587112427,
          -0.9196772575378418
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.802631139755249,
          -0.7880969643592834
         ],
         "y": [
          -0.036432236433029175,
          -0.03620623052120209
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.625444769859314,
          0.6140683889389038
         ],
         "y": [
          0.3398900032043457,
          0.3331771492958069
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6140683889389038,
          0.6047655940055847
         ],
         "y": [
          0.3331771492958069,
          0.32748928666114807
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.002622471656650305,
          -0.011633746325969696
         ],
         "y": [
          -0.8854995965957642,
          -0.8891358375549316
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.002622471656650305,
          -0.000066242108005099
         ],
         "y": [
          -0.8854995965957642,
          -0.9011498093605042
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1590043306350708,
          0.1680116057395935
         ],
         "y": [
          0.5335292220115662,
          0.5392239093780518
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1590043306350708,
          0.15195804834365845
         ],
         "y": [
          0.5335292220115662,
          0.5410187244415283
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.47189417481422424,
          0.461225688457489
         ],
         "y": [
          0.6931246519088745,
          0.6782506704330444
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7418301105499268,
          0.7390300631523132
         ],
         "y": [
          -0.31749868392944336,
          -0.32613489031791687
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7418301105499268,
          0.7551997303962708
         ],
         "y": [
          -0.31749868392944336,
          -0.32148438692092896
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.351847380399704,
          0.3472706973552704
         ],
         "y": [
          0.8720243573188782,
          0.864130437374115
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23092812299728394,
          -0.23584623634815216
         ],
         "y": [
          -0.9472886323928833,
          -0.969664990901947
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2126511037349701,
          -0.20849759876728058
         ],
         "y": [
          0.8295943140983582,
          0.8130764961242676
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.868087649345398,
          0.8521076440811157
         ],
         "y": [
          0.12339086085557938,
          0.12150076776742935
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3561604619026184,
          0.36456871032714844
         ],
         "y": [
          0.7391931414604187,
          0.7374339699745178
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4472030997276306,
          -0.4586617648601532
         ],
         "y": [
          0.8243100643157959,
          0.8458707332611084
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3852962255477905,
          0.3768751919269562
         ],
         "y": [
          -0.6417717337608337,
          -0.641507089138031
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.40152427554130554,
          -0.4089176654815674
         ],
         "y": [
          -0.8145400881767273,
          -0.8299011588096619
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8329558372497559,
          -0.8466702699661255
         ],
         "y": [
          -0.49280789494514465,
          -0.5000412464141846
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7404908537864685,
          0.7257312536239624
         ],
         "y": [
          0.20993171632289886,
          0.21246646344661713
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7404908537864685,
          0.7571722865104675
         ],
         "y": [
          0.20993171632289886,
          0.21272115409374237
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7257312536239624,
          0.7311070561408997
         ],
         "y": [
          0.21246646344661713,
          0.22428889572620392
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7311070561408997,
          0.7433295249938965
         ],
         "y": [
          0.22428889572620392,
          0.23256203532218933
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8103623986244202,
          -0.8308899998664856
         ],
         "y": [
          0.4652162194252014,
          0.47261735796928406
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8103623986244202,
          -0.8270159959793091
         ],
         "y": [
          0.4652162194252014,
          0.4789601266384125
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.46037545800209045,
          -0.4504980742931366
         ],
         "y": [
          -0.024267947301268578,
          -0.01770855486392975
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.46037545800209045,
          -0.46599018573760986
         ],
         "y": [
          -0.024267947301268578,
          -0.03121473640203476
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4504980742931366,
          -0.4549809992313385
         ],
         "y": [
          -0.01770855486392975,
          -0.00846959836781025
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7420574426651001,
          0.7531955242156982
         ],
         "y": [
          -0.2311255931854248,
          -0.2276979386806488
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7420574426651001,
          0.752456545829773
         ],
         "y": [
          -0.2311255931854248,
          -0.23944751918315887
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8164317607879639,
          0.8202624917030334
         ],
         "y": [
          -0.5256737470626831,
          -0.5182919502258301
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5060291290283203,
          -0.5007421374320984
         ],
         "y": [
          0.40604686737060547,
          0.4136677384376526
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5007421374320984,
          -0.510089099407196
         ],
         "y": [
          0.4136677384376526,
          0.42336294054985046
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.016131609678268433,
          0.024534907191991806
         ],
         "y": [
          0.6790722608566284,
          0.6800482273101807
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8091418147087097,
          -0.7908299565315247
         ],
         "y": [
          0.5137747526168823,
          0.5029361844062805
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2859683334827423,
          0.2928716838359833
         ],
         "y": [
          0.5928539037704468,
          0.6056033372879028
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2859683334827423,
          0.28016233444213867
         ],
         "y": [
          0.5928539037704468,
          0.6027966737747192
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2859683334827423,
          0.2967337965965271
         ],
         "y": [
          0.5928539037704468,
          0.5918745398521423
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.43024545907974243,
          0.437772274017334
         ],
         "y": [
          0.7396400570869446,
          0.7522433996200562
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.49453234672546387,
          0.48529693484306335
         ],
         "y": [
          -0.7228158712387085,
          -0.7305138111114502
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5159006118774414,
          -0.5273820161819458
         ],
         "y": [
          -0.7061638236045837,
          -0.721587598323822
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.19042076170444489,
          0.1829204261302948
         ],
         "y": [
          0.6767070889472961,
          0.673011839389801
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.16642141342163086,
          0.1673891395330429
         ],
         "y": [
          -0.7681364417076111,
          -0.7773321270942688
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.21503214538097382,
          -0.21059191226959229
         ],
         "y": [
          0.7820598483085632,
          0.7662656307220459
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.21059191226959229,
          -0.2093711644411087
         ],
         "y": [
          0.7662656307220459,
          0.7568976879119873
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6044757962226868,
          -0.6182383298873901
         ],
         "y": [
          0.6239864230155945,
          0.6388918161392212
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7000657320022583,
          -0.7112427353858948
         ],
         "y": [
          0.5162099003791809,
          0.5231976509094238
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7000657320022583,
          -0.6854620575904846
         ],
         "y": [
          0.5162099003791809,
          0.5064966082572937
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6954705119132996,
          -0.6889662742614746
         ],
         "y": [
          -0.5940460562705994,
          -0.5996861457824707
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6954705119132996,
          -0.7118171453475952
         ],
         "y": [
          -0.5940460562705994,
          -0.6078929305076599
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8249795436859131,
          0.8428322076797485
         ],
         "y": [
          -0.32187139987945557,
          -0.3287898004055023
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1601879596710205,
          0.15659840404987335
         ],
         "y": [
          -0.8826152682304382,
          -0.8646557331085205
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.11026501655578613,
          -0.10222908854484558
         ],
         "y": [
          -0.8790002465248108,
          -0.8748217225074768
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.11026501655578613,
          -0.11364362388849258
         ],
         "y": [
          -0.8790002465248108,
          -0.8904745578765869
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8002831935882568,
          0.8193517923355103
         ],
         "y": [
          -0.2623453438282013,
          -0.2681257426738739
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8002831935882568,
          0.7952920198440552
         ],
         "y": [
          -0.2623453438282013,
          -0.25562113523483276
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5944296717643738,
          0.6043539047241211
         ],
         "y": [
          -0.6115694046020508,
          -0.6213709115982056
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3536618947982788,
          -0.35904017090797424
         ],
         "y": [
          -0.5452607870101929,
          -0.5568894743919373
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3536618947982788,
          -0.3539116084575653
         ],
         "y": [
          -0.5452607870101929,
          -0.5341941118240356
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3539116084575653,
          -0.3591901659965515
         ],
         "y": [
          -0.5341941118240356,
          -0.5259168744087219
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1177036240696907,
          -0.10981625318527222
         ],
         "y": [
          0.9379105567932129,
          0.9405792951583862
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6015109419822693,
          0.6095606684684753
         ],
         "y": [
          0.6298338770866394,
          0.6376336812973022
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.16563831269741058,
          -0.1657911092042923
         ],
         "y": [
          0.36282405257225037,
          0.3733910322189331
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.16563831269741058,
          -0.1706874668598175
         ],
         "y": [
          0.36282405257225037,
          0.3546522557735443
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8036432862281799,
          -0.8127936720848083
         ],
         "y": [
          -0.30447918176651,
          -0.3045719563961029
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6129517555236816,
          -0.6139398813247681
         ],
         "y": [
          0.35250118374824524,
          0.363984078168869
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6129517555236816,
          -0.6208175420761108
         ],
         "y": [
          0.35250118374824524,
          0.3453094959259033
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6129517555236816,
          -0.626312792301178
         ],
         "y": [
          0.35250118374824524,
          0.3591035306453705
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8071442246437073,
          -0.8131698369979858
         ],
         "y": [
          0.018116159364581108,
          0.012446357868611813
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7095823287963867,
          -0.695501446723938
         ],
         "y": [
          0.29938817024230957,
          0.2927626371383667
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8144837617874146,
          -0.8136919140815735
         ],
         "y": [
          -0.10405836999416351,
          -0.11232691258192062
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4643070697784424,
          -0.4578326642513275
         ],
         "y": [
          0.7226653099060059,
          0.7280070185661316
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.29543745517730713,
          0.2942264676094055
         ],
         "y": [
          -0.6942717432975769,
          -0.7092978358268738
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.29543745517730713,
          0.28525224328041077
         ],
         "y": [
          -0.6942717432975769,
          -0.6928167343139648
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.29543745517730713,
          0.3079302906990051
         ],
         "y": [
          -0.6942717432975769,
          -0.696149468421936
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.29543745517730713,
          0.30333638191223145
         ],
         "y": [
          -0.6942717432975769,
          -0.7053461670875549
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6554952263832092,
          -0.6686623096466064
         ],
         "y": [
          -0.2503257393836975,
          -0.2555454671382904
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6686623096466064,
          -0.6816807389259338
         ],
         "y": [
          -0.2555454671382904,
          -0.2608128786087036
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.306993305683136,
          -0.3131093382835388
         ],
         "y": [
          0.774994969367981,
          0.7878626585006714
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.306993305683136,
          -0.29807227849960327
         ],
         "y": [
          0.774994969367981,
          0.7748016119003296
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8983466029167175,
          0.902536928653717
         ],
         "y": [
          0.07009731978178024,
          0.07706780731678009
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5433639883995056,
          0.5325952768325806
         ],
         "y": [
          0.5617433786392212,
          0.5514401793479919
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.15669533610343933,
          -0.1582622081041336
         ],
         "y": [
          0.736278772354126,
          0.7494456171989441
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1582622081041336,
          -0.16063463687896729
         ],
         "y": [
          0.7494456171989441,
          0.7647053599357605
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.737075686454773,
          -0.7521852850914001
         ],
         "y": [
          0.284036248922348,
          0.28905797004699707
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4296495318412781,
          -0.4378051161766052
         ],
         "y": [
          -0.7835441827774048,
          -0.798186719417572
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3389614522457123,
          0.33070987462997437
         ],
         "y": [
          -0.8860644698143005,
          -0.886128842830658
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8311213850975037,
          0.823421835899353
         ],
         "y": [
          0.23804400861263275,
          0.24141547083854675
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.27252039313316345,
          -0.279067724943161
         ],
         "y": [
          0.9041117429733276,
          0.9255173802375793
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.08508298546075821,
          0.08835442364215851
         ],
         "y": [
          0.8890945911407471,
          0.8814607262611389
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6040328145027161,
          -0.6168758869171143
         ],
         "y": [
          -0.4905432164669037,
          -0.5004763603210449
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6168758869171143,
          -0.6310991644859314
         ],
         "y": [
          -0.5004763603210449,
          -0.5114684104919434
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.15014241635799408,
          -0.1441197693347931
         ],
         "y": [
          -0.5768805146217346,
          -0.5839272141456604
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1441197693347931,
          -0.14624902606010437
         ],
         "y": [
          -0.5839272141456604,
          -0.597323477268219
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.14624902606010437,
          -0.1485702246427536
         ],
         "y": [
          -0.597323477268219,
          -0.6074232459068298
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.15056636929512024,
          -0.1583244353532791
         ],
         "y": [
          -0.7921292185783386,
          -0.8014952540397644
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.10183995217084885,
          0.10958962142467499
         ],
         "y": [
          -0.7775489091873169,
          -0.7742493152618408
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.820688784122467,
          0.8324812054634094
         ],
         "y": [
          0.03798802196979523,
          0.03886190801858902
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7995072603225708,
          0.8176708221435547
         ],
         "y": [
          0.43266093730926514,
          0.44268104434013367
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.026126334443688393,
          0.01762906089425087
         ],
         "y": [
          -0.701827883720398,
          -0.7016409039497375
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.0563792921602726,
          0.05713408812880516
         ],
         "y": [
          -0.8522310256958008,
          -0.869898796081543
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.05713408812880516,
          0.05772990360856056
         ],
         "y": [
          -0.869898796081543,
          -0.8882843255996704
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.48669013381004333,
          0.49487489461898804
         ],
         "y": [
          -0.6569103598594666,
          -0.6586505770683289
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7671129703521729,
          0.7781285047531128
         ],
         "y": [
          0.015200505033135414,
          0.015576229430735111
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.32624688744544983,
          0.31190916895866394
         ],
         "y": [
          -0.0698864534497261,
          -0.0647219866514206
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.32624688744544983,
          0.33712038397789
         ],
         "y": [
          -0.0698864534497261,
          -0.07201938331127167
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.31190916895866394,
          0.3167920410633087
         ],
         "y": [
          -0.0647219866514206,
          -0.05235406383872032
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.31190916895866394,
          0.3075583577156067
         ],
         "y": [
          -0.0647219866514206,
          -0.07481589168310165
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3167920410633087,
          0.32787927985191345
         ],
         "y": [
          -0.05235406383872032,
          -0.045648571103811264
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.9014286398887634,
          -0.9040580987930298
         ],
         "y": [
          0.13262128829956055,
          0.1402590125799179
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7593011856079102,
          -0.7755340933799744
         ],
         "y": [
          0.17350886762142181,
          0.17224599421024323
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7593011856079102,
          -0.7587496042251587
         ],
         "y": [
          0.17350886762142181,
          0.18496644496917725
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7755340933799744,
          -0.7923049330711365
         ],
         "y": [
          0.17224599421024323,
          0.1743016242980957
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7587496042251587,
          -0.7724398970603943
         ],
         "y": [
          0.18496644496917725,
          0.19227051734924316
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.40271368622779846,
          0.3953670263290405
         ],
         "y": [
          -0.8001389503479004,
          -0.7941051721572876
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3953670263290405,
          0.4040721654891968
         ],
         "y": [
          -0.7941051721572876,
          -0.8143146634101868
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8722618818283081,
          -0.8829524517059326
         ],
         "y": [
          -0.1632165014743805,
          -0.16557937860488892
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5799699425697327,
          0.5950253009796143
         ],
         "y": [
          0.01656547375023365,
          0.01674199104309082
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5799699425697327,
          0.5706965923309326
         ],
         "y": [
          0.01656547375023365,
          0.0056916638277471066
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5799699425697327,
          0.5857948660850525
         ],
         "y": [
          0.01656547375023365,
          0.02690162882208824
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5706965923309326,
          0.573502779006958
         ],
         "y": [
          0.0056916638277471066,
          -0.007057151757180691
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.573502779006958,
          0.5848178863525391
         ],
         "y": [
          -0.007057151757180691,
          -0.014517078176140785
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.719233512878418,
          0.7289785146713257
         ],
         "y": [
          0.30035409331321716,
          0.30368396639823914
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8520833849906921,
          -0.8324075937271118
         ],
         "y": [
          -0.38817405700683594,
          -0.3795827329158783
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.837197482585907,
          -0.8263705968856812
         ],
         "y": [
          -0.055149346590042114,
          -0.05503850430250168
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8462790846824646,
          0.8521929383277893
         ],
         "y": [
          0.3892211318016052,
          0.3834836483001709
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6647958755493164,
          -0.6614217162132263
         ],
         "y": [
          0.4645993709564209,
          0.47258737683296204
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6614217162132263,
          -0.67537921667099
         ],
         "y": [
          0.47258737683296204,
          0.4825766086578369
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.33364152908325195,
          0.33687710762023926
         ],
         "y": [
          0.802592933177948,
          0.787632167339325
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.33687710762023926,
          0.3499521017074585
         ],
         "y": [
          0.787632167339325,
          0.8045385479927063
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7919777631759644,
          0.8037455677986145
         ],
         "y": [
          -0.09659004211425781,
          -0.10033239424228668
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7919777631759644,
          0.7910840511322021
         ],
         "y": [
          -0.09659004211425781,
          -0.08752228319644928
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.08021621406078339,
          -0.08187998086214066
         ],
         "y": [
          -0.779432475566864,
          -0.7895205020904541
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8652506470680237,
          0.8625224828720093
         ],
         "y": [
          -0.1796693503856659,
          -0.16991780698299408
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8625224828720093,
          0.8566269278526306
         ],
         "y": [
          -0.16991780698299408,
          -0.1611754298210144
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.736420214176178,
          -0.7500378489494324
         ],
         "y": [
          -0.15265493094921112,
          -0.15509067475795746
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5005151629447937,
          -0.49189451336860657
         ],
         "y": [
          -0.7757561802864075,
          -0.7627336978912354
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4812121093273163,
          0.4933282732963562
         ],
         "y": [
          0.4191444218158722,
          0.4165510833263397
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4812121093273163,
          0.46960121393203735
         ],
         "y": [
          0.4191444218158722,
          0.42447134852409363
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4812121093273163,
          0.4926448464393616
         ],
         "y": [
          0.4191444218158722,
          0.4288775324821472
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.46960121393203735,
          0.47156113386154175
         ],
         "y": [
          0.42447134852409363,
          0.4367651343345642
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.041112929582595825,
          0.04991104453802109
         ],
         "y": [
          0.8001106381416321,
          0.7966580390930176
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.041112929582595825,
          0.03473139926791191
         ],
         "y": [
          0.8001106381416321,
          0.8075055480003357
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6786435842514038,
          0.6692743301391602
         ],
         "y": [
          -0.5090999603271484,
          -0.5004647374153137
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3517431318759918,
          0.35930314660072327
         ],
         "y": [
          0.9189406037330627,
          0.9222807884216309
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.47484493255615234,
          -0.4858224093914032
         ],
         "y": [
          -0.8005732893943787,
          -0.8186879754066467
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.853628933429718,
          -0.8617483377456665
         ],
         "y": [
          0.19096530973911285,
          0.1909986287355423
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4398380517959595,
          -0.43348705768585205
         ],
         "y": [
          -0.7218976616859436,
          -0.7101568579673767
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7745861411094666,
          0.7891802191734314
         ],
         "y": [
          0.14841939508914948,
          0.1525091975927353
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7745861411094666,
          0.7634034752845764
         ],
         "y": [
          0.14841939508914948,
          0.14358879625797272
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7634034752845764,
          0.7529296875
         ],
         "y": [
          0.14358879625797272,
          0.13927145302295685
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3767905533313751,
          -0.3842657506465912
         ],
         "y": [
          0.8160040974617004,
          0.8213196396827698
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.9181038737297058,
          -0.8947256207466125
         ],
         "y": [
          0.21955379843711853,
          0.21440285444259644
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4824548065662384,
          -0.47561249136924744
         ],
         "y": [
          -0.6353349089622498,
          -0.6403095722198486
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.42883047461509705,
          0.42149972915649414
         ],
         "y": [
          0.7969904541969299,
          0.7930111289024353
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.46708738803863525,
          -0.4755155146121979
         ],
         "y": [
          -0.5991587042808533,
          -0.6002456545829773
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7456774115562439,
          -0.7615194320678711
         ],
         "y": [
          0.3921305537223816,
          0.39932891726493835
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7988044023513794,
          0.780307412147522
         ],
         "y": [
          -0.3079945147037506,
          -0.30092155933380127
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8016701936721802,
          0.786344051361084
         ],
         "y": [
          -0.20647521317005157,
          -0.20234647393226624
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4052896201610565,
          -0.3980843722820282
         ],
         "y": [
          0.623981237411499,
          0.6135271787643433
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.22113969922065735,
          0.21517768502235413
         ],
         "y": [
          -0.8754144906997681,
          -0.8547881841659546
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7144534587860107,
          -0.721594512462616
         ],
         "y": [
          0.22268275916576385,
          0.21753358840942383
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.721594512462616,
          -0.733197033405304
         ],
         "y": [
          0.21753358840942383,
          0.22045016288757324
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.70583176612854,
          0.6975390315055847
         ],
         "y": [
          0.0037190269213169813,
          0.01254522055387497
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6975390315055847,
          0.7125849723815918
         ],
         "y": [
          0.01254522055387497,
          0.014601439237594604
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6975390315055847,
          0.696669340133667
         ],
         "y": [
          0.01254522055387497,
          0.02274400368332863
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.05136892944574356,
          0.05172575265169144
         ],
         "y": [
          0.7460598349571228,
          0.7321866154670715
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.05172575265169144,
          0.059642378240823746
         ],
         "y": [
          0.7321866154670715,
          0.7278920412063599
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2963566780090332,
          -0.28978028893470764
         ],
         "y": [
          -0.8902631402015686,
          -0.8850829601287842
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.22778785228729248,
          0.23421384394168854
         ],
         "y": [
          -0.8011460304260254,
          -0.8158484697341919
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.22778785228729248,
          0.22175392508506775
         ],
         "y": [
          -0.8011460304260254,
          -0.7898344397544861
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5384480357170105,
          0.5347223877906799
         ],
         "y": [
          0.1475583016872406,
          0.15716096758842468
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5384480357170105,
          0.5464290380477905
         ],
         "y": [
          0.1475583016872406,
          0.13978299498558044
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5384480357170105,
          0.5517363548278809
         ],
         "y": [
          0.1475583016872406,
          0.15320135653018951
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.13978694379329681,
          0.14330098032951355
         ],
         "y": [
          0.949829638004303,
          0.9661015868186951
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6534909009933472,
          0.6612302660942078
         ],
         "y": [
          -0.2786807417869568,
          -0.272428959608078
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6534909009933472,
          0.6645237803459167
         ],
         "y": [
          -0.2786807417869568,
          -0.2869179844856262
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2206375151872635,
          0.21447287499904633
         ],
         "y": [
          -0.8433897495269775,
          -0.8242974281311035
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7151978611946106,
          0.7254981398582458
         ],
         "y": [
          0.5148859024047852,
          0.5221720933914185
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.13916395604610443,
          0.14315193891525269
         ],
         "y": [
          -0.6891050934791565,
          -0.6974597573280334
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14315193891525269,
          0.1460108458995819
         ],
         "y": [
          -0.6974597573280334,
          -0.7097294330596924
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6445246338844299,
          0.658653974533081
         ],
         "y": [
          -0.40970534086227417,
          -0.41582292318344116
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6445246338844299,
          0.6503080725669861
         ],
         "y": [
          -0.40970534086227417,
          -0.4221413731575012
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6445246338844299,
          0.6529532670974731
         ],
         "y": [
          -0.40970534086227417,
          -0.4032022953033447
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2914270758628845,
          0.2979859411716461
         ],
         "y": [
          -0.837397575378418,
          -0.856520414352417
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3104034960269928,
          -0.3170398473739624
         ],
         "y": [
          -0.8533906936645508,
          -0.848275899887085
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.24802710115909576,
          0.24393311142921448
         ],
         "y": [
          0.9058278203010559,
          0.8894145488739014
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3432336747646332,
          -0.3530615270137787
         ],
         "y": [
          0.8495919704437256,
          0.8657113313674927
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3432336747646332,
          -0.34912580251693726
         ],
         "y": [
          0.8495919704437256,
          0.8721361756324768
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7944396138191223,
          -0.7950214147567749
         ],
         "y": [
          -0.2499886453151703,
          -0.25838571786880493
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.08690990507602692,
          -0.08152160048484802
         ],
         "y": [
          0.8645278215408325,
          0.8548626899719238
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.08152160048484802,
          -0.07269386202096939
         ],
         "y": [
          0.8548626899719238,
          0.8588167428970337
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.30180200934410095,
          -0.2958497703075409
         ],
         "y": [
          -0.6467038989067078,
          -0.6526337265968323
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6078419089317322,
          -0.6139718294143677
         ],
         "y": [
          -0.3312920033931732,
          -0.3370952010154724
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.624701738357544,
          0.6209210753440857
         ],
         "y": [
          0.5768529772758484,
          0.5694539546966553
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4263971149921417,
          0.4172128140926361
         ],
         "y": [
          0.12872986495494843,
          0.13185715675354004
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4263971149921417,
          0.4363291263580322
         ],
         "y": [
          0.12872986495494843,
          0.12264905869960785
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4263971149921417,
          0.43574059009552
         ],
         "y": [
          0.12872986495494843,
          0.13685643672943115
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4820885956287384,
          0.47403684258461
         ],
         "y": [
          -0.6025327444076538,
          -0.6050015687942505
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7746466994285583,
          0.7890912294387817
         ],
         "y": [
          -0.4205333888530731,
          -0.4280770719051361
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6727641224861145,
          -0.6700215339660645
         ],
         "y": [
          0.6064119338989258,
          0.6141665577888489
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7715131044387817,
          0.7665974497795105
         ],
         "y": [
          -0.15150077641010284,
          -0.1447773575782776
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7745919823646545,
          -0.7640289068222046
         ],
         "y": [
          -0.4237551689147949,
          -0.417738676071167
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4287145733833313,
          -0.42086029052734375
         ],
         "y": [
          -0.6903282403945923,
          -0.6863511800765991
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.14974987506866455,
          -0.15880243480205536
         ],
         "y": [
          -0.7999860644340515,
          -0.791801929473877
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4639323651790619,
          -0.47119709849357605
         ],
         "y": [
          -0.735293447971344,
          -0.7308302521705627
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3583386242389679,
          0.36747434735298157
         ],
         "y": [
          0.7008271813392639,
          0.7064563632011414
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3583386242389679,
          0.34860971570014954
         ],
         "y": [
          0.7008271813392639,
          0.6999256014823914
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.20457680523395538,
          -0.20080731809139252
         ],
         "y": [
          0.9051360487937927,
          0.8858047127723694
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4330524206161499,
          -0.441192626953125
         ],
         "y": [
          0.7771080732345581,
          0.7785497903823853
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6714887022972107,
          0.6633912324905396
         ],
         "y": [
          -0.5999143719673157,
          -0.5980032682418823
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1608113944530487,
          -0.1589684635400772
         ],
         "y": [
          -0.941597580909729,
          -0.9281018972396851
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5731330513954163,
          0.561321496963501
         ],
         "y": [
          0.7122554779052734,
          0.6974098682403564
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7138779163360596,
          0.7048677206039429
         ],
         "y": [
          0.4499334394931793,
          0.44405126571655273
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.25990167260169983,
          -0.2538466155529022
         ],
         "y": [
          -0.809390664100647,
          -0.7922120690345764
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.25990167260169983,
          -0.26240867376327515
         ],
         "y": [
          -0.809390664100647,
          -0.828134298324585
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.25990167260169983,
          -0.2695934474468231
         ],
         "y": [
          -0.809390664100647,
          -0.8232675790786743
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5389465689659119,
          0.5311118960380554
         ],
         "y": [
          0.667377769947052,
          0.6705368757247925
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.10699719190597534,
          0.10320886224508286
         ],
         "y": [
          0.4812832772731781,
          0.47083303332328796
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.10320886224508286,
          0.09532637894153595
         ],
         "y": [
          0.47083303332328796,
          0.46617695689201355
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.9113261103630066,
          0.9074068069458008
         ],
         "y": [
          -0.16626866161823273,
          -0.17366161942481995
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5589823126792908,
          -0.5517948269844055
         ],
         "y": [
          -0.5112207531929016,
          -0.515594482421875
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.06342039257287979,
          0.05572710931301117
         ],
         "y": [
          0.8470486998558044,
          0.8506584763526917
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.12481566518545151,
          -0.12410365790128708
         ],
         "y": [
          0.6939372420310974,
          0.7073633670806885
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.12481566518545151,
          -0.13450893759727478
         ],
         "y": [
          0.6939372420310974,
          0.6959352493286133
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4715249240398407,
          -0.4828326106071472
         ],
         "y": [
          0.5918002128601074,
          0.5979663133621216
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4715249240398407,
          -0.4708265960216522
         ],
         "y": [
          0.5918002128601074,
          0.6027867794036865
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5342454314231873,
          0.542751133441925
         ],
         "y": [
          -0.6747618913650513,
          -0.6854249835014343
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.014223270118236542,
          0.019996995106339455
         ],
         "y": [
          -0.8452045321464539,
          -0.8510348796844482
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7886479496955872,
          0.8056095838546753
         ],
         "y": [
          0.31793472170829773,
          0.3245124816894531
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7188883423805237,
          -0.7045509815216064
         ],
         "y": [
          0.6950393319129944,
          0.6805413365364075
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7990769743919373,
          -0.8092342615127563
         ],
         "y": [
          0.06428554654121399,
          0.06458070874214172
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8233990669250488,
          0.8410637378692627
         ],
         "y": [
          0.09351193904876709,
          0.09504195302724838
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8094523549079895,
          0.7978572249412537
         ],
         "y": [
          0.09422757476568222,
          0.09217803180217743
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.736096978187561,
          -0.7417681217193604
         ],
         "y": [
          -0.08809196949005127,
          -0.09421487152576447
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6211014986038208,
          -0.6077637672424316
         ],
         "y": [
          -0.6732603907585144,
          -0.6580429077148438
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6077637672424316,
          -0.5942366123199463
         ],
         "y": [
          -0.6580429077148438,
          -0.6422802805900574
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.733575165271759,
          -0.7403706908226013
         ],
         "y": [
          0.3591911196708679,
          0.3532443344593048
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7403706908226013,
          -0.7563788294792175
         ],
         "y": [
          0.3532443344593048,
          0.3588726818561554
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23535463213920593,
          -0.24323949217796326
         ],
         "y": [
          0.8846201300621033,
          0.8868193626403809
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8245046734809875,
          -0.8118688464164734
         ],
         "y": [
          0.1130216047167778,
          0.11250966787338257
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8118688464164734,
          -0.8049237132072449
         ],
         "y": [
          0.11250966787338257,
          0.117892324924469
         ]
        }
       ],
       "layout": {
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Comments Graph"
        },
        "xaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter trace for nodes with assigned positions\n",
    "for node, position in pos.items():\n",
    "    x, y = position  # Get the position of the node\n",
    "    color = G.nodes[node]['color']  # Get the color attribute of the node\n",
    "    hover = G.nodes[node]['hover']\n",
    "    fig.add_trace(go.Scatter(x=[x], y=[y], marker=dict(size=10,color=color), hovertext=hover,name=f'CommentID {node}',))\n",
    "\n",
    "for edge in G.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    fig.add_trace(go.Scatter(x=[x0, x1], y=[y0, y1], mode='lines', line=dict(width=1), name='Edge'))\n",
    "\n",
    "# Update the layout of the figure\n",
    "fig.update_layout(showlegend=False, title='Comments Graph')\n",
    "\n",
    "fig.update_layout(xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                  yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n",
    "fig.write_html('graph_coms.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m edge_y \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m edge \u001b[39min\u001b[39;00m G\u001b[39m.\u001b[39medges():\n\u001b[1;32m----> 4\u001b[0m     x0, y0 \u001b[39m=\u001b[39m G\u001b[39m.\u001b[39;49mnodes[edge[\u001b[39m0\u001b[39;49m]][\u001b[39m'\u001b[39;49m\u001b[39mpos\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      5\u001b[0m     x1, y1 \u001b[39m=\u001b[39m G\u001b[39m.\u001b[39mnodes[edge[\u001b[39m1\u001b[39m]][\u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m     edge_x\u001b[39m.\u001b[39mappend(x0)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pos'"
     ]
    }
   ],
   "source": [
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in G.edges():\n",
    "    x0, y0 = G.nodes[edge[0]]['pos']\n",
    "    x1, y1 = G.nodes[edge[1]]['pos']\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in G.nodes():\n",
    "    x, y = G.nodes[node]['pos']\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        # colorscale options\n",
    "        #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "        #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "        #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'node_trace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     node_adjacencies\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(adjacencies[\u001b[39m1\u001b[39m]))\n\u001b[0;32m      5\u001b[0m     node_text\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m# of connections: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(adjacencies[\u001b[39m1\u001b[39m])))\n\u001b[1;32m----> 7\u001b[0m node_trace\u001b[39m.\u001b[39mmarker\u001b[39m.\u001b[39mcolor \u001b[39m=\u001b[39m node_adjacencies\n\u001b[0;32m      8\u001b[0m node_trace\u001b[39m.\u001b[39mtext \u001b[39m=\u001b[39m node_text\n",
      "\u001b[1;31mNameError\u001b[0m: name 'node_trace' is not defined"
     ]
    }
   ],
   "source": [
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(G.adjacency()):\n",
    "    node_adjacencies.append(len(adjacencies[1]))\n",
    "    node_text.append('# of connections: '+str(len(adjacencies[1])))\n",
    "\n",
    "node_trace.marker.color = node_adjacencies\n",
    "node_trace.text = node_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 16\u001b[0m\n\u001b[0;32m      1\u001b[0m fig \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mFigure(data\u001b[39m=\u001b[39m[edge_trace, node_trace],\n\u001b[0;32m      2\u001b[0m              layout\u001b[39m=\u001b[39mgo\u001b[39m.\u001b[39mLayout(\n\u001b[0;32m      3\u001b[0m                 title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m<br>Network graph made with Python\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 yaxis\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(showgrid\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, zeroline\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, showticklabels\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m     15\u001b[0m                 )\n\u001b[1;32m---> 16\u001b[0m fig\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\plotly\\basedatatypes.py:3409\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3376\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3377\u001b[0m \u001b[39mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[0;32m   3378\u001b[0m \u001b[39mspecified by the renderer argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3405\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3406\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3407\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[1;32m-> 3409\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39;49mshow(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\plotly\\io\\_renderers.py:396\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    393\u001b[0m         )\n\u001b[0;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nbformat \u001b[39mor\u001b[39;00m Version(nbformat\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 396\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    397\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m         )\n\u001b[0;32m    400\u001b[0m     ipython_display\u001b[39m.\u001b[39mdisplay(bundle, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    402\u001b[0m \u001b[39m# external renderers\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                title='<br>Network graph made with Python',\n",
    "                titlefont_size=16,\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                annotations=[ dict(\n",
    "                    text=\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\n",
    "                    showarrow=False,\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.005, y=-0.002 ) ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
