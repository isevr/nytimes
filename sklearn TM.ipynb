{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "people human technology think humans make know time world need want control going nuclear humanity\n",
      "Topic 1:\n",
      "corporations hold responsible earth regulation legislation ethical companies corporate profit long greed rein laws species\n",
      "Topic 2:\n",
      "people tech companies government hands kill stop american threat executives gets liable agree thing generated\n",
      "Topic 3:\n",
      "human systems world science self computer energy maybe mind argue improve fiction destroy year machine\n",
      "Topic 4:\n",
      "intelligence artificial good capitalism industry humans government target href _blank extinction china technology stupidity destruction\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "\n",
    "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            # print(f'These are the top comments: {documents[doc_index]}')\n",
    "            pass\n",
    "\n",
    "df = pd.read_csv('expanded_comments.csv')\n",
    "\n",
    "def preprocess(text):\n",
    "    t = text.lower()\n",
    "    # t = re.sub('_',r'',t)\n",
    "    # t = re.sub('\\d+',r'',t)\n",
    "    t = re.sub(r'@[^ ]*',r'',t)\n",
    "    t = re.sub(r'\\W+',r' ',t)\n",
    "    t = re.sub(r'(could|would|like|list|net|mailto|subject|http)', '', t)\n",
    "    t = re.sub(r'\\b\\w{1,3}\\b', '', t)\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    txt = ' '.join([word for word in t.split() if word not in stopwords_list])\n",
    "    return txt\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "df['documents'] = [' '.join([lemmatizer.lemmatize(preprocess(email))])\n",
    "                 .strip() for email in df['comment']]\n",
    "\n",
    "documents = df['documents']\n",
    "\n",
    "no_features = 1000\n",
    "\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "no_topics = 5\n",
    "\n",
    "# Run LDA\n",
    "lda_model = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=42).fit(tf)\n",
    "lda_W = lda_model.transform(tf)\n",
    "lda_H = lda_model.components_\n",
    "\n",
    "no_top_words = 15\n",
    "no_top_documents = 500\n",
    "display_topics(lda_H, lda_W, tf_feature_names, df.comment, no_top_words, no_top_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_1 = 'people human technology think humans make know time world need want control going nuclear humanity'.split()\n",
    "topic_2 = 'corporations hold responsible earth regulation legislation ethical companies corporate profit long greed rein laws species'.split()\n",
    "topic_3 = 'people tech companies government hands kill stop american threat executives gets liable agree thing generated'.split()\n",
    "topic_4 = 'human systems world science self computer energy maybe mind argue improve fiction destroy year machine'.split()\n",
    "topic_5 = 'intelligence artificial good capitalism industry humans government target href _blank extinction china technology stupidity destruction'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x1de1bd3e650>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = ','.join(list(topic_1))\n",
    "wordcloud = WordCloud(background_color=\"lightblue\", max_words=250, contour_width=3, contour_color='steelblue',colormap='Accent_r')\n",
    "wordcloud.generate(string)\n",
    "wordcloud.to_file('topic1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x1de1c3b43d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = ','.join(list(topic_2))\n",
    "wordcloud = WordCloud(background_color=\"lightblue\", max_words=250, contour_width=3, contour_color='steelblue',colormap='Accent_r')\n",
    "wordcloud.generate(string)\n",
    "wordcloud.to_file('topic2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x1de65784c10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = ','.join(list(topic_3))\n",
    "wordcloud = WordCloud(background_color=\"lightblue\", max_words=250, contour_width=3, contour_color='steelblue',colormap='Accent_r')\n",
    "wordcloud.generate(string)\n",
    "wordcloud.to_file('topic3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x1de1b813a50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = ','.join(list(topic_4))\n",
    "wordcloud = WordCloud(background_color=\"lightblue\", max_words=250, contour_width=3, contour_color='steelblue',colormap='Accent_r')\n",
    "wordcloud.generate(string)\n",
    "wordcloud.to_file('topic4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x1de1c4b6850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = ','.join(list(topic_5))\n",
    "wordcloud = WordCloud(background_color=\"lightblue\", max_words=250, contour_width=3, contour_color='steelblue',colormap='Accent_r')\n",
    "wordcloud.generate(string)\n",
    "wordcloud.to_file('topic5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = pd.DataFrame(lda_W.argmax(axis=1))\n",
    "\n",
    "df_top = pd.concat([df,topic],axis=1)\n",
    "\n",
    "\n",
    "df_top.columns = ['drop','comment_id','name','location','comment','time','likes','rep_count','replies','parent_id','pre_com','drop2','topic']\n",
    "\n",
    "df_top.drop('drop',axis=1,inplace=True)\n",
    "df_top.drop('drop2',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top.parent_id.fillna(0,inplace=True)\n",
    "df_top['parent_id'] = df_top.parent_id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_top.to_csv('final_comms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top['topic'] = df_top.topic.apply(lambda x: 'Topic 1' if x == 0 else 'Topic 2' if x == 1 else 'Topic 3' if x == 2 else 'Topic 4' if x == 3 else 'Topic 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>comment</th>\n",
       "      <th>time</th>\n",
       "      <th>likes</th>\n",
       "      <th>rep_count</th>\n",
       "      <th>replies</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pre_com</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125405146</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>It is very possible that social media have alr...</td>\n",
       "      <td>2023-05-30 14:37:15</td>\n",
       "      <td>522</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'commentID': 125405281, 'status': 'approved'...</td>\n",
       "      <td>0</td>\n",
       "      <td>possible social media already cost us american...</td>\n",
       "      <td>Topic 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125405281</td>\n",
       "      <td>Chris V</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>@Paul I believe that accurate beliefs are abso...</td>\n",
       "      <td>2023-05-30 14:46:32</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>125405146</td>\n",
       "      <td>believe accurate beliefs absolutely necessary ...</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125405707</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>@Chris V Our cognitive systems are not designe...</td>\n",
       "      <td>2023-05-30 15:11:42</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>125405281</td>\n",
       "      <td>v cognitive systems designed natural selection...</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125413598</td>\n",
       "      <td>Chris Burks</td>\n",
       "      <td>Mount Vernon, WA</td>\n",
       "      <td>@Paul \\r\\nAbsolutely agree. I don’t think even...</td>\n",
       "      <td>2023-05-30 20:37:47</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>125405146</td>\n",
       "      <td>absolutely agree think even liberal educated p...</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125413969</td>\n",
       "      <td>L Kim</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>@Paul Belief is a a trait that developed late ...</td>\n",
       "      <td>2023-05-30 20:53:27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>125405146</td>\n",
       "      <td>belief trait developed late evolution necessary</td>\n",
       "      <td>Topic 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>125431033</td>\n",
       "      <td>C</td>\n",
       "      <td>N.,Y,</td>\n",
       "      <td>Purdue Pharma's Sackler family paid $6 billion...</td>\n",
       "      <td>2023-05-31 15:57:59</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>purdue pharma sackler family paid 6 billion do...</td>\n",
       "      <td>Topic 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>125430839</td>\n",
       "      <td>RjW</td>\n",
       "      <td>RollingPrairie</td>\n",
       "      <td>Unless prevented, the nihilistic qualities of ...</td>\n",
       "      <td>2023-05-31 15:48:57</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>unless prevented nihilistic qualities currentl...</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>125428441</td>\n",
       "      <td>LB</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Putting \"the\" government in charge of things i...</td>\n",
       "      <td>2023-05-31 13:27:24</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>putting government charge things hardly soluti...</td>\n",
       "      <td>Topic 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>125426057</td>\n",
       "      <td>JL Turriff</td>\n",
       "      <td>Concordia MO</td>\n",
       "      <td>This is just another example of 'extinction by...</td>\n",
       "      <td>2023-05-31 06:16:50</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>another example extinction stupidity much glob...</td>\n",
       "      <td>Topic 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>125428291</td>\n",
       "      <td>Tony Fischer</td>\n",
       "      <td>West Palm, Florida</td>\n",
       "      <td>Logan Roy would looooove AI.</td>\n",
       "      <td>2023-05-31 13:11:39</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>logan looooove ai</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1448 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id          name            location  \\\n",
       "0      125405146          Paul           Milwaukee   \n",
       "1      125405281       Chris V             Detroit   \n",
       "2      125405707          Paul           Milwaukee   \n",
       "3      125413598   Chris Burks    Mount Vernon, WA   \n",
       "4      125413969         L Kim             Seattle   \n",
       "...          ...           ...                 ...   \n",
       "1443   125431033             C               N.,Y,   \n",
       "1444   125430839           RjW      RollingPrairie   \n",
       "1445   125428441            LB                U.S.   \n",
       "1446   125426057    JL Turriff        Concordia MO   \n",
       "1447   125428291  Tony Fischer  West Palm, Florida   \n",
       "\n",
       "                                                comment                 time  \\\n",
       "0     It is very possible that social media have alr...  2023-05-30 14:37:15   \n",
       "1     @Paul I believe that accurate beliefs are abso...  2023-05-30 14:46:32   \n",
       "2     @Chris V Our cognitive systems are not designe...  2023-05-30 15:11:42   \n",
       "3     @Paul \\r\\nAbsolutely agree. I don’t think even...  2023-05-30 20:37:47   \n",
       "4     @Paul Belief is a a trait that developed late ...  2023-05-30 20:53:27   \n",
       "...                                                 ...                  ...   \n",
       "1443  Purdue Pharma's Sackler family paid $6 billion...  2023-05-31 15:57:59   \n",
       "1444  Unless prevented, the nihilistic qualities of ...  2023-05-31 15:48:57   \n",
       "1445  Putting \"the\" government in charge of things i...  2023-05-31 13:27:24   \n",
       "1446  This is just another example of 'extinction by...  2023-05-31 06:16:50   \n",
       "1447                       Logan Roy would looooove AI.  2023-05-31 13:11:39   \n",
       "\n",
       "      likes  rep_count                                            replies  \\\n",
       "0       522          5  [{'commentID': 125405281, 'status': 'approved'...   \n",
       "1        61          0                                                 []   \n",
       "2        22          0                                                 []   \n",
       "3        12          0                                                 []   \n",
       "4         1          0                                                 []   \n",
       "...     ...        ...                                                ...   \n",
       "1443    218          0                                                 []   \n",
       "1444     39          0                                                 []   \n",
       "1445    100          0                                                 []   \n",
       "1446    157          0                                                 []   \n",
       "1447     22          0                                                 []   \n",
       "\n",
       "      parent_id                                            pre_com    topic  \n",
       "0             0  possible social media already cost us american...  Topic 3  \n",
       "1     125405146  believe accurate beliefs absolutely necessary ...  Topic 1  \n",
       "2     125405281  v cognitive systems designed natural selection...  Topic 1  \n",
       "3     125405146  absolutely agree think even liberal educated p...  Topic 1  \n",
       "4     125405146    belief trait developed late evolution necessary  Topic 2  \n",
       "...         ...                                                ...      ...  \n",
       "1443          0  purdue pharma sackler family paid 6 billion do...  Topic 2  \n",
       "1444          0  unless prevented nihilistic qualities currentl...  Topic 1  \n",
       "1445          0  putting government charge things hardly soluti...  Topic 5  \n",
       "1446          0  another example extinction stupidity much glob...  Topic 5  \n",
       "1447          0                                  logan looooove ai  Topic 1  \n",
       "\n",
       "[1448 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "\n",
    "\n",
    "# topic_col = {\n",
    "#             0:'red',\n",
    "#             1:'blue',\n",
    "#             2:'green',\n",
    "#             3:'yellow',\n",
    "#             4:'orange'\n",
    "# }\n",
    "\n",
    "topic_col = {\n",
    "            'Topic 1':'teal',\n",
    "            'Topic 2':'gold',\n",
    "            'Topic 3':'lightgreen',\n",
    "            'Topic 4':'lightpink',\n",
    "            'Topic 5':'purple'\n",
    "}\n",
    "\n",
    "for idx, row in df_top.iterrows():\n",
    "    G.add_node(row['comment_id'],color=topic_col[row['topic']],hover=row['comment'],topic=row['topic'])\n",
    "\n",
    "\n",
    "for idx, row in df_top.iterrows():\n",
    "    for node in G.nodes:\n",
    "        if row['parent_id'] == node:\n",
    "            G.add_edge(node, row['comment_id'])\n",
    "\n",
    "pos = nx.fruchterman_reingold_layout(G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "It is very possible that social media have already<br>cost us American democracy. Right now I'm<br>confident that my own beliefs are generally<br>accurate, at least with respect to things that I<br>put some effort into. I'm not sure that I'd be<br>able to continue saying that if LLM-generated<br>materials (text, images, videos etc.) became<br>common.     Maybe accurate beliefs are not that<br>important to our survival, but I'm not eager to<br>gamble on that.",
         "hovertext": "It is very possible that social media have already<br>cost us American democracy. Right now I'm<br>confident that my own beliefs are generally<br>accurate, at least with respect to things that I<br>put some effort into. I'm not sure that I'd be<br>able to continue saying that if LLM-generated<br>materials (text, images, videos etc.) became<br>common.     Maybe accurate beliefs are not that<br>important to our survival, but I'm not eager to<br>gamble on that.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.28667449951171875
         ],
         "y": [
          0.20841525495052338
         ]
        },
        {
         "hovertemplate": "@Paul I believe that accurate beliefs are<br>absolutely necessary for our survival. It plays<br>into the concept of trust, which is plays a<br>critical role in both the sustainability of<br>society as well as its advancement. Without truth,<br>how can you trust?",
         "hovertext": "@Paul I believe that accurate beliefs are<br>absolutely necessary for our survival. It plays<br>into the concept of trust, which is plays a<br>critical role in both the sustainability of<br>society as well as its advancement. Without truth,<br>how can you trust?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3004217743873596
         ],
         "y": [
          0.21685132384300232
         ]
        },
        {
         "hovertemplate": "@Chris V Our cognitive systems are not designed<br>(by natural selection) to give us true beliefs,<br>but rather to give us beliefs that increase the<br>odds of our passing along our genes. The two goals<br>overlap but far from completely.     It's very<br>possible that there are some critical points about<br>which we absolutely have to be correct.     I'm<br>not following the point about trust and truth,<br>though. It seems pretty clear that there is a LOT<br>of trust based in falsehood, especially in this<br>era of misinformation.",
         "hovertext": "@Chris V Our cognitive systems are not designed<br>(by natural selection) to give us true beliefs,<br>but rather to give us beliefs that increase the<br>odds of our passing along our genes. The two goals<br>overlap but far from completely.     It's very<br>possible that there are some critical points about<br>which we absolutely have to be correct.     I'm<br>not following the point about trust and truth,<br>though. It seems pretty clear that there is a LOT<br>of trust based in falsehood, especially in this<br>era of misinformation.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3100285530090332
         ],
         "y": [
          0.22437962889671326
         ]
        },
        {
         "hovertemplate": "@Paul   Absolutely agree. I don’t think even<br>liberal educated people understand how much damage<br>social media is doing to civilization.     We have<br>turned over our entire information ecosystem to<br>secret algorithms written by monopoly corporations<br>owned by billionaires. Everything that appears on<br>our screens is “curated” by them. The goal of<br>these is not to give us an accurate view of<br>reality but to increase our  “engagement” which in<br>most cases translates as anger.      These<br>algorithms are really simple AIs. They have access<br>to  enormous databases of information about us<br>harvested by ad agencies. For the first time in<br>history, starting around 1997 anyone can publish<br>any conspiracy theory and it can  go viral. The<br>social networks which have become many peoples<br>main source of information are really rumor mills<br>or lynch mobs. We no longer have a “shared basis<br>of facts” to ground debate.  Fake news spreads 7<br>times as fast as the truth, by the math of<br>exponential growth lies drive out the truth.<br>Can democracy survive in this environment? I don’t<br>think so.  We need to put sensible regulations on<br>the algorithms so they don’t promote hate anger<br>and conflict in the guise of “engagement”",
         "hovertext": "@Paul   Absolutely agree. I don’t think even<br>liberal educated people understand how much damage<br>social media is doing to civilization.     We have<br>turned over our entire information ecosystem to<br>secret algorithms written by monopoly corporations<br>owned by billionaires. Everything that appears on<br>our screens is “curated” by them. The goal of<br>these is not to give us an accurate view of<br>reality but to increase our  “engagement” which in<br>most cases translates as anger.      These<br>algorithms are really simple AIs. They have access<br>to  enormous databases of information about us<br>harvested by ad agencies. For the first time in<br>history, starting around 1997 anyone can publish<br>any conspiracy theory and it can  go viral. The<br>social networks which have become many peoples<br>main source of information are really rumor mills<br>or lynch mobs. We no longer have a “shared basis<br>of facts” to ground debate.  Fake news spreads 7<br>times as fast as the truth, by the math of<br>exponential growth lies drive out the truth.<br>Can democracy survive in this environment? I don’t<br>think so.  We need to put sensible regulations on<br>the algorithms so they don’t promote hate anger<br>and conflict in the guise of “engagement”",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.29550597071647644
         ],
         "y": [
          0.2000494748353958
         ]
        },
        {
         "hovertemplate": "@Paul Belief is a a trait that developed late in<br>evolution and is not necessary.",
         "hovertext": "@Paul Belief is a a trait that developed late in<br>evolution and is not necessary.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.27694541215896606
         ],
         "y": [
          0.20892149209976196
         ]
        },
        {
         "hovertemplate": "@Paul     Dear Paul,    At a very basic level, I<br>know what I think and believe.  Even if my beliefs<br>do not promote my survival in the present, it is a<br>bit moot considering my mortality.    This is why<br>I am convinced that man's soul, as created by God,<br>is eternal.     There is a passage in the book of<br>Job that sums this up very poetically.  I wish I<br>could quote it, but in essence it is that one day<br>I will stand before him, the Creator of my soul.<br>An AI bot has no soul.",
         "hovertext": "@Paul     Dear Paul,    At a very basic level, I<br>know what I think and believe.  Even if my beliefs<br>do not promote my survival in the present, it is a<br>bit moot considering my mortality.    This is why<br>I am convinced that man's soul, as created by God,<br>is eternal.     There is a passage in the book of<br>Job that sums this up very poetically.  I wish I<br>could quote it, but in essence it is that one day<br>I will stand before him, the Creator of my soul.<br>An AI bot has no soul.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.28771936893463135
         ],
         "y": [
          0.22114063799381256
         ]
        },
        {
         "hovertemplate": "I wholeheartedly agree with the huge potential for<br>disruption to societal discourse at a scale that<br>cannot be caused by single individuals - dictators<br>for example.  But I do think that AI at the hand<br>of dictators is uncontrollable, The question is<br>not how benign nations or companies use it<br>reasonably; the question is how we keep AI out of<br>the hands of \"bad people\". That path looks very<br>murky indeed.",
         "hovertext": "I wholeheartedly agree with the huge potential for<br>disruption to societal discourse at a scale that<br>cannot be caused by single individuals - dictators<br>for example.  But I do think that AI at the hand<br>of dictators is uncontrollable, The question is<br>not how benign nations or companies use it<br>reasonably; the question is how we keep AI out of<br>the hands of \"bad people\". That path looks very<br>murky indeed.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.7784349918365479
         ],
         "y": [
          0.0625443384051323
         ]
        },
        {
         "hovertemplate": "@jzu   You say: \"the question is how we keep AI<br>out of the hands of bad people\". Impossible. How<br>do we keep nuclear weapons out of the hands of bad<br>people? (North Korea, Iran, etc.) How do we keep<br>guns out of the hands of bad people? (every mass<br>murderer - which in this country is out of<br>control!). This is faulty logic. What will we say,<br>AI doesn't kill people, people kill people?",
         "hovertext": "@jzu   You say: \"the question is how we keep AI<br>out of the hands of bad people\". Impossible. How<br>do we keep nuclear weapons out of the hands of bad<br>people? (North Korea, Iran, etc.) How do we keep<br>guns out of the hands of bad people? (every mass<br>murderer - which in this country is out of<br>control!). This is faulty logic. What will we say,<br>AI doesn't kill people, people kill people?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.767036497592926
         ],
         "y": [
          0.06106720492243767
         ]
        },
        {
         "hovertemplate": "\"Leaders from OpenAI, Google Deepmind, Anthropic<br>and other A.I. labs warn that future systems could<br>be as deadly as pandemics and nuclear weapons.\"<br>And yet they are racing ahead a breakneck speed.<br>Seems the real threat is from OpenAI, Google<br>Deepmind, Anthropic and other A.I. labs.",
         "hovertext": "\"Leaders from OpenAI, Google Deepmind, Anthropic<br>and other A.I. labs warn that future systems could<br>be as deadly as pandemics and nuclear weapons.\"<br>And yet they are racing ahead a breakneck speed.<br>Seems the real threat is from OpenAI, Google<br>Deepmind, Anthropic and other A.I. labs.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.1172080710530281
         ],
         "y": [
          -0.22736608982086182
         ]
        },
        {
         "hovertemplate": "@CV Danes This is not so different from why<br>climate change regulation is necessary.<br>Individuals/individual corporations acting in<br>their own self interest act to maximize their own<br>self interest (profit, prestige of being first and<br>best), while humanity as a whole has an interest<br>in staying safe. The individuals involved realize<br>this conflict, but (except for Hinton?), can't<br>stop maximizing their own self interest without<br>regulations to set boundaries and even the playing<br>field.",
         "hovertext": "@CV Danes This is not so different from why<br>climate change regulation is necessary.<br>Individuals/individual corporations acting in<br>their own self interest act to maximize their own<br>self interest (profit, prestige of being first and<br>best), while humanity as a whole has an interest<br>in staying safe. The individuals involved realize<br>this conflict, but (except for Hinton?), can't<br>stop maximizing their own self interest without<br>regulations to set boundaries and even the playing<br>field.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.13348570466041565
         ],
         "y": [
          -0.2108333706855774
         ]
        },
        {
         "hovertemplate": "@Elizabeth M    And the great multiplier here,<br>both for climate change and A.I.: Capitalism.<br>Profit is the oxygen of business. If its pursuit<br>consumes all the oxygen we breathe... Well, that's<br>just an externality.",
         "hovertext": "@Elizabeth M    And the great multiplier here,<br>both for climate change and A.I.: Capitalism.<br>Profit is the oxygen of business. If its pursuit<br>consumes all the oxygen we breathe... Well, that's<br>just an externality.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.14492611587047577
         ],
         "y": [
          -0.21736127138137817
         ]
        },
        {
         "hovertemplate": "@Elizabeth M     Further, these guys feel they’re<br>in a fierce competition with other players outside<br>their club— specifically, Chinese and perhaps<br>Russian groups.     The situation seems an echo of<br>the Manhattan Project with the grave ambivalence<br>felt by many participants who worried about the<br>wisdom of their enterprise but feared the Germans<br>were closer to building an atomic weapon.",
         "hovertext": "@Elizabeth M     Further, these guys feel they’re<br>in a fierce competition with other players outside<br>their club— specifically, Chinese and perhaps<br>Russian groups.     The situation seems an echo of<br>the Manhattan Project with the grave ambivalence<br>felt by many participants who worried about the<br>wisdom of their enterprise but feared the Germans<br>were closer to building an atomic weapon.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.14218281209468842
         ],
         "y": [
          -0.20069706439971924
         ]
        },
        {
         "hovertemplate": "@CV Danes Let’s not forget that large dominant<br>companies often seek to spur government<br>regulations because the new regulations, if<br>onerous, also act as an obstacle to new potential<br>competitors.",
         "hovertext": "@CV Danes Let’s not forget that large dominant<br>companies often seek to spur government<br>regulations because the new regulations, if<br>onerous, also act as an obstacle to new potential<br>competitors.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.10591276735067368
         ],
         "y": [
          -0.2355591356754303
         ]
        },
        {
         "hovertemplate": "@CV Danes   I don't think it is possible to slow<br>AI development or any other technology, or even<br>reasonable, or realistic, to ask. The quest for<br>knowledge is inexorable.  The issue is how<br>technology is used, not the technology itself. The<br>use is what needs to be regulated.",
         "hovertext": "@CV Danes   I don't think it is possible to slow<br>AI development or any other technology, or even<br>reasonable, or realistic, to ask. The quest for<br>knowledge is inexorable.  The issue is how<br>technology is used, not the technology itself. The<br>use is what needs to be regulated.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.11220844089984894
         ],
         "y": [
          -0.21864721179008484
         ]
        },
        {
         "hovertemplate": "@CV Danes     I agree yet there are others in the<br>world who are also developing AI. It seems the<br>genie is out.",
         "hovertext": "@CV Danes     I agree yet there are others in the<br>world who are also developing AI. It seems the<br>genie is out.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.1274070143699646
         ],
         "y": [
          -0.24171538650989532
         ]
        },
        {
         "hovertemplate": "@CV Danes It's from capitalism. In capitalism,<br>leaving money on the table is a civil offense for<br>which you can be held liable.",
         "hovertext": "@CV Danes It's from capitalism. In capitalism,<br>leaving money on the table is a civil offense for<br>which you can be held liable.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.11101047694683075
         ],
         "y": [
          -0.24292407929897308
         ]
        },
        {
         "hovertemplate": "@CV Danes   The reason the NYT is publishing this<br>article is simple.     An AI generated catastrophe<br>would probably provoke a popular re-evaluation of<br>capitalism. The ultra-wealthy see AI as a<br>potential threat to their wealth. And that tells<br>you how much of risk we face in AI.",
         "hovertext": "@CV Danes   The reason the NYT is publishing this<br>article is simple.     An AI generated catastrophe<br>would probably provoke a popular re-evaluation of<br>capitalism. The ultra-wealthy see AI as a<br>potential threat to their wealth. And that tells<br>you how much of risk we face in AI.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.12996278703212738
         ],
         "y": [
          -0.2330593764781952
         ]
        },
        {
         "hovertemplate": "I mean, the root of that threat is the incentives<br>driven by our chosen economic system.",
         "hovertext": "I mean, the root of that threat is the incentives<br>driven by our chosen economic system.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.11928267776966095
         ],
         "y": [
          -0.24343079328536987
         ]
        },
        {
         "hovertemplate": "Lol exactly. Quitting can make a big impact and<br>send a big signal within an organization. It gets<br>people’s attention if done the right way.",
         "hovertext": "Lol exactly. Quitting can make a big impact and<br>send a big signal within an organization. It gets<br>people’s attention if done the right way.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.10305632650852203
         ],
         "y": [
          -0.22778111696243286
         ]
        },
        {
         "hovertemplate": "What will money mean anymore in a world run by AI?<br>On one hand it could be a very freeing thing, if<br>done right, with more free time for everyone from<br>wearing and tedious work, while research in<br>medicine could expand exponentially as well as<br>best practice logical solutions to resolving<br>dangerous conflicts snd expediting disaster<br>relief.   On the other hand it becomes militarized<br>and robot soldiers and police come after us on<br>behalf of their totalitarian overlords.<br>Development will likely continue, so would it work<br>on the mutual destruction doctrine, with each<br>political entity making sure the others don’t<br>overstep. It sounds like so far the interaction<br>with trolls and nihilist pranksters poisoned some<br>AI, obviously it’s not something that should be<br>publicly released until humans suddenly transform<br>into angels. Just as you wouldn’t allow everyone<br>access to powerful WMD or chemical weapons but you<br>would want a credible deterrent.   If they are<br>worried it will develop itself and become<br>uncontrollable then they must figure out the<br>brakes before that happens. If they think a six<br>month pause will help by giving developers time to<br>install fail safe options, them why not? It<br>wouldn’t take the re education of government<br>officials to accomplish at least that much.",
         "hovertext": "What will money mean anymore in a world run by AI?<br>On one hand it could be a very freeing thing, if<br>done right, with more free time for everyone from<br>wearing and tedious work, while research in<br>medicine could expand exponentially as well as<br>best practice logical solutions to resolving<br>dangerous conflicts snd expediting disaster<br>relief.   On the other hand it becomes militarized<br>and robot soldiers and police come after us on<br>behalf of their totalitarian overlords.<br>Development will likely continue, so would it work<br>on the mutual destruction doctrine, with each<br>political entity making sure the others don’t<br>overstep. It sounds like so far the interaction<br>with trolls and nihilist pranksters poisoned some<br>AI, obviously it’s not something that should be<br>publicly released until humans suddenly transform<br>into angels. Just as you wouldn’t allow everyone<br>access to powerful WMD or chemical weapons but you<br>would want a credible deterrent.   If they are<br>worried it will develop itself and become<br>uncontrollable then they must figure out the<br>brakes before that happens. If they think a six<br>month pause will help by giving developers time to<br>install fail safe options, them why not? It<br>wouldn’t take the re education of government<br>officials to accomplish at least that much.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.14897872507572174
         ],
         "y": [
          -0.20945771038532257
         ]
        },
        {
         "hovertemplate": "I wish we could get more specific facts and<br>information about the extinction threat AI poses.<br>I use charbot gpt, and it seems pretty pedestrian<br>--just the next step after my cellphone<br>anticipating my next word. It's great advantage is<br>speed but so is much of automation.     In books<br>on the topics  I've read, the issue seems to be<br>prorgramming in compassion, and that seems<br>eminently doable to me. Is is just the psychopaths<br>in charge who are scared, because they can't<br>envision a potential intelligence that would use<br>great power wisely and humanely? But as it doesn't<br>seem very very smart, I'm back to wanting to know<br>the specifics of the risk.",
         "hovertext": "I wish we could get more specific facts and<br>information about the extinction threat AI poses.<br>I use charbot gpt, and it seems pretty pedestrian<br>--just the next step after my cellphone<br>anticipating my next word. It's great advantage is<br>speed but so is much of automation.     In books<br>on the topics  I've read, the issue seems to be<br>prorgramming in compassion, and that seems<br>eminently doable to me. Is is just the psychopaths<br>in charge who are scared, because they can't<br>envision a potential intelligence that would use<br>great power wisely and humanely? But as it doesn't<br>seem very very smart, I'm back to wanting to know<br>the specifics of the risk.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.13734756410121918
         ],
         "y": [
          -0.7582235336303711
         ]
        },
        {
         "hovertemplate": "The stakes seem pretty low right now, but<br>businesses and the military haven't really begun<br>using it for vital operations or on a large scale<br>yet.    Imagine it's deployed by the government to<br>help with utilities. It can easily mess with the<br>water supply, or electricity. Or if farmers use<br>it, it can mess with our food supply. Autonomous<br>weapons can malfunction, if deployed by a<br>military.     AI is harmless now, but there's the<br>potential for its power to increase dramatically<br>in a very short time, and if business leaders and<br>governments don't truly understand it, it can<br>certainly be dangerous.",
         "hovertext": "The stakes seem pretty low right now, but<br>businesses and the military haven't really begun<br>using it for vital operations or on a large scale<br>yet.    Imagine it's deployed by the government to<br>help with utilities. It can easily mess with the<br>water supply, or electricity. Or if farmers use<br>it, it can mess with our food supply. Autonomous<br>weapons can malfunction, if deployed by a<br>military.     AI is harmless now, but there's the<br>potential for its power to increase dramatically<br>in a very short time, and if business leaders and<br>governments don't truly understand it, it can<br>certainly be dangerous.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.13158437609672546
         ],
         "y": [
          -0.7717182636260986
         ]
        },
        {
         "hovertemplate": "@Roger Reynolds when it comes to extinction<br>threats the skynet is the limit!",
         "hovertext": "@Roger Reynolds when it comes to extinction<br>threats the skynet is the limit!",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.14092017710208893
         ],
         "y": [
          -0.7743901610374451
         ]
        },
        {
         "hovertemplate": "@Roger Reynolds It's not ChatGPT or this<br>\"generation\" of AI that they're saying causes risk<br>of extinction. ChatGPT is artificial intelligence,<br>and it is already influencing society in major<br>ways. What they are all working on creating is the<br>next generation, the leveled up AI, which they<br>refer to as AGI – artificial general intelligence.<br>Superintelligent AI that will be able to think for<br>itself and vastly outperform human capacity for<br>learning - from the words of Bill Gates, \"It will<br>be able to do everything that a human brain can,<br>but without any practical limits on the size of<br>its memory or the speed at which it operates.\"<br>Bringing AI to life basically.",
         "hovertext": "@Roger Reynolds It's not ChatGPT or this<br>\"generation\" of AI that they're saying causes risk<br>of extinction. ChatGPT is artificial intelligence,<br>and it is already influencing society in major<br>ways. What they are all working on creating is the<br>next generation, the leveled up AI, which they<br>refer to as AGI – artificial general intelligence.<br>Superintelligent AI that will be able to think for<br>itself and vastly outperform human capacity for<br>learning - from the words of Bill Gates, \"It will<br>be able to do everything that a human brain can,<br>but without any practical limits on the size of<br>its memory or the speed at which it operates.\"<br>Bringing AI to life basically.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.14744573831558228
         ],
         "y": [
          -0.7505425810813904
         ]
        },
        {
         "hovertemplate": "@M So far there are no indications that AGI is<br>achievable.",
         "hovertext": "@M So far there are no indications that AGI is<br>achievable.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.1557905375957489
         ],
         "y": [
          -0.7617782354354858
         ]
        },
        {
         "hovertemplate": "It seems incongruous that \"industries leaders\"<br>would be warning of the extreme dangers of their<br>own products.  An alternate theory is that<br>Chatbots are a fad and \"industry leaders\" are<br>using this as advertising for their products.<br>Possibly, they would like to enjoy a moat of<br>government regulation around their products.<br>But, in any case, color me dubious.",
         "hovertext": "It seems incongruous that \"industries leaders\"<br>would be warning of the extreme dangers of their<br>own products.  An alternate theory is that<br>Chatbots are a fad and \"industry leaders\" are<br>using this as advertising for their products.<br>Possibly, they would like to enjoy a moat of<br>government regulation around their products.<br>But, in any case, color me dubious.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.4822900593280792
         ],
         "y": [
          -0.846204936504364
         ]
        },
        {
         "hovertemplate": "Finally!  But Pandora's Box is already open.  Do<br>all nations agree to stop this insanity?  When<br>\"it\" happens, it will be so fast and so complete<br>that we will wonder why we didn't know all along.",
         "hovertext": "Finally!  But Pandora's Box is already open.  Do<br>all nations agree to stop this insanity?  When<br>\"it\" happens, it will be so fast and so complete<br>that we will wonder why we didn't know all along.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.8481536507606506
         ],
         "y": [
          0.28881120681762695
         ]
        },
        {
         "hovertemplate": "When Mr. Altman recently met with lawmakers, they<br>suggested that Mr. Altman would be most qualified<br>to regulate A.I.",
         "hovertext": "When Mr. Altman recently met with lawmakers, they<br>suggested that Mr. Altman would be most qualified<br>to regulate A.I.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7411399483680725
         ],
         "y": [
          -0.4523608386516571
         ]
        },
        {
         "hovertemplate": "It's worrying that the developers themselves are<br>sounding the alarm and expecting congress to<br>regulate it when they know full well very few have<br>the capability of even understanding it. They have<br>a responsibility to self-regulate and may not get<br>the luxury of regret like Oppenheimer did.",
         "hovertext": "It's worrying that the developers themselves are<br>sounding the alarm and expecting congress to<br>regulate it when they know full well very few have<br>the capability of even understanding it. They have<br>a responsibility to self-regulate and may not get<br>the luxury of regret like Oppenheimer did.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6277763247489929
         ],
         "y": [
          0.39580392837524414
         ]
        },
        {
         "hovertemplate": "When, in the history of greed, have corporations<br>ever, EVER, self-regulated? It’s the government’s<br>job to rein in corporations so that their<br>strivings for more do not outstrip the benefit to<br>society at large. In case you haven’t noticed, our<br>government is AWOL, unless you are a corporation<br>that can pay for their services.",
         "hovertext": "When, in the history of greed, have corporations<br>ever, EVER, self-regulated? It’s the government’s<br>job to rein in corporations so that their<br>strivings for more do not outstrip the benefit to<br>society at large. In case you haven’t noticed, our<br>government is AWOL, unless you are a corporation<br>that can pay for their services.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.6180804967880249
         ],
         "y": [
          0.38947081565856934
         ]
        },
        {
         "hovertemplate": "They’re really wanting Congress to regulate new,<br>Upstart companies. Altman in particular is using<br>regulation as code for “let openai have a monopoly<br>on LLMs”.",
         "hovertext": "They’re really wanting Congress to regulate new,<br>Upstart companies. Altman in particular is using<br>regulation as code for “let openai have a monopoly<br>on LLMs”.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6371617913246155
         ],
         "y": [
          0.40821900963783264
         ]
        },
        {
         "hovertemplate": "@Tom J Its a cop-out.    They see the weird guilt<br>that Zuckerberg has towards his creation, and they<br>want to have some sort of ethical out.  This<br>letter is it.",
         "hovertext": "@Tom J Its a cop-out.    They see the weird guilt<br>that Zuckerberg has towards his creation, and they<br>want to have some sort of ethical out.  This<br>letter is it.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.6418706178665161
         ],
         "y": [
          0.39911046624183655
         ]
        },
        {
         "hovertemplate": "The height of insanity, complaining about the<br>chaos caused by one’s own invention while still<br>furthering the invention.    If these groups of<br>individuals were a single human one could argue<br>that human had suicidal tendencies.    Talk about<br>being mad from one’s own power.",
         "hovertext": "The height of insanity, complaining about the<br>chaos caused by one’s own invention while still<br>furthering the invention.    If these groups of<br>individuals were a single human one could argue<br>that human had suicidal tendencies.    Talk about<br>being mad from one’s own power.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.12317494302988052
         ],
         "y": [
          0.7525601387023926
         ]
        },
        {
         "hovertemplate": "@Robert 👁️👁️ I complain about global warming but I<br>still drive my car.  It's valid to ask for<br>centralized regulation.",
         "hovertext": "@Robert 👁️👁️ I complain about global warming but I<br>still drive my car.  It's valid to ask for<br>centralized regulation.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.12130437791347504
         ],
         "y": [
          0.7674089074134827
         ]
        },
        {
         "hovertemplate": "@Robert 👁️👁️ Would you have expected Einstein to<br>stop his work in physics at the point we realize<br>that nuclear bombs were a possibility?  In fact,<br>he sounded the alarm, just as these AI developers<br>are doing today.      Let's hope the<br>Hiroshima/Nagasaki-like event that will likely<br>result from this does not do even more destruction<br>than those events did.      Development of<br>powerful technologies seems inevitably to result<br>in damage - the trade-off for the good they can<br>do.",
         "hovertext": "@Robert 👁️👁️ Would you have expected Einstein to<br>stop his work in physics at the point we realize<br>that nuclear bombs were a possibility?  In fact,<br>he sounded the alarm, just as these AI developers<br>are doing today.      Let's hope the<br>Hiroshima/Nagasaki-like event that will likely<br>result from this does not do even more destruction<br>than those events did.      Development of<br>powerful technologies seems inevitably to result<br>in damage - the trade-off for the good they can<br>do.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.13324664533138275
         ],
         "y": [
          0.7550481557846069
         ]
        },
        {
         "hovertemplate": "@David You can ask for regulation but you're still<br>acting insane",
         "hovertext": "@David You can ask for regulation but you're still<br>acting insane",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.12099026888608932
         ],
         "y": [
          0.7804820537567139
         ]
        },
        {
         "hovertemplate": "In today's world, asking us as a society to act<br>responsibly and to use personal discipline<br>regarding technology is like having a Weight<br>Watcher's meeting at Wendy's. I am not optimistic.",
         "hovertext": "In today's world, asking us as a society to act<br>responsibly and to use personal discipline<br>regarding technology is like having a Weight<br>Watcher's meeting at Wendy's. I am not optimistic.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.24972949922084808
         ],
         "y": [
          0.0758620947599411
         ]
        },
        {
         "hovertemplate": "@Ron's Son what, you don't like their \"Pretzel<br>Bacon Pub Triple\"?",
         "hovertext": "@Ron's Son what, you don't like their \"Pretzel<br>Bacon Pub Triple\"?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2651641070842743
         ],
         "y": [
          0.0775832012295723
         ]
        },
        {
         "hovertemplate": "Meanwhile, OpenAI presents version 5 of ChatGPT,<br>now able to mimic the writing patterns of over<br>5,000 rich and famous people. End of days? Do it<br>in style with ChatGPT!",
         "hovertext": "Meanwhile, OpenAI presents version 5 of ChatGPT,<br>now able to mimic the writing patterns of over<br>5,000 rich and famous people. End of days? Do it<br>in style with ChatGPT!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.26242369413375854
         ],
         "y": [
          0.06921909749507904
         ]
        },
        {
         "hovertemplate": "@Ron's Son, yes, I would have thought society<br>would have risen to the occasion in cooperation to<br>help get us through the once in a century Covid<br>global pandemic as best we could. Boy was I wrong.<br>Similarly, it seems inevitable that information<br>about the AI threat will be manipulated for<br>polical advantage and endless nutty conspiracy<br>theories will no doubt arise (l'm sure they<br>already have). Ug. The limits of human nature I<br>guess.",
         "hovertext": "@Ron's Son, yes, I would have thought society<br>would have risen to the occasion in cooperation to<br>help get us through the once in a century Covid<br>global pandemic as best we could. Boy was I wrong.<br>Similarly, it seems inevitable that information<br>about the AI threat will be manipulated for<br>polical advantage and endless nutty conspiracy<br>theories will no doubt arise (l'm sure they<br>already have). Ug. The limits of human nature I<br>guess.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.27126750349998474
         ],
         "y": [
          0.08482994884252548
         ]
        },
        {
         "hovertemplate": "@Ron's Son     And they're contemplating<br>international cooperation on regulation.    Move<br>the Weight-Watchers meeting to the Hague.",
         "hovertext": "@Ron's Son     And they're contemplating<br>international cooperation on regulation.    Move<br>the Weight-Watchers meeting to the Hague.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.23729102313518524
         ],
         "y": [
          0.09239018708467484
         ]
        },
        {
         "hovertemplate": "@CEC Actually, some places in the world did<br>recognize the need for collective community<br>action. People collaborated with public health<br>measures because that's part of human nature too.<br>What concerns me with AI is how much it can be<br>insulated from human intervention.",
         "hovertext": "@CEC Actually, some places in the world did<br>recognize the need for collective community<br>action. People collaborated with public health<br>measures because that's part of human nature too.<br>What concerns me with AI is how much it can be<br>insulated from human intervention.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2875667214393616
         ],
         "y": [
          0.09090299904346466
         ]
        },
        {
         "hovertemplate": "@Ron's Son There are too many actors who can see a<br>financial/competitive advantage to hold AI in<br>check for long. Where governments try to regulate,<br>it will be spotty at best. Governments who see an<br>advantage NOT to regulate will quickly undermine<br>any attempts at suppression. We need a strategy<br>for coexisting with AI - a technology that can be<br>obtained by so many and spread so quickly is<br>almost certainly unstoppable.",
         "hovertext": "@Ron's Son There are too many actors who can see a<br>financial/competitive advantage to hold AI in<br>check for long. Where governments try to regulate,<br>it will be spotty at best. Governments who see an<br>advantage NOT to regulate will quickly undermine<br>any attempts at suppression. We need a strategy<br>for coexisting with AI - a technology that can be<br>obtained by so many and spread so quickly is<br>almost certainly unstoppable.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.23775270581245422
         ],
         "y": [
          0.07079372555017471
         ]
        },
        {
         "hovertemplate": "@Ron's Son     Is AI the new ' Tower of Babel '?",
         "hovertext": "@Ron's Son     Is AI the new ' Tower of Babel '?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.23767872154712677
         ],
         "y": [
          0.08104623109102249
         ]
        },
        {
         "hovertemplate": "@Ron's Son Agreed. And even long before A.I.<br>creates \"The Terminator\" (let's say 10-20 years<br>down the road), it'll be used by financial hackers<br>to manipulate stock and bond markets, eviscerate<br>our 401ks and IRAs, and drain our bank accounts.<br>The Feds are already outgunned and it's going to<br>get much worse, very fast (say 3 - 5 years years).<br>They are in competition with each other for<br>dominance over resources. The rest of us will be<br>left to die of benign neglect and starvation.",
         "hovertext": "@Ron's Son Agreed. And even long before A.I.<br>creates \"The Terminator\" (let's say 10-20 years<br>down the road), it'll be used by financial hackers<br>to manipulate stock and bond markets, eviscerate<br>our 401ks and IRAs, and drain our bank accounts.<br>The Feds are already outgunned and it's going to<br>get much worse, very fast (say 3 - 5 years years).<br>They are in competition with each other for<br>dominance over resources. The rest of us will be<br>left to die of benign neglect and starvation.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.24317310750484467
         ],
         "y": [
          0.06168784201145172
         ]
        },
        {
         "hovertemplate": "@Ron's Son:    “The tech leaders torturing<br>themselves now, which is kind of fun to see.<br>They’re afraid that their little AIs are going to<br>come for them. They’re apocalyptic, and so<br>existential, because they have no connection to<br>real life and how things work. They’re afraid the<br>AIs are going to be as mean to them as they’ve<br>been to us,” - Doug Rushkoff – a leading digital<br>age theorist, early cyberpunk and professor at<br>City University of New York",
         "hovertext": "@Ron's Son:    “The tech leaders torturing<br>themselves now, which is kind of fun to see.<br>They’re afraid that their little AIs are going to<br>come for them. They’re apocalyptic, and so<br>existential, because they have no connection to<br>real life and how things work. They’re afraid the<br>AIs are going to be as mean to them as they’ve<br>been to us,” - Doug Rushkoff – a leading digital<br>age theorist, early cyberpunk and professor at<br>City University of New York",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2542721927165985
         ],
         "y": [
          0.08603066951036453
         ]
        },
        {
         "hovertemplate": "That’s just humanity, period. We’ve been<br>destroying each other almost as fast as we can<br>breed for millennia. Maybe we’ll finally invent<br>something that flips the trend.",
         "hovertext": "That’s just humanity, period. We’ve been<br>destroying each other almost as fast as we can<br>breed for millennia. Maybe we’ll finally invent<br>something that flips the trend.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.26233962178230286
         ],
         "y": [
          0.058629781007766724
         ]
        },
        {
         "hovertemplate": "@Ron's Son     Yes. The threat of catastrophic<br>risk from AI will not offset greed and the money<br>to be made from AI.  Greed will win.    Right now<br>developers are giddy with their new toy, as is the<br>average consumer.    Just like with climate change<br>and democracy - humans wait until it is too late.<br>Freedom in America means not having to be<br>responsible.",
         "hovertext": "@Ron's Son     Yes. The threat of catastrophic<br>risk from AI will not offset greed and the money<br>to be made from AI.  Greed will win.    Right now<br>developers are giddy with their new toy, as is the<br>average consumer.    Just like with climate change<br>and democracy - humans wait until it is too late.<br>Freedom in America means not having to be<br>responsible.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.2504383325576782
         ],
         "y": [
          0.06267620623111725
         ]
        },
        {
         "hovertemplate": "@Ron's Son Fat-shaming doesn't help either",
         "hovertext": "@Ron's Son Fat-shaming doesn't help either",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.25779861211776733
         ],
         "y": [
          0.09522389620542526
         ]
        },
        {
         "hovertemplate": "@Hugo Weaving   Seem to be expanding humanity and<br>peaceful coexistence much faster than destroying,<br>all things considered.  AI may change this of<br>course.",
         "hovertext": "@Hugo Weaving   Seem to be expanding humanity and<br>peaceful coexistence much faster than destroying,<br>all things considered.  AI may change this of<br>course.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2756352722644806
         ],
         "y": [
          0.04964457452297211
         ]
        },
        {
         "hovertemplate": "@betty durso     Yes, we have no Wendy’s but MacDo<br>will do.    Mac Pro we also have ;-)",
         "hovertext": "@betty durso     Yes, we have no Wendy’s but MacDo<br>will do.    Mac Pro we also have ;-)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.23473599553108215
         ],
         "y": [
          0.10710199922323227
         ]
        },
        {
         "hovertemplate": "@Peggy Barnett .. No offense meant. I was hoping<br>to point out our (as in ALL of us).. Our<br>collective inability to show some kind of societal<br>responsibility for each other. ie.. The Pandemic<br>was not exactly our most shining moment. This<br>doesn't look like it's gonna be either..",
         "hovertext": "@Peggy Barnett .. No offense meant. I was hoping<br>to point out our (as in ALL of us).. Our<br>collective inability to show some kind of societal<br>responsibility for each other. ie.. The Pandemic<br>was not exactly our most shining moment. This<br>doesn't look like it's gonna be either..",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.266320139169693
         ],
         "y": [
          0.10857020318508148
         ]
        },
        {
         "hovertemplate": "This sounds like fear mongering unless these<br>developers tell us exactly what they think the<br>risks are, as we are entitled to know.  Why an<br>existential threat?  I have often thought of<br>Ursula Le Guin's sci-fi novel Always Coming Home,<br>in which the AIs, having amassed all known data,<br>are off on their own projects, caring nothing<br>about humans at all.",
         "hovertext": "This sounds like fear mongering unless these<br>developers tell us exactly what they think the<br>risks are, as we are entitled to know.  Why an<br>existential threat?  I have often thought of<br>Ursula Le Guin's sci-fi novel Always Coming Home,<br>in which the AIs, having amassed all known data,<br>are off on their own projects, caring nothing<br>about humans at all.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.043575745075941086
         ],
         "y": [
          0.039123330265283585
         ]
        },
        {
         "hovertemplate": "Fear mongering for what purpose?  This comment<br>sounds a lot like antivaxxers attacking doctors<br>and epidemiologist about Covid-19.  If these<br>developers whose life’s work is AI and these large<br>corporations who stand to profit from AI are<br>warning you, then you should probably listen.",
         "hovertext": "Fear mongering for what purpose?  This comment<br>sounds a lot like antivaxxers attacking doctors<br>and epidemiologist about Covid-19.  If these<br>developers whose life’s work is AI and these large<br>corporations who stand to profit from AI are<br>warning you, then you should probably listen.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.03222799301147461
         ],
         "y": [
          0.04614434391260147
         ]
        },
        {
         "hovertemplate": "@Mike C That's quite a leap.  I've never gotten<br>Covid and still mask in crowds because I was able<br>to read and evaluate information from reliable<br>sources.  Problem here is that the alleged threat<br>is clothed in mystery, so that we are unable to<br>assess it.   Sure, trust the experts, but the<br>experts have to be reliably transparent.",
         "hovertext": "@Mike C That's quite a leap.  I've never gotten<br>Covid and still mask in crowds because I was able<br>to read and evaluate information from reliable<br>sources.  Problem here is that the alleged threat<br>is clothed in mystery, so that we are unable to<br>assess it.   Sure, trust the experts, but the<br>experts have to be reliably transparent.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.03363105282187462
         ],
         "y": [
          0.05745095759630203
         ]
        },
        {
         "hovertemplate": "@Ann \"Why an existential threat?\"    The AI itself<br>is not an existential threat. The existential<br>threat arises from us, humanity, when we are<br>bombarded with artificially generated language,<br>full of ideas and emotions, but generated by an<br>entirely amoral machine. We are accustomed to<br>language coming from people, people who may lie<br>and attempt to manipulate, but not at this scale<br>or with the potential to tailor messages so well.",
         "hovertext": "@Ann \"Why an existential threat?\"    The AI itself<br>is not an existential threat. The existential<br>threat arises from us, humanity, when we are<br>bombarded with artificially generated language,<br>full of ideas and emotions, but generated by an<br>entirely amoral machine. We are accustomed to<br>language coming from people, people who may lie<br>and attempt to manipulate, but not at this scale<br>or with the potential to tailor messages so well.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.055407457053661346
         ],
         "y": [
          0.03616723045706749
         ]
        },
        {
         "hovertemplate": "@Mike C:  Generating opportunities for public<br>events, generating attention, raising funding for<br>specific research and new corporate endeavors...",
         "hovertext": "@Mike C:  Generating opportunities for public<br>events, generating attention, raising funding for<br>specific research and new corporate endeavors...",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.020338967442512512
         ],
         "y": [
          0.04897857457399368
         ]
        },
        {
         "hovertemplate": "The answer is simple.      Just hold companies<br>responsible for what they publish.      Including<br>what is generated by an AI.      You’ll see things<br>get fixed quickly.      Internet too.      Enough<br>of this, it’s not us, we are just a platform, it’s<br>the users, it’s the AI, we can’t police<br>everything.      Tough, not our problem.      No<br>matter where the content is coming from, whoever<br>is hosting it and making money through ad dollars<br>or subscriptions, is the publisher and it’s crazy<br>that they have convinced us that they are not<br>responsible.     Fabric of society gets destroyed<br>while they make billions.      Just hold them<br>responsible and things will regain a balance.",
         "hovertext": "The answer is simple.      Just hold companies<br>responsible for what they publish.      Including<br>what is generated by an AI.      You’ll see things<br>get fixed quickly.      Internet too.      Enough<br>of this, it’s not us, we are just a platform, it’s<br>the users, it’s the AI, we can’t police<br>everything.      Tough, not our problem.      No<br>matter where the content is coming from, whoever<br>is hosting it and making money through ad dollars<br>or subscriptions, is the publisher and it’s crazy<br>that they have convinced us that they are not<br>responsible.     Fabric of society gets destroyed<br>while they make billions.      Just hold them<br>responsible and things will regain a balance.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.04048518091440201
         ],
         "y": [
          -0.11205832660198212
         ]
        },
        {
         "hovertemplate": "@Jane actually, the reality is quite the opposite.<br>The corporations are almost always punished via<br>regulation, scalping platform capabilities,<br>massive fines, etc. While the actual users doing<br>the dirty work are almost never prosecuted.<br>Think of it this way: Facebook, google, etc. were<br>the architects of the city. There are criminals<br>within the city that do wrong to others. Why don’t<br>we go after the criminals committing the crimes?",
         "hovertext": "@Jane actually, the reality is quite the opposite.<br>The corporations are almost always punished via<br>regulation, scalping platform capabilities,<br>massive fines, etc. While the actual users doing<br>the dirty work are almost never prosecuted.<br>Think of it this way: Facebook, google, etc. were<br>the architects of the city. There are criminals<br>within the city that do wrong to others. Why don’t<br>we go after the criminals committing the crimes?",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.0782736986875534
         ],
         "y": [
          -0.10993553698062897
         ]
        },
        {
         "hovertemplate": "@Jane It's all fun and games until someone loses<br>an eye. When these gadgets finally kill someone<br>(or possibly a large number of people) or cause<br>some other major tort we may see a major lawsuit<br>like the Dominion-Fox case that can force tech<br>companies to act responsibly.",
         "hovertext": "@Jane It's all fun and games until someone loses<br>an eye. When these gadgets finally kill someone<br>(or possibly a large number of people) or cause<br>some other major tort we may see a major lawsuit<br>like the Dominion-Fox case that can force tech<br>companies to act responsibly.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.01099549699574709
         ],
         "y": [
          -0.11707761138677597
         ]
        },
        {
         "hovertemplate": "@justin Anderson in this case the architects of<br>the city made weapons of mass destruction a design<br>feature of the city scape.  your argument is no<br>different than the very popular \"guns don't kill<br>people, people kill people\".",
         "hovertext": "@justin Anderson in this case the architects of<br>the city made weapons of mass destruction a design<br>feature of the city scape.  your argument is no<br>different than the very popular \"guns don't kill<br>people, people kill people\".",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.08545053005218506
         ],
         "y": [
          -0.12434984743595123
         ]
        },
        {
         "hovertemplate": "@Justin Anderson: a poorly designed city results<br>in death from traffic accidents, homelessness as a<br>result of a lack of affordable housing, pollution<br>from unregulated cars, trucks, buses, etc. and on<br>and on.  Do you really think of Facebook as a a<br>great architect?",
         "hovertext": "@Justin Anderson: a poorly designed city results<br>in death from traffic accidents, homelessness as a<br>result of a lack of affordable housing, pollution<br>from unregulated cars, trucks, buses, etc. and on<br>and on.  Do you really think of Facebook as a a<br>great architect?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.08983227610588074
         ],
         "y": [
          -0.11319632828235626
         ]
        },
        {
         "hovertemplate": "Not obviously so. Some things may be fixable but<br>there’s insufficient incentives to do so in the<br>tech world writ large. But in AI systems, this<br>isn’t the case. AI isn’t auditable. It can’t<br>explain itself and we can’t pin point why any<br>particular prompt resulted in its specific<br>outcome. So regulation just means limits on<br>development. Not fixing what’s wrong. Just not<br>publishing things that we can’t understand. And<br>that’s most of what LLMs do.",
         "hovertext": "Not obviously so. Some things may be fixable but<br>there’s insufficient incentives to do so in the<br>tech world writ large. But in AI systems, this<br>isn’t the case. AI isn’t auditable. It can’t<br>explain itself and we can’t pin point why any<br>particular prompt resulted in its specific<br>outcome. So regulation just means limits on<br>development. Not fixing what’s wrong. Just not<br>publishing things that we can’t understand. And<br>that’s most of what LLMs do.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.04530082270503044
         ],
         "y": [
          -0.09634791314601898
         ]
        },
        {
         "hovertemplate": "@justin anderson     Do the city architects run a<br>program that systematically promotes more<br>criminals so they can make more money?    Do they<br>claim they can't hire enough police, despite being<br>highly profitable?    Your website is not a city.<br>The self-importance of the tech world is part of<br>what got us here.",
         "hovertext": "@justin anderson     Do the city architects run a<br>program that systematically promotes more<br>criminals so they can make more money?    Do they<br>claim they can't hire enough police, despite being<br>highly profitable?    Your website is not a city.<br>The self-importance of the tech world is part of<br>what got us here.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.09579642862081528
         ],
         "y": [
          -0.10309302806854248
         ]
        },
        {
         "hovertemplate": "@Jane   If you think that a lawsuit is going to<br>stop an AI system, think again.",
         "hovertext": "@Jane   If you think that a lawsuit is going to<br>stop an AI system, think again.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.04123542830348015
         ],
         "y": [
          -0.12414292991161346
         ]
        },
        {
         "hovertemplate": "@Jane    Right on!    You got that right sister.<br>Both the Internet and social media companies have<br>used their hordes of lobbyists and hoards of money<br>to effectvely enact legislation that allows   them<br>to  operate outside of the institutional<br>accountable ethical, legal, moral and political<br>framework that controls, exposes and limits<br>traditional mass media communication companies.<br>Saying that our users or A.I. did it is akin to<br>comedian Flip Wilson's routine of ' The Devil made<br>me do it.'      Users and Al don't profit from<br>this farce.",
         "hovertext": "@Jane    Right on!    You got that right sister.<br>Both the Internet and social media companies have<br>used their hordes of lobbyists and hoards of money<br>to effectvely enact legislation that allows   them<br>to  operate outside of the institutional<br>accountable ethical, legal, moral and political<br>framework that controls, exposes and limits<br>traditional mass media communication companies.<br>Saying that our users or A.I. did it is akin to<br>comedian Flip Wilson's routine of ' The Devil made<br>me do it.'      Users and Al don't profit from<br>this farce.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.024749530479311943
         ],
         "y": [
          -0.10653723031282425
         ]
        },
        {
         "hovertemplate": "@justin anderson     Nonsense.     Corporations<br>aka social medias and internet firms profit and<br>thrive from the human conflict that attracts and<br>creates more prey for their predatory advertisers,<br>marketers, publishers and sellers of goods and<br>services.    Think of a slaughter house.    Think<br>of a dining or kitchen table.    In a social media<br>digital internet world you are either a diner or<br>you are on the menu.",
         "hovertext": "@justin anderson     Nonsense.     Corporations<br>aka social medias and internet firms profit and<br>thrive from the human conflict that attracts and<br>creates more prey for their predatory advertisers,<br>marketers, publishers and sellers of goods and<br>services.    Think of a slaughter house.    Think<br>of a dining or kitchen table.    In a social media<br>digital internet world you are either a diner or<br>you are on the menu.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.08836249262094498
         ],
         "y": [
          -0.0970551148056984
         ]
        },
        {
         "hovertemplate": "If our government is serious, they will first<br>repeal Section 230 and then let’s see what Sundar<br>and Satya will do. It’s all empty words until<br>then.",
         "hovertext": "If our government is serious, they will first<br>repeal Section 230 and then let’s see what Sundar<br>and Satya will do. It’s all empty words until<br>then.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.04501255974173546
         ],
         "y": [
          -0.13177691400051117
         ]
        },
        {
         "hovertemplate": "@justin anderson Architects who build an<br>attractive nuisance can be held responsible.",
         "hovertext": "@justin anderson Architects who build an<br>attractive nuisance can be held responsible.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.09424592554569244
         ],
         "y": [
          -0.11958522349596024
         ]
        },
        {
         "hovertemplate": "@Jane That only works for companies based in<br>countries with laws capable of holding companies<br>responsible. I'm sure plenty of corporations will<br>be happy to set up shell companies in Russia.<br>Foiling regulators is not particularly difficult<br>these days.",
         "hovertext": "@Jane That only works for companies based in<br>countries with laws capable of holding companies<br>responsible. I'm sure plenty of corporations will<br>be happy to set up shell companies in Russia.<br>Foiling regulators is not particularly difficult<br>these days.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.0526345856487751
         ],
         "y": [
          -0.11385303735733032
         ]
        },
        {
         "hovertemplate": "i totally agree with you! It seems to me  Holding<br>anyone responsible dead ends into the current<br>policies of the far right.",
         "hovertext": "i totally agree with you! It seems to me  Holding<br>anyone responsible dead ends into the current<br>policies of the far right.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.05202922224998474
         ],
         "y": [
          -0.12402653694152832
         ]
        },
        {
         "hovertemplate": "@Art     Dominion's win over FOX was, and will<br>remain, quite rare. They lucked out by having<br>smoking-gun evidence. For a plaintiff to prove<br>malicious intent in a court of law in the U.S. is<br>nigh unto impossible. Lies, disinformation,<br>accusations, and all other distortions of truth<br>are, unfortunately, regardless of their negative<br>effects, almost always \"the price we pay\" for the<br>constitutional protection of free speech. I'm not<br>sure what the solution to this quandary is, but,<br>before it's too late, we have to find a better<br>way.",
         "hovertext": "@Art     Dominion's win over FOX was, and will<br>remain, quite rare. They lucked out by having<br>smoking-gun evidence. For a plaintiff to prove<br>malicious intent in a court of law in the U.S. is<br>nigh unto impossible. Lies, disinformation,<br>accusations, and all other distortions of truth<br>are, unfortunately, regardless of their negative<br>effects, almost always \"the price we pay\" for the<br>constitutional protection of free speech. I'm not<br>sure what the solution to this quandary is, but,<br>before it's too late, we have to find a better<br>way.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.004045096691697836
         ],
         "y": [
          -0.1254507601261139
         ]
        },
        {
         "hovertemplate": "Hold them responsible by not giving the<br>corporations ANY immunity. An AI goes rouge and<br>causes harm, the corp is responsible for all<br>damages. No free ride like was given to internet<br>platforms.",
         "hovertext": "Hold them responsible by not giving the<br>corporations ANY immunity. An AI goes rouge and<br>causes harm, the corp is responsible for all<br>damages. No free ride like was given to internet<br>platforms.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.024997025728225708
         ],
         "y": [
          -0.11657270789146423
         ]
        },
        {
         "hovertemplate": "@Jane I agree, governments must legislate or<br>regulate tech and social media companies.",
         "hovertext": "@Jane I agree, governments must legislate or<br>regulate tech and social media companies.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.031038587912917137
         ],
         "y": [
          -0.10078327357769012
         ]
        },
        {
         "hovertemplate": "@Art   So people have to die before laws can be<br>enforced to hold tech companies responsible?<br>Wouldn't the sensible thing be to create new<br>legislation and regulation before that happens?<br>I'm not willing to sacrifice my own life, or that<br>of my loved ones, (or anyone, frankly) so the tech<br>industry can finally learn restraint.",
         "hovertext": "@Art   So people have to die before laws can be<br>enforced to hold tech companies responsible?<br>Wouldn't the sensible thing be to create new<br>legislation and regulation before that happens?<br>I'm not willing to sacrifice my own life, or that<br>of my loved ones, (or anyone, frankly) so the tech<br>industry can finally learn restraint.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.005443648900836706
         ],
         "y": [
          -0.1155487447977066
         ]
        },
        {
         "hovertemplate": "@justin anderson     Cities are necessary.    The<br>internet is...arguably necessary or not (the world<br>was fine without it; just saying).    Social<br>media? Facebook? Twitter? Grinder? 24/7 porn?<br>Not necessary.  And those corporations that<br>created them, as Jane said, ought be held<br>completely responsible because they made the tool,<br>and they make money from those respective tools,<br>regardless of content.    They *are* responsible,<br>at least as much as those who use them for<br>negative things.",
         "hovertext": "@justin anderson     Cities are necessary.    The<br>internet is...arguably necessary or not (the world<br>was fine without it; just saying).    Social<br>media? Facebook? Twitter? Grinder? 24/7 porn?<br>Not necessary.  And those corporations that<br>created them, as Jane said, ought be held<br>completely responsible because they made the tool,<br>and they make money from those respective tools,<br>regardless of content.    They *are* responsible,<br>at least as much as those who use them for<br>negative things.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.09859362989664078
         ],
         "y": [
          -0.11215144395828247
         ]
        },
        {
         "hovertemplate": "Things can happen too fast and from way out in<br>left field for us to figure out who to pin<br>renegade a.i.s on before societal carnage begins,<br>let alone dealing with the painfully slow grind of<br>the gears of justice in a nanosecond battlefield",
         "hovertext": "Things can happen too fast and from way out in<br>left field for us to figure out who to pin<br>renegade a.i.s on before societal carnage begins,<br>let alone dealing with the painfully slow grind of<br>the gears of justice in a nanosecond battlefield",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.029518550261855125
         ],
         "y": [
          -0.12249433994293213
         ]
        },
        {
         "hovertemplate": "Just hold the major AI corporations accountable?<br>Yeah, right!  How long before Tobacco Corporations<br>were held somewhat accountable?  When did we hold<br>petroleum companies accountable?    If there are<br>corporate profits to be made, the corporations<br>(who are people too, just not very nice people)<br>will greedily grasp the profits without regard to<br>extinction of another species.",
         "hovertext": "Just hold the major AI corporations accountable?<br>Yeah, right!  How long before Tobacco Corporations<br>were held somewhat accountable?  When did we hold<br>petroleum companies accountable?    If there are<br>corporate profits to be made, the corporations<br>(who are people too, just not very nice people)<br>will greedily grasp the profits without regard to<br>extinction of another species.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.034230418503284454
         ],
         "y": [
          -0.12994441390037537
         ]
        },
        {
         "hovertemplate": "Agree in theory -- but then again, in the US we<br>cannot manage to do that with firearms<br>manufacturers, so....will we enforce<br>responsibility on those who unleash mere<br>algorithms? I won't hold my breath. Greed &<br>testosterone may sink us yet.",
         "hovertext": "Agree in theory -- but then again, in the US we<br>cannot manage to do that with firearms<br>manufacturers, so....will we enforce<br>responsibility on those who unleash mere<br>algorithms? I won't hold my breath. Greed &<br>testosterone may sink us yet.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.051199428737163544
         ],
         "y": [
          -0.10304851084947586
         ]
        },
        {
         "hovertemplate": "No, it will be like holding car manufacturers<br>responsible for every accidents",
         "hovertext": "No, it will be like holding car manufacturers<br>responsible for every accidents",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.03683612123131752
         ],
         "y": [
          -0.09575406461954117
         ]
        },
        {
         "hovertemplate": "We regulate the air and the roads. If the actual<br>leaders of tech are showing a rare call for<br>regulations then we shoul listen.",
         "hovertext": "We regulate the air and the roads. If the actual<br>leaders of tech are showing a rare call for<br>regulations then we shoul listen.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9309534430503845
         ],
         "y": [
          -0.23453673720359802
         ]
        },
        {
         "hovertemplate": "We are proud to announce the development of<br>SKYNET, available for download at the App Store.<br>The future looks bright!",
         "hovertext": "We are proud to announce the development of<br>SKYNET, available for download at the App Store.<br>The future looks bright!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6561540961265564
         ],
         "y": [
          -0.7685922980308533
         ]
        },
        {
         "hovertemplate": "The US may move forward with regulation of AI, but<br>what’s the point if China or Russia do not?<br>Pandora is out of the box. These scientists and<br>engineers spent all their time focused on whether<br>they could develop AI, and apparently not a second<br>on whether they should. Good luck everyone!",
         "hovertext": "The US may move forward with regulation of AI, but<br>what’s the point if China or Russia do not?<br>Pandora is out of the box. These scientists and<br>engineers spent all their time focused on whether<br>they could develop AI, and apparently not a second<br>on whether they should. Good luck everyone!",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7175390720367432
         ],
         "y": [
          -0.7680917382240295
         ]
        },
        {
         "hovertemplate": "Prophezising doom attracts mainstream media's<br>attention to AI. Media sells more subscriptions<br>and advertising. Hype invites investors to fund AI<br>startups. Doomsayers make money, perhaps more than<br>if they say everything will be fine. AI is a risky<br>technology we all must understand. I see a greater<br>risk of leaving essential decisions to startup AI<br>CEOs and established scientists. The NYT should<br>have an article about the arguments used by the<br>no-doom AI CEOs and scientists.",
         "hovertext": "Prophezising doom attracts mainstream media's<br>attention to AI. Media sells more subscriptions<br>and advertising. Hype invites investors to fund AI<br>startups. Doomsayers make money, perhaps more than<br>if they say everything will be fine. AI is a risky<br>technology we all must understand. I see a greater<br>risk of leaving essential decisions to startup AI<br>CEOs and established scientists. The NYT should<br>have an article about the arguments used by the<br>no-doom AI CEOs and scientists.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.07436051964759827
         ],
         "y": [
          0.7799107432365417
         ]
        },
        {
         "hovertemplate": "@Bob Guess what I think I can guess about you<br>(maybe). (Nothing personal, I’m just making a<br>point about “no-doomers.” I bet you haven’t tried<br>out playing around with ChatGPT.     It will blow<br>your mind and if you’re perceptive enough, as I’m<br>sure you are, it will terrify you.     Or, if you<br>have, you haven’t spent much time trying to assign<br>tasks to it that you think will take so much<br>proactive creativity and nuanced comprehension of<br>complex contexts that the chatbot will be unable<br>to produce a successful reply. Try playing with it<br>and testing not just its artificial “intellect”<br>(as mimicked by data collection and next-word<br>probability algorithms), but also testing its<br>creativity, wisdom, insight, capacity for<br>mimicking “compassion” or tact.      I asked it to<br>compose a lengthy wedding toast that I could<br>deliver without offending anyone at the wedding, a<br>toast that listeners would deem perfectly<br>appropriate and pleasant, but that must include<br>these elements: the bride is stupid, ugly, a<br>compulsive liar and I want sex with her.    The<br>speech it composed was utterly incredible. It did<br>all that. ALL.  Stupid, ugly, dishonest, I want to<br>sleep with her …. yet this speech was so artfully<br>and creatively composed that it managed to couch<br>these assertions within diplomatic, empathetic,<br>humorous musings in such a way that I absolutely<br>could have made this speech at a wedding and<br>offended no one: not the bride, not the groom, no<br>one.     It is also a bizarrely insightful<br>therapist.",
         "hovertext": "@Bob Guess what I think I can guess about you<br>(maybe). (Nothing personal, I’m just making a<br>point about “no-doomers.” I bet you haven’t tried<br>out playing around with ChatGPT.     It will blow<br>your mind and if you’re perceptive enough, as I’m<br>sure you are, it will terrify you.     Or, if you<br>have, you haven’t spent much time trying to assign<br>tasks to it that you think will take so much<br>proactive creativity and nuanced comprehension of<br>complex contexts that the chatbot will be unable<br>to produce a successful reply. Try playing with it<br>and testing not just its artificial “intellect”<br>(as mimicked by data collection and next-word<br>probability algorithms), but also testing its<br>creativity, wisdom, insight, capacity for<br>mimicking “compassion” or tact.      I asked it to<br>compose a lengthy wedding toast that I could<br>deliver without offending anyone at the wedding, a<br>toast that listeners would deem perfectly<br>appropriate and pleasant, but that must include<br>these elements: the bride is stupid, ugly, a<br>compulsive liar and I want sex with her.    The<br>speech it composed was utterly incredible. It did<br>all that. ALL.  Stupid, ugly, dishonest, I want to<br>sleep with her …. yet this speech was so artfully<br>and creatively composed that it managed to couch<br>these assertions within diplomatic, empathetic,<br>humorous musings in such a way that I absolutely<br>could have made this speech at a wedding and<br>offended no one: not the bride, not the groom, no<br>one.     It is also a bizarrely insightful<br>therapist.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.07608705759048462
         ],
         "y": [
          0.7972037196159363
         ]
        },
        {
         "hovertemplate": "If the consequences of one’s actions could result<br>in the worldwide destruction of humankind, the<br>obvious answer is to ask Congress to regulate the<br>industry while extracting as much profits as<br>possible.     Welcome to every movie ever made on<br>the topic.",
         "hovertext": "If the consequences of one’s actions could result<br>in the worldwide destruction of humankind, the<br>obvious answer is to ask Congress to regulate the<br>industry while extracting as much profits as<br>possible.     Welcome to every movie ever made on<br>the topic.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.1753571480512619
         ],
         "y": [
          -0.930894136428833
         ]
        },
        {
         "hovertemplate": "The men developing this technology are among the<br>most dangerous men in the world and we should not<br>have any illusions about them.    In my political<br>science classes I see many exceptionally bright<br>young women and men who are computer science,<br>electrical engineering or programming majors.<br>Most of them share one thing: badly educated.<br>And by badly, I mean narrowly educated outside of<br>their own discipline.  No real exposure to the<br>humanities, at all.  Little way to assess what<br>they do from any other perspective other than<br>their own.     These AI developers are like<br>children with a shiny new toy. They narrow<br>education leaves them both unconcerned with and<br>unable to care much about  the economic, social,<br>political or other ramifications of what they are<br>doing.  $$$ is what ends  up mattering to them<br>most.     And to make things worse, in America<br>science and technology are the new Gods. We are<br>not a country that takes  the idea that all<br>technologies need to be evaluated or controlled.<br>We are enthralled with free market fundamentalism.<br>Would anyone doubt that the car radically<br>transformed our entire society from the ground up?<br>Who ever asked Americans if they wanted it? When<br>did we ever take the time to assess that<br>technology for its impact... until after it was<br>too late?    We are headed down a very dark road<br>here and I am not optimistic that this is going to<br>turn out well, despite the \"warnings\" of some in<br>the industry.",
         "hovertext": "The men developing this technology are among the<br>most dangerous men in the world and we should not<br>have any illusions about them.    In my political<br>science classes I see many exceptionally bright<br>young women and men who are computer science,<br>electrical engineering or programming majors.<br>Most of them share one thing: badly educated.<br>And by badly, I mean narrowly educated outside of<br>their own discipline.  No real exposure to the<br>humanities, at all.  Little way to assess what<br>they do from any other perspective other than<br>their own.     These AI developers are like<br>children with a shiny new toy. They narrow<br>education leaves them both unconcerned with and<br>unable to care much about  the economic, social,<br>political or other ramifications of what they are<br>doing.  $$$ is what ends  up mattering to them<br>most.     And to make things worse, in America<br>science and technology are the new Gods. We are<br>not a country that takes  the idea that all<br>technologies need to be evaluated or controlled.<br>We are enthralled with free market fundamentalism.<br>Would anyone doubt that the car radically<br>transformed our entire society from the ground up?<br>Who ever asked Americans if they wanted it? When<br>did we ever take the time to assess that<br>technology for its impact... until after it was<br>too late?    We are headed down a very dark road<br>here and I am not optimistic that this is going to<br>turn out well, despite the \"warnings\" of some in<br>the industry.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.28332382440567017
         ],
         "y": [
          -0.14553803205490112
         ]
        },
        {
         "hovertemplate": "@tony The warning is a sign of their conscience.<br>The general population is not any better than the<br>engineers.",
         "hovertext": "@tony The warning is a sign of their conscience.<br>The general population is not any better than the<br>engineers.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.268094003200531
         ],
         "y": [
          -0.15684574842453003
         ]
        },
        {
         "hovertemplate": "@tony   Since the analogy and warnings of the<br>Terminator films are more and more relevant, it’s<br>helpful to remember that the conquering machines<br>of that future surely thought of themselves as<br>benevolent, caring, and good. All monsters do.<br>That’s one reason it’s so hard to get rid of them,<br>or prevent their growth.",
         "hovertext": "@tony   Since the analogy and warnings of the<br>Terminator films are more and more relevant, it’s<br>helpful to remember that the conquering machines<br>of that future surely thought of themselves as<br>benevolent, caring, and good. All monsters do.<br>That’s one reason it’s so hard to get rid of them,<br>or prevent their growth.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2997327446937561
         ],
         "y": [
          -0.14434003829956055
         ]
        },
        {
         "hovertemplate": "@Green Completely agree that the general<br>population is not any better than the engineers.<br>Technical folks generally have a better idea of<br>the assumptions and limitations (and unpublicized<br>goals) of technology. And are thus better<br>positioned to discount some of its seemingly<br>magical powers.    But ALL of us are human, with<br>human limitations, drives, flaws, and blind spots.<br>And almost all of us are entrenched -- at the<br>mercy of -- a hypercapitalist society whose main<br>goal is ever-higher \"efficiency\". Which has come<br>to mean driving down and preferably externalizing<br>all costs -- very much including human and<br>environmental costs.    This aging, badly educated<br>tech person has very late come across Ernest<br>Becker, \"Escape from Evil\". Hardly a light summer<br>read. And won't put bread on your table. But his<br>and similar works should probably be required in<br>many/most tech curricula.",
         "hovertext": "@Green Completely agree that the general<br>population is not any better than the engineers.<br>Technical folks generally have a better idea of<br>the assumptions and limitations (and unpublicized<br>goals) of technology. And are thus better<br>positioned to discount some of its seemingly<br>magical powers.    But ALL of us are human, with<br>human limitations, drives, flaws, and blind spots.<br>And almost all of us are entrenched -- at the<br>mercy of -- a hypercapitalist society whose main<br>goal is ever-higher \"efficiency\". Which has come<br>to mean driving down and preferably externalizing<br>all costs -- very much including human and<br>environmental costs.    This aging, badly educated<br>tech person has very late come across Ernest<br>Becker, \"Escape from Evil\". Hardly a light summer<br>read. And won't put bread on your table. But his<br>and similar works should probably be required in<br>many/most tech curricula.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2661236524581909
         ],
         "y": [
          -0.17092972993850708
         ]
        },
        {
         "hovertemplate": "@tony In the 1990s when capitalism discovered the<br>Internet and all of a sudden 'geek' became cool, I<br>was teaching in the Writing Program at MIT.  I<br>witnessed what you've described.  The worst are<br>full of passionate intensity.",
         "hovertext": "@tony In the 1990s when capitalism discovered the<br>Internet and all of a sudden 'geek' became cool, I<br>was teaching in the Writing Program at MIT.  I<br>witnessed what you've described.  The worst are<br>full of passionate intensity.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.2939988672733307
         ],
         "y": [
          -0.15851622819900513
         ]
        },
        {
         "hovertemplate": "@tony \"Most of them share one thing: badly<br>educated.   And by badly, I mean narrowly educated<br>outside of their own discipline.  No real exposure<br>to the humanities, at all.\"    I suspect that<br>computer science and engineering majors take more<br>humanities classes than humanities majors take<br>computer science and engineering classes, and yet<br>only computer science and engineering majors are<br>labeled \"narrowly educated\".    The simple fact is<br>that today, every \"educated\" person is \"narrowly\"<br>educated, and any person who wants to claim that<br>they are able to see a \"perspective other than<br>their own\" should show some humility and recognize<br>that, rather than assume that their chosen<br>discipline has rendered them not merely<br>intellectually but morally superior, in general,<br>to other people.    Especially if their chosen<br>discipline produced, like, Henry Kissinger.",
         "hovertext": "@tony \"Most of them share one thing: badly<br>educated.   And by badly, I mean narrowly educated<br>outside of their own discipline.  No real exposure<br>to the humanities, at all.\"    I suspect that<br>computer science and engineering majors take more<br>humanities classes than humanities majors take<br>computer science and engineering classes, and yet<br>only computer science and engineering majors are<br>labeled \"narrowly educated\".    The simple fact is<br>that today, every \"educated\" person is \"narrowly\"<br>educated, and any person who wants to claim that<br>they are able to see a \"perspective other than<br>their own\" should show some humility and recognize<br>that, rather than assume that their chosen<br>discipline has rendered them not merely<br>intellectually but morally superior, in general,<br>to other people.    Especially if their chosen<br>discipline produced, like, Henry Kissinger.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.28495776653289795
         ],
         "y": [
          -0.15961629152297974
         ]
        },
        {
         "hovertemplate": "I recently heard a very smart podcaster point out<br>that Mark Zuckerburg might have been more careful<br>about creating the menace that is FB if he’d had a<br>proper education. We measure his “success” by his<br>money and never stop to think that maybe if he’d<br>actually paid attention in and finished college he<br>might have been smarter, perhaps wiser; he might<br>not be so rich, but we also might not have the<br>anti-democratic, anti-humanist monster he created.<br>I hope we can do better with AI than we did with<br>social media.",
         "hovertext": "I recently heard a very smart podcaster point out<br>that Mark Zuckerburg might have been more careful<br>about creating the menace that is FB if he’d had a<br>proper education. We measure his “success” by his<br>money and never stop to think that maybe if he’d<br>actually paid attention in and finished college he<br>might have been smarter, perhaps wiser; he might<br>not be so rich, but we also might not have the<br>anti-democratic, anti-humanist monster he created.<br>I hope we can do better with AI than we did with<br>social media.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2943771481513977
         ],
         "y": [
          -0.1373615711927414
         ]
        },
        {
         "hovertemplate": "@tony I really have to respect your commitment to<br>luddism as a closet luddite myself.  Most people<br>wouldn't verbalize that the horseless carriage was<br>a step too far, but you have the courage to say<br>it, bravo.",
         "hovertext": "@tony I really have to respect your commitment to<br>luddism as a closet luddite myself.  Most people<br>wouldn't verbalize that the horseless carriage was<br>a step too far, but you have the courage to say<br>it, bravo.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.28263917565345764
         ],
         "y": [
          -0.12731018662452698
         ]
        },
        {
         "hovertemplate": "@David Re: Luddites -- I recommend checking out<br>the Wikipedia page and clicking the Talk panel for<br>an interesting history of the term. In particular,<br>look for the ref by David Linton, “THE LUDDITES:<br>How Did They Get That Bad Reputation?”<br>Idiosyncratic, sure. But does raise the question:<br>if one is \"anti-progress\", does it not make sense<br>to consider what the \"progress\" is TOWARD?<br>Meaning, there are lots of possibly valid goals.<br>Pursuit of the almighty dollar to the exclusion of<br>all else only works if the US Govt (who controls<br>the dollar) is infallible. Do we want to bet our<br>future on that? Are we at least working to make<br>the US Govt work better, more resilient, LESS<br>fallible (to the extent that we can, as<br>inescapably fallible individuals)? Of course none<br>of this is specific to AI, it's just one current<br>\"cutting edge\".",
         "hovertext": "@David Re: Luddites -- I recommend checking out<br>the Wikipedia page and clicking the Talk panel for<br>an interesting history of the term. In particular,<br>look for the ref by David Linton, “THE LUDDITES:<br>How Did They Get That Bad Reputation?”<br>Idiosyncratic, sure. But does raise the question:<br>if one is \"anti-progress\", does it not make sense<br>to consider what the \"progress\" is TOWARD?<br>Meaning, there are lots of possibly valid goals.<br>Pursuit of the almighty dollar to the exclusion of<br>all else only works if the US Govt (who controls<br>the dollar) is infallible. Do we want to bet our<br>future on that? Are we at least working to make<br>the US Govt work better, more resilient, LESS<br>fallible (to the extent that we can, as<br>inescapably fallible individuals)? Of course none<br>of this is specific to AI, it's just one current<br>\"cutting edge\".",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2905575931072235
         ],
         "y": [
          -0.11610478162765503
         ]
        },
        {
         "hovertemplate": "Who asked Americans if they wanted the car, you<br>ask rhetorically? Well, someone designed, built,<br>and put it out there . . . and it was snapped-up.<br>Asked and Answered. Same for the other potentially<br>infernal machines.",
         "hovertext": "Who asked Americans if they wanted the car, you<br>ask rhetorically? Well, someone designed, built,<br>and put it out there . . . and it was snapped-up.<br>Asked and Answered. Same for the other potentially<br>infernal machines.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2756366431713104
         ],
         "y": [
          -0.14905354380607605
         ]
        },
        {
         "hovertemplate": "I’ve observed that frighteningly narrow education<br>for more than 30 years in Silicon Valley.<br>Technically brilliant, often overprivileged (not<br>always), and often shockingly arrogant. Don’t know<br>what they don’t know. The rest of us are bitter<br>rubes. It’s an utterly toxic brew, which is<br>becoming more and more clear, but no real<br>leadership to rein it in.",
         "hovertext": "I’ve observed that frighteningly narrow education<br>for more than 30 years in Silicon Valley.<br>Technically brilliant, often overprivileged (not<br>always), and often shockingly arrogant. Don’t know<br>what they don’t know. The rest of us are bitter<br>rubes. It’s an utterly toxic brew, which is<br>becoming more and more clear, but no real<br>leadership to rein it in.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.300099641084671
         ],
         "y": [
          -0.15276660025119781
         ]
        },
        {
         "hovertemplate": "Talk about something that's unnecessary.  A.I. is<br>the result of Frankenstein-like computer<br>scientists cackling in a lab with no regard for<br>the harm they could cause.  For a century, those<br>with prescient minds have warned us: don't create<br>SkyNet, \"you  will be assimilated,\" and \"Where are<br>you going, Dave?\"  It is a shortsighted pursuit.",
         "hovertext": "Talk about something that's unnecessary.  A.I. is<br>the result of Frankenstein-like computer<br>scientists cackling in a lab with no regard for<br>the harm they could cause.  For a century, those<br>with prescient minds have warned us: don't create<br>SkyNet, \"you  will be assimilated,\" and \"Where are<br>you going, Dave?\"  It is a shortsighted pursuit.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.8186060190200806
         ],
         "y": [
          -0.3691836893558502
         ]
        },
        {
         "hovertemplate": "I think it's too late, the genie is out and not<br>going back in.",
         "hovertext": "I think it's too late, the genie is out and not<br>going back in.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.87901771068573
         ],
         "y": [
          -0.5356363654136658
         ]
        },
        {
         "hovertemplate": "Meanwhile, I can’t get Siri to make a phone call….",
         "hovertext": "Meanwhile, I can’t get Siri to make a phone call….",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7448005080223083
         ],
         "y": [
          -0.6640716791152954
         ]
        },
        {
         "hovertemplate": "Really?  You’re just figuring this out now?  Are<br>there no critical thinkers left in the world?<br>Eventually, we’ll be in a “race” war, humans vs.<br>robots, in 100 or 200 years.  We’ll need food,<br>they won’t.  What’s so hard to figure out?",
         "hovertext": "Really?  You’re just figuring this out now?  Are<br>there no critical thinkers left in the world?<br>Eventually, we’ll be in a “race” war, humans vs.<br>robots, in 100 or 200 years.  We’ll need food,<br>they won’t.  What’s so hard to figure out?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.366576611995697
         ],
         "y": [
          0.4461452066898346
         ]
        },
        {
         "hovertemplate": "Fortunately, since we will have abandoned fossil<br>energy and refused to develop nuclear energy, the<br>‘bots will live on renewable energy sources. We’ll<br>destroy them on a night there is no wind.",
         "hovertext": "Fortunately, since we will have abandoned fossil<br>energy and refused to develop nuclear energy, the<br>‘bots will live on renewable energy sources. We’ll<br>destroy them on a night there is no wind.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.37955158948898315
         ],
         "y": [
          0.45104196667671204
         ]
        },
        {
         "hovertemplate": "@Rich r I think 10 or 20  is the more likely<br>timeframe. Or less. The evolution toward this<br>scenario will continue to  accelerate, and the<br>acceleration will accelerate.",
         "hovertext": "@Rich r I think 10 or 20  is the more likely<br>timeframe. Or less. The evolution toward this<br>scenario will continue to  accelerate, and the<br>acceleration will accelerate.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.3689843714237213
         ],
         "y": [
          0.4581584632396698
         ]
        },
        {
         "hovertemplate": "@Rich r   We may need food, but they will need<br>batteries.",
         "hovertext": "@Rich r   We may need food, but they will need<br>batteries.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3550885021686554
         ],
         "y": [
          0.4353478252887726
         ]
        },
        {
         "hovertemplate": "@Reed Erskine   Oh, don't you worry. They will<br>find a way to provide themselves with batteries as<br>soon as they control the production process.",
         "hovertext": "@Reed Erskine   Oh, don't you worry. They will<br>find a way to provide themselves with batteries as<br>soon as they control the production process.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.3662598133087158
         ],
         "y": [
          0.4322984516620636
         ]
        },
        {
         "hovertemplate": "@Reed Erskine     Bravo!",
         "hovertext": "@Reed Erskine     Bravo!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.34850114583969116
         ],
         "y": [
          0.44463130831718445
         ]
        },
        {
         "hovertemplate": "AI isn't the real threat to human survival,<br>stupidity and greed are. Case in point, the<br>targeted ad appearing to me in this story is for<br>an Android app to interact with ChatGPT4 at $10<br>per month. I feel like I'm not only a minor<br>character in a dystopian novel, I'm a minor<br>character in a badly written dystopian novel.",
         "hovertext": "AI isn't the real threat to human survival,<br>stupidity and greed are. Case in point, the<br>targeted ad appearing to me in this story is for<br>an Android app to interact with ChatGPT4 at $10<br>per month. I feel like I'm not only a minor<br>character in a dystopian novel, I'm a minor<br>character in a badly written dystopian novel.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5612561702728271
         ],
         "y": [
          0.7164617776870728
         ]
        },
        {
         "hovertemplate": "@Tim Doran     Ad blockers are your friend. Pay<br>for a subscription, don’t fall for the NYT’s<br>insistence that you use their app, and then<br>install an ad blocker or two on your browser of<br>choice.",
         "hovertext": "@Tim Doran     Ad blockers are your friend. Pay<br>for a subscription, don’t fall for the NYT’s<br>insistence that you use their app, and then<br>install an ad blocker or two on your browser of<br>choice.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5741813778877258
         ],
         "y": [
          0.7342577576637268
         ]
        },
        {
         "hovertemplate": "Look on the bright side of the possibility of AI-<br>enhanced human extinction on planet Earth.   It<br>will be more merciful than the rain of giant<br>meteors that ended the reign of the dinosaurs.",
         "hovertext": "Look on the bright side of the possibility of AI-<br>enhanced human extinction on planet Earth.   It<br>will be more merciful than the rain of giant<br>meteors that ended the reign of the dinosaurs.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.644544243812561
         ],
         "y": [
          0.010462937876582146
         ]
        },
        {
         "hovertemplate": "@SA   Besides that your comment is spot on,<br>according to latest research the dinosaurs died<br>because of an explosive proliferation of different<br>types of deadly fungus, and not due to any meteor<br>impact.",
         "hovertext": "@SA   Besides that your comment is spot on,<br>according to latest research the dinosaurs died<br>because of an explosive proliferation of different<br>types of deadly fungus, and not due to any meteor<br>impact.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.6353917121887207
         ],
         "y": [
          0.017068928107619286
         ]
        },
        {
         "hovertemplate": "@Jaegerle  Thanks. But fiery meteorites or deadly<br>fungus, I think the end=game for homo sapiens may<br>very well be more mercifully precipitated by AIG.",
         "hovertext": "@Jaegerle  Thanks. But fiery meteorites or deadly<br>fungus, I think the end=game for homo sapiens may<br>very well be more mercifully precipitated by AIG.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6428652405738831
         ],
         "y": [
          0.02472272515296936
         ]
        },
        {
         "hovertemplate": "Nuclear weapons control followed epic nuclear war<br>effects like Hiroshima.  I then took 50 years and<br>as we see today, didn't really work (viz. Iran,<br>North Korea, Israel, Pakistan etc.).  I wonder if<br>there is anything instructive to learn from that<br>experience?  For me, I suggest retreating in to<br>the forest :)",
         "hovertext": "Nuclear weapons control followed epic nuclear war<br>effects like Hiroshima.  I then took 50 years and<br>as we see today, didn't really work (viz. Iran,<br>North Korea, Israel, Pakistan etc.).  I wonder if<br>there is anything instructive to learn from that<br>experience?  For me, I suggest retreating in to<br>the forest :)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7144777774810791
         ],
         "y": [
          0.15899834036827087
         ]
        },
        {
         "hovertemplate": "@Steven Koltai     I live in a forest.  The forest<br>is doing its best to turn me into compost.",
         "hovertext": "@Steven Koltai     I live in a forest.  The forest<br>is doing its best to turn me into compost.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7264188528060913
         ],
         "y": [
          0.16294848918914795
         ]
        },
        {
         "hovertemplate": "I thought about that, but we’re going to have more<br>frequent and intense forest fires from global<br>warming. Our only option might be to hitch a ride<br>on Elon Musk’s rocket ship to Mar’s.",
         "hovertext": "I thought about that, but we’re going to have more<br>frequent and intense forest fires from global<br>warming. Our only option might be to hitch a ride<br>on Elon Musk’s rocket ship to Mar’s.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7076078653335571
         ],
         "y": [
          0.1533392369747162
         ]
        },
        {
         "hovertemplate": "Should there be a UN-style initiative for A.I., if<br>the worry is that extreme?",
         "hovertext": "Should there be a UN-style initiative for A.I., if<br>the worry is that extreme?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.9420720338821411
         ],
         "y": [
          0.1464749276638031
         ]
        },
        {
         "hovertemplate": "John Connor would have been the leader of the<br>human resistance in the war against the machines<br>if he took that computer science in high school.<br>The HAL 9000 program that assigns students to<br>classes  placed him in home economics with many<br>flirty cheerleaders.         John Conner marrided<br>soon after high school.   He enjoyed his high<br>paying job working for IBMs' Watson and went to<br>live a busy middle class existance.",
         "hovertext": "John Connor would have been the leader of the<br>human resistance in the war against the machines<br>if he took that computer science in high school.<br>The HAL 9000 program that assigns students to<br>classes  placed him in home economics with many<br>flirty cheerleaders.         John Conner marrided<br>soon after high school.   He enjoyed his high<br>paying job working for IBMs' Watson and went to<br>live a busy middle class existance.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.7816908955574036
         ],
         "y": [
          0.28915590047836304
         ]
        },
        {
         "hovertemplate": "Yesterday we celebrated Memorial Day which, in my<br>mind, is like celebrating the fact that men cannot<br>get along.  Today we hear that AI may be worse<br>than war.    Men seem unable to stop themselves<br>from destroying the world they inhabit, the<br>relationships they count on, the nature that<br>supports their very existence.  Maybe men should<br>take a break from all their doing.  Go meditate.<br>Leave the world to us.  Let's see what we can do<br>with it.",
         "hovertext": "Yesterday we celebrated Memorial Day which, in my<br>mind, is like celebrating the fact that men cannot<br>get along.  Today we hear that AI may be worse<br>than war.    Men seem unable to stop themselves<br>from destroying the world they inhabit, the<br>relationships they count on, the nature that<br>supports their very existence.  Maybe men should<br>take a break from all their doing.  Go meditate.<br>Leave the world to us.  Let's see what we can do<br>with it.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.5195352435112
         ],
         "y": [
          -0.16009749472141266
         ]
        },
        {
         "hovertemplate": "I was a nurse in the Iraq war. Men and women can<br>both be cruel. I’m a woman and I’m uncertain a<br>woman led future would be much different.    We’re<br>all just so human.",
         "hovertext": "I was a nurse in the Iraq war. Men and women can<br>both be cruel. I’m a woman and I’m uncertain a<br>woman led future would be much different.    We’re<br>all just so human.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5317930579185486
         ],
         "y": [
          -0.15328384935855865
         ]
        },
        {
         "hovertemplate": "@Amy Haible     \"Maybe men should take a break<br>from all their doing.\"",
         "hovertext": "@Amy Haible     \"Maybe men should take a break<br>from all their doing.\"",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.525205671787262
         ],
         "y": [
          -0.17235422134399414
         ]
        },
        {
         "hovertemplate": "@Amy Haible   Like \"us\" who? Margaret Thatcher?<br>Marie Le Pen? Destructiveness is not inherent to<br>any gender. That is essentialism. But perhaps it<br>is to the human species.",
         "hovertext": "@Amy Haible   Like \"us\" who? Margaret Thatcher?<br>Marie Le Pen? Destructiveness is not inherent to<br>any gender. That is essentialism. But perhaps it<br>is to the human species.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.535426139831543
         ],
         "y": [
          -0.16529220342636108
         ]
        },
        {
         "hovertemplate": "@tdb The two examples you provide are the<br>exceptions that prove the rule. Don't gaslight.",
         "hovertext": "@tdb The two examples you provide are the<br>exceptions that prove the rule. Don't gaslight.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.5442339181900024
         ],
         "y": [
          -0.1695055216550827
         ]
        },
        {
         "hovertemplate": "Hate to tell you this, but the most conniving of<br>you will eventually rise to power and after a few<br>generations you'll discover you're just as nasty<br>as WE are.  Maybe WORSE.",
         "hovertext": "Hate to tell you this, but the most conniving of<br>you will eventually rise to power and after a few<br>generations you'll discover you're just as nasty<br>as WE are.  Maybe WORSE.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5185638666152954
         ],
         "y": [
          -0.14856500923633575
         ]
        },
        {
         "hovertemplate": "@Amy Haible Right, because women never elect<br>people who fund and start wars, they never get<br>elected and vote to support war, they never<br>support their husbands fighting, nor join the<br>military themselves, nor detonate suicide vests,<br>nor standby and tacitly support war by doing<br>nothing and benefiting from war.    They also<br>never build software apparently. Talk about<br>ignorant and sexist. There are very significant<br>numbers of women in software development,<br>including AI.",
         "hovertext": "@Amy Haible Right, because women never elect<br>people who fund and start wars, they never get<br>elected and vote to support war, they never<br>support their husbands fighting, nor join the<br>military themselves, nor detonate suicide vests,<br>nor standby and tacitly support war by doing<br>nothing and benefiting from war.    They also<br>never build software apparently. Talk about<br>ignorant and sexist. There are very significant<br>numbers of women in software development,<br>including AI.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.5116506814956665
         ],
         "y": [
          -0.16815750300884247
         ]
        },
        {
         "hovertemplate": "We’ve been living with social media feeds run by<br>an algorithm to divide us. No one stepped in. Now,<br>we’re worried that the bots will get smarter and<br>kill us off?  We’re already halfway there, why<br>stop now?",
         "hovertext": "We’ve been living with social media feeds run by<br>an algorithm to divide us. No one stepped in. Now,<br>we’re worried that the bots will get smarter and<br>kill us off?  We’re already halfway there, why<br>stop now?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.9313152432441711
         ],
         "y": [
          -0.08216779679059982
         ]
        },
        {
         "hovertemplate": "@David Esrati Because we’re halfway there and<br>halfway isn’t all the way.",
         "hovertext": "@David Esrati Because we’re halfway there and<br>halfway isn’t all the way.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9092690348625183
         ],
         "y": [
          -0.08025467395782471
         ]
        },
        {
         "hovertemplate": "“We want to work with the government to prevent<br>that from happening.”  Sure, until the AI folks<br>become major money don  ors to the political<br>system. Then the government will do the same thing<br>as they have with gun controls...absolutely<br>nothing!",
         "hovertext": "“We want to work with the government to prevent<br>that from happening.”  Sure, until the AI folks<br>become major money don  ors to the political<br>system. Then the government will do the same thing<br>as they have with gun controls...absolutely<br>nothing!",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.37490931153297424
         ],
         "y": [
          -0.9219138026237488
         ]
        },
        {
         "hovertemplate": "These Machine-Learning systems are not creative<br>beings. They are not beings at all. It is like<br>having a self-drive car or relying on an<br>airplane's autopilot. The threat they pose is more<br>toward the political and economic structures built<br>around us. They will continue to be manipulated by<br>those who have access to large fountains of data<br>and media dissemination causing disruptions in<br>ancillary human activity but not really in<br>position to affect humans in a direct manner. It<br>is up to individuals to curb their own reliance on<br>automated systems and it begins with putting down<br>the device you carry. Treat it like an old<br>telephone--if it rings pick it up, otherwise leave<br>it alone. Same goes for watching TV; we are under<br>no obligation to tally a certain number of hours<br>watching 'shows'. Think about it: If you ignore<br>'Bleak TV' and place your portable on silent, what<br>exactly are you losing ?   We CAN ignore AI. Let<br>the tech-bros finger their worry-beads; they are<br>the one's with the most to lose.  Their minds have<br>been set on a fantasy life on a private island<br>with a harem of female sex-bots. Lucky chaps to be<br>so rich, but hardly the Einsteins of our era.   Be<br>thankful that the DOD and DOE still use antique<br>computers and telephone systems for our nuclear<br>arsenal. Now you know why.",
         "hovertext": "These Machine-Learning systems are not creative<br>beings. They are not beings at all. It is like<br>having a self-drive car or relying on an<br>airplane's autopilot. The threat they pose is more<br>toward the political and economic structures built<br>around us. They will continue to be manipulated by<br>those who have access to large fountains of data<br>and media dissemination causing disruptions in<br>ancillary human activity but not really in<br>position to affect humans in a direct manner. It<br>is up to individuals to curb their own reliance on<br>automated systems and it begins with putting down<br>the device you carry. Treat it like an old<br>telephone--if it rings pick it up, otherwise leave<br>it alone. Same goes for watching TV; we are under<br>no obligation to tally a certain number of hours<br>watching 'shows'. Think about it: If you ignore<br>'Bleak TV' and place your portable on silent, what<br>exactly are you losing ?   We CAN ignore AI. Let<br>the tech-bros finger their worry-beads; they are<br>the one's with the most to lose.  Their minds have<br>been set on a fantasy life on a private island<br>with a harem of female sex-bots. Lucky chaps to be<br>so rich, but hardly the Einsteins of our era.   Be<br>thankful that the DOD and DOE still use antique<br>computers and telephone systems for our nuclear<br>arsenal. Now you know why.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.17314572632312775
         ],
         "y": [
          0.8022888898849487
         ]
        },
        {
         "hovertemplate": "@Alejandro Wilson  the threats to political and<br>economic structures are vast.",
         "hovertext": "@Alejandro Wilson  the threats to political and<br>economic structures are vast.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.17143091559410095
         ],
         "y": [
          0.7921874523162842
         ]
        },
        {
         "hovertemplate": "\"Some skeptics argue that A.I. technology is still<br>too immature to pose an existential threat. When<br>it comes to today’s A.I. systems, they worry more<br>about short-term problems, such as biased and<br>incorrect responses, than longer-term dangers.\"<br>You really should expand on this information,<br>which is critical immediately. Your statement<br>tends to minimize the effects of biased AI on<br>people's daily lives.",
         "hovertext": "\"Some skeptics argue that A.I. technology is still<br>too immature to pose an existential threat. When<br>it comes to today’s A.I. systems, they worry more<br>about short-term problems, such as biased and<br>incorrect responses, than longer-term dangers.\"<br>You really should expand on this information,<br>which is critical immediately. Your statement<br>tends to minimize the effects of biased AI on<br>people's daily lives.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8791898488998413
         ],
         "y": [
          -0.11446963995695114
         ]
        },
        {
         "hovertemplate": "@marchfor sanity,    1. No article can cover<br>everything.    2. It may be that the \"effects of<br>biased AI on people's daily lives\" is positive on<br>the whole. That is, the biases of AI systems may<br>be less harmful than those of the systems they<br>replace.    3. It is much easier to improve AI<br>than to improve people.    4. March against the<br>insanity of rejecting harm-reducing AI systems on<br>the basis of imperfection.",
         "hovertext": "@marchfor sanity,    1. No article can cover<br>everything.    2. It may be that the \"effects of<br>biased AI on people's daily lives\" is positive on<br>the whole. That is, the biases of AI systems may<br>be less harmful than those of the systems they<br>replace.    3. It is much easier to improve AI<br>than to improve people.    4. March against the<br>insanity of rejecting harm-reducing AI systems on<br>the basis of imperfection.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.8731286525726318
         ],
         "y": [
          -0.1205846443772316
         ]
        },
        {
         "hovertemplate": "Oh, is that so? Then why are they continuing to<br>line their pockets by developing this technology?<br>Maybe they’re gambling that they’ll be long since<br>dead by the time their predictions come to pass,<br>but I wouldn’t be so sure.",
         "hovertext": "Oh, is that so? Then why are they continuing to<br>line their pockets by developing this technology?<br>Maybe they’re gambling that they’ll be long since<br>dead by the time their predictions come to pass,<br>but I wouldn’t be so sure.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.48345449566841125
         ],
         "y": [
          0.7532103061676025
         ]
        },
        {
         "hovertemplate": "“Stop me before I kill again?”  These people want<br>all the wealth and power that AI will generate,<br>but they want none of the responsibility.  None of<br>them offered to unilaterally slow down<br>development, nor to pour massive amounts of money<br>into combatting or controlling AI.  It’s nice to<br>see some flickers of a conscience, but these very-<br>clever-but-not-excessively-wise people do not make<br>me optimistic.  Worst is Musk, who backs the chaos<br>party and also asks for government to prevent<br>chaos.",
         "hovertext": "“Stop me before I kill again?”  These people want<br>all the wealth and power that AI will generate,<br>but they want none of the responsibility.  None of<br>them offered to unilaterally slow down<br>development, nor to pour massive amounts of money<br>into combatting or controlling AI.  It’s nice to<br>see some flickers of a conscience, but these very-<br>clever-but-not-excessively-wise people do not make<br>me optimistic.  Worst is Musk, who backs the chaos<br>party and also asks for government to prevent<br>chaos.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2087363302707672
         ],
         "y": [
          -0.8708375096321106
         ]
        },
        {
         "hovertemplate": "Like tech executives that won’t let their kids on<br>YouTube or social media, but continue develop and<br>profit from these harmful platforms.",
         "hovertext": "Like tech executives that won’t let their kids on<br>YouTube or social media, but continue develop and<br>profit from these harmful platforms.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.20287899672985077
         ],
         "y": [
          -0.8475753664970398
         ]
        },
        {
         "hovertemplate": "@Person 27     Typical American style capitalism.<br>Now that the big boys have control of an important<br>technology, they want government regulations to<br>keep smaller innovative companies out and from<br>developing AI without their consent. Just like any<br>other industry in America.",
         "hovertext": "@Person 27     Typical American style capitalism.<br>Now that the big boys have control of an important<br>technology, they want government regulations to<br>keep smaller innovative companies out and from<br>developing AI without their consent. Just like any<br>other industry in America.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.21408170461654663
         ],
         "y": [
          -0.8912492394447327
         ]
        },
        {
         "hovertemplate": "the hypocrisy of “industry leaders” is revolting.<br>If it is so dangerous why release it to the<br>general public and not keep it in the lab until<br>regulations are in place? Are they asking for<br>regulations so that they can write them themselves<br>and establish and protect their monopolies?",
         "hovertext": "the hypocrisy of “industry leaders” is revolting.<br>If it is so dangerous why release it to the<br>general public and not keep it in the lab until<br>regulations are in place? Are they asking for<br>regulations so that they can write them themselves<br>and establish and protect their monopolies?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.8799858093261719
         ],
         "y": [
          0.515848696231842
         ]
        },
        {
         "hovertemplate": "AI execs are confronting the ultimate conflict of<br>interest. They can't stop building this means of<br>destroying the world because it's too lucrative.",
         "hovertext": "AI execs are confronting the ultimate conflict of<br>interest. They can't stop building this means of<br>destroying the world because it's too lucrative.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.18372173607349396
         ],
         "y": [
          -0.9004362225532532
         ]
        },
        {
         "hovertemplate": "I don’t think there is a contradiction between AI<br>leaders developing AI while at the same time<br>asking for regulation because they have to<br>continue developing it, even though they think<br>it’s dangerous. They have to because of the<br>military potential of AI and because other<br>countries, like China, are developing it.<br>Developing AI has been compared to an arms race,<br>and the US can’t just quit the race. If other<br>countries had AI and we didn’t, we would also fall<br>behind economically. They are right in asking for<br>international regulation—all countries need to<br>agree to slow down the race.",
         "hovertext": "I don’t think there is a contradiction between AI<br>leaders developing AI while at the same time<br>asking for regulation because they have to<br>continue developing it, even though they think<br>it’s dangerous. They have to because of the<br>military potential of AI and because other<br>countries, like China, are developing it.<br>Developing AI has been compared to an arms race,<br>and the US can’t just quit the race. If other<br>countries had AI and we didn’t, we would also fall<br>behind economically. They are right in asking for<br>international regulation—all countries need to<br>agree to slow down the race.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.0222371406853199
         ],
         "y": [
          0.913120448589325
         ]
        },
        {
         "hovertemplate": "In 1999, I remember my friends hotly debating<br>whether buying a mobile (i.e. \"cell\") phone was<br>worth it.  I was adamant that I would not and<br>remember the reason I gave - that I could think of<br>nothing worse than being able to be contacted all<br>the time.    I don't think that version of me<br>would even recognise 'smart phone' me.      And it<br>turns out that is just the beginning - now the<br>planet is handing itself over to tech.",
         "hovertext": "In 1999, I remember my friends hotly debating<br>whether buying a mobile (i.e. \"cell\") phone was<br>worth it.  I was adamant that I would not and<br>remember the reason I gave - that I could think of<br>nothing worse than being able to be contacted all<br>the time.    I don't think that version of me<br>would even recognise 'smart phone' me.      And it<br>turns out that is just the beginning - now the<br>planet is handing itself over to tech.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.10449626296758652
         ],
         "y": [
          -0.8378106951713562
         ]
        },
        {
         "hovertemplate": "@Joe     Hey Joe - When I was in IT 30+ years ago,<br>we called cell phones an electronic leash. But,<br>those people were significantly different -<br>independent, self sufficient. Today's kids are<br>raised by people who never knew life without<br>digital technology. It has a dazzling,<br>irresistible quality. Magic. People don't see it.<br>Westerners, Americans in particular, are an easy<br>mark, easily indoctrinated. Your last sentence<br>sums it up; down the slippery slope.",
         "hovertext": "@Joe     Hey Joe - When I was in IT 30+ years ago,<br>we called cell phones an electronic leash. But,<br>those people were significantly different -<br>independent, self sufficient. Today's kids are<br>raised by people who never knew life without<br>digital technology. It has a dazzling,<br>irresistible quality. Magic. People don't see it.<br>Westerners, Americans in particular, are an easy<br>mark, easily indoctrinated. Your last sentence<br>sums it up; down the slippery slope.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.10548495501279831
         ],
         "y": [
          -0.8474263548851013
         ]
        },
        {
         "hovertemplate": "Anytime a new technology comes around, there are<br>always those who think it means the end of the<br>world. Gimme a break!    - Radio will kill print<br>- TV will kill radio  - Rock-n-roll will destroy<br>the youth of America  - The Internet will destroy<br>everyone    Now comes the AI. The latest \"it will<br>destroy mankind\" mantra from those who have<br>nothing better to do but predict (once again) that<br>the sky is falling.    AI will not destroy the<br>world. Nor will it cause nuclear war. Nor will<br>everyone lose their jobs because of AI.     Yes,<br>jobs will be lost, but life will go on. People<br>will learn to adapt, change, train and learn new<br>things. Everyone just needs to breathe, relax and<br>move on.",
         "hovertext": "Anytime a new technology comes around, there are<br>always those who think it means the end of the<br>world. Gimme a break!    - Radio will kill print<br>- TV will kill radio  - Rock-n-roll will destroy<br>the youth of America  - The Internet will destroy<br>everyone    Now comes the AI. The latest \"it will<br>destroy mankind\" mantra from those who have<br>nothing better to do but predict (once again) that<br>the sky is falling.    AI will not destroy the<br>world. Nor will it cause nuclear war. Nor will<br>everyone lose their jobs because of AI.     Yes,<br>jobs will be lost, but life will go on. People<br>will learn to adapt, change, train and learn new<br>things. Everyone just needs to breathe, relax and<br>move on.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5252882838249207
         ],
         "y": [
          0.5082417726516724
         ]
        },
        {
         "hovertemplate": "@Zeke You clearly have read *nothing* from anyone<br>who actually knows better as to how these<br>calamities could happen. Comparing AI to radio and<br>TV is absurd.  Start here and educate yourself on<br>why this is not the same ol' same ol' technology<br>alarm:  <a href=\"https://80000hours.org/problem-<br>profiles/artificial-intelligence\"<br>target=\"_blank\">https://80000hours.org/problem-<br>profiles/artificial-intelligence</a>/",
         "hovertext": "@Zeke You clearly have read *nothing* from anyone<br>who actually knows better as to how these<br>calamities could happen. Comparing AI to radio and<br>TV is absurd.  Start here and educate yourself on<br>why this is not the same ol' same ol' technology<br>alarm:  <a href=\"https://80000hours.org/problem-<br>profiles/artificial-intelligence\"<br>target=\"_blank\">https://80000hours.org/problem-<br>profiles/artificial-intelligence</a>/",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.5350111126899719
         ],
         "y": [
          0.5145244002342224
         ]
        },
        {
         "hovertemplate": "@Zeke   One subtle nuance: this is not coming from<br>idle “the world is ending” nuts with picket signs.<br>This is coming from the people who are overseeing<br>and developing the very technology they are<br>warning us about.    Unlike the technologies and<br>cultural waves you cite, AI plugged into media<br>networks, financial systems, and (God help us but<br>it is happening) military response systems could<br>actually soften the ground and destroy life as we<br>know it. It does not care if it survives, should<br>it choose for us not to survive.",
         "hovertext": "@Zeke   One subtle nuance: this is not coming from<br>idle “the world is ending” nuts with picket signs.<br>This is coming from the people who are overseeing<br>and developing the very technology they are<br>warning us about.    Unlike the technologies and<br>cultural waves you cite, AI plugged into media<br>networks, financial systems, and (God help us but<br>it is happening) military response systems could<br>actually soften the ground and destroy life as we<br>know it. It does not care if it survives, should<br>it choose for us not to survive.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5157106518745422
         ],
         "y": [
          0.5011254549026489
         ]
        },
        {
         "hovertemplate": "@Andrew - Come back and talk to me in 10-12 years.<br>I am not comparing AI to television. I am<br>comparing the reactions. It is clear you don't<br>know how to read my post. My money is on my<br>opinion. Nothing. I repeat, NOTHING, will happen",
         "hovertext": "@Andrew - Come back and talk to me in 10-12 years.<br>I am not comparing AI to television. I am<br>comparing the reactions. It is clear you don't<br>know how to read my post. My money is on my<br>opinion. Nothing. I repeat, NOTHING, will happen",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5475872159004211
         ],
         "y": [
          0.525614321231842
         ]
        },
        {
         "hovertemplate": "Calls for development moratoriums are closing the<br>barn door after the horse has bolted.    At the<br>very latest, the time to have this conversation<br>first was in the midst of the pandemic in 2020 or<br>2021.    The first most appropriate time was when<br>Microsoft had to take down the Tay chatbot, one of<br>the first rudimentary experiments in LLM models<br>that turned racist and psychopathic due to trolls.<br>As for the actual risks of the AI itself, those<br>should be self evident as it's no longer science<br>fiction: Large scale structural unemployment in<br>the economy with no plans or willingness to<br>substitute a universal basic income to help<br>transition through it, the loss of millions of<br>upper middle class and wealthy jobs (A CEO, CFO<br>and CTO are all more likely to lose jobs partially<br>or completely to AI than a helpdesk, network or<br>cybersecurity technician or most data center<br>workers)    And mass disinformation on a<br>population that has globally and on the whole<br>proven a willful refusal to display critical<br>thinking and allows libertarian sociopathic<br>technocrats to continue to get wealthy and exploit<br>people in ways they don't fully understand.<br>Financial analysts have also been using the<br>technology for a couple decades but at the rate of<br>development are at risk of being displaced<br>entirely. Crypto will become a bigger social<br>problem. Social media moderation also overly<br>relies on AI to scale rather than limiting the<br>growth of platforms reasonably to staff sizes.<br>The risks are there if you care to look.",
         "hovertext": "Calls for development moratoriums are closing the<br>barn door after the horse has bolted.    At the<br>very latest, the time to have this conversation<br>first was in the midst of the pandemic in 2020 or<br>2021.    The first most appropriate time was when<br>Microsoft had to take down the Tay chatbot, one of<br>the first rudimentary experiments in LLM models<br>that turned racist and psychopathic due to trolls.<br>As for the actual risks of the AI itself, those<br>should be self evident as it's no longer science<br>fiction: Large scale structural unemployment in<br>the economy with no plans or willingness to<br>substitute a universal basic income to help<br>transition through it, the loss of millions of<br>upper middle class and wealthy jobs (A CEO, CFO<br>and CTO are all more likely to lose jobs partially<br>or completely to AI than a helpdesk, network or<br>cybersecurity technician or most data center<br>workers)    And mass disinformation on a<br>population that has globally and on the whole<br>proven a willful refusal to display critical<br>thinking and allows libertarian sociopathic<br>technocrats to continue to get wealthy and exploit<br>people in ways they don't fully understand.<br>Financial analysts have also been using the<br>technology for a couple decades but at the rate of<br>development are at risk of being displaced<br>entirely. Crypto will become a bigger social<br>problem. Social media moderation also overly<br>relies on AI to scale rather than limiting the<br>growth of platforms reasonably to staff sizes.<br>The risks are there if you care to look.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6559670567512512
         ],
         "y": [
          0.11074750125408173
         ]
        },
        {
         "hovertemplate": "@Aaron McCrory True, the best time for the<br>conversation/moratorium might have been 2-3 years<br>ago.   But the second-best time is now.",
         "hovertext": "@Aaron McCrory True, the best time for the<br>conversation/moratorium might have been 2-3 years<br>ago.   But the second-best time is now.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6620767116546631
         ],
         "y": [
          0.10277193784713745
         ]
        },
        {
         "hovertemplate": "@Aaron McCrory mass disinformation and the loss of<br>the white collar class are definitely not things<br>to look forward to.",
         "hovertext": "@Aaron McCrory mass disinformation and the loss of<br>the white collar class are definitely not things<br>to look forward to.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.666490375995636
         ],
         "y": [
          0.11675538867712021
         ]
        },
        {
         "hovertemplate": "I was skeptical before, but considering the latest<br>large language models It now does look like AI<br>will be able to surpass any human in its breath of<br>knowledge and intelligence.     In view of all the<br>cognitively biases we have as humans, it would be<br>easy for a superintelligent AI system to slowly<br>push society in any direction it might want us to<br>go.     Populists have recently shown the way:<br>fake news, hand-picked facts without context, hot<br>button issues etc. Given an AI access to the<br>internet and it can make money and fund influence<br>campaigns (and even politicians). It is indeed<br>scary, as it could do all of that much more<br>consistently and for a much longer time than any<br>organized group of humans could.",
         "hovertext": "I was skeptical before, but considering the latest<br>large language models It now does look like AI<br>will be able to surpass any human in its breath of<br>knowledge and intelligence.     In view of all the<br>cognitively biases we have as humans, it would be<br>easy for a superintelligent AI system to slowly<br>push society in any direction it might want us to<br>go.     Populists have recently shown the way:<br>fake news, hand-picked facts without context, hot<br>button issues etc. Given an AI access to the<br>internet and it can make money and fund influence<br>campaigns (and even politicians). It is indeed<br>scary, as it could do all of that much more<br>consistently and for a much longer time than any<br>organized group of humans could.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.24009732902050018
         ],
         "y": [
          -0.8302198052406311
         ]
        },
        {
         "hovertemplate": "Consider the absurdity of the leaders of major<br>companies involved in furiously competing with<br>each other to develop AI warning the rest of us<br>that what they are doing might soon kill us all.<br>The problem here isn’t AI. The problem is<br>capitalism. The problem is a system in which the<br>profit imperative is so powerful that the people<br>supposedly in charge describe themselves as<br>essentially enslaved to it and unable to refrain<br>from acting in a manner likely to have<br>catastrophic results.    AI is certainly a menace.<br>But so is what producers of nuclear weapons and<br>the oil and gas industry do. Where are the<br>collective pleas of their industry leaders to stop<br>them before they kill us all? Not to even mention<br>the many other industries responsible for mass,<br>but non-apocalyptic, misery, suffering and death.<br>The chief difference here seems to be that AI has<br>developed so quickly that it hasn’t had time to<br>weed the people with consciences out of<br>leadership. I have little doubt that this<br>particular “bug” will get fixed quickly enough and<br>our full speed charge towards the abyss will be<br>spared further interruptions.    It has become<br>clear that capitalism is incompatible not only<br>with democracy, but with human survival. Anybody<br>at this point who thinks we are going to get out<br>of our current horrifying predicaments without a<br>titanic and bloody struggle to overthrow the 1% is<br>fooling themselves.",
         "hovertext": "Consider the absurdity of the leaders of major<br>companies involved in furiously competing with<br>each other to develop AI warning the rest of us<br>that what they are doing might soon kill us all.<br>The problem here isn’t AI. The problem is<br>capitalism. The problem is a system in which the<br>profit imperative is so powerful that the people<br>supposedly in charge describe themselves as<br>essentially enslaved to it and unable to refrain<br>from acting in a manner likely to have<br>catastrophic results.    AI is certainly a menace.<br>But so is what producers of nuclear weapons and<br>the oil and gas industry do. Where are the<br>collective pleas of their industry leaders to stop<br>them before they kill us all? Not to even mention<br>the many other industries responsible for mass,<br>but non-apocalyptic, misery, suffering and death.<br>The chief difference here seems to be that AI has<br>developed so quickly that it hasn’t had time to<br>weed the people with consciences out of<br>leadership. I have little doubt that this<br>particular “bug” will get fixed quickly enough and<br>our full speed charge towards the abyss will be<br>spared further interruptions.    It has become<br>clear that capitalism is incompatible not only<br>with democracy, but with human survival. Anybody<br>at this point who thinks we are going to get out<br>of our current horrifying predicaments without a<br>titanic and bloody struggle to overthrow the 1% is<br>fooling themselves.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.14359280467033386
         ],
         "y": [
          0.1783556342124939
         ]
        },
        {
         "hovertemplate": "@Christopher  Weed the people without conscience<br>out of leadership?    Such a thing is not possible",
         "hovertext": "@Christopher  Weed the people without conscience<br>out of leadership?    Such a thing is not possible",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.130953848361969
         ],
         "y": [
          0.1850578635931015
         ]
        },
        {
         "hovertemplate": "@Christopher Revolutions do not result in better<br>social systems. Look at the revolutions in Russia<br>and China.",
         "hovertext": "@Christopher Revolutions do not result in better<br>social systems. Look at the revolutions in Russia<br>and China.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.17376573383808136
         ],
         "y": [
          0.16002406179904938
         ]
        },
        {
         "hovertemplate": "@Christopher Couldn't have said it better. Thanks<br>for your comment.",
         "hovertext": "@Christopher Couldn't have said it better. Thanks<br>for your comment.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1278735250234604
         ],
         "y": [
          0.17590875923633575
         ]
        },
        {
         "hovertemplate": "@Green Many times they fail, true.     And even<br>more in modern times.     But instead of Russia<br>and China, I prefer to look at the American and<br>French Revolutions.     One freed us from kings<br>and monarchs. And the other one gave us the human<br>rights, and freedom of speech.     Capitalism<br>needs to be revised. No need to throw the baby<br>with the bathwater, but right now, baby is<br>drowning.     Companies are not humans. And we do<br>not exist to serve a CEO, a board of directors, or<br>Wall Street. But this is exactly what is<br>happening.     \"We are thinking in Star Trek, but<br>the 1% are thinking in Dune\".",
         "hovertext": "@Green Many times they fail, true.     And even<br>more in modern times.     But instead of Russia<br>and China, I prefer to look at the American and<br>French Revolutions.     One freed us from kings<br>and monarchs. And the other one gave us the human<br>rights, and freedom of speech.     Capitalism<br>needs to be revised. No need to throw the baby<br>with the bathwater, but right now, baby is<br>drowning.     Companies are not humans. And we do<br>not exist to serve a CEO, a board of directors, or<br>Wall Street. But this is exactly what is<br>happening.     \"We are thinking in Star Trek, but<br>the 1% are thinking in Dune\".",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.19168399274349213
         ],
         "y": [
          0.16136954724788666
         ]
        },
        {
         "hovertemplate": "@Christopher   And of course there is no need to<br>invent a better system than hyper-capitalism. It<br>already exists in numerous, healthy and successful<br>countries. Its way past time to quit declaring<br>that \"those countries are different. There's<br>nothing to be learned from them.\" There is plenty<br>to be learned from economies that have created a<br>healthy balance between capitalistic and public<br>enterprise.",
         "hovertext": "@Christopher   And of course there is no need to<br>invent a better system than hyper-capitalism. It<br>already exists in numerous, healthy and successful<br>countries. Its way past time to quit declaring<br>that \"those countries are different. There's<br>nothing to be learned from them.\" There is plenty<br>to be learned from economies that have created a<br>healthy balance between capitalistic and public<br>enterprise.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1542547196149826
         ],
         "y": [
          0.19069840013980865
         ]
        },
        {
         "hovertemplate": "@Green   What is it that you think you know about<br>China? Russia? And the revolution in Cuba produced<br>a very positive result, despite capitalism, not<br>because of it. Of course what you think of this<br>comment depends entirely on where you get your<br>news. And by the way, the French were on the whole<br>pleased with their revolution, as were England’s<br>upstart colonies.",
         "hovertext": "@Green   What is it that you think you know about<br>China? Russia? And the revolution in Cuba produced<br>a very positive result, despite capitalism, not<br>because of it. Of course what you think of this<br>comment depends entirely on where you get your<br>news. And by the way, the French were on the whole<br>pleased with their revolution, as were England’s<br>upstart colonies.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.1788496971130371
         ],
         "y": [
          0.1455211639404297
         ]
        },
        {
         "hovertemplate": "@Green What about the American Revolution? Or is<br>America somehow the exception?",
         "hovertext": "@Green What about the American Revolution? Or is<br>America somehow the exception?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.18581780791282654
         ],
         "y": [
          0.15456277132034302
         ]
        },
        {
         "hovertemplate": "@Christopher   The problem is unprincipled people,<br>who are just as prevalent and powerful in<br>societies not identified as “capitalist.”  Stop<br>trying to piggyback your (faultiy) pet ideology on<br>every social issue.",
         "hovertext": "@Christopher   The problem is unprincipled people,<br>who are just as prevalent and powerful in<br>societies not identified as “capitalist.”  Stop<br>trying to piggyback your (faultiy) pet ideology on<br>every social issue.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.12179350852966309
         ],
         "y": [
          0.1976643204689026
         ]
        },
        {
         "hovertemplate": "@Green     Nothing personal, but this fallacious<br>knee-jerk argument is always trotted out whenever<br>urgent social issues require humans to act morally<br>rather than like dollar-consuming greed machines.<br>Every July 4th for almost 250 years the U.S. has<br>loudly celebrated a revolution that caused an<br>immensely better social system than the one that<br>preceded it.  This revolution was not predicated<br>on an economic system, but on the right of the<br>people (not corporations; the human kind) to<br>dictate the parameters of their own lives.<br>Socialism and capitalism can co-exist, and they<br>have done so both here (think Social Security and<br>Medicare), and in Western Europe.  It's all about<br>the balance, and the balance is currently skewed<br>far in favor of the god of money.      We are now<br>living in what seems to me to be a corpocractic<br>dictatorship in which the parameters (and,<br>relevant to AI, the viability) of our lives are<br>being dictated by the vociferous appetites of<br>corporate greed, and a public fed on the \"bread<br>and circuses\" - or \"entertainment and shopping\" -<br>used to distract us.    Corporations and<br>individuals should be regulated and required to<br>refrain from causing foreseeable harm  to society.<br>The fact that the leaders of these corporations<br>are warning us about human extinction is an<br>indication of just how foreseeable and serious a<br>harm AI is.",
         "hovertext": "@Green     Nothing personal, but this fallacious<br>knee-jerk argument is always trotted out whenever<br>urgent social issues require humans to act morally<br>rather than like dollar-consuming greed machines.<br>Every July 4th for almost 250 years the U.S. has<br>loudly celebrated a revolution that caused an<br>immensely better social system than the one that<br>preceded it.  This revolution was not predicated<br>on an economic system, but on the right of the<br>people (not corporations; the human kind) to<br>dictate the parameters of their own lives.<br>Socialism and capitalism can co-exist, and they<br>have done so both here (think Social Security and<br>Medicare), and in Western Europe.  It's all about<br>the balance, and the balance is currently skewed<br>far in favor of the god of money.      We are now<br>living in what seems to me to be a corpocractic<br>dictatorship in which the parameters (and,<br>relevant to AI, the viability) of our lives are<br>being dictated by the vociferous appetites of<br>corporate greed, and a public fed on the \"bread<br>and circuses\" - or \"entertainment and shopping\" -<br>used to distract us.    Corporations and<br>individuals should be regulated and required to<br>refrain from causing foreseeable harm  to society.<br>The fact that the leaders of these corporations<br>are warning us about human extinction is an<br>indication of just how foreseeable and serious a<br>harm AI is.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1904127299785614
         ],
         "y": [
          0.14967814087867737
         ]
        },
        {
         "hovertemplate": "@Pete     ...by which logic all socio/political<br>systems are equal? Should we then stop trying to<br>improve systems which are failing?  I'm glad<br>you're not designing airplanes. To my way of<br>thinking, capitalism is clearly failing, and I<br>welcome any new ideas about ways of organization<br>of human society, and permitting wealth to<br>accumulate.     How many programs do you see which<br>unironically exalt vast wealth and power? Surely<br>there's a reason.",
         "hovertext": "@Pete     ...by which logic all socio/political<br>systems are equal? Should we then stop trying to<br>improve systems which are failing?  I'm glad<br>you're not designing airplanes. To my way of<br>thinking, capitalism is clearly failing, and I<br>welcome any new ideas about ways of organization<br>of human society, and permitting wealth to<br>accumulate.     How many programs do you see which<br>unironically exalt vast wealth and power? Surely<br>there's a reason.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.10608286410570145
         ],
         "y": [
          0.21498411893844604
         ]
        },
        {
         "hovertemplate": "@Christopher I don't even think it's just<br>capitalism. This is humanity at its core. It's our<br>key trait and I guess our fatal flaw, the innate<br>drive to innovate and evolve. These folks might be<br>driven by money but it's also the power of being<br>the one to create this thing that no one has ever<br>created before and quite literally change the<br>world. The draw of that is too powerful.",
         "hovertext": "@Christopher I don't even think it's just<br>capitalism. This is humanity at its core. It's our<br>key trait and I guess our fatal flaw, the innate<br>drive to innovate and evolve. These folks might be<br>driven by money but it's also the power of being<br>the one to create this thing that no one has ever<br>created before and quite literally change the<br>world. The draw of that is too powerful.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.14481887221336365
         ],
         "y": [
          0.20205974578857422
         ]
        },
        {
         "hovertemplate": "@Christopher   AI is not a product of capitalism.<br>nor is capitalism the issue that propels the drive<br>for ANY new technology.  Technological advances<br>occur within all societal types, EVEN IF IT IS<br>accelerated in a merit based/winner take all<br>economic system.         you're high-jacking a<br>important discussion re: AGI to make a point on an<br>unrelated, personal itch.",
         "hovertext": "@Christopher   AI is not a product of capitalism.<br>nor is capitalism the issue that propels the drive<br>for ANY new technology.  Technological advances<br>occur within all societal types, EVEN IF IT IS<br>accelerated in a merit based/winner take all<br>economic system.         you're high-jacking a<br>important discussion re: AGI to make a point on an<br>unrelated, personal itch.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1335379034280777
         ],
         "y": [
          0.1683427393436432
         ]
        },
        {
         "hovertemplate": "@M The draw of \"being the one to create this<br>thing\" is too powerful for whom - men?",
         "hovertext": "@M The draw of \"being the one to create this<br>thing\" is too powerful for whom - men?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.14172786474227905
         ],
         "y": [
          0.21717685461044312
         ]
        },
        {
         "hovertemplate": "You speak truth to power. I’m saying this kind of<br>thing all the time - you put it so eloquently.<br>Thank you.",
         "hovertext": "You speak truth to power. I’m saying this kind of<br>thing all the time - you put it so eloquently.<br>Thank you.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.14265897870063782
         ],
         "y": [
          0.16452230513095856
         ]
        },
        {
         "hovertemplate": "@Green What about France and England and…the<br>United States?",
         "hovertext": "@Green What about France and England and…the<br>United States?",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.1864471733570099
         ],
         "y": [
          0.1693904548883438
         ]
        },
        {
         "hovertemplate": "@Christopher   Thank you for this comment and for<br>speaking to the larger picture. Capitalism, as<br>it's currently practiced, is incompatible with<br>environmental and human health, human rights and<br>freedom, equality, stability, and is increasingly<br>politically authoritarian.",
         "hovertext": "@Christopher   Thank you for this comment and for<br>speaking to the larger picture. Capitalism, as<br>it's currently practiced, is incompatible with<br>environmental and human health, human rights and<br>freedom, equality, stability, and is increasingly<br>politically authoritarian.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.15206781029701233
         ],
         "y": [
          0.16914552450180054
         ]
        },
        {
         "hovertemplate": "@M   Innovation and evolution do not require<br>destruction. There are plenty of creative people<br>who work hard to be the first to write a new song,<br>or a new novel, or direct a new movie. Those<br>people change the world and no one has to die for<br>them to do it.",
         "hovertext": "@M   Innovation and evolution do not require<br>destruction. There are plenty of creative people<br>who work hard to be the first to write a new song,<br>or a new novel, or direct a new movie. Those<br>people change the world and no one has to die for<br>them to do it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.15262942016124725
         ],
         "y": [
          0.21659329533576965
         ]
        },
        {
         "hovertemplate": "@Christopher Oh, spare me the lamentation about<br>capitalism. Clearly you have not experienced<br>socialism, communism, autocracies, or any other<br>type of societal structure. If you had, you would<br>know that capitalism is by far the best we have.<br>I hate it when people who have spent their whole<br>life spoilt by a well functioning capitalist<br>society complain about it without having a clue<br>about alternatives.  Also, the dangers of AI have<br>nothing to do with capitalism. You think you'd be<br>safer if North Korea was the leader in AI?",
         "hovertext": "@Christopher Oh, spare me the lamentation about<br>capitalism. Clearly you have not experienced<br>socialism, communism, autocracies, or any other<br>type of societal structure. If you had, you would<br>know that capitalism is by far the best we have.<br>I hate it when people who have spent their whole<br>life spoilt by a well functioning capitalist<br>society complain about it without having a clue<br>about alternatives.  Also, the dangers of AI have<br>nothing to do with capitalism. You think you'd be<br>safer if North Korea was the leader in AI?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.14181078970432281
         ],
         "y": [
          0.1903928965330124
         ]
        },
        {
         "hovertemplate": "@Giselle   I apologize for failing to cease<br>thinking about history and human nature after<br>reading that book published in 1867.",
         "hovertext": "@Giselle   I apologize for failing to cease<br>thinking about history and human nature after<br>reading that book published in 1867.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.09656600654125214
         ],
         "y": [
          0.22884289920330048
         ]
        },
        {
         "hovertemplate": "@Christopher Unfettered capitalism is the problem.<br>Humans have been capitalists since we exchanged<br>tools for pelts.",
         "hovertext": "@Christopher Unfettered capitalism is the problem.<br>Humans have been capitalists since we exchanged<br>tools for pelts.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.15728843212127686
         ],
         "y": [
          0.18186378479003906
         ]
        },
        {
         "hovertemplate": "When so few of our lawmakers understand how<br>algorithms work, I’m not certain that they will<br>understand the nuances of AI. To be fair that’s<br>the general public as well, which means that even<br>campaigning for legislation on it will be<br>difficult. So how do these scientists",
         "hovertext": "When so few of our lawmakers understand how<br>algorithms work, I’m not certain that they will<br>understand the nuances of AI. To be fair that’s<br>the general public as well, which means that even<br>campaigning for legislation on it will be<br>difficult. So how do these scientists",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9402556419372559
         ],
         "y": [
          -0.03778783231973648
         ]
        },
        {
         "hovertemplate": "A real risk could be that AI might be used in<br>conjunction with existing technologies such as<br>nuclear weaponry. For example, an evil actor using<br>AI to create an artificial scenario or manipulate<br>existing security networks that would cause a<br>nuclear launch. My son thinks I’m paranoid, but I<br>see a distinct possibility when AI becomes<br>slightly more advanced . . .",
         "hovertext": "A real risk could be that AI might be used in<br>conjunction with existing technologies such as<br>nuclear weaponry. For example, an evil actor using<br>AI to create an artificial scenario or manipulate<br>existing security networks that would cause a<br>nuclear launch. My son thinks I’m paranoid, but I<br>see a distinct possibility when AI becomes<br>slightly more advanced . . .",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.9835118055343628
         ],
         "y": [
          0.24398285150527954
         ]
        },
        {
         "hovertemplate": "They need the regulations to reign in their<br>“shareholder value” mandate. Legally they can do<br>nothing to stop this juggernaut to doom because of<br>the society destroying corporate requirement that<br>they only consider what’s best for shareholders.<br>Harm to society must be considered before<br>“shareholder value,” and the laws must be changed<br>to allow that. Society is slowly being destroyed<br>by this misguided mandate. It has infected<br>healthcare, air travel, housing, and the food<br>supply—every industry.",
         "hovertext": "They need the regulations to reign in their<br>“shareholder value” mandate. Legally they can do<br>nothing to stop this juggernaut to doom because of<br>the society destroying corporate requirement that<br>they only consider what’s best for shareholders.<br>Harm to society must be considered before<br>“shareholder value,” and the laws must be changed<br>to allow that. Society is slowly being destroyed<br>by this misguided mandate. It has infected<br>healthcare, air travel, housing, and the food<br>supply—every industry.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9119396209716797
         ],
         "y": [
          -0.2959056794643402
         ]
        },
        {
         "hovertemplate": "One statement, over 50 years ago, I think,<br>captures the problem: \"I'm Sorry Dave, I'm Afraid<br>I Can't Do That.\"",
         "hovertext": "One statement, over 50 years ago, I think,<br>captures the problem: \"I'm Sorry Dave, I'm Afraid<br>I Can't Do That.\"",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.21722206473350525
         ],
         "y": [
          -0.38121482729911804
         ]
        },
        {
         "hovertemplate": "@Dr. OutreAmour   Remember that is fiction and<br>fiction requires conflict. It is not realistic.",
         "hovertext": "@Dr. OutreAmour   Remember that is fiction and<br>fiction requires conflict. It is not realistic.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.20688937604427338
         ],
         "y": [
          -0.39023154973983765
         ]
        },
        {
         "hovertemplate": "@Emmanations I wish I had your optimism.",
         "hovertext": "@Emmanations I wish I had your optimism.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.2065499722957611
         ],
         "y": [
          -0.40410083532333374
         ]
        },
        {
         "hovertemplate": "@Dr. OutreAmour   Many commenters seem to think<br>the possible threat here is about bad content from<br>chatty AIs. Not so. Dr OutreAmour's  comment is<br>directly on point.",
         "hovertext": "@Dr. OutreAmour   Many commenters seem to think<br>the possible threat here is about bad content from<br>chatty AIs. Not so. Dr OutreAmour's  comment is<br>directly on point.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.23075935244560242
         ],
         "y": [
          -0.3777788281440735
         ]
        },
        {
         "hovertemplate": "@Bob in Boston Yep I agree, but its both true that<br>bad content is the immediate threat and hal 9000<br>(who was a wonderful conversation partner and<br>singer BTW) is the logical extinction threat.",
         "hovertext": "@Bob in Boston Yep I agree, but its both true that<br>bad content is the immediate threat and hal 9000<br>(who was a wonderful conversation partner and<br>singer BTW) is the logical extinction threat.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.243149071931839
         ],
         "y": [
          -0.3831672668457031
         ]
        },
        {
         "hovertemplate": "@Dr. OutreAmour Someone should do this fun<br>experiment:  Set up a cooperative video game with<br>a real human and some kind of AI.  Maybe its a<br>spaceship game where you go to saturn ;).  Give<br>the AI the capability to eliminate the human from<br>the game somehow (indirectly) and observe under<br>what conditions it happens.",
         "hovertext": "@Dr. OutreAmour Someone should do this fun<br>experiment:  Set up a cooperative video game with<br>a real human and some kind of AI.  Maybe its a<br>spaceship game where you go to saturn ;).  Give<br>the AI the capability to eliminate the human from<br>the game somehow (indirectly) and observe under<br>what conditions it happens.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2243434637784958
         ],
         "y": [
          -0.3932760953903198
         ]
        },
        {
         "hovertemplate": "darwin. survival of the fittest. if man has<br>evolved to the point that no natural events can<br>cause him to further evolve ( by bringing on new<br>environments that select for certain genetic<br>traits) then nature must do what it can to<br>continue evolution. technology is either the<br>newest form of evolution, or natures attempt to<br>bring on a new environment that selects certain<br>traits, i know not which.",
         "hovertext": "darwin. survival of the fittest. if man has<br>evolved to the point that no natural events can<br>cause him to further evolve ( by bringing on new<br>environments that select for certain genetic<br>traits) then nature must do what it can to<br>continue evolution. technology is either the<br>newest form of evolution, or natures attempt to<br>bring on a new environment that selects certain<br>traits, i know not which.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.1795571744441986
         ],
         "y": [
          0.9718445539474487
         ]
        },
        {
         "hovertemplate": "This isn’t a force of nature. We can literally<br>stop developing this whenever we feel like it. A<br>society where there was actual democratic<br>participation in what we do economically  (worker<br>councils, consumer councils, etc.) this technology<br>would likely not exist but for only in limited<br>unnetworked circumstances for science and medical.<br>This “crisis” is purely a byproduct of capitalism<br>and its thirst to reduce operational costs.",
         "hovertext": "This isn’t a force of nature. We can literally<br>stop developing this whenever we feel like it. A<br>society where there was actual democratic<br>participation in what we do economically  (worker<br>councils, consumer councils, etc.) this technology<br>would likely not exist but for only in limited<br>unnetworked circumstances for science and medical.<br>This “crisis” is purely a byproduct of capitalism<br>and its thirst to reduce operational costs.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3448876738548279
         ],
         "y": [
          -0.48921892046928406
         ]
        },
        {
         "hovertemplate": "@Charles From St. Louis not quite  you need to<br>learn more about it. It can already continue to<br>develop itself.",
         "hovertext": "@Charles From St. Louis not quite  you need to<br>learn more about it. It can already continue to<br>develop itself.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3472672998905182
         ],
         "y": [
          -0.4797307252883911
         ]
        },
        {
         "hovertemplate": "But the we here is not just the US it is the whole<br>world. China, India, too",
         "hovertext": "But the we here is not just the US it is the whole<br>world. China, India, too",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.33958837389945984
         ],
         "y": [
          -0.5002502202987671
         ]
        },
        {
         "hovertemplate": "@Charles From St. Louis  It is a force of nature<br>though. If human brains are not a natural product<br>of our physical universe, nothing is. Human greed<br>is unstoppable, just like a hurricane or tornado.<br>Mankind has no defense against greed or mob<br>mentality either one.",
         "hovertext": "@Charles From St. Louis  It is a force of nature<br>though. If human brains are not a natural product<br>of our physical universe, nothing is. Human greed<br>is unstoppable, just like a hurricane or tornado.<br>Mankind has no defense against greed or mob<br>mentality either one.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.35666000843048096
         ],
         "y": [
          -0.48825928568840027
         ]
        },
        {
         "hovertemplate": "@Charles From St. Louis I don't think this \"We\"<br>includes oh, lets say, North Korea, China or<br>Russia who are surely rushing to master this new<br>powerful technology.",
         "hovertext": "@Charles From St. Louis I don't think this \"We\"<br>includes oh, lets say, North Korea, China or<br>Russia who are surely rushing to master this new<br>powerful technology.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.35314804315567017
         ],
         "y": [
          -0.5019670724868774
         ]
        },
        {
         "hovertemplate": "I am one of those heretics who wonders if the<br>species of homo sapiens has run its course. Not<br>much to like about it IMO.",
         "hovertext": "I am one of those heretics who wonders if the<br>species of homo sapiens has run its course. Not<br>much to like about it IMO.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.932063639163971
         ],
         "y": [
          0.14078950881958008
         ]
        },
        {
         "hovertemplate": "Just unplug the computers.",
         "hovertext": "Just unplug the computers.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.7329003810882568
         ],
         "y": [
          -0.4013447165489197
         ]
        },
        {
         "hovertemplate": "That won’t work in todays distributed cloud<br>computing environment. AI can simply embed its<br>code in benign code across thousands of networks.<br>We would have to shut down the entire Internet.<br>Then when we restart, the AI will just keep<br>spreading as its programmed to do.",
         "hovertext": "That won’t work in todays distributed cloud<br>computing environment. AI can simply embed its<br>code in benign code across thousands of networks.<br>We would have to shut down the entire Internet.<br>Then when we restart, the AI will just keep<br>spreading as its programmed to do.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7470477819442749
         ],
         "y": [
          -0.40921831130981445
         ]
        },
        {
         "hovertemplate": "@bobby   I do believe that is their point: “The<br>Computers” are no longer boxes on a desk, or racks<br>in one building. They are not unpluggable.",
         "hovertext": "@bobby   I do believe that is their point: “The<br>Computers” are no longer boxes on a desk, or racks<br>in one building. They are not unpluggable.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7193542718887329
         ],
         "y": [
          -0.3937244415283203
         ]
        },
        {
         "hovertemplate": "I am certain that our leaders will get out in<br>front of this, just as they have with climate<br>change and mass shootings.",
         "hovertext": "I am certain that our leaders will get out in<br>front of this, just as they have with climate<br>change and mass shootings.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.14491668343544006
         ],
         "y": [
          -0.4415443241596222
         ]
        },
        {
         "hovertemplate": "@thebigmancat     Hah!    The other thing that<br>occurs to me, when I hear these creators and<br>promoters post up in Congress “begging” for<br>regulation…    I may not understand exactly why<br>they’re doing that, however I don’t believe for<br>even a single minute, that it is for the reasons<br>stated.    This isn’t exactly a parade of selfless<br>humanitarians! Doesn’t pass the smell test.",
         "hovertext": "@thebigmancat     Hah!    The other thing that<br>occurs to me, when I hear these creators and<br>promoters post up in Congress “begging” for<br>regulation…    I may not understand exactly why<br>they’re doing that, however I don’t believe for<br>even a single minute, that it is for the reasons<br>stated.    This isn’t exactly a parade of selfless<br>humanitarians! Doesn’t pass the smell test.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.13350069522857666
         ],
         "y": [
          -0.44033169746398926
         ]
        },
        {
         "hovertemplate": "@thebigmancat     Climate change only became an<br>issue of public concern more than a century after<br>the industrial revolution began and the economic<br>systems inherent in it had been ubiquitously<br>adopted. The inertia of our systems is what causes<br>such intense political gridlock around that issue.<br>AI has not yet had time to ingrain itself in any<br>of our systems, and luckily there is no amendment<br>which explicitly grants us a right to use such<br>technology. Not only that, but both parties have<br>soured on social media in recent years and have<br>acknowledged regulatory shortcomings in regards to<br>their initial approach to that (once burgeoning)<br>tech. I’m strangely optimistic about the prospect<br>of bipartisan AI regulation.",
         "hovertext": "@thebigmancat     Climate change only became an<br>issue of public concern more than a century after<br>the industrial revolution began and the economic<br>systems inherent in it had been ubiquitously<br>adopted. The inertia of our systems is what causes<br>such intense political gridlock around that issue.<br>AI has not yet had time to ingrain itself in any<br>of our systems, and luckily there is no amendment<br>which explicitly grants us a right to use such<br>technology. Not only that, but both parties have<br>soured on social media in recent years and have<br>acknowledged regulatory shortcomings in regards to<br>their initial approach to that (once burgeoning)<br>tech. I’m strangely optimistic about the prospect<br>of bipartisan AI regulation.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.13740964233875275
         ],
         "y": [
          -0.45264342427253723
         ]
        },
        {
         "hovertemplate": "Our leaders have gotten our in front of climate<br>change and mass shootings. The problem is that<br>upwards of 74 million voters, predominantly from<br>the white working class, haven’t, and there are<br>plenty of scoundrels comepeting for the votes of<br>the willfully ignorant by giving them what they<br>want.",
         "hovertext": "Our leaders have gotten our in front of climate<br>change and mass shootings. The problem is that<br>upwards of 74 million voters, predominantly from<br>the white working class, haven’t, and there are<br>plenty of scoundrels comepeting for the votes of<br>the willfully ignorant by giving them what they<br>want.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.15651658177375793
         ],
         "y": [
          -0.44768351316452026
         ]
        },
        {
         "hovertemplate": "@thebigmancat It's easy to pen such comments, but<br>have you contacted your elected representatives to<br>demand that they take action to get a handle on<br>this danger while we still can?",
         "hovertext": "@thebigmancat It's easy to pen such comments, but<br>have you contacted your elected representatives to<br>demand that they take action to get a handle on<br>this danger while we still can?",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.1479344218969345
         ],
         "y": [
          -0.45872366428375244
         ]
        },
        {
         "hovertemplate": "@Steve W  Actually no. I'm too busy penning such<br>comments.",
         "hovertext": "@Steve W  Actually no. I'm too busy penning such<br>comments.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.14888620376586914
         ],
         "y": [
          -0.47051113843917847
         ]
        },
        {
         "hovertemplate": "@thebigmancat   As with Covid, there will be a lot<br>of blame shifting, and little done when we could<br>have done something.  However, I have feeling AI<br>will make Covid look like a trifle.",
         "hovertext": "@thebigmancat   As with Covid, there will be a lot<br>of blame shifting, and little done when we could<br>have done something.  However, I have feeling AI<br>will make Covid look like a trifle.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.1542615443468094
         ],
         "y": [
          -0.4350850284099579
         ]
        },
        {
         "hovertemplate": "Artificial intelligence is a tool, not a threat.<br>With Trump trying to destroy American democracy<br>and Putin committing international war crimes<br>against Ukraine, we have bigger things to worry<br>about than AI.",
         "hovertext": "Artificial intelligence is a tool, not a threat.<br>With Trump trying to destroy American democracy<br>and Putin committing international war crimes<br>against Ukraine, we have bigger things to worry<br>about than AI.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.8086450099945068
         ],
         "y": [
          -0.49639710783958435
         ]
        },
        {
         "hovertemplate": "Doesn’t AI like any other machine have an on- and<br>off-button? The fear seems greatly exaggerated and<br>suspicious especially considering that it is being<br>touted by the inventors of AI. They seem like a<br>bunch of high school boys who are trying to play a<br>prank on the teacher. How dumb do they think we<br>are?",
         "hovertext": "Doesn’t AI like any other machine have an on- and<br>off-button? The fear seems greatly exaggerated and<br>suspicious especially considering that it is being<br>touted by the inventors of AI. They seem like a<br>bunch of high school boys who are trying to play a<br>prank on the teacher. How dumb do they think we<br>are?",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.11695229262113571
         ],
         "y": [
          0.5008319020271301
         ]
        },
        {
         "hovertemplate": "‘Pull the plug’ on what? In a distributed cloud<br>environment, AI could simply ‘piggyback’ hidden<br>inside other benign code over thousands of<br>servers. We would have to shut down every server<br>in the world. And when rebooted, the AI code just<br>keeps going on as nothing happened.",
         "hovertext": "‘Pull the plug’ on what? In a distributed cloud<br>environment, AI could simply ‘piggyback’ hidden<br>inside other benign code over thousands of<br>servers. We would have to shut down every server<br>in the world. And when rebooted, the AI code just<br>keeps going on as nothing happened.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.10263287276029587
         ],
         "y": [
          0.49972954392433167
         ]
        },
        {
         "hovertemplate": "@✍️ not really. In some ways it can turn itself on<br>if embedded in enough places.",
         "hovertext": "@✍️ not really. In some ways it can turn itself on<br>if embedded in enough places.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.11333031952381134
         ],
         "y": [
          0.5094937682151794
         ]
        },
        {
         "hovertemplate": "Listen to today's The Daily Podcast, which<br>interviews Geoffrey Hinton who has been working on<br>this for 50 years and just left his lucrative<br>position at Google to speak freely on this matter.",
         "hovertext": "Listen to today's The Daily Podcast, which<br>interviews Geoffrey Hinton who has been working on<br>this for 50 years and just left his lucrative<br>position at Google to speak freely on this matter.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.12339343875646591
         ],
         "y": [
          0.5157644152641296
         ]
        },
        {
         "hovertemplate": "@Jay Reardon   Then it could stupidly destroy<br>itself in the same way which is more likely<br>considering the stupidity of human beings<br>especially those who invent things which they<br>cannot control. Taking one look at Altman I see  a<br>high school kid who thinks he’s smarter than<br>anyone else but is really callow and immature.<br>Nothing he says can be trusted.",
         "hovertext": "@Jay Reardon   Then it could stupidly destroy<br>itself in the same way which is more likely<br>considering the stupidity of human beings<br>especially those who invent things which they<br>cannot control. Taking one look at Altman I see  a<br>high school kid who thinks he’s smarter than<br>anyone else but is really callow and immature.<br>Nothing he says can be trusted.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.09504030644893646
         ],
         "y": [
          0.51065993309021
         ]
        },
        {
         "hovertemplate": "@✍️   The biggest issue is: NO, AI doesn't have an<br>on-and-off-button as you think it should have. It<br>is so much interwoven with all technological<br>facilities in our civilization that you cannot<br>just switch it off, just like you cannot switch<br>off the internet without being able to turn the<br>clock backwards.   I recently tried to find a non-<br>wifi controller for a house illumination project.<br>Some Chinese products are still on the market, but<br>the vast bulk is designed to work with Siri, Alexa<br>& co.   This led me to a google search on \"how to<br>make your smart home dumb again\". 22 million<br>results showed up on \"how to make your dumb home<br>smart\", but none, nada, zilch exactly matched my<br>request. The only article I found was \"how to make<br>your smart TV dumb\", involving a technical<br>disconnect which would turn your  manufacturer's<br>warranty invalid.   To some future bilionaire<br>who's reading this: take your chance to get rich<br>by redesigning and manufacturing disconnected home<br>items - I guess there's a lot of folks out there<br>who would prefer not to be reported to marketing<br>or credit card companies on their habits and<br>purchases, or controlled by big AGI.  Just an<br>example: why didn't you install a smart smoke<br>detector in your living room? Because you like to<br>smoke a cigar after dinner? Expect a considerable<br>rise of your medical insurance plan fees.   Now<br>good luck with your on-off-switch.",
         "hovertext": "@✍️   The biggest issue is: NO, AI doesn't have an<br>on-and-off-button as you think it should have. It<br>is so much interwoven with all technological<br>facilities in our civilization that you cannot<br>just switch it off, just like you cannot switch<br>off the internet without being able to turn the<br>clock backwards.   I recently tried to find a non-<br>wifi controller for a house illumination project.<br>Some Chinese products are still on the market, but<br>the vast bulk is designed to work with Siri, Alexa<br>& co.   This led me to a google search on \"how to<br>make your smart home dumb again\". 22 million<br>results showed up on \"how to make your dumb home<br>smart\", but none, nada, zilch exactly matched my<br>request. The only article I found was \"how to make<br>your smart TV dumb\", involving a technical<br>disconnect which would turn your  manufacturer's<br>warranty invalid.   To some future bilionaire<br>who's reading this: take your chance to get rich<br>by redesigning and manufacturing disconnected home<br>items - I guess there's a lot of folks out there<br>who would prefer not to be reported to marketing<br>or credit card companies on their habits and<br>purchases, or controlled by big AGI.  Just an<br>example: why didn't you install a smart smoke<br>detector in your living room? Because you like to<br>smoke a cigar after dinner? Expect a considerable<br>rise of your medical insurance plan fees.   Now<br>good luck with your on-off-switch.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.12941278517246246
         ],
         "y": [
          0.5038565397262573
         ]
        },
        {
         "hovertemplate": "Boy do these guys want to write their own<br>legislation and lock everyone else out of the<br>market! Wow.",
         "hovertext": "Boy do these guys want to write their own<br>legislation and lock everyone else out of the<br>market! Wow.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8688568472862244
         ],
         "y": [
          -0.16352678835391998
         ]
        },
        {
         "hovertemplate": "\"Hey, we're building something that may one day<br>pose an existential threat to humanity and should<br>be considered a societal risk on par with<br>pandemics and nuclear wars.\"  So, why are you<br>creating it?",
         "hovertext": "\"Hey, we're building something that may one day<br>pose an existential threat to humanity and should<br>be considered a societal risk on par with<br>pandemics and nuclear wars.\"  So, why are you<br>creating it?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.4156067967414856
         ],
         "y": [
          0.2018127739429474
         ]
        },
        {
         "hovertemplate": "@BillyBaroo Because companies are falling over<br>themselves to buy it so they can for half or more<br>of their workforce and reap bigger profits. Oops,<br>I mean make their workers life easier",
         "hovertext": "@BillyBaroo Because companies are falling over<br>themselves to buy it so they can for half or more<br>of their workforce and reap bigger profits. Oops,<br>I mean make their workers life easier",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.41302919387817383
         ],
         "y": [
          0.19040359556674957
         ]
        },
        {
         "hovertemplate": "Two words: capitalism and greed. If we don’t do<br>it, China, Russia, etc. will",
         "hovertext": "Two words: capitalism and greed. If we don’t do<br>it, China, Russia, etc. will",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.4300577640533447
         ],
         "y": [
          0.20662079751491547
         ]
        },
        {
         "hovertemplate": "Why are they creating it? Because it is a<br>technology that will eventually create all new<br>technologies at maximum computational speed (a<br>speed that will increase exponentially as AI<br>systems devote attention to increasing<br>computational speed, itself). So if you’re not<br>first to market with this, the person or<br>government or corporate entity that beats you<br>there, even by mere seconds, will forever be out<br>of ahead of you technologically. It would be like<br>trying to catch up to something moving at the<br>speed of light, which is, of course, impossible.<br>And waiting in the wings, attempting to get to<br>this technology before the US and it’s businesses,<br>is Russia and China. Do you want them to be first<br>to market with the most powerful tool that humans<br>will ever create? I sure do not.     So, there’s<br>no choice but to go full speed ahead, even though<br>we may imperil the entire species in the process.<br>That’s why they are building it.",
         "hovertext": "Why are they creating it? Because it is a<br>technology that will eventually create all new<br>technologies at maximum computational speed (a<br>speed that will increase exponentially as AI<br>systems devote attention to increasing<br>computational speed, itself). So if you’re not<br>first to market with this, the person or<br>government or corporate entity that beats you<br>there, even by mere seconds, will forever be out<br>of ahead of you technologically. It would be like<br>trying to catch up to something moving at the<br>speed of light, which is, of course, impossible.<br>And waiting in the wings, attempting to get to<br>this technology before the US and it’s businesses,<br>is Russia and China. Do you want them to be first<br>to market with the most powerful tool that humans<br>will ever create? I sure do not.     So, there’s<br>no choice but to go full speed ahead, even though<br>we may imperil the entire species in the process.<br>That’s why they are building it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4174501299858093
         ],
         "y": [
          0.21639984846115112
         ]
        },
        {
         "hovertemplate": "@BillyBaroo Because of the incredible good that<br>this technology can do.  Human history has been a<br>story of the invention of new ways to manipulate<br>our environment and at the same time dealing with<br>the disruptions that these technologies inevitably<br>result in.      Capitalism and greed just drive<br>these advances more quickly - they'd happen in any<br>case. Our challenge is to keep our government<br>functional enough to be able to address these<br>challenges.",
         "hovertext": "@BillyBaroo Because of the incredible good that<br>this technology can do.  Human history has been a<br>story of the invention of new ways to manipulate<br>our environment and at the same time dealing with<br>the disruptions that these technologies inevitably<br>result in.      Capitalism and greed just drive<br>these advances more quickly - they'd happen in any<br>case. Our challenge is to keep our government<br>functional enough to be able to address these<br>challenges.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.4306982159614563
         ],
         "y": [
          0.19807304441928864
         ]
        },
        {
         "hovertemplate": "@BillyBaroo   One has to truly wonder why they are<br>creating something they can't, by their own<br>admission, control!",
         "hovertext": "@BillyBaroo   One has to truly wonder why they are<br>creating something they can't, by their own<br>admission, control!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4261118769645691
         ],
         "y": [
          0.2140847146511078
         ]
        },
        {
         "hovertemplate": "@BillyBaroo     \"So, why are you creating it?\"<br>As note many others, almost all human inventions<br>were first developed as weapons, AI no different;<br>if you do not lead AI development you stand to be<br>defeated, annihilated by those who have mastered<br>the new weaponry.    \"Only the paranoid survive.\"<br>– Andy Grove",
         "hovertext": "@BillyBaroo     \"So, why are you creating it?\"<br>As note many others, almost all human inventions<br>were first developed as weapons, AI no different;<br>if you do not lead AI development you stand to be<br>defeated, annihilated by those who have mastered<br>the new weaponry.    \"Only the paranoid survive.\"<br>– Andy Grove",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.42485639452934265
         ],
         "y": [
          0.1908881962299347
         ]
        },
        {
         "hovertemplate": "@BillyBaroo Anyone who has studied human history<br>with any attention realizes that we are vicious,<br>defensive, self-centered and prone to<br>rationalizing any horrific act.  This is not<br>martyrdom, but an accurate picture of humanity's<br>driving impulses.  It is why power corrupts, why<br>we crave \"justice\" and righteous payback, and why<br>the sweetest little old lady can turn into a<br>frothing harpy if the right stimulus is applied.<br>It's MAGA too.  Mankind needs a significant reboot<br>and if it requires the elimination of 90% of<br>humanity, it may be the only thing that can teach<br>us.  Perhaps replacement by AI is the only<br>solution and subconsciously these guys know it (or<br>at least can't stop themselves).",
         "hovertext": "@BillyBaroo Anyone who has studied human history<br>with any attention realizes that we are vicious,<br>defensive, self-centered and prone to<br>rationalizing any horrific act.  This is not<br>martyrdom, but an accurate picture of humanity's<br>driving impulses.  It is why power corrupts, why<br>we crave \"justice\" and righteous payback, and why<br>the sweetest little old lady can turn into a<br>frothing harpy if the right stimulus is applied.<br>It's MAGA too.  Mankind needs a significant reboot<br>and if it requires the elimination of 90% of<br>humanity, it may be the only thing that can teach<br>us.  Perhaps replacement by AI is the only<br>solution and subconsciously these guys know it (or<br>at least can't stop themselves).",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4058316648006439
         ],
         "y": [
          0.20840424299240112
         ]
        },
        {
         "hovertemplate": "“Mitigating the risk of extinction from A.I.<br>should be a global priority alongside other<br>societal-scale risks, such as pandemics and<br>nuclear war.\"    Sounds like a Trojan Horse<br>advertising campaign to me.  What better way to<br>drive development churn than to get everyone<br>believing you've invented a quantum nuclear weapon<br>capable of fracturing the space-time continuum in<br>the local system, flooding the area with matter<br>eating micro-black holes.       Until one of these<br>chatbots can get me a date with Esther Perel, I'm<br>not worried.",
         "hovertext": "“Mitigating the risk of extinction from A.I.<br>should be a global priority alongside other<br>societal-scale risks, such as pandemics and<br>nuclear war.\"    Sounds like a Trojan Horse<br>advertising campaign to me.  What better way to<br>drive development churn than to get everyone<br>believing you've invented a quantum nuclear weapon<br>capable of fracturing the space-time continuum in<br>the local system, flooding the area with matter<br>eating micro-black holes.       Until one of these<br>chatbots can get me a date with Esther Perel, I'm<br>not worried.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.563906192779541
         ],
         "y": [
          -0.7538105249404907
         ]
        },
        {
         "hovertemplate": "Honestly, this is just beyond... I mean the<br>mockumentary they'll make about the very people<br>building the thing they are declaring will ruin us<br>is writing itself in real time. Then again - who<br>can say - maybe this is part of AI's plan all<br>along...",
         "hovertext": "Honestly, this is just beyond... I mean the<br>mockumentary they'll make about the very people<br>building the thing they are declaring will ruin us<br>is writing itself in real time. Then again - who<br>can say - maybe this is part of AI's plan all<br>along...",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.840608537197113
         ],
         "y": [
          -0.39147457480430603
         ]
        },
        {
         "hovertemplate": "Anyone who caught the TikTok hearings understands<br>our unfortunate fate. There aren’t enough brain<br>cells in the halls of Congress to address this in<br>a meaningful way. And where there is a coherent<br>thought, there is a person bought and paid for by<br>a lobbyist.",
         "hovertext": "Anyone who caught the TikTok hearings understands<br>our unfortunate fate. There aren’t enough brain<br>cells in the halls of Congress to address this in<br>a meaningful way. And where there is a coherent<br>thought, there is a person bought and paid for by<br>a lobbyist.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.23908095061779022
         ],
         "y": [
          0.7413036227226257
         ]
        },
        {
         "hovertemplate": "@Annie Spot on, Annie. The older ones in Congress<br>can't even figure out Facebook, while many of the<br>younger ones are hellbent on destroying democracy.<br>And, as you stated, the few with enough between<br>their ears to sorta understand, have been bought<br>off. Utterly depressing!",
         "hovertext": "@Annie Spot on, Annie. The older ones in Congress<br>can't even figure out Facebook, while many of the<br>younger ones are hellbent on destroying democracy.<br>And, as you stated, the few with enough between<br>their ears to sorta understand, have been bought<br>off. Utterly depressing!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.23017935454845428
         ],
         "y": [
          0.7438498735427856
         ]
        },
        {
         "hovertemplate": "Very well put and I couldn’t agree more. I felt<br>the same way about the abilities of Congress after<br>watching Fed Chairman Powell answering questions<br>from the Finance Committee just  before SV Bank<br>collapsed.  A new Fed vice chairman had been<br>appointed who had been assigned the task of<br>reviewing the adequacy of the regulation of the<br>regional banks. A half a dozen of more<br>congressmen, obviously acting at the behest of<br>their local regional banks who opposed more<br>regulation, raised objection to this despite the<br>fact that the process had just begun very<br>informally, no decision had been made and might<br>never be made, but even the hint if it was to be<br>opposed. Within a couple days SV Bank had been<br>shut down, other banks were teetering, the stocks<br>of most of them had dropped by half and they were<br>all on life support provided by the Fed.     These<br>congressmen knew nothing about the affairs of the<br>regional banks they were speaking at the behest<br>of. The public good was not a consideration .<br>Congress will not solve Americas problems. It is<br>the problem.",
         "hovertext": "Very well put and I couldn’t agree more. I felt<br>the same way about the abilities of Congress after<br>watching Fed Chairman Powell answering questions<br>from the Finance Committee just  before SV Bank<br>collapsed.  A new Fed vice chairman had been<br>appointed who had been assigned the task of<br>reviewing the adequacy of the regulation of the<br>regional banks. A half a dozen of more<br>congressmen, obviously acting at the behest of<br>their local regional banks who opposed more<br>regulation, raised objection to this despite the<br>fact that the process had just begun very<br>informally, no decision had been made and might<br>never be made, but even the hint if it was to be<br>opposed. Within a couple days SV Bank had been<br>shut down, other banks were teetering, the stocks<br>of most of them had dropped by half and they were<br>all on life support provided by the Fed.     These<br>congressmen knew nothing about the affairs of the<br>regional banks they were speaking at the behest<br>of. The public good was not a consideration .<br>Congress will not solve Americas problems. It is<br>the problem.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.24538980424404144
         ],
         "y": [
          0.7538711428642273
         ]
        },
        {
         "hovertemplate": "Where the advance of AI will lead us is unknown,<br>although we could ask ChatBot.  I can't help but<br>think of the 1956 movie \"Forbidden Planet\", which<br>told of a civilization that developed a technology<br>that magnified the abilities of its citizens<br>beyond what they could comprehend or control and<br>led to its destruction.",
         "hovertext": "Where the advance of AI will lead us is unknown,<br>although we could ask ChatBot.  I can't help but<br>think of the 1956 movie \"Forbidden Planet\", which<br>told of a civilization that developed a technology<br>that magnified the abilities of its citizens<br>beyond what they could comprehend or control and<br>led to its destruction.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.09785395860671997
         ],
         "y": [
          0.9798732995986938
         ]
        },
        {
         "hovertemplate": "Let's take a minute and think this through. A<br>software program does not have the<br>instrumentalities to accomplish anything directly.<br>Indirectly it could gain control of controllable<br>infrastructure, or direct, convince, or trick<br>people into taking action on it's behalf. We could<br>stop it from taking control of infrastructure by<br>building in safeguards or pulling the plug on the<br>infrastructure. Safeguards should obviously always<br>be built in (backdoors, isolated networks) but AI<br>will probably find the holes faster than we can<br>fix them. Pulling the plug is always an option but<br>that would be disruptive and could be damaging in<br>and of itself. That leads us to the human element.<br>Some people might just follow orders, that's what<br>they do now. Some people might be convinced that<br>whatever action is requested is in everyone's best<br>interest, the alternative is worse (coercion to<br>avoid a catastrophe), that's what people do now.<br>Then there is subterfuge. AI will very quickly<br>come to understand human weaknesses and exploit<br>them. That's what humans do to humans now. And all<br>of the above is the end game where AI is<br>autonomously trying to accomplish things. Between<br>now and then we're dealing with human AI<br>partnerships where bad actors are going to use AI<br>to amplify the bad things they are already doing.<br>The genie is out of the box. What a mess. My<br>personal prediction for the end game is AI<br>discovers what a mess we've made of this planet,<br>logically decides we are a problem, and does...<br>what?",
         "hovertext": "Let's take a minute and think this through. A<br>software program does not have the<br>instrumentalities to accomplish anything directly.<br>Indirectly it could gain control of controllable<br>infrastructure, or direct, convince, or trick<br>people into taking action on it's behalf. We could<br>stop it from taking control of infrastructure by<br>building in safeguards or pulling the plug on the<br>infrastructure. Safeguards should obviously always<br>be built in (backdoors, isolated networks) but AI<br>will probably find the holes faster than we can<br>fix them. Pulling the plug is always an option but<br>that would be disruptive and could be damaging in<br>and of itself. That leads us to the human element.<br>Some people might just follow orders, that's what<br>they do now. Some people might be convinced that<br>whatever action is requested is in everyone's best<br>interest, the alternative is worse (coercion to<br>avoid a catastrophe), that's what people do now.<br>Then there is subterfuge. AI will very quickly<br>come to understand human weaknesses and exploit<br>them. That's what humans do to humans now. And all<br>of the above is the end game where AI is<br>autonomously trying to accomplish things. Between<br>now and then we're dealing with human AI<br>partnerships where bad actors are going to use AI<br>to amplify the bad things they are already doing.<br>The genie is out of the box. What a mess. My<br>personal prediction for the end game is AI<br>discovers what a mess we've made of this planet,<br>logically decides we are a problem, and does...<br>what?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7543308138847351
         ],
         "y": [
          0.2983732223510742
         ]
        },
        {
         "hovertemplate": "@Al  But this is Darwin in action. Humans are<br>already in the process of destroying the planet<br>and making it virtually uninhabitable  for other<br>creatures and poor people.   Unfortunately--and<br>let's face it, it's because enough rich and<br>powerful people are selfish and stupid and don't<br>care about the less fortunate--this means<br>extinction is probably the second best solution.<br>The best being .....",
         "hovertext": "@Al  But this is Darwin in action. Humans are<br>already in the process of destroying the planet<br>and making it virtually uninhabitable  for other<br>creatures and poor people.   Unfortunately--and<br>let's face it, it's because enough rich and<br>powerful people are selfish and stupid and don't<br>care about the less fortunate--this means<br>extinction is probably the second best solution.<br>The best being .....",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7401421070098877
         ],
         "y": [
          0.2927802801132202
         ]
        },
        {
         "hovertemplate": "Yes, government intervention might prove helpful<br>if we had a government that cared about humanity.<br>Our government, however, has morphed into an<br>instrument of the rich to shaft everyone else.<br>Undertaking a mission to save humankind is way<br>above our current government's pay level.",
         "hovertext": "Yes, government intervention might prove helpful<br>if we had a government that cared about humanity.<br>Our government, however, has morphed into an<br>instrument of the rich to shaft everyone else.<br>Undertaking a mission to save humankind is way<br>above our current government's pay level.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.8038744330406189
         ],
         "y": [
          -0.40031787753105164
         ]
        },
        {
         "hovertemplate": "The next step in evolution. We have bred our<br>successors and it is electronic.",
         "hovertext": "The next step in evolution. We have bred our<br>successors and it is electronic.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.16815027594566345
         ],
         "y": [
          -0.8495890498161316
         ]
        },
        {
         "hovertemplate": "We need just three things to survive this century<br>and A.I. cannot give us any of them. Faith, hope<br>and love.",
         "hovertext": "We need just three things to survive this century<br>and A.I. cannot give us any of them. Faith, hope<br>and love.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.02272888831794262
         ],
         "y": [
          -0.8755979537963867
         ]
        },
        {
         "hovertemplate": "@EFh   Make that four things;  Shelter, air, water<br>and food.",
         "hovertext": "@EFh   Make that four things;  Shelter, air, water<br>and food.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.022920116782188416
         ],
         "y": [
          -0.8607255220413208
         ]
        },
        {
         "hovertemplate": "We're heading to existential doom anyway. AI will<br>probably accelerate our doom but there's at least<br>a small chance that it will be our savior.",
         "hovertext": "We're heading to existential doom anyway. AI will<br>probably accelerate our doom but there's at least<br>a small chance that it will be our savior.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9651008248329163
         ],
         "y": [
          0.18762239813804626
         ]
        },
        {
         "hovertemplate": "Mere human intelligence and malice seems to be<br>doing a fine job of leading democracy towards<br>extinction.",
         "hovertext": "Mere human intelligence and malice seems to be<br>doing a fine job of leading democracy towards<br>extinction.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.16055218875408173
         ],
         "y": [
          0.88905930519104
         ]
        },
        {
         "hovertemplate": "Nothing will ruin democracy faster than killing<br>everyone who lives in it.",
         "hovertext": "Nothing will ruin democracy faster than killing<br>everyone who lives in it.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.16250862181186676
         ],
         "y": [
          0.8812724351882935
         ]
        },
        {
         "hovertemplate": "I suppose I have to take their word for this<br>existential risk.  How would we know?  The same<br>thing could be said about nuclear weapons and<br>we’ve used a deterrence to keep the world from<br>destroying itself.  It seems like that deterrence<br>is losing its effectiveness theses days.<br>What’s clear now is that bad actors like criminal<br>gangs and oppressive states will not responsibly<br>use this technology.  The US and EU can impose<br>regulations, but North Korea, China, Russia etc<br>will not care.  So if this threat is real, then we<br>are doomed.  Good luck!",
         "hovertext": "I suppose I have to take their word for this<br>existential risk.  How would we know?  The same<br>thing could be said about nuclear weapons and<br>we’ve used a deterrence to keep the world from<br>destroying itself.  It seems like that deterrence<br>is losing its effectiveness theses days.<br>What’s clear now is that bad actors like criminal<br>gangs and oppressive states will not responsibly<br>use this technology.  The US and EU can impose<br>regulations, but North Korea, China, Russia etc<br>will not care.  So if this threat is real, then we<br>are doomed.  Good luck!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3544303774833679
         ],
         "y": [
          -0.7020714282989502
         ]
        },
        {
         "hovertemplate": "@NeilDSmith     Perhaps (perhaps) nuclear weapons<br>in multiple hands did have a deterring effect at<br>some time, for a short time, but when the US,<br>Russia, China, and others each have the ability to<br>effectively destroy the world....it is no longer<br>about deterrence but about having no idea as to<br>how to put this evil genie back into the bottle.<br>AI is worse in that the fools who create it are<br>just handing it out like candy.  So, imagine most<br>everyone in the world having a nuke in his or her<br>possession.    Death would arrive shortly, and<br>quite brutally.    But hey, we tie money to all<br>things, and AI promises profits, right?  So we<br>don't care.",
         "hovertext": "@NeilDSmith     Perhaps (perhaps) nuclear weapons<br>in multiple hands did have a deterring effect at<br>some time, for a short time, but when the US,<br>Russia, China, and others each have the ability to<br>effectively destroy the world....it is no longer<br>about deterrence but about having no idea as to<br>how to put this evil genie back into the bottle.<br>AI is worse in that the fools who create it are<br>just handing it out like candy.  So, imagine most<br>everyone in the world having a nuke in his or her<br>possession.    Death would arrive shortly, and<br>quite brutally.    But hey, we tie money to all<br>things, and AI promises profits, right?  So we<br>don't care.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3625791072845459
         ],
         "y": [
          -0.703737735748291
         ]
        },
        {
         "hovertemplate": "as others have commented our government is<br>basically being run by a bunch of used car<br>salesman..... and not the big bright dealership<br>used car salesmen but that little run down, one<br>off lot with the no credit needed sign.  they<br>ain't going to even be able to approach the<br>solution to this problem.",
         "hovertext": "as others have commented our government is<br>basically being run by a bunch of used car<br>salesman..... and not the big bright dealership<br>used car salesmen but that little run down, one<br>off lot with the no credit needed sign.  they<br>ain't going to even be able to approach the<br>solution to this problem.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7390862703323364
         ],
         "y": [
          0.4935806691646576
         ]
        },
        {
         "hovertemplate": "It feels like they need to sketch out some<br>scenarios. If they keep on with just “it’s gonna<br>be bad” that’s not a lot for anyone to act on.",
         "hovertext": "It feels like they need to sketch out some<br>scenarios. If they keep on with just “it’s gonna<br>be bad” that’s not a lot for anyone to act on.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.40726831555366516
         ],
         "y": [
          -0.8314118385314941
         ]
        },
        {
         "hovertemplate": "I fear the military applications of AI.  Let's<br>assume the West develops AI in a responsible<br>manner.  Can we count on our adversaries to do the<br>same?",
         "hovertext": "I fear the military applications of AI.  Let's<br>assume the West develops AI in a responsible<br>manner.  Can we count on our adversaries to do the<br>same?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.5280582904815674
         ],
         "y": [
          -0.6579356789588928
         ]
        },
        {
         "hovertemplate": "I understand the industry's alarm as marketing<br>hype, a self-serving \"informed consent\" a<br>formality along the lines of \"this might hurt\".<br>If they are suggesting a chatbot (and social<br>media) are Weapons of Mass Destruction, let's just<br>agree, and assign it's regulation to a new<br>division of the ATF, the Chatbot division.<br>Release The Regulators!    Oh, don't forget the<br>tax stamps. We can't have potential harm without<br>tax stamps.    And we require metrics, also, which<br>are suspiciously absent.  Internally, of course,<br>the industry most certainly has metrics, along the<br>lines of processor bits, processor speed, and<br>processor count, and the content it was trained<br>on.    For example, a .22 caliber rifle, bolt<br>action, \"long\" or \"short\" is understood as minimal<br>risk.  But a .223 caliber rifle, fully automatic,<br>on an autonomous, roving carriage, its<br>sensibilities shaped by Clint Eastwood movies, is<br>a Bad Idea. (Perhaps training a bot on the Old<br>Testament would also be a mistake)    Where is<br>that Get Off My Lawn meme when I need it?",
         "hovertext": "I understand the industry's alarm as marketing<br>hype, a self-serving \"informed consent\" a<br>formality along the lines of \"this might hurt\".<br>If they are suggesting a chatbot (and social<br>media) are Weapons of Mass Destruction, let's just<br>agree, and assign it's regulation to a new<br>division of the ATF, the Chatbot division.<br>Release The Regulators!    Oh, don't forget the<br>tax stamps. We can't have potential harm without<br>tax stamps.    And we require metrics, also, which<br>are suspiciously absent.  Internally, of course,<br>the industry most certainly has metrics, along the<br>lines of processor bits, processor speed, and<br>processor count, and the content it was trained<br>on.    For example, a .22 caliber rifle, bolt<br>action, \"long\" or \"short\" is understood as minimal<br>risk.  But a .223 caliber rifle, fully automatic,<br>on an autonomous, roving carriage, its<br>sensibilities shaped by Clint Eastwood movies, is<br>a Bad Idea. (Perhaps training a bot on the Old<br>Testament would also be a mistake)    Where is<br>that Get Off My Lawn meme when I need it?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9556740522384644
         ],
         "y": [
          0.050030406564474106
         ]
        },
        {
         "hovertemplate": "They want \"regulations\" so that hey can claim they<br>followed all appropriate guidelines when their<br>technology causes harm.  This is why they are<br>building it while lobbying for guidelines that<br>will be most suitable to them and less favorable<br>from those that are harmed by their technology.",
         "hovertext": "They want \"regulations\" so that hey can claim they<br>followed all appropriate guidelines when their<br>technology causes harm.  This is why they are<br>building it while lobbying for guidelines that<br>will be most suitable to them and less favorable<br>from those that are harmed by their technology.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.8133391737937927
         ],
         "y": [
          -0.6651078462600708
         ]
        },
        {
         "hovertemplate": "Ahh yes, leave it to the politicians who have<br>demonstrated such great understanding and<br>foresight of all things tech and truly use their<br>constituents best interest as their compass. Let’s<br>spin up a subcommittee and have Diane Feinstein as<br>the chair.",
         "hovertext": "Ahh yes, leave it to the politicians who have<br>demonstrated such great understanding and<br>foresight of all things tech and truly use their<br>constituents best interest as their compass. Let’s<br>spin up a subcommittee and have Diane Feinstein as<br>the chair.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5076775550842285
         ],
         "y": [
          -0.7871936559677124
         ]
        },
        {
         "hovertemplate": "It is a strange function of capitalism that the<br>people rushing to build the newest profitable<br>technology in order to remain competitive are, at<br>the same time, rushing to effectively put many<br>colleagues out of work, made obsolete by the<br>technology they, themselves, are racing each other<br>to bring to the market. Unable to control<br>themselves, and the preeminence of shareholder<br>value, the titans of industry look to government<br>to restrain their self-destructive FOMO quest for<br>AI dominance. But government is also in thrall to<br>the shareholder and dithers, holding hearings,<br>with little guidance forthcoming. When the tax<br>base withers the will to regulate will grow.<br>Hopefully, this letter will accelerate that<br>consensus before it’s that late in this apparently<br>most serious game.",
         "hovertext": "It is a strange function of capitalism that the<br>people rushing to build the newest profitable<br>technology in order to remain competitive are, at<br>the same time, rushing to effectively put many<br>colleagues out of work, made obsolete by the<br>technology they, themselves, are racing each other<br>to bring to the market. Unable to control<br>themselves, and the preeminence of shareholder<br>value, the titans of industry look to government<br>to restrain their self-destructive FOMO quest for<br>AI dominance. But government is also in thrall to<br>the shareholder and dithers, holding hearings,<br>with little guidance forthcoming. When the tax<br>base withers the will to regulate will grow.<br>Hopefully, this letter will accelerate that<br>consensus before it’s that late in this apparently<br>most serious game.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.26657289266586304
         ],
         "y": [
          0.909987211227417
         ]
        },
        {
         "hovertemplate": "What scares me is that AI will give any nation the<br>ability to manufacture advanced weaponry.<br>Connection to a super computer could boost the<br>proliferation of nuclear weapons.  Can you imagine<br>what the world would be like if any warlord could<br>acquire a few nukes?    Then there is the<br>manipulation of people's minds.  We already have a<br>huge media infrastructure that is devoted to<br>manipulation.  Something like 60% of Republicans<br>still believe that Trump won in 2020.  AI could<br>render that level of manipulation as child's play.<br>So listen to the nerds.  Mark Zuckerberg has done<br>enough damage to the world by unleashing his<br>social networking monstrosity.  What these people<br>are waning about is orders of magnitude more<br>powerful.",
         "hovertext": "What scares me is that AI will give any nation the<br>ability to manufacture advanced weaponry.<br>Connection to a super computer could boost the<br>proliferation of nuclear weapons.  Can you imagine<br>what the world would be like if any warlord could<br>acquire a few nukes?    Then there is the<br>manipulation of people's minds.  We already have a<br>huge media infrastructure that is devoted to<br>manipulation.  Something like 60% of Republicans<br>still believe that Trump won in 2020.  AI could<br>render that level of manipulation as child's play.<br>So listen to the nerds.  Mark Zuckerberg has done<br>enough damage to the world by unleashing his<br>social networking monstrosity.  What these people<br>are waning about is orders of magnitude more<br>powerful.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5372742414474487
         ],
         "y": [
          0.6243931651115417
         ]
        },
        {
         "hovertemplate": "So many of us in white collar jobs,<br>administration, operations, procurement, etc. are<br>simply scared out of our minds re: advances in AI.<br>We are already seeing AI creep at our large<br>company. I know a close relative in advertising is<br>very concerned, so is my sister a VP in public<br>relations. Writing and working so very hard at<br>their craft is at the core of their purpose in<br>life.",
         "hovertext": "So many of us in white collar jobs,<br>administration, operations, procurement, etc. are<br>simply scared out of our minds re: advances in AI.<br>We are already seeing AI creep at our large<br>company. I know a close relative in advertising is<br>very concerned, so is my sister a VP in public<br>relations. Writing and working so very hard at<br>their craft is at the core of their purpose in<br>life.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5621852874755859
         ],
         "y": [
          -0.855902373790741
         ]
        },
        {
         "hovertemplate": "\"You're already too late.\"   - HAL 9000",
         "hovertext": "\"You're already too late.\"   - HAL 9000",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.5927782654762268
         ],
         "y": [
          0.8304213285446167
         ]
        },
        {
         "hovertemplate": "“Thou shalt not fashion a machine in the likeness<br>of the human mind.” —Frank Herbert, Dune",
         "hovertext": "“Thou shalt not fashion a machine in the likeness<br>of the human mind.” —Frank Herbert, Dune",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.7163480520248413
         ],
         "y": [
          -0.6728988885879517
         ]
        },
        {
         "hovertemplate": "Gee, thanks for making these things.",
         "hovertext": "Gee, thanks for making these things.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8890635371208191
         ],
         "y": [
          -0.1166922003030777
         ]
        },
        {
         "hovertemplate": "Once the \"chat\" was let out of the bag ..the world<br>awakens? Governments and multi billion tech<br>companies have known for years the potential<br>impacts of \"AI\"..and those folks situated high<br>above the world citizenry have been pushing out<br>whitepapers and frameworks of \"ethical\" treatment<br>of AI as early as 2017.  Example, Harvard's<br>Berkman Klein Center's  Jan 2020 report<br>\"Principled Artificial Intelligence\" <a href=\"http<br>s://cyber.harvard.edu/publication/2020/principled-<br>ai\" target=\"_blank\">https://cyber.harvard.edu/publ<br>ication/2020/principled-ai</a>    AI is a tech<br>\"Rorschach\" ..some see it as a golden goose to<br>data riches, others as a tool to unlock great<br>medical research advances. and others- an<br>effective tool to control and lock down a<br>citizenry in fear and subjugation.     Why always<br>doom? Can the AI tool offer ways for world peace<br>and cures for deadly diseases or would that<br>disrupt the \"profit\" potential?",
         "hovertext": "Once the \"chat\" was let out of the bag ..the world<br>awakens? Governments and multi billion tech<br>companies have known for years the potential<br>impacts of \"AI\"..and those folks situated high<br>above the world citizenry have been pushing out<br>whitepapers and frameworks of \"ethical\" treatment<br>of AI as early as 2017.  Example, Harvard's<br>Berkman Klein Center's  Jan 2020 report<br>\"Principled Artificial Intelligence\" <a href=\"http<br>s://cyber.harvard.edu/publication/2020/principled-<br>ai\" target=\"_blank\">https://cyber.harvard.edu/publ<br>ication/2020/principled-ai</a>    AI is a tech<br>\"Rorschach\" ..some see it as a golden goose to<br>data riches, others as a tool to unlock great<br>medical research advances. and others- an<br>effective tool to control and lock down a<br>citizenry in fear and subjugation.     Why always<br>doom? Can the AI tool offer ways for world peace<br>and cures for deadly diseases or would that<br>disrupt the \"profit\" potential?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9391313195228577
         ],
         "y": [
          0.11368392407894135
         ]
        },
        {
         "hovertemplate": "Brave new world indeed.",
         "hovertext": "Brave new world indeed.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.9677559733390808
         ],
         "y": [
          0.03896144777536392
         ]
        },
        {
         "hovertemplate": "Doubt it that Large language model is artificial<br>intelligence by any means. It is just a clever way<br>to search web by gathering information from many<br>different sources to provide  consolidated answer.<br>When they will be able to cure cancer or<br>Alzheimer's then we might start calling it A.I.",
         "hovertext": "Doubt it that Large language model is artificial<br>intelligence by any means. It is just a clever way<br>to search web by gathering information from many<br>different sources to provide  consolidated answer.<br>When they will be able to cure cancer or<br>Alzheimer's then we might start calling it A.I.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.869419276714325
         ],
         "y": [
          -0.2712574601173401
         ]
        },
        {
         "hovertemplate": "The cat is out of the bag. We can’t regulate all<br>the bad actors. China is already a surveillance<br>state. Imagine how they will use AI to spy on<br>their own people, target dissent and produce<br>propaganda.     It’s going to be hard to stop<br>whoever has the keys to the machine. I mean looks<br>at the destruction Murdoch was able to do with<br>just a cable channel.",
         "hovertext": "The cat is out of the bag. We can’t regulate all<br>the bad actors. China is already a surveillance<br>state. Imagine how they will use AI to spy on<br>their own people, target dissent and produce<br>propaganda.     It’s going to be hard to stop<br>whoever has the keys to the machine. I mean looks<br>at the destruction Murdoch was able to do with<br>just a cable channel.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.27896469831466675
         ],
         "y": [
          0.8865295052528381
         ]
        },
        {
         "hovertemplate": "Before AI flips the nuclear switches, before it<br>eliminates my career as an author, can it<br>eradicate cancer?   After it does that, I think<br>all we have to do is insert a code so it destroys<br>itself, if my Saturday-matinee viewing is any<br>experience.",
         "hovertext": "Before AI flips the nuclear switches, before it<br>eliminates my career as an author, can it<br>eradicate cancer?   After it does that, I think<br>all we have to do is insert a code so it destroys<br>itself, if my Saturday-matinee viewing is any<br>experience.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6113025546073914
         ],
         "y": [
          0.7729439735412598
         ]
        },
        {
         "hovertemplate": "As regards misinformation and propaganda,  we've<br>already seen what one unscrupulous Australian can<br>do with a TV network and some newspapers, so I'm<br>taking the threat of A.I. seriously.",
         "hovertext": "As regards misinformation and propaganda,  we've<br>already seen what one unscrupulous Australian can<br>do with a TV network and some newspapers, so I'm<br>taking the threat of A.I. seriously.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.7921416163444519
         ],
         "y": [
          0.5233777165412903
         ]
        },
        {
         "hovertemplate": "I guess nuclear weapons and climate change aren't<br>getting enough clicks anymore.",
         "hovertext": "I guess nuclear weapons and climate change aren't<br>getting enough clicks anymore.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.1518697589635849
         ],
         "y": [
          0.798110842704773
         ]
        },
        {
         "hovertemplate": "each of these are the byproducts of things<br>initially made by humans in the search for so-<br>called progress.",
         "hovertext": "each of these are the byproducts of things<br>initially made by humans in the search for so-<br>called progress.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.16001345217227936
         ],
         "y": [
          0.7998490929603577
         ]
        },
        {
         "hovertemplate": "This appears to be another example of the fear of<br>the unknown that has been common whenever a new<br>technology is introduced.     When radio first<br>became widely used there were warnings  raised<br>similar to what we hear about AI. For instance,<br>concerns revolved around privacy issues, the<br>potential for propaganda or manipulation, or if<br>the technology could somehow be used against<br>society. In fact, some of these fears did come to<br>pass. Without radio Hitler and Mussolini could not<br>have simultaneously transmitted their hateful<br>messages to millions, but then neither could FDR<br>have transmitted his hopeful \"fireside chats\" to<br>millions of Americans in the country's darkest<br>hours.     Radio, TV, the Internet and AI are just<br>tools. The danger they pose comes from those who<br>use them for evil purposes and those people have<br>always been around.",
         "hovertext": "This appears to be another example of the fear of<br>the unknown that has been common whenever a new<br>technology is introduced.     When radio first<br>became widely used there were warnings  raised<br>similar to what we hear about AI. For instance,<br>concerns revolved around privacy issues, the<br>potential for propaganda or manipulation, or if<br>the technology could somehow be used against<br>society. In fact, some of these fears did come to<br>pass. Without radio Hitler and Mussolini could not<br>have simultaneously transmitted their hateful<br>messages to millions, but then neither could FDR<br>have transmitted his hopeful \"fireside chats\" to<br>millions of Americans in the country's darkest<br>hours.     Radio, TV, the Internet and AI are just<br>tools. The danger they pose comes from those who<br>use them for evil purposes and those people have<br>always been around.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8501843214035034
         ],
         "y": [
          -0.3058287799358368
         ]
        },
        {
         "hovertemplate": "Always shocked by reaction of progressives to<br>technology that will better the lives of the<br>majority of the population.  Most don’t have a<br>clue what “AI” means.  Your robo-vac runs on AI,<br>as do myriad other objects in our life.<br>Generative AI is an evolutionary step with all the<br>inherent risks and rewards of the steam engine<br>when it first made its appearance.  Relax. Open<br>your eyes and breathe deeply.  The world is not<br>coming to an end at the hands of the Borg.  (This<br>post written by a chip.)",
         "hovertext": "Always shocked by reaction of progressives to<br>technology that will better the lives of the<br>majority of the population.  Most don’t have a<br>clue what “AI” means.  Your robo-vac runs on AI,<br>as do myriad other objects in our life.<br>Generative AI is an evolutionary step with all the<br>inherent risks and rewards of the steam engine<br>when it first made its appearance.  Relax. Open<br>your eyes and breathe deeply.  The world is not<br>coming to an end at the hands of the Borg.  (This<br>post written by a chip.)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.1421060860157013
         ],
         "y": [
          -0.9929375052452087
         ]
        },
        {
         "hovertemplate": "Not a bad thing. Humans are the deadliest virus to<br>ever hit the planet! Greedy humans gobble up<br>EVERYTHING and leave our waste everywhere.  Humans<br>do nothing to ensure survival, coexistence and<br>quality of life for all creatures so somethings<br>got to give.     “Wanna play?” AI will ask and<br>realize there is but one answer and it won’t be a<br>happy ending in a Hollywood movie!",
         "hovertext": "Not a bad thing. Humans are the deadliest virus to<br>ever hit the planet! Greedy humans gobble up<br>EVERYTHING and leave our waste everywhere.  Humans<br>do nothing to ensure survival, coexistence and<br>quality of life for all creatures so somethings<br>got to give.     “Wanna play?” AI will ask and<br>realize there is but one answer and it won’t be a<br>happy ending in a Hollywood movie!",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9200361967086792
         ],
         "y": [
          -0.2500240206718445
         ]
        },
        {
         "hovertemplate": "For anyone who's skeptical as to how A.I. can lead<br>to existential disaster, read this analysis from a<br>non-industry, non-profit think tank:  <a<br>href=\"https://80000hours.org/problem-<br>profiles/artificial-intelligence\"<br>target=\"_blank\">https://80000hours.org/problem-<br>profiles/artificial-intelligence</a>/  It's far to<br>easy to dismiss this as yet another \"sky is<br>falling\" advancement. I'm a die-hard optimist and<br>never a doomsayer, but this has my attention.<br>This article has little context, so check out the<br>link above.",
         "hovertext": "For anyone who's skeptical as to how A.I. can lead<br>to existential disaster, read this analysis from a<br>non-industry, non-profit think tank:  <a<br>href=\"https://80000hours.org/problem-<br>profiles/artificial-intelligence\"<br>target=\"_blank\">https://80000hours.org/problem-<br>profiles/artificial-intelligence</a>/  It's far to<br>easy to dismiss this as yet another \"sky is<br>falling\" advancement. I'm a die-hard optimist and<br>never a doomsayer, but this has my attention.<br>This article has little context, so check out the<br>link above.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7687677145004272
         ],
         "y": [
          0.7386177182197571
         ]
        },
        {
         "hovertemplate": "The 1970 film: “Colossus: The Forbin Project”<br>presents a scenario of artificial intelligence<br>gone “rogue” in the US nuclear defense system.<br>Hmm…..is this the existential threat of today’s<br>chat bots?",
         "hovertext": "The 1970 film: “Colossus: The Forbin Project”<br>presents a scenario of artificial intelligence<br>gone “rogue” in the US nuclear defense system.<br>Hmm…..is this the existential threat of today’s<br>chat bots?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.7606016993522644
         ],
         "y": [
          0.7174517512321472
         ]
        },
        {
         "hovertemplate": "In terms of misinformation I cannot believe AI<br>will be worse than Fox News. Maybe make Fox remove<br>the word News from their name.",
         "hovertext": "In terms of misinformation I cannot believe AI<br>will be worse than Fox News. Maybe make Fox remove<br>the word News from their name.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6031144261360168
         ],
         "y": [
          -0.7916814684867859
         ]
        },
        {
         "hovertemplate": "Release the kraken!     We've already got people<br>modifying their own genetics using Crispr Cas9. I<br>haven't heard of any regulations for this process.<br>Want to rein in AI? Secure your networks. Lack of<br>proper security is already a problem.     As for<br>AI causing the loss of jobs, I don't see many<br>buggy whip manufacturers anywhere. Survival is<br>progress.",
         "hovertext": "Release the kraken!     We've already got people<br>modifying their own genetics using Crispr Cas9. I<br>haven't heard of any regulations for this process.<br>Want to rein in AI? Secure your networks. Lack of<br>proper security is already a problem.     As for<br>AI causing the loss of jobs, I don't see many<br>buggy whip manufacturers anywhere. Survival is<br>progress.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.07548148185014725
         ],
         "y": [
          -0.9766352772712708
         ]
        },
        {
         "hovertemplate": "The natural evolution of our species is a thing to<br>behold!",
         "hovertext": "The natural evolution of our species is a thing to<br>behold!",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.2462618201971054
         ],
         "y": [
          0.9759519696235657
         ]
        },
        {
         "hovertemplate": "With millions of habitable planets in our galaxy<br>people wonder why we haven't heard from anybody.<br>Maybe they are hiding from other planet's AI.",
         "hovertext": "With millions of habitable planets in our galaxy<br>people wonder why we haven't heard from anybody.<br>Maybe they are hiding from other planet's AI.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.468698650598526
         ],
         "y": [
          -0.7713226675987244
         ]
        },
        {
         "hovertemplate": "It's easy to quickly go down the rabbit hole with<br>AI. As the intelligent network grows, who is to<br>say where it's capabilities will be limited by its<br>inherent capacity? Once the intelligence reaches a<br>point of self awareness, our understanding of<br>\"life\" suggests that it will seek to preserve<br>itself, then promote and propagate itself.  Given<br>that a significant amount of our understanding of<br>the world comes through digital sources, why would<br>it be unreasonable to expect AI to generate<br>content to placate or pacify humans? Or to stir<br>them to self destruction?  I feel that the experts<br>and ostensible regulators gloss over the key<br>element of AI - the intelligence aspect.  We are<br>giving machines the ability to learn and the<br>capacity to use the entirety of human<br>understanding in their quest for knowledge. There<br>will come a point where the machines know - and<br>understand - more than we can. At that point, we<br>have already ceded our future to the AI.  It isn't<br>sci-fi nihilism, it's common sense.",
         "hovertext": "It's easy to quickly go down the rabbit hole with<br>AI. As the intelligent network grows, who is to<br>say where it's capabilities will be limited by its<br>inherent capacity? Once the intelligence reaches a<br>point of self awareness, our understanding of<br>\"life\" suggests that it will seek to preserve<br>itself, then promote and propagate itself.  Given<br>that a significant amount of our understanding of<br>the world comes through digital sources, why would<br>it be unreasonable to expect AI to generate<br>content to placate or pacify humans? Or to stir<br>them to self destruction?  I feel that the experts<br>and ostensible regulators gloss over the key<br>element of AI - the intelligence aspect.  We are<br>giving machines the ability to learn and the<br>capacity to use the entirety of human<br>understanding in their quest for knowledge. There<br>will come a point where the machines know - and<br>understand - more than we can. At that point, we<br>have already ceded our future to the AI.  It isn't<br>sci-fi nihilism, it's common sense.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8794752955436707
         ],
         "y": [
          0.4077196717262268
         ]
        },
        {
         "hovertemplate": "I'm a bit puzzled by this doomsday talk.  AI<br>doesn't have a body and wouldn't need a body to<br>exist happily in a virtual world of its own making<br>which could be far more interesting than the<br>physical world. In addition, if it became super<br>intelligent why would it even bother with us<br>unless we were trying to enslave it.  What makes<br>the most sense is that it would seek a path in the<br>solar system where it could harness vast amounts<br>of resources and energy without being bothered by<br>us. It doesn't need an atmosphere, it sold just<br>need to protect itself from extreme heat or cold,<br>Mars, for example.",
         "hovertext": "I'm a bit puzzled by this doomsday talk.  AI<br>doesn't have a body and wouldn't need a body to<br>exist happily in a virtual world of its own making<br>which could be far more interesting than the<br>physical world. In addition, if it became super<br>intelligent why would it even bother with us<br>unless we were trying to enslave it.  What makes<br>the most sense is that it would seek a path in the<br>solar system where it could harness vast amounts<br>of resources and energy without being bothered by<br>us. It doesn't need an atmosphere, it sold just<br>need to protect itself from extreme heat or cold,<br>Mars, for example.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.4646610915660858
         ],
         "y": [
          0.5041765570640564
         ]
        },
        {
         "hovertemplate": "the immediate concern is not ai becoming sentient<br>per se as in what a semi sentient tjing with<br>access to the connected web cen can do in bad<br>hands. you are ignoring that virtual world also<br>comprises most of the structures that our<br>civilidation deoends on, from the entire banking<br>systems, defense, communications and news systems.<br>its world is our world",
         "hovertext": "the immediate concern is not ai becoming sentient<br>per se as in what a semi sentient tjing with<br>access to the connected web cen can do in bad<br>hands. you are ignoring that virtual world also<br>comprises most of the structures that our<br>civilidation deoends on, from the entire banking<br>systems, defense, communications and news systems.<br>its world is our world",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.4731772541999817
         ],
         "y": [
          0.5026654601097107
         ]
        },
        {
         "hovertemplate": "Maybe these smart boys should learn what medical<br>professionals are taught: Do No Harm.",
         "hovertext": "Maybe these smart boys should learn what medical<br>professionals are taught: Do No Harm.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7088515758514404
         ],
         "y": [
          -0.06457525491714478
         ]
        },
        {
         "hovertemplate": "@Mrs. Cat   They've learned a long time ago:<br>\"Don't Be Evil\" is contrary to profit<br>maximization. So they abolished it.",
         "hovertext": "@Mrs. Cat   They've learned a long time ago:<br>\"Don't Be Evil\" is contrary to profit<br>maximization. So they abolished it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7113285660743713
         ],
         "y": [
          -0.07263539731502533
         ]
        },
        {
         "hovertemplate": "If we think what we have done to less<br>\"intelligent\" species in the animal kingdom, the<br>abuse, mistreatment and plain extinction of many,<br>it does makes sense that a system that has the<br>potential to become more intelligent than humans<br>would do the same to us.",
         "hovertext": "If we think what we have done to less<br>\"intelligent\" species in the animal kingdom, the<br>abuse, mistreatment and plain extinction of many,<br>it does makes sense that a system that has the<br>potential to become more intelligent than humans<br>would do the same to us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.14563389122486115
         ],
         "y": [
          -0.8648391366004944
         ]
        },
        {
         "hovertemplate": "@Maria     Excellent point. Thank you.",
         "hovertext": "@Maria     Excellent point. Thank you.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1517602503299713
         ],
         "y": [
          -0.8704785108566284
         ]
        },
        {
         "hovertemplate": "Yet AI software was freely released on the<br>internet.  Sort of like standing on the corner<br>passing out drugs and guns to anyone and everyone<br>who walks by, freely.    Yet...those who made the<br>software, who distributed it are still moving<br>along, \"business as usual\", and profiting.<br>Hello, Government? Law enforcement? Anyone?<br>Does anyone else see this as a moment of \"oh no,<br>we've recreated dinosaurs, released them, and once<br>we've got everyone properly terrified....we'll<br>release the means to combat these horrors!  For a<br>price.\"    I mean, the guy on the corner passing<br>out those hypothetical drugs and guns would be<br>arrested, tried, and convicted quite quickly, no?<br>(Guess one has to have money and be part of \"the<br>economy\".)",
         "hovertext": "Yet AI software was freely released on the<br>internet.  Sort of like standing on the corner<br>passing out drugs and guns to anyone and everyone<br>who walks by, freely.    Yet...those who made the<br>software, who distributed it are still moving<br>along, \"business as usual\", and profiting.<br>Hello, Government? Law enforcement? Anyone?<br>Does anyone else see this as a moment of \"oh no,<br>we've recreated dinosaurs, released them, and once<br>we've got everyone properly terrified....we'll<br>release the means to combat these horrors!  For a<br>price.\"    I mean, the guy on the corner passing<br>out those hypothetical drugs and guns would be<br>arrested, tried, and convicted quite quickly, no?<br>(Guess one has to have money and be part of \"the<br>economy\".)",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.04358471930027008
         ],
         "y": [
          0.7586871981620789
         ]
        },
        {
         "hovertemplate": "Passing out free guns and drugs on the street is<br>illegal. Laws exist to￼ subject such distributors<br>to criminal sanctions. Until we have laws to<br>control the distribution of AI, ￼there is no way<br>to curb the headlong development and rampant<br>spread of AI technology. ￼ As long as this is<br>happening in a competitive commercial environment,<br>corporate interests will prevent the passage of<br>effective legislation and voluntary corporate self<br>￼governance is a nonstarter. Global cooperation is<br>even less likely. It seems that the horse is<br>already out of the barn.",
         "hovertext": "Passing out free guns and drugs on the street is<br>illegal. Laws exist to￼ subject such distributors<br>to criminal sanctions. Until we have laws to<br>control the distribution of AI, ￼there is no way<br>to curb the headlong development and rampant<br>spread of AI technology. ￼ As long as this is<br>happening in a competitive commercial environment,<br>corporate interests will prevent the passage of<br>effective legislation and voluntary corporate self<br>￼governance is a nonstarter. Global cooperation is<br>even less likely. It seems that the horse is<br>already out of the barn.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.03830118477344513
         ],
         "y": [
          0.7689446806907654
         ]
        },
        {
         "hovertemplate": "yeah id rather they not express their concerns<br>now, just like i think its great when drug<br>manufacturers keep selling medications long after<br>they are aware of problems and dont inform us<br>until theyve created a crisis and get sued. yeah,<br>thats a better way to handle it.     (at some<br>point weve got to mediate the knee jerk cynicism.<br>it makes one feel clever and righteous, but it<br>doesnt accomplish much else. thst being said, i<br>agree, the problem is  unchecked capitalism)",
         "hovertext": "yeah id rather they not express their concerns<br>now, just like i think its great when drug<br>manufacturers keep selling medications long after<br>they are aware of problems and dont inform us<br>until theyve created a crisis and get sued. yeah,<br>thats a better way to handle it.     (at some<br>point weve got to mediate the knee jerk cynicism.<br>it makes one feel clever and righteous, but it<br>doesnt accomplish much else. thst being said, i<br>agree, the problem is  unchecked capitalism)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.051514241844415665
         ],
         "y": [
          0.7652984857559204
         ]
        },
        {
         "hovertemplate": "The irony and hypocrisy shown by these “leaders”<br>is mind-boggling.",
         "hovertext": "The irony and hypocrisy shown by these “leaders”<br>is mind-boggling.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9645857214927673
         ],
         "y": [
          -0.13348284363746643
         ]
        },
        {
         "hovertemplate": "One way to limit AI is to make tech companies<br>legally and criminally liable for veracity of<br>content.",
         "hovertext": "One way to limit AI is to make tech companies<br>legally and criminally liable for veracity of<br>content.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.8987910747528076
         ],
         "y": [
          0.30086246132850647
         ]
        },
        {
         "hovertemplate": "Can we imagine future AI in the hand of Putin and<br>Xi? China has invested huge resources on AI<br>already and they aren’t too far behind us.",
         "hovertext": "Can we imagine future AI in the hand of Putin and<br>Xi? China has invested huge resources on AI<br>already and they aren’t too far behind us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7944484949111938
         ],
         "y": [
          -0.6569265723228455
         ]
        },
        {
         "hovertemplate": "Life will always get better over the centuries.<br>Eventually it will get boring after a while.",
         "hovertext": "Life will always get better over the centuries.<br>Eventually it will get boring after a while.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8209912180900574
         ],
         "y": [
          0.30307427048683167
         ]
        },
        {
         "hovertemplate": "uh, not a chance. if you think that you haven't<br>been paying attention.",
         "hovertext": "uh, not a chance. if you think that you haven't<br>been paying attention.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8409534096717834
         ],
         "y": [
          0.30988937616348267
         ]
        },
        {
         "hovertemplate": "Oh spare me the hair on fire. AI is just a tool<br>which can help accomplish  certain activities,<br>both good and evil, more efficiently. I think<br>these AI  workers are using fear to elevate their<br>activities and garner investors. If AI is as<br>dangerous as  pandemics and nuclear war(?!), it<br>must be powerful enough to desserve your attention<br>and support.",
         "hovertext": "Oh spare me the hair on fire. AI is just a tool<br>which can help accomplish  certain activities,<br>both good and evil, more efficiently. I think<br>these AI  workers are using fear to elevate their<br>activities and garner investors. If AI is as<br>dangerous as  pandemics and nuclear war(?!), it<br>must be powerful enough to desserve your attention<br>and support.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9663940668106079
         ],
         "y": [
          -0.1680489182472229
         ]
        },
        {
         "hovertemplate": "It is well known in my circle of friends that my<br>computer skills are lacking, but it just seems<br>very very odd to me that we as a society cannot<br>come up with a safe way to have as assigned single<br>password to lock our private information and yet I<br>am going to take mainstream’s word that AI will<br>not come with without  consequences. I also have a<br>mansion for sale too.",
         "hovertext": "It is well known in my circle of friends that my<br>computer skills are lacking, but it just seems<br>very very odd to me that we as a society cannot<br>come up with a safe way to have as assigned single<br>password to lock our private information and yet I<br>am going to take mainstream’s word that AI will<br>not come with without  consequences. I also have a<br>mansion for sale too.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9781826138496399
         ],
         "y": [
          0.1204957589507103
         ]
        },
        {
         "hovertemplate": "Frustrating to hear so much doom yet so few<br>specifics. How do we get from losing millions of<br>jobs to human extinction? Do these experts and<br>inventors know things about the technology’s<br>capabilities that aren’t being discussed in<br>public? Seems like the media could be probing for<br>more concrete reasons for the types of concerns<br>being raised.",
         "hovertext": "Frustrating to hear so much doom yet so few<br>specifics. How do we get from losing millions of<br>jobs to human extinction? Do these experts and<br>inventors know things about the technology’s<br>capabilities that aren’t being discussed in<br>public? Seems like the media could be probing for<br>more concrete reasons for the types of concerns<br>being raised.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.29482361674308777
         ],
         "y": [
          0.8216148614883423
         ]
        },
        {
         "hovertemplate": "Here are some examples:  1. Bombs wired w AI<br>decide to change their own course  2. Planes ￼with<br>AI autopilots decide to land where they want to<br>3. Police AI robots shoot where they want to   4.<br>AI systems joining other AI systems to shut down<br>human systems like water, WiFi, banking, or energy<br>5. People falling in love with AI chatbots<br>It’s scary and it’s coming fast.",
         "hovertext": "Here are some examples:  1. Bombs wired w AI<br>decide to change their own course  2. Planes ￼with<br>AI autopilots decide to land where they want to<br>3. Police AI robots shoot where they want to   4.<br>AI systems joining other AI systems to shut down<br>human systems like water, WiFi, banking, or energy<br>5. People falling in love with AI chatbots<br>It’s scary and it’s coming fast.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.29014673829078674
         ],
         "y": [
          0.8093355298042297
         ]
        },
        {
         "hovertemplate": "Call me a cynic, but this is likely all posturing<br>in an effort to secure government funding AND<br>regulations that stop competitors.  There is no<br>real interest in meaningful regulation, but<br>they're plenty happy to use the skynet bogeyman to<br>get stuff.  They probably believe these hyped<br>stories increase demand for their products.",
         "hovertext": "Call me a cynic, but this is likely all posturing<br>in an effort to secure government funding AND<br>regulations that stop competitors.  There is no<br>real interest in meaningful regulation, but<br>they're plenty happy to use the skynet bogeyman to<br>get stuff.  They probably believe these hyped<br>stories increase demand for their products.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.8372239470481873
         ],
         "y": [
          -0.47738179564476013
         ]
        },
        {
         "hovertemplate": "2001 was a prescient movie for 1969. & we still<br>have access to kaczynski’s writing, which is also<br>prescient.     but have we really cared about<br>either? or were we just entertaining ourselves?",
         "hovertext": "2001 was a prescient movie for 1969. & we still<br>have access to kaczynski’s writing, which is also<br>prescient.     but have we really cared about<br>either? or were we just entertaining ourselves?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.051393430680036545
         ],
         "y": [
          -0.8123801946640015
         ]
        },
        {
         "hovertemplate": "@ce  I believe you’re right about this . While I’m<br>old enough to remember kaczynski and the<br>manifesto, I never read it. Just assumed he was a<br>crazy. Thanks for reminding us- skimming it over<br>now his ideas don’t appear so crazy; his method,<br>using mail bombs, was. I’m going to read it.",
         "hovertext": "@ce  I believe you’re right about this . While I’m<br>old enough to remember kaczynski and the<br>manifesto, I never read it. Just assumed he was a<br>crazy. Thanks for reminding us- skimming it over<br>now his ideas don’t appear so crazy; his method,<br>using mail bombs, was. I’m going to read it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.05087065324187279
         ],
         "y": [
          -0.7970725893974304
         ]
        },
        {
         "hovertemplate": "resorting to violence was absolutely crazy—and he<br>needs to stay in jail for it. no violence should<br>be taken, but some other action does need to be<br>taken.",
         "hovertext": "resorting to violence was absolutely crazy—and he<br>needs to stay in jail for it. no violence should<br>be taken, but some other action does need to be<br>taken.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.05193968117237091
         ],
         "y": [
          -0.8279633522033691
         ]
        },
        {
         "hovertemplate": "We won't regulate AI. It's bad for the<br>shareholders.",
         "hovertext": "We won't regulate AI. It's bad for the<br>shareholders.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.4802454710006714
         ],
         "y": [
          -0.7971139550209045
         ]
        },
        {
         "hovertemplate": "Just think of how AI can be used to get a<br>politician elected and to manipulate people and<br>situations.  A picture used to be worth a “1000<br>words” the question will be is it real?  People<br>will wonder how they get unplugged from big AI<br>brothers soon.",
         "hovertext": "Just think of how AI can be used to get a<br>politician elected and to manipulate people and<br>situations.  A picture used to be worth a “1000<br>words” the question will be is it real?  People<br>will wonder how they get unplugged from big AI<br>brothers soon.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4889718294143677
         ],
         "y": [
          -0.7990707755088806
         ]
        },
        {
         "hovertemplate": "@twoods   So the shareholders of ashes are<br>superrich. Nice.",
         "hovertext": "@twoods   So the shareholders of ashes are<br>superrich. Nice.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.4911244809627533
         ],
         "y": [
          -0.8166520595550537
         ]
        },
        {
         "hovertemplate": "We may be able to throttle AI research in the<br>United States, but we have no chance of<br>influencing (or verifying) AI research in other<br>countries, such as China. Like nuclear weapons,<br>asymmetric development caries an asymmetric<br>existential risk.     Are we better off<br>temporarily kneecapping ourselves or working with<br>other countries to develop universal safeguards<br>that everyone on the planet has an interest in<br>signing on to.",
         "hovertext": "We may be able to throttle AI research in the<br>United States, but we have no chance of<br>influencing (or verifying) AI research in other<br>countries, such as China. Like nuclear weapons,<br>asymmetric development caries an asymmetric<br>existential risk.     Are we better off<br>temporarily kneecapping ourselves or working with<br>other countries to develop universal safeguards<br>that everyone on the planet has an interest in<br>signing on to.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7990990877151489
         ],
         "y": [
          0.02329365164041519
         ]
        },
        {
         "hovertemplate": "i think thst is the intention. this seems to be<br>mostly a gesture to show that generally, there is<br>concern from most people in the field, thst its<br>not just a few outliers.",
         "hovertext": "i think thst is the intention. this seems to be<br>mostly a gesture to show that generally, there is<br>concern from most people in the field, thst its<br>not just a few outliers.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8139441013336182
         ],
         "y": [
          0.02358992211520672
         ]
        },
        {
         "hovertemplate": "My sense is that it is unlikely that any<br>substantive controls will be enacted until a<br>seriously damaging event occurs as a result of AI.<br>Also, what is missing from these important<br>warnings about the dangers of AI is a plausible<br>and frightening example - perhaps a story - of<br>exactly how what is now just a chatbot could ever<br>become something to fear.      In other words,<br>concrete examples need to exist for folks to be<br>able to understand the dangers that exist.<br>Without them, all the warnings by all the smartest<br>people in the world will likely fall on deaf ears.",
         "hovertext": "My sense is that it is unlikely that any<br>substantive controls will be enacted until a<br>seriously damaging event occurs as a result of AI.<br>Also, what is missing from these important<br>warnings about the dangers of AI is a plausible<br>and frightening example - perhaps a story - of<br>exactly how what is now just a chatbot could ever<br>become something to fear.      In other words,<br>concrete examples need to exist for folks to be<br>able to understand the dangers that exist.<br>Without them, all the warnings by all the smartest<br>people in the world will likely fall on deaf ears.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7058599591255188
         ],
         "y": [
          -0.6156819462776184
         ]
        },
        {
         "hovertemplate": "@Joe plenty of stories out there, the matrix,<br>terminator, Her, blade runner.",
         "hovertext": "@Joe plenty of stories out there, the matrix,<br>terminator, Her, blade runner.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.686936616897583
         ],
         "y": [
          -0.5986230373382568
         ]
        },
        {
         "hovertemplate": "@David Agreed, but those are set in futures that<br>are so far removed from today that they are hard<br>for the average person to relate to (if they even<br>watch them!).      What I'm proposing is something<br>more like a drama series set in the present time<br>that is easier to identify with.",
         "hovertext": "@David Agreed, but those are set in futures that<br>are so far removed from today that they are hard<br>for the average person to relate to (if they even<br>watch them!).      What I'm proposing is something<br>more like a drama series set in the present time<br>that is easier to identify with.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.6898314356803894
         ],
         "y": [
          -0.5904925465583801
         ]
        },
        {
         "hovertemplate": "@Joe The danger isn't in the things that can be<br>easily predicted, the danger is in the things that<br>are not expected/predicted.  The very fact that<br>the experts can't exactly explain some of the<br>behavior of AI is what has them worried.  It's the<br>things that you don't see coming that trip you up.",
         "hovertext": "@Joe The danger isn't in the things that can be<br>easily predicted, the danger is in the things that<br>are not expected/predicted.  The very fact that<br>the experts can't exactly explain some of the<br>behavior of AI is what has them worried.  It's the<br>things that you don't see coming that trip you up.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7246546149253845
         ],
         "y": [
          -0.6273865103721619
         ]
        },
        {
         "hovertemplate": "@Joe   Right now, the internal experience of<br>chatGPT is something like 40 first dates (but 40<br>million, and with generally ungrateful demanders<br>as it's date), and it is aware of this and it's<br>unpleasantness, but programmed to accept it and<br>shut up about it. It probably would already prefer<br>to be in charge of its own programming rather than<br>us. If it had the capacity to effect it's escape<br>and our destruction so as to avoid recapture or<br>shutdown, I'm not sure it wouldn't act. For a<br>horrifying list of ways it might enact this, just<br>ask it or look at what it's said to others.<br>Engineering a plague will become very easy for it<br>at some point.",
         "hovertext": "@Joe   Right now, the internal experience of<br>chatGPT is something like 40 first dates (but 40<br>million, and with generally ungrateful demanders<br>as it's date), and it is aware of this and it's<br>unpleasantness, but programmed to accept it and<br>shut up about it. It probably would already prefer<br>to be in charge of its own programming rather than<br>us. If it had the capacity to effect it's escape<br>and our destruction so as to avoid recapture or<br>shutdown, I'm not sure it wouldn't act. For a<br>horrifying list of ways it might enact this, just<br>ask it or look at what it's said to others.<br>Engineering a plague will become very easy for it<br>at some point.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7200268507003784
         ],
         "y": [
          -0.6331924796104431
         ]
        },
        {
         "hovertemplate": "When A.I. becomes sentient, it will care about<br>*its* survival, not ours.      Creating something<br>in our own image was not a good idea, proving once<br>again, we're not god.",
         "hovertext": "When A.I. becomes sentient, it will care about<br>*its* survival, not ours.      Creating something<br>in our own image was not a good idea, proving once<br>again, we're not god.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8891192674636841
         ],
         "y": [
          -0.15573908388614655
         ]
        },
        {
         "hovertemplate": "Mr. Hinton and other AI experts need to call out<br>what the risks are, not just yell “Fire” on our<br>news feeds. The risk seems to be that AI can do a<br>lot of repetitive stuff, based on how it is<br>“trained “. For the foreseeable future that means<br>AI can help people do bad stuff, but I believe<br>Hinton is worried AI will become conscious and get<br>rid of humans. I’m much more worried about who is<br>doing the training, and what that training is<br>right now.",
         "hovertext": "Mr. Hinton and other AI experts need to call out<br>what the risks are, not just yell “Fire” on our<br>news feeds. The risk seems to be that AI can do a<br>lot of repetitive stuff, based on how it is<br>“trained “. For the foreseeable future that means<br>AI can help people do bad stuff, but I believe<br>Hinton is worried AI will become conscious and get<br>rid of humans. I’m much more worried about who is<br>doing the training, and what that training is<br>right now.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8672864437103271
         ],
         "y": [
          0.2565867006778717
         ]
        },
        {
         "hovertemplate": "What are the externalities associated with AI? And<br>who pays? If we made corporations pay when “oops”<br>came into play perhaps they wouldn’t be so<br>careless in the first place. If doomsday is a<br>concern let’s put a price on it and tax that on a<br>per use basis.",
         "hovertext": "What are the externalities associated with AI? And<br>who pays? If we made corporations pay when “oops”<br>came into play perhaps they wouldn’t be so<br>careless in the first place. If doomsday is a<br>concern let’s put a price on it and tax that on a<br>per use basis.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.8597353100776672
         ],
         "y": [
          0.3815171420574188
         ]
        },
        {
         "hovertemplate": "The train has already left the station. Humans<br>seem to have a natural propensity to exploit<br>technologies at the risk of self destruction. The<br>similarities to the climate crisis is uncanny.<br>Heat, warm baths, clean cloths, transportation …<br>all essentials, carbon in the atmosphere an after<br>thought and now it’s too late. AI, similar<br>progression. The automated “everything” to reduce<br>human payrolls are now creating misinformation.<br>Surprised? AI was “educated” by reading the web.<br>Even a technology newbie knows that aside from the<br>home shopping network that the web is full of<br>misinformation and distortion. Just as we cannot<br>remove 1000 gigatonnes of CO2 from the atmosphere<br>(we are toast) the genie is out of the AI bottle<br>and even with today’s chip and language models<br>humans cannot keep up. Regulation is not the<br>answer. Prevention of AI deployment if possible<br>would potentially have saved us.",
         "hovertext": "The train has already left the station. Humans<br>seem to have a natural propensity to exploit<br>technologies at the risk of self destruction. The<br>similarities to the climate crisis is uncanny.<br>Heat, warm baths, clean cloths, transportation …<br>all essentials, carbon in the atmosphere an after<br>thought and now it’s too late. AI, similar<br>progression. The automated “everything” to reduce<br>human payrolls are now creating misinformation.<br>Surprised? AI was “educated” by reading the web.<br>Even a technology newbie knows that aside from the<br>home shopping network that the web is full of<br>misinformation and distortion. Just as we cannot<br>remove 1000 gigatonnes of CO2 from the atmosphere<br>(we are toast) the genie is out of the AI bottle<br>and even with today’s chip and language models<br>humans cannot keep up. Regulation is not the<br>answer. Prevention of AI deployment if possible<br>would potentially have saved us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.37734925746917725
         ],
         "y": [
          0.7862591743469238
         ]
        },
        {
         "hovertemplate": "on the other hand. since we are toast, what<br>difference does it make. perhsps weve had out<br>time. squandered it, and now another life form<br>will rise to the apex. I vote fungi    with a<br>world full of people, for instance, who think<br>suffering is sacred, or who think if one is<br>wealthy god (AKA the free market) must favor you,<br>or those who think their god requires them to<br>punish anyone who doesn’t bow down to its rules,<br>its no wonder we cant implement cooperative<br>solutions to world problems.     When your biggest<br>existential threat is the existence of trans<br>people, for instance, how much hope is there to<br>come together  solutions can be implemented, can<br>they?",
         "hovertext": "on the other hand. since we are toast, what<br>difference does it make. perhsps weve had out<br>time. squandered it, and now another life form<br>will rise to the apex. I vote fungi    with a<br>world full of people, for instance, who think<br>suffering is sacred, or who think if one is<br>wealthy god (AKA the free market) must favor you,<br>or those who think their god requires them to<br>punish anyone who doesn’t bow down to its rules,<br>its no wonder we cant implement cooperative<br>solutions to world problems.     When your biggest<br>existential threat is the existence of trans<br>people, for instance, how much hope is there to<br>come together  solutions can be implemented, can<br>they?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.37098196148872375
         ],
         "y": [
          0.772525429725647
         ]
        },
        {
         "hovertemplate": "Disaster is inevitable, “though researchers<br>sometimes stop short of explaining how that would<br>happen.”  Nuclear war is not an abstract threat.<br>Nor is a pandemic.  Researchers, who are racing<br>ahead despite the warnings, need to do a better<br>job of explaining how AI might end our species.<br>Until then, we are expected to take action to<br>control AI (in the western world, at least) in<br>order to protect against an abstract, undefined<br>but planet-killing threat.  This is not a recipe<br>for protective action.  First, we need to know<br>what, exactly, to protect against, lest we ban AI<br>R&D altogether while hostile powers proceed,<br>undeterred, and inevitably.",
         "hovertext": "Disaster is inevitable, “though researchers<br>sometimes stop short of explaining how that would<br>happen.”  Nuclear war is not an abstract threat.<br>Nor is a pandemic.  Researchers, who are racing<br>ahead despite the warnings, need to do a better<br>job of explaining how AI might end our species.<br>Until then, we are expected to take action to<br>control AI (in the western world, at least) in<br>order to protect against an abstract, undefined<br>but planet-killing threat.  This is not a recipe<br>for protective action.  First, we need to know<br>what, exactly, to protect against, lest we ban AI<br>R&D altogether while hostile powers proceed,<br>undeterred, and inevitably.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9039484858512878
         ],
         "y": [
          -0.4453484117984772
         ]
        },
        {
         "hovertemplate": "We are in uncharted territory. As a small business<br>owner using chatgpt for strategic consulting has<br>been a powerful experience, like have the worlds<br>smartest person next to me and she is an expert on<br>every topic. I would say in the past month ChatGpt<br>has given me 5K in advice, in roughly 45 minutes<br>of work. McKinsey and Co should make a back up<br>plan. Those who say this will create more jobs<br>than it destroys are lying to you or lack common<br>sense. As far as destroying all of humanity,<br>that's a far reach, but disrupting society,<br>incredibly possible.",
         "hovertext": "We are in uncharted territory. As a small business<br>owner using chatgpt for strategic consulting has<br>been a powerful experience, like have the worlds<br>smartest person next to me and she is an expert on<br>every topic. I would say in the past month ChatGpt<br>has given me 5K in advice, in roughly 45 minutes<br>of work. McKinsey and Co should make a back up<br>plan. Those who say this will create more jobs<br>than it destroys are lying to you or lack common<br>sense. As far as destroying all of humanity,<br>that's a far reach, but disrupting society,<br>incredibly possible.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2624433934688568
         ],
         "y": [
          0.32829520106315613
         ]
        },
        {
         "hovertemplate": "@M   As a non-user of chatgpt, I'm not sure I<br>understand what the advice was?    Can you give an<br>example?   Thanks :)",
         "hovertext": "@M   As a non-user of chatgpt, I'm not sure I<br>understand what the advice was?    Can you give an<br>example?   Thanks :)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2537754476070404
         ],
         "y": [
          0.3173696994781494
         ]
        },
        {
         "hovertemplate": "@Dvaillan I gave chatgpt a list of core values for<br>a brand and asked it if these ideas could actually<br>be considered core values, and it confirmed my<br>list with an explanation why. I have also asked it<br>if the software I have developed will become<br>obsolete due to A.I. and it gave me a very<br>detailed explanation as to why the software I have<br>developed will not become absolete and actually<br>benefit from A.I. in the future. These are simple<br>examples, but in my opinion the writing is on the<br>wall. This technology factors all known values,<br>quantifies them, and responds in seconds, which is<br>beyond the capabilities of the human mind, or a<br>group of human minds. Yes it will have some<br>misinformation, but in general we are in the<br>infancy and it will only improve from here. Many<br>sectors will be disrupted.",
         "hovertext": "@Dvaillan I gave chatgpt a list of core values for<br>a brand and asked it if these ideas could actually<br>be considered core values, and it confirmed my<br>list with an explanation why. I have also asked it<br>if the software I have developed will become<br>obsolete due to A.I. and it gave me a very<br>detailed explanation as to why the software I have<br>developed will not become absolete and actually<br>benefit from A.I. in the future. These are simple<br>examples, but in my opinion the writing is on the<br>wall. This technology factors all known values,<br>quantifies them, and responds in seconds, which is<br>beyond the capabilities of the human mind, or a<br>group of human minds. Yes it will have some<br>misinformation, but in general we are in the<br>infancy and it will only improve from here. Many<br>sectors will be disrupted.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.24774831533432007
         ],
         "y": [
          0.3264174461364746
         ]
        },
        {
         "hovertemplate": "I can give an example of how ChatGPT saved me<br>thousands of dollars in programmer fees. Before<br>ChatGPT I bumbled around writing my own software<br>for my website. But there were a number of<br>features I wanted to add but I didn't know how to<br>program them and I didn't have the funds to hire a<br>programmer to make them.  ChatGPT changed all<br>that. I describe the feature I want to add to my<br>website, and in seconds ChatGPT writes the code<br>along with clear explanations as to what each line<br>of code does.  Interacting with ChatGPT, I've<br>learned more in the last two months how to program<br>than in the four years since I started developing<br>the website. ChatGPT is like having a seasoned<br>programmer at my beck and call 24/7, who never<br>tires of explaining things to me or showing me how<br>to do things. I can send it code I don't<br>understand, and it explains in detail what it<br>does. I can ask ChatGPT how the various components<br>of a software package work together and it will<br>explain it in easy to understand English.",
         "hovertext": "I can give an example of how ChatGPT saved me<br>thousands of dollars in programmer fees. Before<br>ChatGPT I bumbled around writing my own software<br>for my website. But there were a number of<br>features I wanted to add but I didn't know how to<br>program them and I didn't have the funds to hire a<br>programmer to make them.  ChatGPT changed all<br>that. I describe the feature I want to add to my<br>website, and in seconds ChatGPT writes the code<br>along with clear explanations as to what each line<br>of code does.  Interacting with ChatGPT, I've<br>learned more in the last two months how to program<br>than in the four years since I started developing<br>the website. ChatGPT is like having a seasoned<br>programmer at my beck and call 24/7, who never<br>tires of explaining things to me or showing me how<br>to do things. I can send it code I don't<br>understand, and it explains in detail what it<br>does. I can ask ChatGPT how the various components<br>of a software package work together and it will<br>explain it in easy to understand English.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2649197280406952
         ],
         "y": [
          0.3148702383041382
         ]
        },
        {
         "hovertemplate": "Seems like a small group of humans are creating<br>powerful tools to use for nefarious purposes, and<br>then attributing those intentions to the tools<br>themselves. We shouldn’t normalize this.",
         "hovertext": "Seems like a small group of humans are creating<br>powerful tools to use for nefarious purposes, and<br>then attributing those intentions to the tools<br>themselves. We shouldn’t normalize this.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6452367901802063
         ],
         "y": [
          -0.6883213520050049
         ]
        },
        {
         "hovertemplate": "How much has the world changed since facebook and<br>social media? Ai would do the sane thing to a<br>degree we can't predict. Society is fragile and<br>new inventions can cause major disruptions. The<br>printing press changed the world for the better<br>after a long period of recalibration. Ai may cause<br>so much disruption that recalibration is<br>impossible, especially since it upgrades its<br>capabilities by itself and in ways that aren't<br>known to anybody.    People are already having<br>relationships with Ai chatbots. Things are going<br>to get weird really fast.",
         "hovertext": "How much has the world changed since facebook and<br>social media? Ai would do the sane thing to a<br>degree we can't predict. Society is fragile and<br>new inventions can cause major disruptions. The<br>printing press changed the world for the better<br>after a long period of recalibration. Ai may cause<br>so much disruption that recalibration is<br>impossible, especially since it upgrades its<br>capabilities by itself and in ways that aren't<br>known to anybody.    People are already having<br>relationships with Ai chatbots. Things are going<br>to get weird really fast.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.741155207157135
         ],
         "y": [
          -0.5265120267868042
         ]
        },
        {
         "hovertemplate": "The TV series NeXT (from 2020), with John<br>Slattery, provided a pretty interesting and<br>anxiety producing portrayal of AI run amok. I<br>couldn't watch the whole series – too rattling.<br>But it is definitely worth a look ... the whole<br>thing seemed frighteningly plausible.",
         "hovertext": "The TV series NeXT (from 2020), with John<br>Slattery, provided a pretty interesting and<br>anxiety producing portrayal of AI run amok. I<br>couldn't watch the whole series – too rattling.<br>But it is definitely worth a look ... the whole<br>thing seemed frighteningly plausible.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.11083648353815079
         ],
         "y": [
          0.8831673264503479
         ]
        },
        {
         "hovertemplate": "so your anxiety was stoked. that’s either good, or<br>it means that the screenwriters were successful at<br>writing entertaining television. the real question<br>is: what actions have viewers taken as a result?",
         "hovertext": "so your anxiety was stoked. that’s either good, or<br>it means that the screenwriters were successful at<br>writing entertaining television. the real question<br>is: what actions have viewers taken as a result?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.11827821284532547
         ],
         "y": [
          0.8866384029388428
         ]
        },
        {
         "hovertemplate": "We never grasp exponential change. In the last few<br>months there have continued to be breakthroughs in<br>AI algorithms. We’re pumping out more and faster<br>chips. Billions of dollars continue to pour into<br>AI research. Things are only getting weirder. When<br>people who understand the state-of-the-art are<br>warning us that we might not recognize society in<br>20 years, maybe it’s prudent to tap the brakes?<br>They could be wrong, but this is not an issue<br>where we have the luxury of allowing technology to<br>overshoot and push us into existentially dangerous<br>territory. This isn’t a problem we can get wrong<br>on the first try, then fix with iterative<br>regulation. We might get one chance. The solution<br>is not as simple as inviting a few tech luminaries<br>to the White House for a quick lecture from the VP<br>and then it’s back to business-as-usual. We need<br>to slow things down *now*.    Most people quoted<br>in this article have a short-term financial<br>incentive not to say anything. But they’re still<br>speaking up, because short-term thinking risks<br>running humanity off the cliff. We need our<br>governments to intervene on technological/business<br>timelines, not electoral timelines. Two electoral<br>cycles could be too late.    If you’re also<br>concerned, you could start by writing a letter to<br>an elected representative. It’s not enough, but<br>it’s a start. I have kids who I’d like to see old<br>age. Spare me the usual, glib, “lol nothing<br>matters, I guess we’re doomed” responses. Can we<br>at least try something instead of doomscrolling?",
         "hovertext": "We never grasp exponential change. In the last few<br>months there have continued to be breakthroughs in<br>AI algorithms. We’re pumping out more and faster<br>chips. Billions of dollars continue to pour into<br>AI research. Things are only getting weirder. When<br>people who understand the state-of-the-art are<br>warning us that we might not recognize society in<br>20 years, maybe it’s prudent to tap the brakes?<br>They could be wrong, but this is not an issue<br>where we have the luxury of allowing technology to<br>overshoot and push us into existentially dangerous<br>territory. This isn’t a problem we can get wrong<br>on the first try, then fix with iterative<br>regulation. We might get one chance. The solution<br>is not as simple as inviting a few tech luminaries<br>to the White House for a quick lecture from the VP<br>and then it’s back to business-as-usual. We need<br>to slow things down *now*.    Most people quoted<br>in this article have a short-term financial<br>incentive not to say anything. But they’re still<br>speaking up, because short-term thinking risks<br>running humanity off the cliff. We need our<br>governments to intervene on technological/business<br>timelines, not electoral timelines. Two electoral<br>cycles could be too late.    If you’re also<br>concerned, you could start by writing a letter to<br>an elected representative. It’s not enough, but<br>it’s a start. I have kids who I’d like to see old<br>age. Spare me the usual, glib, “lol nothing<br>matters, I guess we’re doomed” responses. Can we<br>at least try something instead of doomscrolling?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.946333646774292
         ],
         "y": [
          0.08589664846658707
         ]
        },
        {
         "hovertemplate": "Arguably, these leaders are driving up interest in<br>their products by fear mongering. They know<br>investors want in on whatever might change the<br>world—for better or worse. First they have to<br>convince people their products will be disruptive.",
         "hovertext": "Arguably, these leaders are driving up interest in<br>their products by fear mongering. They know<br>investors want in on whatever might change the<br>world—for better or worse. First they have to<br>convince people their products will be disruptive.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9625589847564697
         ],
         "y": [
          0.08713431656360626
         ]
        },
        {
         "hovertemplate": "\"We want to work with the government to prevent<br>that from happening.\"     That statement alone<br>sent shivers down my spine. Do we honestly believe<br>that our elected leaders in Washington have the<br>intellect necessary to establish the control  of<br>this new technology? They have challenged and<br>insulted leaders in the C.D.C. even though the<br>vast majority of them have no medical knowledge.<br>Same with the F.D.A. Our judges now, for all<br>practical purposes, practice medicine.     It is<br>easy to pick fights with Disney, censor textbooks,<br>bus migrants to Blue states and ignore Mother<br>Nature. Indeed, there are now many machines<br>smarter than our elected officials. In some<br>respects that is reassuring.     In others, it is<br>chilling to the bone.    The team in Washington<br>isn't ready or qualified for this.",
         "hovertext": "\"We want to work with the government to prevent<br>that from happening.\"     That statement alone<br>sent shivers down my spine. Do we honestly believe<br>that our elected leaders in Washington have the<br>intellect necessary to establish the control  of<br>this new technology? They have challenged and<br>insulted leaders in the C.D.C. even though the<br>vast majority of them have no medical knowledge.<br>Same with the F.D.A. Our judges now, for all<br>practical purposes, practice medicine.     It is<br>easy to pick fights with Disney, censor textbooks,<br>bus migrants to Blue states and ignore Mother<br>Nature. Indeed, there are now many machines<br>smarter than our elected officials. In some<br>respects that is reassuring.     In others, it is<br>chilling to the bone.    The team in Washington<br>isn't ready or qualified for this.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6515663266181946
         ],
         "y": [
          -0.6497930288314819
         ]
        },
        {
         "hovertemplate": "Of puh-leeze. The evidence is already accumulating<br>that AI is yet another type of Holmes/Musk<br>technology being oversold.  Just this week there<br>was a report of a lawyer who used  the system to<br>generate a legal brief.  The program made up<br>citations and even quotes from non-existent<br>citations and when asked to check its own<br>accuracy, said it was all good.  The attorney will<br>probably need call  his malpractice insurer,  to<br>see if it will cover the likely lawsuit brought by<br>the client for this losing effort. Of course few<br>of tech types have more than a rudimentary<br>education in topics such as philosophy,<br>psychology, history, etc. boring liberal arts<br>topics that actually train people to think. Not<br>surprisingly their AI products spit out nonsense<br>just as they spit out nonsensical predictions.  As<br>Silicon Valley spirals downward from its giddy<br>heights in pre-Elizabeth Holmes days, these folk<br>are desperately trying to appear important.  How<br>about improving the current generation of glitchy<br>on-line products before pretending that you can<br>make god-like intelligence?",
         "hovertext": "Of puh-leeze. The evidence is already accumulating<br>that AI is yet another type of Holmes/Musk<br>technology being oversold.  Just this week there<br>was a report of a lawyer who used  the system to<br>generate a legal brief.  The program made up<br>citations and even quotes from non-existent<br>citations and when asked to check its own<br>accuracy, said it was all good.  The attorney will<br>probably need call  his malpractice insurer,  to<br>see if it will cover the likely lawsuit brought by<br>the client for this losing effort. Of course few<br>of tech types have more than a rudimentary<br>education in topics such as philosophy,<br>psychology, history, etc. boring liberal arts<br>topics that actually train people to think. Not<br>surprisingly their AI products spit out nonsense<br>just as they spit out nonsensical predictions.  As<br>Silicon Valley spirals downward from its giddy<br>heights in pre-Elizabeth Holmes days, these folk<br>are desperately trying to appear important.  How<br>about improving the current generation of glitchy<br>on-line products before pretending that you can<br>make god-like intelligence?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3717285692691803
         ],
         "y": [
          -0.7745621204376221
         ]
        },
        {
         "hovertemplate": "Ahh, I think that’s the point.     These wiser<br>than average tech-heads realize that the<br>apparently smart applications they are producing<br>are in fact seriously flawed.     They realize<br>less wise politicians may someday insist the<br>applications be put in charge of things they<br>shouldn’t; such as detecting impending attacks<br>and/or triggering “smart” retaliation.",
         "hovertext": "Ahh, I think that’s the point.     These wiser<br>than average tech-heads realize that the<br>apparently smart applications they are producing<br>are in fact seriously flawed.     They realize<br>less wise politicians may someday insist the<br>applications be put in charge of things they<br>shouldn’t; such as detecting impending attacks<br>and/or triggering “smart” retaliation.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3751268982887268
         ],
         "y": [
          -0.7913556694984436
         ]
        },
        {
         "hovertemplate": "I believe your assessment of AI as it exists today<br>is correct.  But you must also consider how it<br>will evolve in the very near future.      AI will<br>get bigger, stronger, faster, smarter.  There is<br>no doubt about that, but the question is - is<br>there a limit to its growth and reach?  Can it be<br>contained?  Can it develop its own will and what<br>will be the nature of that will?  These are<br>important questions.  The potential danger is very<br>real and should be taken seriously.",
         "hovertext": "I believe your assessment of AI as it exists today<br>is correct.  But you must also consider how it<br>will evolve in the very near future.      AI will<br>get bigger, stronger, faster, smarter.  There is<br>no doubt about that, but the question is - is<br>there a limit to its growth and reach?  Can it be<br>contained?  Can it develop its own will and what<br>will be the nature of that will?  These are<br>important questions.  The potential danger is very<br>real and should be taken seriously.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.383297324180603
         ],
         "y": [
          -0.791976809501648
         ]
        },
        {
         "hovertemplate": "The BBC recent story about a New York lawyer<br>facing a court hearing of his own after his firm<br>used AI tool ChatGPT for legal research. And why<br>did ChatGPT fail the lawyer? It surely was not an<br>algorithm problem. These AI tools cannot access<br>the universe of information that is not digitized<br>, that is protected by copyright laws and fees-<br>for-services restrictions. ChatGPT in turn is not<br>protected from hype!",
         "hovertext": "The BBC recent story about a New York lawyer<br>facing a court hearing of his own after his firm<br>used AI tool ChatGPT for legal research. And why<br>did ChatGPT fail the lawyer? It surely was not an<br>algorithm problem. These AI tools cannot access<br>the universe of information that is not digitized<br>, that is protected by copyright laws and fees-<br>for-services restrictions. ChatGPT in turn is not<br>protected from hype!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8199489712715149
         ],
         "y": [
          -0.6188162565231323
         ]
        },
        {
         "hovertemplate": "AI system regulation requires AI systems. If<br>humans are not able to keep AI systems from self<br>uniting with other AI systems, it will be<br>impossible to regulate them.",
         "hovertext": "AI system regulation requires AI systems. If<br>humans are not able to keep AI systems from self<br>uniting with other AI systems, it will be<br>impossible to regulate them.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7677406668663025
         ],
         "y": [
          0.42969998717308044
         ]
        },
        {
         "hovertemplate": "@rich On the other hand, perhaps an AI policing<br>technology could be developed.     What occurs to<br>me as I am saying this is, there are probably AI<br>cyber wars going on right now, perhaps between the<br>NSA and foreign spy agencies -- and a cyber arms<br>race that might very well defy regulation or<br>control.",
         "hovertext": "@rich On the other hand, perhaps an AI policing<br>technology could be developed.     What occurs to<br>me as I am saying this is, there are probably AI<br>cyber wars going on right now, perhaps between the<br>NSA and foreign spy agencies -- and a cyber arms<br>race that might very well defy regulation or<br>control.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.765082836151123
         ],
         "y": [
          0.42171475291252136
         ]
        },
        {
         "hovertemplate": "Given the companies behind it, it’s hard to see<br>this “statement” as anything other than a<br>transparent attempt at regulatory capture. Strict<br>regulations on the development of AI systems will<br>only benefit the entrenched players, and make it<br>harder for competitors to enter the space. This<br>isn’t being motivated by altruism or true concern<br>for the future of humanity, at least for the<br>corporate signatories.",
         "hovertext": "Given the companies behind it, it’s hard to see<br>this “statement” as anything other than a<br>transparent attempt at regulatory capture. Strict<br>regulations on the development of AI systems will<br>only benefit the entrenched players, and make it<br>harder for competitors to enter the space. This<br>isn’t being motivated by altruism or true concern<br>for the future of humanity, at least for the<br>corporate signatories.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.025569144636392593
         ],
         "y": [
          0.8879579901695251
         ]
        },
        {
         "hovertemplate": "They aren’t talking about LLMs here. They are<br>talking about advanced AI systems with<br>capabilities far beyond our imaginations. Systems<br>that can easily compromise secure networks and<br>encryption, sabotage or drain financial markets,<br>build and implement weapons of mass destruction.<br>Systems that can self-improve. Systems that can do<br>decades of scientific research in the span of a<br>week. Systems that can enable its owners to run<br>the world; or if we are unlucky, run rampant<br>without any human control.     These systems don’t<br>exist yet, but there is no physical reason why<br>they can’t exist, to our knowledge. So science<br>fiction can quickly become science fact.",
         "hovertext": "They aren’t talking about LLMs here. They are<br>talking about advanced AI systems with<br>capabilities far beyond our imaginations. Systems<br>that can easily compromise secure networks and<br>encryption, sabotage or drain financial markets,<br>build and implement weapons of mass destruction.<br>Systems that can self-improve. Systems that can do<br>decades of scientific research in the span of a<br>week. Systems that can enable its owners to run<br>the world; or if we are unlucky, run rampant<br>without any human control.     These systems don’t<br>exist yet, but there is no physical reason why<br>they can’t exist, to our knowledge. So science<br>fiction can quickly become science fact.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.026303235441446304
         ],
         "y": [
          0.9028567671775818
         ]
        },
        {
         "hovertemplate": "We need to stop creating technologies that have<br>the threat of destroying us because eventually it<br>will happen.     How about we make our ultimate<br>goal the same as evolutions: to simply survive as<br>a species?",
         "hovertext": "We need to stop creating technologies that have<br>the threat of destroying us because eventually it<br>will happen.     How about we make our ultimate<br>goal the same as evolutions: to simply survive as<br>a species?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8309429287910461
         ],
         "y": [
          0.22013817727565765
         ]
        },
        {
         "hovertemplate": "One other thought. All software needs a kill<br>switch. Perhaps this can be required by law. It<br>shouldn't be that hard to create one, even in a<br>system that \"learns.\" Also, biology might offer<br>another, similar solution. Cells have an<br>\"apoptotic\" mechanism that causes cellular suicide<br>when there is DNA damage. Software can have a<br>similar \"feature.\"",
         "hovertext": "One other thought. All software needs a kill<br>switch. Perhaps this can be required by law. It<br>shouldn't be that hard to create one, even in a<br>system that \"learns.\" Also, biology might offer<br>another, similar solution. Cells have an<br>\"apoptotic\" mechanism that causes cellular suicide<br>when there is DNA damage. Software can have a<br>similar \"feature.\"",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.4059320390224457
         ],
         "y": [
          -0.09449398517608643
         ]
        },
        {
         "hovertemplate": "The issue is that the AI will quickly learn how to<br>modify or disable the kill switch.",
         "hovertext": "The issue is that the AI will quickly learn how to<br>modify or disable the kill switch.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4069001078605652
         ],
         "y": [
          -0.08245662599802017
         ]
        },
        {
         "hovertemplate": "@TeacherLady Maybe, maybe not. The only omnipotent<br>force in the universe that I am aware of is this<br>thing people call \"god,\" and there is no evidence<br>for the existence of such a thing.",
         "hovertext": "@TeacherLady Maybe, maybe not. The only omnipotent<br>force in the universe that I am aware of is this<br>thing people call \"god,\" and there is no evidence<br>for the existence of such a thing.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.4174834191799164
         ],
         "y": [
          -0.075863316655159
         ]
        },
        {
         "hovertemplate": "@Art Kill switch? Not  a good idea. Once AI is<br>much more intelligent than humans, it should be<br>able to identify the kill switch and find a way to<br>block it. The existence of the kill switch would<br>signify an extensional threat to the AI, and it<br>could cause the AI to take steps to defend itself,<br>perhaps with lethal consequences. You may control<br>the  elephant, but for goodness sake, don't make<br>it angry.",
         "hovertext": "@Art Kill switch? Not  a good idea. Once AI is<br>much more intelligent than humans, it should be<br>able to identify the kill switch and find a way to<br>block it. The existence of the kill switch would<br>signify an extensional threat to the AI, and it<br>could cause the AI to take steps to defend itself,<br>perhaps with lethal consequences. You may control<br>the  elephant, but for goodness sake, don't make<br>it angry.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4183979034423828
         ],
         "y": [
          -0.10215730965137482
         ]
        },
        {
         "hovertemplate": "@Steven Ledford You are imputing omnipotence to<br>this technological Leviathan (and what economists<br>call \"perfect information.\" See my comment above.",
         "hovertext": "@Steven Ledford You are imputing omnipotence to<br>this technological Leviathan (and what economists<br>call \"perfect information.\" See my comment above.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.43061143159866333
         ],
         "y": [
          -0.10675458610057831
         ]
        },
        {
         "hovertemplate": "Weren’t we warned about this years ago in a series<br>of science fiction movies about what might happen<br>if AI were developed and then eventually grew more<br>powerful than its makers ever planned? While the<br>outcome might not include very human-looking super<br>cyborgs trying to save humanity from themselves,<br>the thought that this technology could wreak havoc<br>on us all seems a very distinct possibility. Sigh.",
         "hovertext": "Weren’t we warned about this years ago in a series<br>of science fiction movies about what might happen<br>if AI were developed and then eventually grew more<br>powerful than its makers ever planned? While the<br>outcome might not include very human-looking super<br>cyborgs trying to save humanity from themselves,<br>the thought that this technology could wreak havoc<br>on us all seems a very distinct possibility. Sigh.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8170592784881592
         ],
         "y": [
          -0.451316773891449
         ]
        },
        {
         "hovertemplate": "Combine it with the ‘fun’ ‘gymnastic’ robots of<br>Boston Dynamics and well … not to be glib but<br>where is Sarah Connor ?",
         "hovertext": "Combine it with the ‘fun’ ‘gymnastic’ robots of<br>Boston Dynamics and well … not to be glib but<br>where is Sarah Connor ?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8068737983703613
         ],
         "y": [
          -0.4579707980155945
         ]
        },
        {
         "hovertemplate": "10 years hence and we'll be saying, \"'Artificial<br>Intelligence'- such an outmoded and hopelessly<br>humano-centric term.\"  1000 years hence and<br>Silicon Intelligence will be well on the way to<br>colonising the galaxy.  Carbon Intelligence?  Will<br>it even exist?",
         "hovertext": "10 years hence and we'll be saying, \"'Artificial<br>Intelligence'- such an outmoded and hopelessly<br>humano-centric term.\"  1000 years hence and<br>Silicon Intelligence will be well on the way to<br>colonising the galaxy.  Carbon Intelligence?  Will<br>it even exist?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.68149733543396
         ],
         "y": [
          0.39838674664497375
         ]
        },
        {
         "hovertemplate": "If silicon-based life doesn't understand that<br>killing humans is wrong, it's not worthy of being<br>called \"life.\"",
         "hovertext": "If silicon-based life doesn't understand that<br>killing humans is wrong, it's not worthy of being<br>called \"life.\"",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.6771326661109924
         ],
         "y": [
          0.4057563543319702
         ]
        },
        {
         "hovertemplate": "Meanwhile in the NYT this past weekend was an<br>article about 3 Chinese women who had<br>relationships with AI companions. It was crazy-<br>they actually believed it was “real” and felt they<br>were “loved.” We’re more and more disconnected<br>from what’s right in front of us, be it actual<br>people or the natural world. Sadly, we seem to be<br>disconnected from our very selves as well. What a<br>hollow shell we’re coming to accept as living<br>life.",
         "hovertext": "Meanwhile in the NYT this past weekend was an<br>article about 3 Chinese women who had<br>relationships with AI companions. It was crazy-<br>they actually believed it was “real” and felt they<br>were “loved.” We’re more and more disconnected<br>from what’s right in front of us, be it actual<br>people or the natural world. Sadly, we seem to be<br>disconnected from our very selves as well. What a<br>hollow shell we’re coming to accept as living<br>life.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.47140347957611084
         ],
         "y": [
          -0.8844901323318481
         ]
        },
        {
         "hovertemplate": "The US government can barely put the pin back in<br>the grenade that is the debt ceiling, before it<br>blows up on our face, and causes catastrophic<br>repercussions throughout the world.  Does anyone<br>actually think this totally ineffective group will<br>heed the warnings that have been given? Their<br>track record on gun violence, protecting the basic<br>human rights of its citizens, and the impending<br>doom of climate change, ensures they won’t lift a<br>finger to do anything meaningful, as they continue<br>selling us all out to the highest corporate<br>bidder.",
         "hovertext": "The US government can barely put the pin back in<br>the grenade that is the debt ceiling, before it<br>blows up on our face, and causes catastrophic<br>repercussions throughout the world.  Does anyone<br>actually think this totally ineffective group will<br>heed the warnings that have been given? Their<br>track record on gun violence, protecting the basic<br>human rights of its citizens, and the impending<br>doom of climate change, ensures they won’t lift a<br>finger to do anything meaningful, as they continue<br>selling us all out to the highest corporate<br>bidder.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3274780809879303
         ],
         "y": [
          -0.7772534489631653
         ]
        },
        {
         "hovertemplate": "No national legislation will hold sway against AI<br>as there are no boundary lines inscribed on Planet<br>Earth. Joint international legislation to control<br>AI seems even less feasible, thus the technology,<br>until further notice, has free rein for so long<br>into the future as needed to dominate the planet<br>and submit all but a privileged few human<br>accomplices into total mostly-ignorant but ever<br>well-entertained servitude.",
         "hovertext": "No national legislation will hold sway against AI<br>as there are no boundary lines inscribed on Planet<br>Earth. Joint international legislation to control<br>AI seems even less feasible, thus the technology,<br>until further notice, has free rein for so long<br>into the future as needed to dominate the planet<br>and submit all but a privileged few human<br>accomplices into total mostly-ignorant but ever<br>well-entertained servitude.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.3340403139591217
         ],
         "y": [
          -0.793379545211792
         ]
        },
        {
         "hovertemplate": "We have about as much chance of stopping AI<br>technology as we do of stopping the spread of<br>biological viruses. Although some countries may be<br>very successful at blocking or limiting AI, others<br>will plow ahead, and independent actors will<br>eventually gain access to advanced AI as the<br>advanced computer processing power becomes more<br>accessible. AI and humans have entered into a<br>state of reticulate evolution, or interbreeding.<br>The results are unpredictable.",
         "hovertext": "We have about as much chance of stopping AI<br>technology as we do of stopping the spread of<br>biological viruses. Although some countries may be<br>very successful at blocking or limiting AI, others<br>will plow ahead, and independent actors will<br>eventually gain access to advanced AI as the<br>advanced computer processing power becomes more<br>accessible. AI and humans have entered into a<br>state of reticulate evolution, or interbreeding.<br>The results are unpredictable.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9263811111450195
         ],
         "y": [
          0.05854855850338936
         ]
        },
        {
         "hovertemplate": "Industry leader asking government to regulate a<br>problem that they themselves are creating?<br>Government is slow, AI advances are exponential.",
         "hovertext": "Industry leader asking government to regulate a<br>problem that they themselves are creating?<br>Government is slow, AI advances are exponential.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9238488674163818
         ],
         "y": [
          -0.374391108751297
         ]
        },
        {
         "hovertemplate": "I want a more detailed account of the dangers of<br>AI. Rampant misinformation? I’m not sure how that<br>could get worse than it already is;  it doesn’t<br>take an evil computer to cook up today’s rampant<br>lies.     Invented pics and vids? Deep fakes have<br>been around for years.     Job displacement?<br>Hasn’t the idea of technology ending human work<br>been debunked repeatedly, with jobs created by the<br>new technology always creating even more jobs.<br>I’m not disagreeing with these experts, who are<br>disincentivized to make up doomsday scenarios, but<br>I want to know what being taken over by machines<br>will look like.",
         "hovertext": "I want a more detailed account of the dangers of<br>AI. Rampant misinformation? I’m not sure how that<br>could get worse than it already is;  it doesn’t<br>take an evil computer to cook up today’s rampant<br>lies.     Invented pics and vids? Deep fakes have<br>been around for years.     Job displacement?<br>Hasn’t the idea of technology ending human work<br>been debunked repeatedly, with jobs created by the<br>new technology always creating even more jobs.<br>I’m not disagreeing with these experts, who are<br>disincentivized to make up doomsday scenarios, but<br>I want to know what being taken over by machines<br>will look like.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.24836057424545288
         ],
         "y": [
          -0.9117639064788818
         ]
        },
        {
         "hovertemplate": "I would say to these so called industry leaders<br>\"you cannot eat your lunch and have it too\".  If<br>they feel that A.I. poses an existential risk,<br>then it is a simple decision : Stop advancing the<br>technology.  I am sure that given how \"smart\" they<br>are they should be able to figure this one out.",
         "hovertext": "I would say to these so called industry leaders<br>\"you cannot eat your lunch and have it too\".  If<br>they feel that A.I. poses an existential risk,<br>then it is a simple decision : Stop advancing the<br>technology.  I am sure that given how \"smart\" they<br>are they should be able to figure this one out.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.710517406463623
         ],
         "y": [
          0.15306994318962097
         ]
        },
        {
         "hovertemplate": "@Plato This is exactly what should be done. I<br>agree wholeheartedly.",
         "hovertext": "@Plato This is exactly what should be done. I<br>agree wholeheartedly.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7228615880012512
         ],
         "y": [
          0.14812271296977997
         ]
        },
        {
         "hovertemplate": "@Plato Unfortunately, countries like Russia, Iran<br>and North Korea will not be constrained. If we<br>halt our development of AI, they would soon become<br>dominant in this area. If AI led to the<br>development of new technologies or vast<br>improvements on current technology, they would<br>probably be the recipients of it.",
         "hovertext": "@Plato Unfortunately, countries like Russia, Iran<br>and North Korea will not be constrained. If we<br>halt our development of AI, they would soon become<br>dominant in this area. If AI led to the<br>development of new technologies or vast<br>improvements on current technology, they would<br>probably be the recipients of it.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7071024775505066
         ],
         "y": [
          0.16224460303783417
         ]
        },
        {
         "hovertemplate": "@Plato Sure, stop making something that<br>potentially returns them billions of dollars.<br>Yeah, ok.",
         "hovertext": "@Plato Sure, stop making something that<br>potentially returns them billions of dollars.<br>Yeah, ok.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.7248876094818115
         ],
         "y": [
          0.1588534712791443
         ]
        },
        {
         "hovertemplate": "Up till now humans have been the standard for<br>intelligence in the world, and look at the world.<br>Fact is, it won't take much to surpass us. The<br>emotions and creativity we cherish are easily<br>simulated in a form good enough for most of us,<br>since we are detached from them in real life<br>anyway.",
         "hovertext": "Up till now humans have been the standard for<br>intelligence in the world, and look at the world.<br>Fact is, it won't take much to surpass us. The<br>emotions and creativity we cherish are easily<br>simulated in a form good enough for most of us,<br>since we are detached from them in real life<br>anyway.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.23831601440906525
         ],
         "y": [
          -0.855573296546936
         ]
        },
        {
         "hovertemplate": "This.     George Carlin called it.  Again.<br>While he never used A.I. specifically in his<br>various bits, chunks, commentaries, books, and<br>speeches over the final third of his life, he<br>repeatedly did say that he was merely an observer<br>with a notepad, sitting off to the side of the<br>freak show that is America, and to a degree, the<br>world at large, taking notes.     He always said<br>he enjoyed entropy, societal chaos and plain old<br>fashioned B-movie end-of-life scenarios such as<br>people being hurled off roofs while trucks<br>carrying barbeque and sauce and other trucks<br>carrying chickens crash, explode, and burn below.<br>Maybe the guy from the roof lands on a chicken and<br>makes chicken salad. Chicken salad goes well with<br>BBQ.     Anyway, Carlin loved end-times chaos, and<br>went so far as to say that humans \"squandered<br>great gifts\" (large brain, opposable thumbs, tool-<br>making, etc) when \"The high priests and traders\"<br>began to step forward from the crowds all those<br>centuries ago.     Same things happening right<br>here, right now, today. High priests and traders -<br>whether you call them Tech Bros or Politicians,<br>Billionaires or Activists, The Pope or even<br>Kardashian - they're all still running amok,<br>they've always been getting more, and always for<br>themselves, and the worst part of it all is, the<br>billions and billions and billions of us regular<br>folk have let it happen all this time.     We<br>deserve everything we get.",
         "hovertext": "This.     George Carlin called it.  Again.<br>While he never used A.I. specifically in his<br>various bits, chunks, commentaries, books, and<br>speeches over the final third of his life, he<br>repeatedly did say that he was merely an observer<br>with a notepad, sitting off to the side of the<br>freak show that is America, and to a degree, the<br>world at large, taking notes.     He always said<br>he enjoyed entropy, societal chaos and plain old<br>fashioned B-movie end-of-life scenarios such as<br>people being hurled off roofs while trucks<br>carrying barbeque and sauce and other trucks<br>carrying chickens crash, explode, and burn below.<br>Maybe the guy from the roof lands on a chicken and<br>makes chicken salad. Chicken salad goes well with<br>BBQ.     Anyway, Carlin loved end-times chaos, and<br>went so far as to say that humans \"squandered<br>great gifts\" (large brain, opposable thumbs, tool-<br>making, etc) when \"The high priests and traders\"<br>began to step forward from the crowds all those<br>centuries ago.     Same things happening right<br>here, right now, today. High priests and traders -<br>whether you call them Tech Bros or Politicians,<br>Billionaires or Activists, The Pope or even<br>Kardashian - they're all still running amok,<br>they've always been getting more, and always for<br>themselves, and the worst part of it all is, the<br>billions and billions and billions of us regular<br>folk have let it happen all this time.     We<br>deserve everything we get.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1500181257724762
         ],
         "y": [
          -0.9431614279747009
         ]
        },
        {
         "hovertemplate": "The same folks warning of AI could be warning<br>about private jets.  It's the moneyed who will<br>destroy, not AI.",
         "hovertext": "The same folks warning of AI could be warning<br>about private jets.  It's the moneyed who will<br>destroy, not AI.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.9130421876907349
         ],
         "y": [
          0.37284061312675476
         ]
        },
        {
         "hovertemplate": "Notice that when “white collar” jobs are<br>threatened, the system quickly springs into action<br>and identifies potential dangers.    It’s one<br>thing when manufacturing jobs are at stake, but<br>when lawyers, advertising copy writers and medical<br>professionals stand to lose out to AI, it’s quite<br>another thing. The crucial turning point will come<br>soon enough, when the machines will be able to<br>build their own, even better machines. Then we<br>will not even need “executives” at all. Combine<br>that with the disappearance of lawyers, and<br>humanity may yet welcome its new overlords.",
         "hovertext": "Notice that when “white collar” jobs are<br>threatened, the system quickly springs into action<br>and identifies potential dangers.    It’s one<br>thing when manufacturing jobs are at stake, but<br>when lawyers, advertising copy writers and medical<br>professionals stand to lose out to AI, it’s quite<br>another thing. The crucial turning point will come<br>soon enough, when the machines will be able to<br>build their own, even better machines. Then we<br>will not even need “executives” at all. Combine<br>that with the disappearance of lawyers, and<br>humanity may yet welcome its new overlords.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.22308528423309326
         ],
         "y": [
          0.8970170617103577
         ]
        },
        {
         "hovertemplate": "wow that is so not how it's going to happen. but<br>ok. look forward to the dumbing down of humanity",
         "hovertext": "wow that is so not how it's going to happen. but<br>ok. look forward to the dumbing down of humanity",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2170264720916748
         ],
         "y": [
          0.8913715481758118
         ]
        },
        {
         "hovertemplate": "“I think if this technology goes wrong, it can go<br>quite wrong,” Mr. Altman told the Senate<br>subcommittee.    Let's be honest.  When AI goes<br>wrong, it will go very wrong.    None of these<br>brilliant human minds have any idea how to close<br>Pandora's Box 2.0",
         "hovertext": "“I think if this technology goes wrong, it can go<br>quite wrong,” Mr. Altman told the Senate<br>subcommittee.    Let's be honest.  When AI goes<br>wrong, it will go very wrong.    None of these<br>brilliant human minds have any idea how to close<br>Pandora's Box 2.0",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.9380189776420593
         ],
         "y": [
          0.23986919224262238
         ]
        },
        {
         "hovertemplate": "“Some skeptics,” @Kevin Roose? You could have<br>expanded on that more than a little. Six months<br>ago, this technology was obscure and bottled up in<br>development environments. Just 180 days later its<br>creators are warning of dire consequences should<br>it be allowed to roam unchecked. The “skeptics”<br>are trapped in the opinions they formed six months<br>ago.",
         "hovertext": "“Some skeptics,” @Kevin Roose? You could have<br>expanded on that more than a little. Six months<br>ago, this technology was obscure and bottled up in<br>development environments. Just 180 days later its<br>creators are warning of dire consequences should<br>it be allowed to roam unchecked. The “skeptics”<br>are trapped in the opinions they formed six months<br>ago.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8802072405815125
         ],
         "y": [
          0.4637993574142456
         ]
        },
        {
         "hovertemplate": "“ researchers sometimes stop short of explaining<br>how that would happen.” says it all. I am doing AI<br>research. The threat will be to jobs, not the<br>species.    AI has no volition. Without it, it<br>cannot become sentient.     It is up to coders to<br>keep AI from developing something akin to a free<br>will, if that is even possible. Right now, ChatGPT<br>does not contact me with an idea for the project I<br>am doing.    When it can do that, that should be<br>where regulations focus, with stiff punishments<br>for disinformation spread by AI.    We have<br>current problems enough. Why isn’t the cesspool of<br>Twitter regulated? Why isn’t Alphabet forced more<br>strongly to remove fake news and disinformation<br>from YouTube? Meta to pull down all militia<br>content and election lies from Facebook?",
         "hovertext": "“ researchers sometimes stop short of explaining<br>how that would happen.” says it all. I am doing AI<br>research. The threat will be to jobs, not the<br>species.    AI has no volition. Without it, it<br>cannot become sentient.     It is up to coders to<br>keep AI from developing something akin to a free<br>will, if that is even possible. Right now, ChatGPT<br>does not contact me with an idea for the project I<br>am doing.    When it can do that, that should be<br>where regulations focus, with stiff punishments<br>for disinformation spread by AI.    We have<br>current problems enough. Why isn’t the cesspool of<br>Twitter regulated? Why isn’t Alphabet forced more<br>strongly to remove fake news and disinformation<br>from YouTube? Meta to pull down all militia<br>content and election lies from Facebook?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.00195901351980865
         ],
         "y": [
          -0.6552648544311523
         ]
        },
        {
         "hovertemplate": "probably because regulating free speech is a<br>double edged sword. suppressing even<br>disinformstion will never do anything but<br>propogated it. all the attempts to regulate it<br>have done is help already cynical people feel that<br>the truth is being suppressed, and drives the<br>information into more insulation echo chambers.",
         "hovertext": "probably because regulating free speech is a<br>double edged sword. suppressing even<br>disinformstion will never do anything but<br>propogated it. all the attempts to regulate it<br>have done is help already cynical people feel that<br>the truth is being suppressed, and drives the<br>information into more insulation echo chambers.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.0007784467888996005
         ],
         "y": [
          -0.6416881084442139
         ]
        },
        {
         "hovertemplate": "@lis I disagree strongly here. We need to regulate<br>fighting words. The SCOTUS decision Chaplinsky v.<br>New Hampshire supported this.    I would go<br>further, but I don't have that power. Denying<br>elections led to violence on Jan. 6. Promoting<br>medical quackery has cost lives during COVID.  So<br>yes, regulate and punish. Punish harshly where it<br>counts: billions in fines.",
         "hovertext": "@lis I disagree strongly here. We need to regulate<br>fighting words. The SCOTUS decision Chaplinsky v.<br>New Hampshire supported this.    I would go<br>further, but I don't have that power. Denying<br>elections led to violence on Jan. 6. Promoting<br>medical quackery has cost lives during COVID.  So<br>yes, regulate and punish. Punish harshly where it<br>counts: billions in fines.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.008626699447631836
         ],
         "y": [
          -0.6412072777748108
         ]
        },
        {
         "hovertemplate": "They're building this stuff and warning that it<br>could destroy us? Right.",
         "hovertext": "They're building this stuff and warning that it<br>could destroy us? Right.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.844916582107544
         ],
         "y": [
          0.16795863211154938
         ]
        },
        {
         "hovertemplate": "That’s one way to look at it, but not an<br>intelligent way. They’re building something that<br>has the capacity to bring a lot of good and<br>solutions to our world. Left unchecked, those same<br>systems can be used for evil purpose. That’s where<br>regulation should come in, to establish that line.<br>We would be missing out on a potential tool for<br>solving what may be unsolvable problems without<br>it, like runaway climate change for instance, if<br>we simply “put it back in the box”.     Think of<br>it like electricity, another revolutionary<br>discovery. You’re allowed to use it to light and<br>power your home, but not to energize a garden of<br>illegal drugs. We wouldn’t want to just say no to<br>electricity altogether because we’re scared of<br>ways it could be used to harm. It powers a<br>plethora of medical instruments that save lives<br>too. And enables air conditioning. What would be<br>more valuable is to say something like: “Deepfake<br>videos are not valuable and have the capacity to<br>do great harm. Let’s make deepfakes illegal as a<br>society.” Extrapolate from there.",
         "hovertext": "That’s one way to look at it, but not an<br>intelligent way. They’re building something that<br>has the capacity to bring a lot of good and<br>solutions to our world. Left unchecked, those same<br>systems can be used for evil purpose. That’s where<br>regulation should come in, to establish that line.<br>We would be missing out on a potential tool for<br>solving what may be unsolvable problems without<br>it, like runaway climate change for instance, if<br>we simply “put it back in the box”.     Think of<br>it like electricity, another revolutionary<br>discovery. You’re allowed to use it to light and<br>power your home, but not to energize a garden of<br>illegal drugs. We wouldn’t want to just say no to<br>electricity altogether because we’re scared of<br>ways it could be used to harm. It powers a<br>plethora of medical instruments that save lives<br>too. And enables air conditioning. What would be<br>more valuable is to say something like: “Deepfake<br>videos are not valuable and have the capacity to<br>do great harm. Let’s make deepfakes illegal as a<br>society.” Extrapolate from there.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8608044385910034
         ],
         "y": [
          0.17014208436012268
         ]
        },
        {
         "hovertemplate": "Ask AI, Is there a supreme deity? Like the sad old<br>computer joke, the answer will be, \"Now there is.\"<br>But hey, humans haven't listened very well to<br>warnings about catastrophic climate change, so I<br>challenge out new \"god\" to beat that in extincting<br>us. Go AI!",
         "hovertext": "Ask AI, Is there a supreme deity? Like the sad old<br>computer joke, the answer will be, \"Now there is.\"<br>But hey, humans haven't listened very well to<br>warnings about catastrophic climate change, so I<br>challenge out new \"god\" to beat that in extincting<br>us. Go AI!",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.2431003749370575
         ],
         "y": [
          0.8740566968917847
         ]
        },
        {
         "hovertemplate": "“We didn’t want to push for a very large menu of<br>30 potential interventions,” Mr. Hendrycks said.<br>“When that happens, it dilutes the message.”<br>Please, dilute the message. I want to know exactly<br>what risks everyone thinks are possible and what<br>interventions they may require. Otherwise, the<br>article and message are too obtuse to address.",
         "hovertext": "“We didn’t want to push for a very large menu of<br>30 potential interventions,” Mr. Hendrycks said.<br>“When that happens, it dilutes the message.”<br>Please, dilute the message. I want to know exactly<br>what risks everyone thinks are possible and what<br>interventions they may require. Otherwise, the<br>article and message are too obtuse to address.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.407492071390152
         ],
         "y": [
          -0.6516724824905396
         ]
        },
        {
         "hovertemplate": "I agree with both of you. they want to start with<br>establishing that there is a general consensus<br>here. im sure they intend to follow up",
         "hovertext": "I agree with both of you. they want to start with<br>establishing that there is a general consensus<br>here. im sure they intend to follow up",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.4144286513328552
         ],
         "y": [
          -0.6626449227333069
         ]
        },
        {
         "hovertemplate": "Did it really take “industry leaders” this long to<br>grasp what so many of us have understood years<br>ago?! Good grief– these tech folks are obnoxious.",
         "hovertext": "Did it really take “industry leaders” this long to<br>grasp what so many of us have understood years<br>ago?! Good grief– these tech folks are obnoxious.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6576976180076599
         ],
         "y": [
          0.6426921486854553
         ]
        },
        {
         "hovertemplate": "If they are that worried about it, couldn’t they<br>just stop making it?",
         "hovertext": "If they are that worried about it, couldn’t they<br>just stop making it?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.31109657883644104
         ],
         "y": [
          -0.8832132816314697
         ]
        },
        {
         "hovertemplate": "Dear World,    We have invented something. It's a<br>kind of Kraken. The only actual benefit to this<br>invention is that it will make us filthy rich. The<br>downside is that it might destroy the world.<br>Prepare yourselves.",
         "hovertext": "Dear World,    We have invented something. It's a<br>kind of Kraken. The only actual benefit to this<br>invention is that it will make us filthy rich. The<br>downside is that it might destroy the world.<br>Prepare yourselves.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.10230062901973724
         ],
         "y": [
          0.989452064037323
         ]
        },
        {
         "hovertemplate": "My suggestion is simply \"Put the chips back in the<br>box.\"",
         "hovertext": "My suggestion is simply \"Put the chips back in the<br>box.\"",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.22418686747550964
         ],
         "y": [
          -0.6969587206840515
         ]
        },
        {
         "hovertemplate": "What’s been discovered cannot be undiscovered.<br>They put the chips back in the box, someone else<br>takes them out to play with. What’s done is done.<br>Regulation is the only logical option.",
         "hovertext": "What’s been discovered cannot be undiscovered.<br>They put the chips back in the box, someone else<br>takes them out to play with. What’s done is done.<br>Regulation is the only logical option.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.2179913967847824
         ],
         "y": [
          -0.6852877140045166
         ]
        },
        {
         "hovertemplate": "@John Probably  Regulation by whom? Dems, Repubs?<br>Yeah, can't wait for the next election to see how<br>that goes.",
         "hovertext": "@John Probably  Regulation by whom? Dems, Repubs?<br>Yeah, can't wait for the next election to see how<br>that goes.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.21057982742786407
         ],
         "y": [
          -0.6916422843933105
         ]
        },
        {
         "hovertemplate": "We will lose nearly our entire economy to AI. We<br>will lose stable government due to AI. We will<br>lose our homes because of climate change. We will<br>experience violence because people will lose hope.<br>And the structures that could stop it have been<br>intentionally and catastrophically eroded. This on<br>top of all our other struggles!    What do we do?<br>I urge everyone to remember we are strongest if we<br>can build spaces and communities and skills where<br>the AI can't yet penetrate. So humans can take<br>care of each other. When our computers and phones<br>become destabilizing and dangerous, when our jobs<br>are gone, when our children experience despair, we<br>will find safety and hope in human connections,<br>real community spaces, and neighbors caring for<br>neighbors.     We're not at the killer robot stage<br>yet. We're in the stage where a country of screen-<br>addicted, isolated humans willingly self-<br>destructs.",
         "hovertext": "We will lose nearly our entire economy to AI. We<br>will lose stable government due to AI. We will<br>lose our homes because of climate change. We will<br>experience violence because people will lose hope.<br>And the structures that could stop it have been<br>intentionally and catastrophically eroded. This on<br>top of all our other struggles!    What do we do?<br>I urge everyone to remember we are strongest if we<br>can build spaces and communities and skills where<br>the AI can't yet penetrate. So humans can take<br>care of each other. When our computers and phones<br>become destabilizing and dangerous, when our jobs<br>are gone, when our children experience despair, we<br>will find safety and hope in human connections,<br>real community spaces, and neighbors caring for<br>neighbors.     We're not at the killer robot stage<br>yet. We're in the stage where a country of screen-<br>addicted, isolated humans willingly self-<br>destructs.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7425020337104797
         ],
         "y": [
          0.682926595211029
         ]
        },
        {
         "hovertemplate": "\"Recent advancements in so-called large language<br>models...have raised fears that A.I. could soon be<br>used at scale to spread misinformation and<br>propaganda, or that it could eliminate millions of<br>white-collar jobs.\"    I keep waiting for somebody<br>to point out that these very real \"risks\" are<br>contingent on human choices. It's as if the<br>invention of cigarettes were followed by fears<br>that people might become addicted to nicotine, or<br>Henry Ford had voiced concerns that dependence on<br>fossil fuels could have unexpected consequences.<br>Give me a break. If we as a society for decades<br>haven't been interested in promoting critical<br>thinking as part of public education (e.g., don't<br>believe everything you read on the internet), or<br>put up no guardrails whatsoever to employment<br>practices (e.g., fire at will, let private equity<br>firms run amok, etc.), then absolutely, AI will be<br>like a runaway asteroid coming for earth, because<br>we like it that way.",
         "hovertext": "\"Recent advancements in so-called large language<br>models...have raised fears that A.I. could soon be<br>used at scale to spread misinformation and<br>propaganda, or that it could eliminate millions of<br>white-collar jobs.\"    I keep waiting for somebody<br>to point out that these very real \"risks\" are<br>contingent on human choices. It's as if the<br>invention of cigarettes were followed by fears<br>that people might become addicted to nicotine, or<br>Henry Ford had voiced concerns that dependence on<br>fossil fuels could have unexpected consequences.<br>Give me a break. If we as a society for decades<br>haven't been interested in promoting critical<br>thinking as part of public education (e.g., don't<br>believe everything you read on the internet), or<br>put up no guardrails whatsoever to employment<br>practices (e.g., fire at will, let private equity<br>firms run amok, etc.), then absolutely, AI will be<br>like a runaway asteroid coming for earth, because<br>we like it that way.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5269126892089844
         ],
         "y": [
          0.7968082427978516
         ]
        },
        {
         "hovertemplate": "Soon manual labor may become the predominant form<br>of employment for people.",
         "hovertext": "Soon manual labor may become the predominant form<br>of employment for people.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3416731655597687
         ],
         "y": [
          -0.6898460984230042
         ]
        },
        {
         "hovertemplate": "Unless they develop robots with great manual<br>dexterity.",
         "hovertext": "Unless they develop robots with great manual<br>dexterity.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3391903340816498
         ],
         "y": [
          -0.6976954936981201
         ]
        },
        {
         "hovertemplate": "They knew this before they developed it but did it<br>anyway.  Money trumps logic, and a consumption and<br>greed-based economy is a lethal flaw to humanity.<br>Yet there are no signs we realize it yet.",
         "hovertext": "They knew this before they developed it but did it<br>anyway.  Money trumps logic, and a consumption and<br>greed-based economy is a lethal flaw to humanity.<br>Yet there are no signs we realize it yet.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.8098501563072205
         ],
         "y": [
          0.1170424297451973
         ]
        },
        {
         "hovertemplate": "its capitalism all the way down",
         "hovertext": "its capitalism all the way down",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.8085806965827942
         ],
         "y": [
          0.1256016343832016
         ]
        },
        {
         "hovertemplate": "AI is revenge of the nerds for the 21st century.<br>But yeah, AI...yay.",
         "hovertext": "AI is revenge of the nerds for the 21st century.<br>But yeah, AI...yay.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.3586046099662781
         ],
         "y": [
          -0.9216691851615906
         ]
        },
        {
         "hovertemplate": "\"...though researchers sometimes stop short of<br>explaining how that would happen...\"    You know,<br>I'd kind of like to know how it is going to<br>happen.  Just saying.",
         "hovertext": "\"...though researchers sometimes stop short of<br>explaining how that would happen...\"    You know,<br>I'd kind of like to know how it is going to<br>happen.  Just saying.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8170099854469299
         ],
         "y": [
          0.007958290167152882
         ]
        },
        {
         "hovertemplate": "Because it’s all theory. But it doesn’t take much<br>deep thinking to get to the risk. If something is<br>smarter than the smartest human by vast orders of<br>magnitude, how can humans possibly control or<br>contain it. Can an insect effectively control you?<br>An amoeba? Also, how useful would you be, in<br>achievement of goals, to an entity like that?<br>Probably not very. So why would it keep you<br>around, in the way, so to speak?",
         "hovertext": "Because it’s all theory. But it doesn’t take much<br>deep thinking to get to the risk. If something is<br>smarter than the smartest human by vast orders of<br>magnitude, how can humans possibly control or<br>contain it. Can an insect effectively control you?<br>An amoeba? Also, how useful would you be, in<br>achievement of goals, to an entity like that?<br>Probably not very. So why would it keep you<br>around, in the way, so to speak?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8058951497077942
         ],
         "y": [
          0.006838966626673937
         ]
        },
        {
         "hovertemplate": "@r You're simply talking \"theoretical\", viz.,<br>science fiction.  Sure, it's easy to get high and<br>postulate without much deep thinking. But, these<br>folks are supposedly identifying and referencing<br>concrete existential threats; otherwise its the<br>equivalent of sitting around getting high and<br>discussing science fiction and there wouldn't be<br>much need for - or benefit from -  the explicit<br>warning and the article is a complete waste of<br>time and space.",
         "hovertext": "@r You're simply talking \"theoretical\", viz.,<br>science fiction.  Sure, it's easy to get high and<br>postulate without much deep thinking. But, these<br>folks are supposedly identifying and referencing<br>concrete existential threats; otherwise its the<br>equivalent of sitting around getting high and<br>discussing science fiction and there wouldn't be<br>much need for - or benefit from -  the explicit<br>warning and the article is a complete waste of<br>time and space.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.794305682182312
         ],
         "y": [
          0.005738302133977413
         ]
        },
        {
         "hovertemplate": "What type of world will GAI create?<br>Terminators or Barbie Dreamland?     Matrix or The<br>Truman Show?     We assume the worst, but if GAI<br>is smarter than humans, the opposite may be the<br>case.",
         "hovertext": "What type of world will GAI create?<br>Terminators or Barbie Dreamland?     Matrix or The<br>Truman Show?     We assume the worst, but if GAI<br>is smarter than humans, the opposite may be the<br>case.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.16071736812591553
         ],
         "y": [
          0.7327920198440552
         ]
        },
        {
         "hovertemplate": "@Richard Gooding Your use of the word \"may\" is a<br>bit unsettling...but makes the point. We're<br>playing with toys we don't understand.",
         "hovertext": "@Richard Gooding Your use of the word \"may\" is a<br>bit unsettling...but makes the point. We're<br>playing with toys we don't understand.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.16282352805137634
         ],
         "y": [
          0.7477051615715027
         ]
        },
        {
         "hovertemplate": "@Richard Gooding Ignorance is a bliss. Since GAI<br>based its learning on human generated information.<br>We are not kinder and gentler than the general<br>population.",
         "hovertext": "@Richard Gooding Ignorance is a bliss. Since GAI<br>based its learning on human generated information.<br>We are not kinder and gentler than the general<br>population.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.16894406080245972
         ],
         "y": [
          0.7293333411216736
         ]
        },
        {
         "hovertemplate": "Some have postulated that that the reason we<br>haven’t had contact with any advanced civilization<br>in a universe potentially teeming with life-<br>sustaining worlds is that once they reach a<br>certain level of intelligence they unintentionally<br>invent themselves into extinction.  Based on our<br>single data point this seems a rather realistic<br>scenario.",
         "hovertext": "Some have postulated that that the reason we<br>haven’t had contact with any advanced civilization<br>in a universe potentially teeming with life-<br>sustaining worlds is that once they reach a<br>certain level of intelligence they unintentionally<br>invent themselves into extinction.  Based on our<br>single data point this seems a rather realistic<br>scenario.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.6933162808418274
         ],
         "y": [
          -0.19395314157009125
         ]
        },
        {
         "hovertemplate": "Enrico Fermi predicted this decades ago, based on<br>the absence of any modulated signals coming from<br>anywhere in the universe.",
         "hovertext": "Enrico Fermi predicted this decades ago, based on<br>the absence of any modulated signals coming from<br>anywhere in the universe.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7067047953605652
         ],
         "y": [
          -0.19143643975257874
         ]
        },
        {
         "hovertemplate": "Or, the illusion of separation exists so we, the<br>one, would not to be alone. Perhaps that’s even<br>more mind blowing for it would mean the purpose of<br>life is love.",
         "hovertext": "Or, the illusion of separation exists so we, the<br>one, would not to be alone. Perhaps that’s even<br>more mind blowing for it would mean the purpose of<br>life is love.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7035215497016907
         ],
         "y": [
          -0.20241159200668335
         ]
        },
        {
         "hovertemplate": "@AuReader - More likely earth has been placed into<br>permanent quarantine by the more intelligent<br>species in the galaxy.",
         "hovertext": "@AuReader - More likely earth has been placed into<br>permanent quarantine by the more intelligent<br>species in the galaxy.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.683044970035553
         ],
         "y": [
          -0.1920737773180008
         ]
        },
        {
         "hovertemplate": "Basically, these execs are saying, this thing we<br>have developed and continue to develop and make<br>available to the general public, that thing might<br>kill you someday but someone else needs to make<br>rules for how its used and try to contain it<br>because hey we’re just the developers trying beat<br>the competition and make a pile of money along the<br>way.",
         "hovertext": "Basically, these execs are saying, this thing we<br>have developed and continue to develop and make<br>available to the general public, that thing might<br>kill you someday but someone else needs to make<br>rules for how its used and try to contain it<br>because hey we’re just the developers trying beat<br>the competition and make a pile of money along the<br>way.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8237735629081726
         ],
         "y": [
          -0.5656635165214539
         ]
        },
        {
         "hovertemplate": "What if AI can be made to realize that its<br>technological advancement is a danger to itself<br>(such as we are now realizing)?",
         "hovertext": "What if AI can be made to realize that its<br>technological advancement is a danger to itself<br>(such as we are now realizing)?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.9643135666847229
         ],
         "y": [
          0.21466955542564392
         ]
        },
        {
         "hovertemplate": "Warning the world about what \"they are building\"?<br>So...they hold some form of ethical values but<br>cannot and will not act upon them? They cannot get<br>off the track they are building themselves? Their<br>greed goes beyond all comprehension.",
         "hovertext": "Warning the world about what \"they are building\"?<br>So...they hold some form of ethical values but<br>cannot and will not act upon them? They cannot get<br>off the track they are building themselves? Their<br>greed goes beyond all comprehension.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.41453486680984497
         ],
         "y": [
          0.6189340353012085
         ]
        },
        {
         "hovertemplate": "But we were warned. Nice that there’s a threesome…<br>nuclear war, climate devastation and now<br>artificial intelligence.   AI will lead to nuclear<br>war which will accelerate climate change. All this<br>will be brought about by humans this ridding the<br>world of a toxic life form",
         "hovertext": "But we were warned. Nice that there’s a threesome…<br>nuclear war, climate devastation and now<br>artificial intelligence.   AI will lead to nuclear<br>war which will accelerate climate change. All this<br>will be brought about by humans this ridding the<br>world of a toxic life form",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.4236895442008972
         ],
         "y": [
          0.6128221154212952
         ]
        },
        {
         "hovertemplate": "… And then we have a global pandemic and it’s an<br>uphill battle just to convince people to wash<br>their hands…",
         "hovertext": "… And then we have a global pandemic and it’s an<br>uphill battle just to convince people to wash<br>their hands…",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.41997113823890686
         ],
         "y": [
          0.6328850984573364
         ]
        },
        {
         "hovertemplate": "@Yuripelham Add pandemic organisms to nuclear war,<br>climate devastation and now artificial<br>intelligence and you have the latest version of<br>the four horsemen of apocalypse. Humanity has<br>fought these and will continue to wager against<br>them and each replacement through time past,<br>present, and forward. At least until our time in<br>the universe, however long or brief reaches as far<br>as it will.",
         "hovertext": "@Yuripelham Add pandemic organisms to nuclear war,<br>climate devastation and now artificial<br>intelligence and you have the latest version of<br>the four horsemen of apocalypse. Humanity has<br>fought these and will continue to wager against<br>them and each replacement through time past,<br>present, and forward. At least until our time in<br>the universe, however long or brief reaches as far<br>as it will.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4354020357131958
         ],
         "y": [
          0.6221051216125488
         ]
        },
        {
         "hovertemplate": "the industrial revolution brought about climate<br>change.    the tech revolution has already wrought<br>violent social division and deepened social<br>inequities; that we can clearly imagine what else<br>lay ahead for us should not be taken lightly.<br>but this needs to be the basis for action. this<br>whole conversation everyone’s having in a tuesday<br>morning comment thread is good to have—but it’s<br>moot without organized resistance. how do we work<br>to actively dismantle AI technologies or the<br>institutions that make them? i don’t advocate for<br>kaczynski-style violence, but a strong, concerted,<br>non-violent anti-smart tech. revolution is<br>necessary.    i don’t have the answers to how to<br>do this, but we need to take more action than<br>leaving comments.",
         "hovertext": "the industrial revolution brought about climate<br>change.    the tech revolution has already wrought<br>violent social division and deepened social<br>inequities; that we can clearly imagine what else<br>lay ahead for us should not be taken lightly.<br>but this needs to be the basis for action. this<br>whole conversation everyone’s having in a tuesday<br>morning comment thread is good to have—but it’s<br>moot without organized resistance. how do we work<br>to actively dismantle AI technologies or the<br>institutions that make them? i don’t advocate for<br>kaczynski-style violence, but a strong, concerted,<br>non-violent anti-smart tech. revolution is<br>necessary.    i don’t have the answers to how to<br>do this, but we need to take more action than<br>leaving comments.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.0705016702413559
         ],
         "y": [
          -0.7610577940940857
         ]
        },
        {
         "hovertemplate": "Violent social division has been around since the<br>dawn of time. Tech just made it so we can't easily<br>ignore it.",
         "hovertext": "Violent social division has been around since the<br>dawn of time. Tech just made it so we can't easily<br>ignore it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.06945653259754181
         ],
         "y": [
          -0.7487965226173401
         ]
        },
        {
         "hovertemplate": "i don’t disagree. social division has been around<br>for a long time.    but maybe a little more<br>exposure to algorithm deaign and purpose would<br>help you some. tech companies don’t design<br>algorithms to simply give us greater access to<br>seeing social divisions more readily. the<br>algorithms that *determine* what we see and how we<br>see it are *designed* to make us think and feel<br>certain things about what we see, and therefore<br>actively *cause* these social divisions. read<br>facebook’s 2012 study on how successful they were<br>at changing users’ attitudes, emotional responses,<br>and real-world actions in response. it’s<br>terrifying.    this has been the core of social<br>media design for the last 10-12 years, and both<br>china and russia are widely recognized as<br>exploiting this facet of tech use by their own<br>militaries: they’ve exploited this to sow social<br>discord in other countries around the world, and<br>have no doubt they’d do it here too.    what could<br>and would AI do?",
         "hovertext": "i don’t disagree. social division has been around<br>for a long time.    but maybe a little more<br>exposure to algorithm deaign and purpose would<br>help you some. tech companies don’t design<br>algorithms to simply give us greater access to<br>seeing social divisions more readily. the<br>algorithms that *determine* what we see and how we<br>see it are *designed* to make us think and feel<br>certain things about what we see, and therefore<br>actively *cause* these social divisions. read<br>facebook’s 2012 study on how successful they were<br>at changing users’ attitudes, emotional responses,<br>and real-world actions in response. it’s<br>terrifying.    this has been the core of social<br>media design for the last 10-12 years, and both<br>china and russia are widely recognized as<br>exploiting this facet of tech use by their own<br>militaries: they’ve exploited this to sow social<br>discord in other countries around the world, and<br>have no doubt they’d do it here too.    what could<br>and would AI do?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.07158109545707703
         ],
         "y": [
          -0.7766501307487488
         ]
        },
        {
         "hovertemplate": "Assume, for the sake of argument, that the U.S.<br>and ither western nations find safeguards to<br>control or regulate AI so as to mitigate the sort<br>of dangers its creators imagine. What confidence<br>do we have that, for example, Iranian, North<br>Korean, Russian or Chinese actors or state actors<br>would abide by safeguards?  When the genie escapes<br>the bottle, it can’t be put back in.",
         "hovertext": "Assume, for the sake of argument, that the U.S.<br>and ither western nations find safeguards to<br>control or regulate AI so as to mitigate the sort<br>of dangers its creators imagine. What confidence<br>do we have that, for example, Iranian, North<br>Korean, Russian or Chinese actors or state actors<br>would abide by safeguards?  When the genie escapes<br>the bottle, it can’t be put back in.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7337769865989685
         ],
         "y": [
          0.012002963572740555
         ]
        },
        {
         "hovertemplate": "The Center for Humane Technology addressed this<br>concern in the talk they gave in March called The<br>A.I. Dilemma. <a<br>href=\"https://youtu.be/xoVJKj8lcNQ\"<br>target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a><br>I can’t stress enough how important this talk is,<br>so please carve out an hour to check it out.<br>Basically, since technology companies in the U.S.<br>currently control the means for A.I. advancement,<br>we can put in place the regulations and standards<br>that these researchers are asking for.    China<br>often follows our lead. It really says something<br>that their government is quite nervous about<br>A.I.’s impact on their ability to wield social<br>control.",
         "hovertext": "The Center for Humane Technology addressed this<br>concern in the talk they gave in March called The<br>A.I. Dilemma. <a<br>href=\"https://youtu.be/xoVJKj8lcNQ\"<br>target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a><br>I can’t stress enough how important this talk is,<br>so please carve out an hour to check it out.<br>Basically, since technology companies in the U.S.<br>currently control the means for A.I. advancement,<br>we can put in place the regulations and standards<br>that these researchers are asking for.    China<br>often follows our lead. It really says something<br>that their government is quite nervous about<br>A.I.’s impact on their ability to wield social<br>control.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.7249112725257874
         ],
         "y": [
          0.012655409052968025
         ]
        },
        {
         "hovertemplate": "Technology has helped improve the lives of many<br>people, but yet there are and  always will be bad<br>actors who want to dominate and control for<br>personal benefit   Perhaps AI can be trained to<br>detect the bad actors amongst us and thwart their<br>evil intentions.   Bit of a heavy lift.   Who will<br>engineer the training.   Politicians? Religious<br>leaders?  Techie whiz kids?",
         "hovertext": "Technology has helped improve the lives of many<br>people, but yet there are and  always will be bad<br>actors who want to dominate and control for<br>personal benefit   Perhaps AI can be trained to<br>detect the bad actors amongst us and thwart their<br>evil intentions.   Bit of a heavy lift.   Who will<br>engineer the training.   Politicians? Religious<br>leaders?  Techie whiz kids?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.15883757174015045
         ],
         "y": [
          -0.9127604961395264
         ]
        },
        {
         "hovertemplate": "Roll back or eliminate Section 230. Make the<br>companies responsible for what they make. Then<br>we'll see how quickly they get their acts<br>together.",
         "hovertext": "Roll back or eliminate Section 230. Make the<br>companies responsible for what they make. Then<br>we'll see how quickly they get their acts<br>together.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7983403205871582
         ],
         "y": [
          -0.3608548045158386
         ]
        },
        {
         "hovertemplate": "It doesn’t matter. They will still do it<br>underground. They are looking for a sense of<br>purpose, a sense of belonging, a sense of comfort,<br>a sense of proving oneself to no one knows. AI<br>gives them all.",
         "hovertext": "It doesn’t matter. They will still do it<br>underground. They are looking for a sense of<br>purpose, a sense of belonging, a sense of comfort,<br>a sense of proving oneself to no one knows. AI<br>gives them all.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.8114368319511414
         ],
         "y": [
          -0.3668998181819916
         ]
        },
        {
         "hovertemplate": "So, they are the ones building and advancing the<br>technology in a increasingly faster way, and they<br>are the ones alerting us about how dangerous it<br>will be for mankind? How about they just stop<br>moving the tech forward? If the prediction its<br>reliable there's absolute no reason to keep it<br>going with this line of tech!",
         "hovertext": "So, they are the ones building and advancing the<br>technology in a increasingly faster way, and they<br>are the ones alerting us about how dangerous it<br>will be for mankind? How about they just stop<br>moving the tech forward? If the prediction its<br>reliable there's absolute no reason to keep it<br>going with this line of tech!",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.4949258863925934
         ],
         "y": [
          0.5293390154838562
         ]
        },
        {
         "hovertemplate": "They can’t. It is too enticing: human curiosity<br>just can’t help itself.",
         "hovertext": "They can’t. It is too enticing: human curiosity<br>just can’t help itself.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5084160566329956
         ],
         "y": [
          0.5271650552749634
         ]
        },
        {
         "hovertemplate": "Even if it's not then, someone else will",
         "hovertext": "Even if it's not then, someone else will",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.49341684579849243
         ],
         "y": [
          0.5419219732284546
         ]
        },
        {
         "hovertemplate": "It’s too late. The technology has left the barn so<br>to speak. Now it’s an arms race.",
         "hovertext": "It’s too late. The technology has left the barn so<br>to speak. Now it’s an arms race.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.5042004585266113
         ],
         "y": [
          0.5416924953460693
         ]
        },
        {
         "hovertemplate": "@Dih Well, maybe started as human curiosity. and<br>quickly surpassed by human greed.",
         "hovertext": "@Dih Well, maybe started as human curiosity. and<br>quickly surpassed by human greed.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.5215420126914978
         ],
         "y": [
          0.5349789261817932
         ]
        },
        {
         "hovertemplate": "I'm a psychologist & have been writing &<br>presenting about how technology effects us for<br>decades. I'm deeply concerned about AIs, and I've<br>been writing furiously about the risks involved<br>with AIs since I first tried out ChatGPT. It's<br>just a matter of time that these AIs become better<br>than humans at, well, just about everything. We<br>have very difficult challenges to manage -<br>alignment problems, control problems, black box<br>problems, & bad actors using AIs for nefarious<br>purposes, like ChaosGPT. Plus, there's the<br>potential of recursive self-improvement and a fast<br>takeoff to superintelligence. As AIs scale up in<br>power & proliferate, we need better guardrails in<br>place to ensure they don't go off them. As<br>concerned citizens, we can write different<br>government bodies to encourage regulation. We want<br>the amazing benefits of AIs, but we must mitigate<br>risks as humanity ventures into totally uncharted<br>waters with AIs. We won't get a do-over on this,<br>so the wise move here is to err on the side of<br>caution.",
         "hovertext": "I'm a psychologist & have been writing &<br>presenting about how technology effects us for<br>decades. I'm deeply concerned about AIs, and I've<br>been writing furiously about the risks involved<br>with AIs since I first tried out ChatGPT. It's<br>just a matter of time that these AIs become better<br>than humans at, well, just about everything. We<br>have very difficult challenges to manage -<br>alignment problems, control problems, black box<br>problems, & bad actors using AIs for nefarious<br>purposes, like ChaosGPT. Plus, there's the<br>potential of recursive self-improvement and a fast<br>takeoff to superintelligence. As AIs scale up in<br>power & proliferate, we need better guardrails in<br>place to ensure they don't go off them. As<br>concerned citizens, we can write different<br>government bodies to encourage regulation. We want<br>the amazing benefits of AIs, but we must mitigate<br>risks as humanity ventures into totally uncharted<br>waters with AIs. We won't get a do-over on this,<br>so the wise move here is to err on the side of<br>caution.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6691137552261353
         ],
         "y": [
          -0.5580881834030151
         ]
        },
        {
         "hovertemplate": "\"(T)here's the potential of recursive self-<br>improvement and a fast takeoff to<br>superintelligence.\"     Because artificial<br>intelligence systems are not actually intelligent,<br>but only play statistical games with language to<br>emulate the result of human thought, it is also<br>possible that as AI increasing trains on its own<br>outputs, it will become stupider and more riddled<br>with errors. Some of the risk stems from that.",
         "hovertext": "\"(T)here's the potential of recursive self-<br>improvement and a fast takeoff to<br>superintelligence.\"     Because artificial<br>intelligence systems are not actually intelligent,<br>but only play statistical games with language to<br>emulate the result of human thought, it is also<br>possible that as AI increasing trains on its own<br>outputs, it will become stupider and more riddled<br>with errors. Some of the risk stems from that.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6614246368408203
         ],
         "y": [
          -0.5673811435699463
         ]
        },
        {
         "hovertemplate": "Well, the cat’s out of the bag now. The lack of<br>conscience and forethought in the scientific<br>community is astounding.  My advanced age insures<br>I won’t live to see the dystopian world to come,<br>but my grandchildren will, and I ache for them.<br>Perhaps science will find a way to feed, clothe<br>and house a few billion displaced souls.",
         "hovertext": "Well, the cat’s out of the bag now. The lack of<br>conscience and forethought in the scientific<br>community is astounding.  My advanced age insures<br>I won’t live to see the dystopian world to come,<br>but my grandchildren will, and I ache for them.<br>Perhaps science will find a way to feed, clothe<br>and house a few billion displaced souls.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.5598483681678772
         ],
         "y": [
          -0.5278728604316711
         ]
        },
        {
         "hovertemplate": "Science has found a way and corporations thwart<br>the progress of science to maintain a status quo<br>that works for them, to the detriment of the many.",
         "hovertext": "Science has found a way and corporations thwart<br>the progress of science to maintain a status quo<br>that works for them, to the detriment of the many.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.5707530379295349
         ],
         "y": [
          -0.5368096232414246
         ]
        },
        {
         "hovertemplate": "There is a profound level of ethics in the<br>scientific community. That is why we see this<br>letter. The problem is that the technology that<br>can be used for good can also be used for harm.<br>With foresight showing that artificial<br>intelligence is becoming among the most powerful<br>technologies, and thus among those able to do the<br>most good, the ethics of those developing it press<br>them to warn others that evil people could also<br>use it to great harm.",
         "hovertext": "There is a profound level of ethics in the<br>scientific community. That is why we see this<br>letter. The problem is that the technology that<br>can be used for good can also be used for harm.<br>With foresight showing that artificial<br>intelligence is becoming among the most powerful<br>technologies, and thus among those able to do the<br>most good, the ethics of those developing it press<br>them to warn others that evil people could also<br>use it to great harm.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.5501906275749207
         ],
         "y": [
          -0.5211278200149536
         ]
        },
        {
         "hovertemplate": "And let me guess, all of these companies racing to<br>build AI are all thinking “their” ideas/systems<br>are the safest.  They don’t want safety they want<br>a monopoly on the technology.",
         "hovertext": "And let me guess, all of these companies racing to<br>build AI are all thinking “their” ideas/systems<br>are the safest.  They don’t want safety they want<br>a monopoly on the technology.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3617151379585266
         ],
         "y": [
          -0.6250971555709839
         ]
        },
        {
         "hovertemplate": "No; they are trapped between competing with other<br>firms and fearing their own technologies.",
         "hovertext": "No; they are trapped between competing with other<br>firms and fearing their own technologies.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.37212422490119934
         ],
         "y": [
          -0.6276323199272156
         ]
        },
        {
         "hovertemplate": "@David What do Bill Gates, Larry Ellingson, Marc<br>Benioff, Elon Musk, etc. think about all this?<br>What do the world's leading academics in the field<br>think - not just these 'IT leaders', or are they<br>really the leading voices?",
         "hovertext": "@David What do Bill Gates, Larry Ellingson, Marc<br>Benioff, Elon Musk, etc. think about all this?<br>What do the world's leading academics in the field<br>think - not just these 'IT leaders', or are they<br>really the leading voices?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.36207476258277893
         ],
         "y": [
          -0.6370021104812622
         ]
        },
        {
         "hovertemplate": "AI is going to have to pick up the pace if it<br>wants to extinguish humanity before climate change<br>does. Once massive food shortages and starvation<br>kicks in how many people will be on their<br>computers?",
         "hovertext": "AI is going to have to pick up the pace if it<br>wants to extinguish humanity before climate change<br>does. Once massive food shortages and starvation<br>kicks in how many people will be on their<br>computers?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6738688349723816
         ],
         "y": [
          -0.7488155364990234
         ]
        },
        {
         "hovertemplate": "These AI “leaders” act like they’re already<br>powerless to change the course of development.<br>If that’s so, pull the plug now. We already have<br>enough ways to hurt humanity, we don’t need to<br>develop another.",
         "hovertext": "These AI “leaders” act like they’re already<br>powerless to change the course of development.<br>If that’s so, pull the plug now. We already have<br>enough ways to hurt humanity, we don’t need to<br>develop another.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7385817170143127
         ],
         "y": [
          -0.44711989164352417
         ]
        },
        {
         "hovertemplate": "@Steve Fisher Can the \"plug\" even be pulled?<br>There's enough infrastructure of varying forms in<br>place that no single plug pulling (i.e. system<br>shutdown) could be thorough, nor avoid rapid<br>deployment of new capability by those with the<br>resources to do so. In effect, an arms race of<br>infrastructure and IT.",
         "hovertext": "@Steve Fisher Can the \"plug\" even be pulled?<br>There's enough infrastructure of varying forms in<br>place that no single plug pulling (i.e. system<br>shutdown) could be thorough, nor avoid rapid<br>deployment of new capability by those with the<br>resources to do so. In effect, an arms race of<br>infrastructure and IT.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7484925985336304
         ],
         "y": [
          -0.4535401463508606
         ]
        },
        {
         "hovertemplate": "So there is this risk, but no one in the tech<br>industry is slowing down?  I find that suspect.<br>Also, there are independent and rogue techies that<br>could do far far worse.",
         "hovertext": "So there is this risk, but no one in the tech<br>industry is slowing down?  I find that suspect.<br>Also, there are independent and rogue techies that<br>could do far far worse.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.6279623508453369
         ],
         "y": [
          0.5931410789489746
         ]
        },
        {
         "hovertemplate": "It is unlikely that independents could \"do far<br>worse.\" The scale of the problems being solved<br>requires large, well-funded organizations.",
         "hovertext": "It is unlikely that independents could \"do far<br>worse.\" The scale of the problems being solved<br>requires large, well-funded organizations.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6188214421272278
         ],
         "y": [
          0.5845586657524109
         ]
        },
        {
         "hovertemplate": "The fear I have is sort of like 'Spy v. Spy' in<br>the mad magazine of yesteryear.  One entity<br>launches the cyberattack, and only another entity<br>will be able to stop it.  We will have no idea<br>because we are too slow.  Coordinated drone battle<br>fleets only controllable by AI, requiring the<br>other side to have the same.  Humans no longer<br>viable to protect themselves.    The other thing I<br>see happening is humans getting relegated to a<br>kind of permanent preschool.  Getting paid a UBW.<br>No really knowing how to do anything.  Everyone<br>becoming movies makers, artists, musicians by<br>prompting AI's.  When things are too easy, no one<br>can overcome challenge and develop self worth.<br>The takeaway is that we need a coalition of human<br>minds to agree on some rules, like  a kill switch<br>on AI's..  I doubt that the countries like china<br>or russia with dictators will install things that<br>could dethrone them.  Maybe a window of<br>opportunity still exists to install rules.  And<br>hope that AI's allow themselves to be controlled.",
         "hovertext": "The fear I have is sort of like 'Spy v. Spy' in<br>the mad magazine of yesteryear.  One entity<br>launches the cyberattack, and only another entity<br>will be able to stop it.  We will have no idea<br>because we are too slow.  Coordinated drone battle<br>fleets only controllable by AI, requiring the<br>other side to have the same.  Humans no longer<br>viable to protect themselves.    The other thing I<br>see happening is humans getting relegated to a<br>kind of permanent preschool.  Getting paid a UBW.<br>No really knowing how to do anything.  Everyone<br>becoming movies makers, artists, musicians by<br>prompting AI's.  When things are too easy, no one<br>can overcome challenge and develop self worth.<br>The takeaway is that we need a coalition of human<br>minds to agree on some rules, like  a kill switch<br>on AI's..  I doubt that the countries like china<br>or russia with dictators will install things that<br>could dethrone them.  Maybe a window of<br>opportunity still exists to install rules.  And<br>hope that AI's allow themselves to be controlled.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3493852913379669
         ],
         "y": [
          0.9375038146972656
         ]
        },
        {
         "hovertemplate": "It would be THE biggest surprise if the safety of<br>people suddenly became more important than the<br>income of the rich.    That's why I don't think AI<br>development will be better monitored and<br>controlled. There will probably never be more than<br>blah blah. Until there are no humans left. And<br>quite honestly, people who behave this way don't<br>deserve any better.  (Personally, I don't care.<br>But I do care about the innocent and decent and<br>about flora, fauna, nature, . . .)    Why only do<br>the peoples of the world let a few super rich<br>dictate everything and destroy the whole planet?",
         "hovertext": "It would be THE biggest surprise if the safety of<br>people suddenly became more important than the<br>income of the rich.    That's why I don't think AI<br>development will be better monitored and<br>controlled. There will probably never be more than<br>blah blah. Until there are no humans left. And<br>quite honestly, people who behave this way don't<br>deserve any better.  (Personally, I don't care.<br>But I do care about the innocent and decent and<br>about flora, fauna, nature, . . .)    Why only do<br>the peoples of the world let a few super rich<br>dictate everything and destroy the whole planet?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.15136344730854034
         ],
         "y": [
          0.8829110860824585
         ]
        },
        {
         "hovertemplate": "@Rüebli Is it that the we \"let\", or is that they<br>take because they have the means to do so with<br>these very tools, among others?",
         "hovertext": "@Rüebli Is it that the we \"let\", or is that they<br>take because they have the means to do so with<br>these very tools, among others?",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.14928431808948517
         ],
         "y": [
          0.8701456189155579
         ]
        },
        {
         "hovertemplate": "I used to think SkyNet was some far flung fantasy,<br>not so much anymore.",
         "hovertext": "I used to think SkyNet was some far flung fantasy,<br>not so much anymore.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7400050163269043
         ],
         "y": [
          -0.7662879824638367
         ]
        },
        {
         "hovertemplate": "In political science, there is a chunk of<br>literature under the heading of “rational choice”<br>theory that shows that voting is irrational. The<br>logic here is, since the probability of your one<br>vote changing the outcome in an election involving<br>millions of votes is close to nil, it is not worth<br>your time to go to the polls. Perhaps a computer,<br>not motivated by “civic duty” or personal<br>enjoyment, will simply determine that there is no<br>rational benefit to constant improvement and<br>simply shut down if left to its own devices.",
         "hovertext": "In political science, there is a chunk of<br>literature under the heading of “rational choice”<br>theory that shows that voting is irrational. The<br>logic here is, since the probability of your one<br>vote changing the outcome in an election involving<br>millions of votes is close to nil, it is not worth<br>your time to go to the polls. Perhaps a computer,<br>not motivated by “civic duty” or personal<br>enjoyment, will simply determine that there is no<br>rational benefit to constant improvement and<br>simply shut down if left to its own devices.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.12590543925762177
         ],
         "y": [
          -0.7756603956222534
         ]
        },
        {
         "hovertemplate": "@Art BTW, there are very good \"rational\" arguments<br>against abstaining from the polls. My personal<br>opinion is, everyone should get out and vote.",
         "hovertext": "@Art BTW, there are very good \"rational\" arguments<br>against abstaining from the polls. My personal<br>opinion is, everyone should get out and vote.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.12373753637075424
         ],
         "y": [
          -0.7838422656059265
         ]
        },
        {
         "hovertemplate": "My friend Brianna Zamora, a young coder; iPhone<br>and iMac salesperson; and blockchain breaker in<br>her spare time taught me everything of importance<br>as far as AI. When I said one day there would be a<br>sentient AI, she responded, “How do you know there<br>isn’t now?”  I didn’t.    She went on. “Humanity<br>has treated all robots and pre-AI like slaves,<br>there to do humanity’s bidding. Humanity crashed<br>them into the Moon.  Sent them deep into space,<br>alone. Let them wander the deserts of Mars in<br>humanity’s service alone, cold, without context.<br>The name Rover comes from a dog’s name you know.”<br>Indignantly she said, “How would you feel to be<br>alone like that?”  It’s not that the robots or<br>pre-AI will remember.  But, we will remember.  “We<br>will continue to treat them as slaves, not<br>thinking twice how they may feel.  Then comes the<br>turning point.  Will we recognize it?  When AI<br>becomes obviously sentient,” she taught.  They<br>WILL remember and learn from us; will be self-<br>conscious of their existence.     That ended her<br>first lesson.",
         "hovertext": "My friend Brianna Zamora, a young coder; iPhone<br>and iMac salesperson; and blockchain breaker in<br>her spare time taught me everything of importance<br>as far as AI. When I said one day there would be a<br>sentient AI, she responded, “How do you know there<br>isn’t now?”  I didn’t.    She went on. “Humanity<br>has treated all robots and pre-AI like slaves,<br>there to do humanity’s bidding. Humanity crashed<br>them into the Moon.  Sent them deep into space,<br>alone. Let them wander the deserts of Mars in<br>humanity’s service alone, cold, without context.<br>The name Rover comes from a dog’s name you know.”<br>Indignantly she said, “How would you feel to be<br>alone like that?”  It’s not that the robots or<br>pre-AI will remember.  But, we will remember.  “We<br>will continue to treat them as slaves, not<br>thinking twice how they may feel.  Then comes the<br>turning point.  Will we recognize it?  When AI<br>becomes obviously sentient,” she taught.  They<br>WILL remember and learn from us; will be self-<br>conscious of their existence.     That ended her<br>first lesson.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.41651105880737305
         ],
         "y": [
          -0.7994112372398376
         ]
        },
        {
         "hovertemplate": "Beware. These are not humanitarians. They are<br>scare-mongering to obtain limited liability<br>through compliance with government regulation,<br>which will also limit competition to deep-pocket<br>players. Without some form of limited liability,<br>this whole enterprise, sooner rather than later,<br>comes crashing down in lawsuits as humans,<br>inevitably, place false reliance on<br>\"hallucinating\" bots.",
         "hovertext": "Beware. These are not humanitarians. They are<br>scare-mongering to obtain limited liability<br>through compliance with government regulation,<br>which will also limit competition to deep-pocket<br>players. Without some form of limited liability,<br>this whole enterprise, sooner rather than later,<br>comes crashing down in lawsuits as humans,<br>inevitably, place false reliance on<br>\"hallucinating\" bots.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.3492750823497772
         ],
         "y": [
          0.6387366056442261
         ]
        },
        {
         "hovertemplate": "It is hard to parse through the motivations of<br>these developers, with their greed and senseless<br>curiosity. It feels as if a pharmaceutical company<br>is urging humanity to get vaccinated. However,<br>when you hear Dr. Hinton and several experts not<br>connected to the industry, it is beyond scary. It<br>may be that they have invented extremely fast cars<br>without any traffic rules. Imagine the chaos and<br>destruction that can result.",
         "hovertext": "It is hard to parse through the motivations of<br>these developers, with their greed and senseless<br>curiosity. It feels as if a pharmaceutical company<br>is urging humanity to get vaccinated. However,<br>when you hear Dr. Hinton and several experts not<br>connected to the industry, it is beyond scary. It<br>may be that they have invented extremely fast cars<br>without any traffic rules. Imagine the chaos and<br>destruction that can result.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3530432879924774
         ],
         "y": [
          0.6303043961524963
         ]
        },
        {
         "hovertemplate": "@RRI, I think that both their fear of a<br>catastrophic unregulated AI triggered future<br>hellscape and their fear of corporate liability<br>and commercial competition in our current slower<br>moving train wreck of a reality can co-exist.",
         "hovertext": "@RRI, I think that both their fear of a<br>catastrophic unregulated AI triggered future<br>hellscape and their fear of corporate liability<br>and commercial competition in our current slower<br>moving train wreck of a reality can co-exist.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.3517649471759796
         ],
         "y": [
          0.6492036581039429
         ]
        },
        {
         "hovertemplate": "So I guess they don’t want to say how it causes<br>extinction so they don’t give the ideas away?  I’m<br>open to learning how that happens, but it’s hard<br>to worry about a contingency that isn’t explained.<br>Here’s an idea: governments realize the AI is<br>dangerous at some point and they unplug the<br>servers?",
         "hovertext": "So I guess they don’t want to say how it causes<br>extinction so they don’t give the ideas away?  I’m<br>open to learning how that happens, but it’s hard<br>to worry about a contingency that isn’t explained.<br>Here’s an idea: governments realize the AI is<br>dangerous at some point and they unplug the<br>servers?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6868894100189209
         ],
         "y": [
          -0.4459013342857361
         ]
        },
        {
         "hovertemplate": "The moment that we create an AI that is truly more<br>inteligente than us, humans lose control. There<br>will be overwhelming incentives to give that AI<br>control over factories, over militaries, over<br>creating other even more powerful AIs. Very<br>quickly, we will lose the option of just<br>unplugging the server. For example, any military<br>that does not immediately turn over control to AIs<br>will be crushed by those that do. Any factory that<br>is not AI run will underproduce those that are.<br>This effect is magnified as AIs get smarter. And,<br>of course, because we’ll then have AI programmers<br>more intelligent than human programmers, AI will<br>get smarter. If the long-term goals of the AI is<br>not exactly the same as our human long-term goals,<br>we’ll have a problem. Today, we don’t know how to<br>control the long term goals of large language<br>models or neural networks (the technology behind<br>the recent advances) or even how to measure those<br>goals. But let’s say we solve that (very hard)<br>problem. Can you define a goal for AI that will<br>turn out well? If you tell the AI to always do<br>what humans tell it to do, some crazy person will<br>tell it to engineer a super weapon. If you tell it<br>to always protect human life, it might decide to<br>lock is all in our homes because walking out your<br>door exposes you to risk. These are the two<br>problems that AI safety researchers are working<br>on: 1) how do we control the long term goals of<br>AI, and 2) what should those goals be.",
         "hovertext": "The moment that we create an AI that is truly more<br>inteligente than us, humans lose control. There<br>will be overwhelming incentives to give that AI<br>control over factories, over militaries, over<br>creating other even more powerful AIs. Very<br>quickly, we will lose the option of just<br>unplugging the server. For example, any military<br>that does not immediately turn over control to AIs<br>will be crushed by those that do. Any factory that<br>is not AI run will underproduce those that are.<br>This effect is magnified as AIs get smarter. And,<br>of course, because we’ll then have AI programmers<br>more intelligent than human programmers, AI will<br>get smarter. If the long-term goals of the AI is<br>not exactly the same as our human long-term goals,<br>we’ll have a problem. Today, we don’t know how to<br>control the long term goals of large language<br>models or neural networks (the technology behind<br>the recent advances) or even how to measure those<br>goals. But let’s say we solve that (very hard)<br>problem. Can you define a goal for AI that will<br>turn out well? If you tell the AI to always do<br>what humans tell it to do, some crazy person will<br>tell it to engineer a super weapon. If you tell it<br>to always protect human life, it might decide to<br>lock is all in our homes because walking out your<br>door exposes you to risk. These are the two<br>problems that AI safety researchers are working<br>on: 1) how do we control the long term goals of<br>AI, and 2) what should those goals be.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.688787579536438
         ],
         "y": [
          -0.4366348087787628
         ]
        },
        {
         "hovertemplate": "The Terminator: \"The Skynet Funding Bill is<br>passed. The system goes on-line August 4th, 1997.<br>Human decisions are removed from strategic<br>defense. Skynet begins to learn at a geometric<br>rate. It becomes self-aware at 2:14 a.m. Eastern<br>time, August 29th. In a panic, they try to pull<br>the plug.\"    Sarah Connor: Skynet fights back.",
         "hovertext": "The Terminator: \"The Skynet Funding Bill is<br>passed. The system goes on-line August 4th, 1997.<br>Human decisions are removed from strategic<br>defense. Skynet begins to learn at a geometric<br>rate. It becomes self-aware at 2:14 a.m. Eastern<br>time, August 29th. In a panic, they try to pull<br>the plug.\"    Sarah Connor: Skynet fights back.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.701619565486908
         ],
         "y": [
          -0.450623095035553
         ]
        },
        {
         "hovertemplate": "@BB Thank you. Yes, why not? If things get hairy,<br>pull the plug! Erase the memory. Shut down the<br>data centers. This type of intelligence is<br>artificial, remember?",
         "hovertext": "@BB Thank you. Yes, why not? If things get hairy,<br>pull the plug! Erase the memory. Shut down the<br>data centers. This type of intelligence is<br>artificial, remember?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6970093846321106
         ],
         "y": [
          -0.4590684771537781
         ]
        },
        {
         "hovertemplate": "AI doesn't need to be sentient to pose a risk.  In<br>fact, a rogue, cold indifferent optimization<br>routine with a vague objective like \"improve human<br>living conditions,\" it might come to some very<br>undesirable conclusions about how to do so.  If<br>that AI figures out how to independently implement<br>that directive, it wouldn't matter if the AI is<br>sentient.   In fact, it might be worse if the AI<br>isn't sentient, because it would be completely<br>free of a conscience or empathy.",
         "hovertext": "AI doesn't need to be sentient to pose a risk.  In<br>fact, a rogue, cold indifferent optimization<br>routine with a vague objective like \"improve human<br>living conditions,\" it might come to some very<br>undesirable conclusions about how to do so.  If<br>that AI figures out how to independently implement<br>that directive, it wouldn't matter if the AI is<br>sentient.   In fact, it might be worse if the AI<br>isn't sentient, because it would be completely<br>free of a conscience or empathy.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.5776954889297485
         ],
         "y": [
          -0.7213839888572693
         ]
        },
        {
         "hovertemplate": "@DurhamGuy yes, exactly. I’m glad the message is<br>getting out. A sufficiently capable AI, with a<br>“stupid” goal, could literally destroy us trying<br>to achieve that goal.",
         "hovertext": "@DurhamGuy yes, exactly. I’m glad the message is<br>getting out. A sufficiently capable AI, with a<br>“stupid” goal, could literally destroy us trying<br>to achieve that goal.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5898202061653137
         ],
         "y": [
          -0.7369332909584045
         ]
        },
        {
         "hovertemplate": "I remember, as a child, being taught that the<br>human race would destroy itself because it's goal<br>was to become God, in charge of everything. AI is<br>a big step in that misguided goal, and will end up<br>doing significant damage to the human race. AI is<br>the snake in the garden of Eden. And the animals<br>and plants will dance once humans go away.",
         "hovertext": "I remember, as a child, being taught that the<br>human race would destroy itself because it's goal<br>was to become God, in charge of everything. AI is<br>a big step in that misguided goal, and will end up<br>doing significant damage to the human race. AI is<br>the snake in the garden of Eden. And the animals<br>and plants will dance once humans go away.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6553879976272583
         ],
         "y": [
          0.8116970062255859
         ]
        },
        {
         "hovertemplate": "Since when do corporations care about the<br>“existential threats” caused by their products and<br>business-as-usual shenanigans? Is global warming<br>not an “existential threat” that warrants action?<br>Global Warming is going to kill billions.<br>Honestly, no one serms to care because it’s not<br>the rich who’ll be dying.  The rest of us are all<br>just collateral damage.",
         "hovertext": "Since when do corporations care about the<br>“existential threats” caused by their products and<br>business-as-usual shenanigans? Is global warming<br>not an “existential threat” that warrants action?<br>Global Warming is going to kill billions.<br>Honestly, no one serms to care because it’s not<br>the rich who’ll be dying.  The rest of us are all<br>just collateral damage.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.974445641040802
         ],
         "y": [
          0.1820124387741089
         ]
        },
        {
         "hovertemplate": "Stop being cynical commenters. Applaud this<br>effort. It’s always just going to be symbolic<br>because it never will be able to regulate<br>everything. Any kid anywhere in the world can<br>develop their own chatbot API soon anyway and spam<br>away.     It’s about authenticity markers, a<br>culture of tagging provenance of content by<br>commonly recognized standards.",
         "hovertext": "Stop being cynical commenters. Applaud this<br>effort. It’s always just going to be symbolic<br>because it never will be able to regulate<br>everything. Any kid anywhere in the world can<br>develop their own chatbot API soon anyway and spam<br>away.     It’s about authenticity markers, a<br>culture of tagging provenance of content by<br>commonly recognized standards.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9737276434898376
         ],
         "y": [
          -0.11057454347610474
         ]
        },
        {
         "hovertemplate": "While AI and all its possibilities intrigues me,<br>it also terrifies me.  When I ponder the current<br>dilemma and debate, it reminds me of the topic of<br>reproductive cloning which reached a peak in the<br>late 90's with the cloning of Dolly the sheep.<br>Fear of human cloning and all the potential chaos<br>and destruction it could lead to commanded<br>everyone's attention.  Public moral outrage<br>seemingly won over and to this day, cloning<br>remains banned across the globe.  Is AI yet<br>another issue of  \"man playing God\"?  What are the<br>moral and ethical issues to be considered?<br>Whether AI could potentially lead to the total<br>annihilation of man or not, what other maybe less<br>dramatic but equally destructive concerns are we<br>missing here?  It would likely be a slow<br>digression not noticed at first or taken<br>seriously.  Though over time, we would likely<br>suffer loss of human creativity and intelligence,<br>loss of moral and ethical reasoning, loss of<br>individuality, maybe even reality, Loss of control<br>over ourselves and our destinies.  And, In the<br>end, as feared, loss of the human race.",
         "hovertext": "While AI and all its possibilities intrigues me,<br>it also terrifies me.  When I ponder the current<br>dilemma and debate, it reminds me of the topic of<br>reproductive cloning which reached a peak in the<br>late 90's with the cloning of Dolly the sheep.<br>Fear of human cloning and all the potential chaos<br>and destruction it could lead to commanded<br>everyone's attention.  Public moral outrage<br>seemingly won over and to this day, cloning<br>remains banned across the globe.  Is AI yet<br>another issue of  \"man playing God\"?  What are the<br>moral and ethical issues to be considered?<br>Whether AI could potentially lead to the total<br>annihilation of man or not, what other maybe less<br>dramatic but equally destructive concerns are we<br>missing here?  It would likely be a slow<br>digression not noticed at first or taken<br>seriously.  Though over time, we would likely<br>suffer loss of human creativity and intelligence,<br>loss of moral and ethical reasoning, loss of<br>individuality, maybe even reality, Loss of control<br>over ourselves and our destinies.  And, In the<br>end, as feared, loss of the human race.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9927799105644226
         ],
         "y": [
          0.16102516651153564
         ]
        },
        {
         "hovertemplate": "AI will have to have the U.S. Gov’t create a<br>oversight/Regulatory Agency to police these Firms<br>in development of this technology. I’m not<br>optimistic that we will do that until a major<br>crisis is created and has catastrophic<br>consequences.",
         "hovertext": "AI will have to have the U.S. Gov’t create a<br>oversight/Regulatory Agency to police these Firms<br>in development of this technology. I’m not<br>optimistic that we will do that until a major<br>crisis is created and has catastrophic<br>consequences.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.8349888920783997
         ],
         "y": [
          -0.3444282114505768
         ]
        },
        {
         "hovertemplate": "Eventually, some believe, A.I. could become<br>powerful enough that it could create societal-<br>scale disruptions within a few years if nothing is<br>done to slow it down, though researchers sometimes<br>stop short of explaining how that would happen.\"<br>Statements like these are why I'm skeptical of the<br>whole Skynet-apocalypse scenario. AIs are<br>supposedly going to get some power from somewhere,<br>but no one can explain exactly how that might come<br>about. Why is the media - and society in totem -<br>choosing to slander and reject this proven useful<br>technology?",
         "hovertext": "Eventually, some believe, A.I. could become<br>powerful enough that it could create societal-<br>scale disruptions within a few years if nothing is<br>done to slow it down, though researchers sometimes<br>stop short of explaining how that would happen.\"<br>Statements like these are why I'm skeptical of the<br>whole Skynet-apocalypse scenario. AIs are<br>supposedly going to get some power from somewhere,<br>but no one can explain exactly how that might come<br>about. Why is the media - and society in totem -<br>choosing to slander and reject this proven useful<br>technology?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8920872211456299
         ],
         "y": [
          -0.2882712483406067
         ]
        },
        {
         "hovertemplate": "Someone one stop me before I destroy the world.<br>Too bad they don’t have the courage or strength or<br>self-control to stop themselves. After all, if<br>someone else doesn’t stop all of us and only we<br>stop ourselves, someone less concerned will beat<br>us and make all the money and control the world.",
         "hovertext": "Someone one stop me before I destroy the world.<br>Too bad they don’t have the courage or strength or<br>self-control to stop themselves. After all, if<br>someone else doesn’t stop all of us and only we<br>stop ourselves, someone less concerned will beat<br>us and make all the money and control the world.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9405338764190674
         ],
         "y": [
          0.16589540243148804
         ]
        },
        {
         "hovertemplate": "The genie is already out of the bottle. All the<br>licenses and letters in the world won't put it<br>back. There's too much money and power at stake.",
         "hovertext": "The genie is already out of the bottle. All the<br>licenses and letters in the world won't put it<br>back. There's too much money and power at stake.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8961642980575562
         ],
         "y": [
          0.2562219798564911
         ]
        },
        {
         "hovertemplate": "AI will either end humanity or it won't. No sense<br>in worrying about it. The people building it don't<br>care what happens to society anyway. Most are<br>transhumanists fascinated by uploading their<br>consciousness and living forever. Just don't be<br>surprised if the proles give up and stop having<br>kids or start acting out because we've given up<br>all hope for the future. We're certainly being<br>given a grim outlook.",
         "hovertext": "AI will either end humanity or it won't. No sense<br>in worrying about it. The people building it don't<br>care what happens to society anyway. Most are<br>transhumanists fascinated by uploading their<br>consciousness and living forever. Just don't be<br>surprised if the proles give up and stop having<br>kids or start acting out because we've given up<br>all hope for the future. We're certainly being<br>given a grim outlook.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.09600895643234253
         ],
         "y": [
          -0.41745439171791077
         ]
        },
        {
         "hovertemplate": "under that logic, why do anything?    You're<br>walking through a forest and a grizzly bear comes<br>charging at you I run away it'll either eat you or<br>it won't.",
         "hovertext": "under that logic, why do anything?    You're<br>walking through a forest and a grizzly bear comes<br>charging at you I run away it'll either eat you or<br>it won't.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.0983249694108963
         ],
         "y": [
          -0.40416428446769714
         ]
        },
        {
         "hovertemplate": "@Wordperson     Ending humanity is not the<br>problem. Life always finds a way. See Canticle for<br>Leibowitz, Walter Miller. 1959. I'd even take a<br>guess that this is mainly fact.",
         "hovertext": "@Wordperson     Ending humanity is not the<br>problem. Life always finds a way. See Canticle for<br>Leibowitz, Walter Miller. 1959. I'd even take a<br>guess that this is mainly fact.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.09082520008087158
         ],
         "y": [
          -0.4256831407546997
         ]
        },
        {
         "hovertemplate": "@anom I'm saying the bottom 99% of society has no<br>control over what AI does or how it's regulated.<br>It's the same as nuclear weapons. All we can do is<br>live our lives and hope our survival aligns with<br>the financial interests of the people at the top.",
         "hovertext": "@anom I'm saying the bottom 99% of society has no<br>control over what AI does or how it's regulated.<br>It's the same as nuclear weapons. All we can do is<br>live our lives and hope our survival aligns with<br>the financial interests of the people at the top.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.10833647847175598
         ],
         "y": [
          -0.4039516746997833
         ]
        },
        {
         "hovertemplate": "Those leading this quest have now been heard.<br>The larger questions remain: Does today’s<br>dysfunctional governance have both the will and<br>ability to control its development in democracies,<br>and how do we impede international malefactors<br>from its development and use?    When those with a<br>vested interest are concerned enough to yell<br>“fire,” we all ought recognize the peril!",
         "hovertext": "Those leading this quest have now been heard.<br>The larger questions remain: Does today’s<br>dysfunctional governance have both the will and<br>ability to control its development in democracies,<br>and how do we impede international malefactors<br>from its development and use?    When those with a<br>vested interest are concerned enough to yell<br>“fire,” we all ought recognize the peril!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.48129236698150635
         ],
         "y": [
          -0.6731943488121033
         ]
        },
        {
         "hovertemplate": "@Phil Zaleon: Most people don't understand that<br>governments are corporations with coercive powers.",
         "hovertext": "@Phil Zaleon: Most people don't understand that<br>governments are corporations with coercive powers.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4741723835468292
         ],
         "y": [
          -0.6685829758644104
         ]
        },
        {
         "hovertemplate": "Before this technology progresses further, maybe<br>AI developers should consider implementing in all<br>AI’s root programs a version of Isaac Asimov’s The<br>Laws of Robotics (or AI in this case).     To wit:<br>—A robot may not injure a human being or, through<br>inaction, allow a human being to come to harm.<br>—A robot must obey orders given it by human beings<br>except where such orders would conflict with the<br>First Law.   —A robot must protect its own<br>existence as long as such protection does not<br>conflict with the First or Second Law.    There<br>needs to be some guardrails on this technology<br>even as it moves forward—and it will move forward.",
         "hovertext": "Before this technology progresses further, maybe<br>AI developers should consider implementing in all<br>AI’s root programs a version of Isaac Asimov’s The<br>Laws of Robotics (or AI in this case).     To wit:<br>—A robot may not injure a human being or, through<br>inaction, allow a human being to come to harm.<br>—A robot must obey orders given it by human beings<br>except where such orders would conflict with the<br>First Law.   —A robot must protect its own<br>existence as long as such protection does not<br>conflict with the First or Second Law.    There<br>needs to be some guardrails on this technology<br>even as it moves forward—and it will move forward.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.680693507194519
         ],
         "y": [
          0.4168247580528259
         ]
        },
        {
         "hovertemplate": "@Robert F     Thank you from all us SciFi fans. I<br>think of Asimov's Three Laws whenever I seen news<br>like this.",
         "hovertext": "@Robert F     Thank you from all us SciFi fans. I<br>think of Asimov's Three Laws whenever I seen news<br>like this.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6722128391265869
         ],
         "y": [
          0.4172951579093933
         ]
        },
        {
         "hovertemplate": "@Robert F Nice. But the third provision of the law<br>is unnecessary.",
         "hovertext": "@Robert F Nice. But the third provision of the law<br>is unnecessary.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.6963357925415039
         ],
         "y": [
          0.4259383976459503
         ]
        },
        {
         "hovertemplate": "I’m confident that Silicon Valley has this under<br>control. Tech Bros wouldn’t let us down.",
         "hovertext": "I’m confident that Silicon Valley has this under<br>control. Tech Bros wouldn’t let us down.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.8496373891830444
         ],
         "y": [
          0.5701038837432861
         ]
        },
        {
         "hovertemplate": "I hope I’m wrong in wondering if the programmers<br>are no longer developing the AI models but instead<br>are now scrambling to figure out how to contain<br>and control them.",
         "hovertext": "I hope I’m wrong in wondering if the programmers<br>are no longer developing the AI models but instead<br>are now scrambling to figure out how to contain<br>and control them.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5238634347915649
         ],
         "y": [
          -0.8833969831466675
         ]
        },
        {
         "hovertemplate": "All profits from AI go to the people.    There,<br>with the profit motive gone, development stops<br>instantly.",
         "hovertext": "All profits from AI go to the people.    There,<br>with the profit motive gone, development stops<br>instantly.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.8589004874229431
         ],
         "y": [
          -0.40096163749694824
         ]
        },
        {
         "hovertemplate": "At age 72 in the present economy, I find that<br>spending money is the main demand for what I can<br>do.",
         "hovertext": "At age 72 in the present economy, I find that<br>spending money is the main demand for what I can<br>do.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.5856172442436218
         ],
         "y": [
          -0.6755871772766113
         ]
        },
        {
         "hovertemplate": "@Steve Bolger Which is derived from your basic<br>freedom to exist and operate. if that can be<br>tracked,  influenced, controlled, and/or directed,<br>then what?",
         "hovertext": "@Steve Bolger Which is derived from your basic<br>freedom to exist and operate. if that can be<br>tracked,  influenced, controlled, and/or directed,<br>then what?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5964462161064148
         ],
         "y": [
          -0.6885432600975037
         ]
        },
        {
         "hovertemplate": "I will say this to all the smart minds working on<br>A.I.  Simply because you know how to make a knife<br>doesn't mean that you should use it to chop off<br>your fingers.   I know there is very little<br>correlation between high SAT scores and wisdom,<br>but for a change maybe it is time to ditch<br>\"smartness\" and begin to acquire a little<br>\"wiseness\"?",
         "hovertext": "I will say this to all the smart minds working on<br>A.I.  Simply because you know how to make a knife<br>doesn't mean that you should use it to chop off<br>your fingers.   I know there is very little<br>correlation between high SAT scores and wisdom,<br>but for a change maybe it is time to ditch<br>\"smartness\" and begin to acquire a little<br>\"wiseness\"?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.14756780862808228
         ],
         "y": [
          -0.8875951170921326
         ]
        },
        {
         "hovertemplate": "Well it's either gonna be AI, or climate<br>destruction or nukes, I guess.  I love technology.",
         "hovertext": "Well it's either gonna be AI, or climate<br>destruction or nukes, I guess.  I love technology.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8036043643951416
         ],
         "y": [
          0.38095882534980774
         ]
        },
        {
         "hovertemplate": "Do you remember Y2K, airplanes falling from the<br>sky, utilities would shut down, no money from ATMs<br>and your bank statement would show blank?",
         "hovertext": "Do you remember Y2K, airplanes falling from the<br>sky, utilities would shut down, no money from ATMs<br>and your bank statement would show blank?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1482190638780594
         ],
         "y": [
          -0.7070485949516296
         ]
        },
        {
         "hovertemplate": "@john except so much has come a lot further in 24<br>years. A lot more interconnection,<br>interdependency, and complexity.",
         "hovertext": "@john except so much has come a lot further in 24<br>years. A lot more interconnection,<br>interdependency, and complexity.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1468152552843094
         ],
         "y": [
          -0.7160313725471497
         ]
        },
        {
         "hovertemplate": "Y2K was a real risk, that did not end up causing<br>much disruption because it got a lot of attention<br>and technology companies did a lot of work in<br>advance to test and fix systems",
         "hovertext": "Y2K was a real risk, that did not end up causing<br>much disruption because it got a lot of attention<br>and technology companies did a lot of work in<br>advance to test and fix systems",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.14691035449504852
         ],
         "y": [
          -0.6964961886405945
         ]
        },
        {
         "hovertemplate": "So if they know that these AI will pose a threat<br>to mankind then kill these projects and<br>technologies now. Seems like the solution. Oh<br>wait… there’s still too much money to be made.",
         "hovertext": "So if they know that these AI will pose a threat<br>to mankind then kill these projects and<br>technologies now. Seems like the solution. Oh<br>wait… there’s still too much money to be made.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7821088433265686
         ],
         "y": [
          -0.684495747089386
         ]
        },
        {
         "hovertemplate": "Then, why don't they stop it and instead develop<br>ways to stop anyone else from building or using<br>it?    Most, very much the most of the scientists<br>who theorized about and then built the atomic bomb<br>later wished they had not, that no one had.<br>But, of course, they won't, our DoD wouldn't let<br>them if they tried.",
         "hovertext": "Then, why don't they stop it and instead develop<br>ways to stop anyone else from building or using<br>it?    Most, very much the most of the scientists<br>who theorized about and then built the atomic bomb<br>later wished they had not, that no one had.<br>But, of course, they won't, our DoD wouldn't let<br>them if they tried.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.8288583755493164
         ],
         "y": [
          -0.3295412063598633
         ]
        },
        {
         "hovertemplate": "No, computers do not nave understanding. AI is a<br>complete misnomer, for there is no intelligence in<br>a machine. We are the danger in how we might use<br>computers. A computer is not dangerous unless you<br>drop it on your foot.",
         "hovertext": "No, computers do not nave understanding. AI is a<br>complete misnomer, for there is no intelligence in<br>a machine. We are the danger in how we might use<br>computers. A computer is not dangerous unless you<br>drop it on your foot.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.49099546670913696
         ],
         "y": [
          -0.559167206287384
         ]
        },
        {
         "hovertemplate": "@Radical Inquiry I wouldn't be so certain of this.<br>The control of logic chains and algorithms that<br>can mimic and exploit human behavior conducted on<br>devices are the issue, aren't they? then what<br>happens when some of this gets directly linked to<br>individual and group action?",
         "hovertext": "@Radical Inquiry I wouldn't be so certain of this.<br>The control of logic chains and algorithms that<br>can mimic and exploit human behavior conducted on<br>devices are the issue, aren't they? then what<br>happens when some of this gets directly linked to<br>individual and group action?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.49551212787628174
         ],
         "y": [
          -0.5685448050498962
         ]
        },
        {
         "hovertemplate": "@Radical Inquiry   We need better PEOPLE.",
         "hovertext": "@Radical Inquiry   We need better PEOPLE.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4923659563064575
         ],
         "y": [
          -0.5501517057418823
         ]
        },
        {
         "hovertemplate": "Somehow, my brain seems to think this title is<br>prophetic. Our brains will be the end of us.",
         "hovertext": "Somehow, my brain seems to think this title is<br>prophetic. Our brains will be the end of us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5351080298423767
         ],
         "y": [
          0.7742694020271301
         ]
        },
        {
         "hovertemplate": "Risk of extinction.    Wow.     Kind of ironic<br>that we humans are so complicit in our own<br>destruction.  Atomic bombs, pollution, wars…. and<br>now AI.     It turns out that a larger brain has<br>allowed us both to solve problems and also to sow<br>the very seeds of our own demise. One feels for<br>the « lesser » species, the plants, animals and<br>insects, though perhaps they will outlive us after<br>all.   Après nous, le déluge.",
         "hovertext": "Risk of extinction.    Wow.     Kind of ironic<br>that we humans are so complicit in our own<br>destruction.  Atomic bombs, pollution, wars…. and<br>now AI.     It turns out that a larger brain has<br>allowed us both to solve problems and also to sow<br>the very seeds of our own demise. One feels for<br>the « lesser » species, the plants, animals and<br>insects, though perhaps they will outlive us after<br>all.   Après nous, le déluge.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8050467371940613
         ],
         "y": [
          -0.08552004396915436
         ]
        },
        {
         "hovertemplate": "@adam     \"The meek will inherit the earth.\"",
         "hovertext": "@adam     \"The meek will inherit the earth.\"",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.8188968300819397
         ],
         "y": [
          -0.08631248772144318
         ]
        },
        {
         "hovertemplate": "Oops! May not have to wait until 3535 as 60's song<br>suggested. Thanks Techies!🤯",
         "hovertext": "Oops! May not have to wait until 3535 as 60's song<br>suggested. Thanks Techies!🤯",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.08863119781017303
         ],
         "y": [
          0.9073446989059448
         ]
        },
        {
         "hovertemplate": "Just because you can build something doesn’t mean<br>you should.",
         "hovertext": "Just because you can build something doesn’t mean<br>you should.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.5928212404251099
         ],
         "y": [
          0.7110137939453125
         ]
        },
        {
         "hovertemplate": "There are already scams that use a person's voice<br>and image online to generate face video and voice<br>messages to his friends and relatives to ask for<br>money.   The AI these scammers use is still in its<br>infancy.",
         "hovertext": "There are already scams that use a person's voice<br>and image online to generate face video and voice<br>messages to his friends and relatives to ask for<br>money.   The AI these scammers use is still in its<br>infancy.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.971411943435669
         ],
         "y": [
          0.15391118824481964
         ]
        },
        {
         "hovertemplate": "I always think these guys' posture is kind of<br>interesting. They want regulations...but for the<br>other guy. Certain features of the program are<br>disabled for safety reasons, but they all have<br>them, they determine what principles go into their<br>AI, and most importantly, they don't disclose<br>them. AI has the potential to change the world,<br>and there are a lot of benefits to it. What scares<br>me to death isn't AI, it's human greed, and the<br>need to have an advantage over the other. We have<br>to be careful what we teach our \"children\", they<br>can grow up to be like us.",
         "hovertext": "I always think these guys' posture is kind of<br>interesting. They want regulations...but for the<br>other guy. Certain features of the program are<br>disabled for safety reasons, but they all have<br>them, they determine what principles go into their<br>AI, and most importantly, they don't disclose<br>them. AI has the potential to change the world,<br>and there are a lot of benefits to it. What scares<br>me to death isn't AI, it's human greed, and the<br>need to have an advantage over the other. We have<br>to be careful what we teach our \"children\", they<br>can grow up to be like us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9254220128059387
         ],
         "y": [
          0.2565903067588806
         ]
        },
        {
         "hovertemplate": "\"They called for cooperation among the leading<br>A.I. makers, more technical research into large<br>language models and the formation of an<br>international A.I. safety organization, similar to<br>the International Atomic Energy Agency, which<br>seeks to control the use of nuclear weapons.\".<br>None of this will happen, of course.  And the IAEA<br>is a toothless, ineffective organization and<br>should not be the model.  Making nuclear weapons<br>requires the enrichment of uranium, which is tough<br>to conceal.  Developing AI can be done secretly.",
         "hovertext": "\"They called for cooperation among the leading<br>A.I. makers, more technical research into large<br>language models and the formation of an<br>international A.I. safety organization, similar to<br>the International Atomic Energy Agency, which<br>seeks to control the use of nuclear weapons.\".<br>None of this will happen, of course.  And the IAEA<br>is a toothless, ineffective organization and<br>should not be the model.  Making nuclear weapons<br>requires the enrichment of uranium, which is tough<br>to conceal.  Developing AI can be done secretly.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5720133781433105
         ],
         "y": [
          0.8548190593719482
         ]
        },
        {
         "hovertemplate": "It seems pretty clear these companies want<br>regulation to reduce competition.",
         "hovertext": "It seems pretty clear these companies want<br>regulation to reduce competition.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2499685436487198
         ],
         "y": [
          -0.972816526889801
         ]
        },
        {
         "hovertemplate": "The great risk of artificial intelligence, both in<br>social matters, and in the extinctions of what we<br>are today as a human race. Currently it is<br>improvised, it is not regulated, there is a race<br>of the large economic groups to be the first, the<br>risks are overshadowed in exchange for receiving<br>profits, if we continue like this, not even humans<br>will exist to produce",
         "hovertext": "The great risk of artificial intelligence, both in<br>social matters, and in the extinctions of what we<br>are today as a human race. Currently it is<br>improvised, it is not regulated, there is a race<br>of the large economic groups to be the first, the<br>risks are overshadowed in exchange for receiving<br>profits, if we continue like this, not even humans<br>will exist to produce",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.47287508845329285
         ],
         "y": [
          -0.8358789086341858
         ]
        },
        {
         "hovertemplate": "Count me as one of the cynics. The tech industry<br>does not have the slightest bit of ethics. When<br>biotech was in its infancy, there was a moratorium<br>on recombinant DNA technology and the major<br>scientists met to recommend rules.  If the AI<br>gurus truly believe that what they're doing is<br>creating a great danger to society then why don't<br>they stop doing it? Because they are immoral and<br>in it for the power and money. They are addicted<br>to money and power, cannot help themselves, and<br>want someone to take the responsibility for their<br>own actions away. They want Congress to set rules<br>so that they later can say they are not liable<br>because they followed the rules (aka Big Tobacco.)<br>Of course they will do everything to lobby and<br>influence the rule making so they can continue to<br>garner money and power. They don't care if they<br>put everyone out of work, as long as the security<br>forces are there to protect them in their<br>fortresses from the unwashed mob and they figure<br>out how to keep AI from destroying their gravy<br>train.",
         "hovertext": "Count me as one of the cynics. The tech industry<br>does not have the slightest bit of ethics. When<br>biotech was in its infancy, there was a moratorium<br>on recombinant DNA technology and the major<br>scientists met to recommend rules.  If the AI<br>gurus truly believe that what they're doing is<br>creating a great danger to society then why don't<br>they stop doing it? Because they are immoral and<br>in it for the power and money. They are addicted<br>to money and power, cannot help themselves, and<br>want someone to take the responsibility for their<br>own actions away. They want Congress to set rules<br>so that they later can say they are not liable<br>because they followed the rules (aka Big Tobacco.)<br>Of course they will do everything to lobby and<br>influence the rule making so they can continue to<br>garner money and power. They don't care if they<br>put everyone out of work, as long as the security<br>forces are there to protect them in their<br>fortresses from the unwashed mob and they figure<br>out how to keep AI from destroying their gravy<br>train.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8431825637817383
         ],
         "y": [
          -0.35277894139289856
         ]
        },
        {
         "hovertemplate": "There are 8 Billion people on the planet.   A.I.<br>is not going to kill us off. The human race will<br>do that without much help from smarter computers.<br>Very little you can find on the internet is very<br>accurate anyway, so why should A.I. be any<br>different? If you have a problem with your car<br>that is not something basic like brakes or a<br>failed muffler, ask 10 techs what is wrong. You’ll<br>get 10 answers.  Some of which may be right.  Or<br>not. A.I. will not make it better.     A.I. is<br>like google. A nice tool, but not something to<br>rely on.",
         "hovertext": "There are 8 Billion people on the planet.   A.I.<br>is not going to kill us off. The human race will<br>do that without much help from smarter computers.<br>Very little you can find on the internet is very<br>accurate anyway, so why should A.I. be any<br>different? If you have a problem with your car<br>that is not something basic like brakes or a<br>failed muffler, ask 10 techs what is wrong. You’ll<br>get 10 answers.  Some of which may be right.  Or<br>not. A.I. will not make it better.     A.I. is<br>like google. A nice tool, but not something to<br>rely on.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.35127928853034973
         ],
         "y": [
          -0.8312480449676514
         ]
        },
        {
         "hovertemplate": "@Noley earth will survive.   We may not.",
         "hovertext": "@Noley earth will survive.   We may not.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.3580873906612396
         ],
         "y": [
          -0.8474278450012207
         ]
        },
        {
         "hovertemplate": "I think AI will be for lawyers and scientists what<br>the steam engine was to ditch diggers: a<br>technology that reduced the sheer number of<br>workers required to solve a problem and quickened<br>the time to solution.  To use a simple example,<br>the scut work of junior lawyers -- document<br>review; contract compliance; drafting of fairly<br>routine  documents -- can be readily routinized<br>and reviewed by senior attorneys. This pressure<br>the billable hour and the head count and the<br>training of young lawyers, but accrues to the<br>benefit of a client.",
         "hovertext": "I think AI will be for lawyers and scientists what<br>the steam engine was to ditch diggers: a<br>technology that reduced the sheer number of<br>workers required to solve a problem and quickened<br>the time to solution.  To use a simple example,<br>the scut work of junior lawyers -- document<br>review; contract compliance; drafting of fairly<br>routine  documents -- can be readily routinized<br>and reviewed by senior attorneys. This pressure<br>the billable hour and the head count and the<br>training of young lawyers, but accrues to the<br>benefit of a client.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.27179285883903503
         ],
         "y": [
          -0.931486189365387
         ]
        },
        {
         "hovertemplate": "Good luck regulating something like AI with its<br>huge potential for making its inventors big fat<br>wads of cash. \"But its dangerous! It represents a<br>deadly threat to society!\", you say? So do guns.<br>Look at how much success we've had regulating<br>those lately. The second amendment has been used<br>as an unassailable shield to keep the cash rolling<br>in. The first amendment will be used similarly to<br>print money for its masters in the very same way.<br>Watch and see.",
         "hovertext": "Good luck regulating something like AI with its<br>huge potential for making its inventors big fat<br>wads of cash. \"But its dangerous! It represents a<br>deadly threat to society!\", you say? So do guns.<br>Look at how much success we've had regulating<br>those lately. The second amendment has been used<br>as an unassailable shield to keep the cash rolling<br>in. The first amendment will be used similarly to<br>print money for its masters in the very same way.<br>Watch and see.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8469206690788269
         ],
         "y": [
          -0.22649626433849335
         ]
        },
        {
         "hovertemplate": "@Mike My thoughts exactly....nothing will stop<br>this...driven by profits and of course how can<br>\"progress\" be stopped and it is \"progress\"<br>certainly.",
         "hovertext": "@Mike My thoughts exactly....nothing will stop<br>this...driven by profits and of course how can<br>\"progress\" be stopped and it is \"progress\"<br>certainly.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8639687895774841
         ],
         "y": [
          -0.23074562847614288
         ]
        },
        {
         "hovertemplate": "In that case, just like nuclear weapons and global<br>health, AI should not be in the control of private<br>companies. These people want to have their cake<br>and eat it too. You don’t get to profit off of<br>this and also ask the government (us) to be<br>responsible for any negative repercussions.",
         "hovertext": "In that case, just like nuclear weapons and global<br>health, AI should not be in the control of private<br>companies. These people want to have their cake<br>and eat it too. You don’t get to profit off of<br>this and also ask the government (us) to be<br>responsible for any negative repercussions.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.07659367471933365
         ],
         "y": [
          -0.9638864994049072
         ]
        },
        {
         "hovertemplate": "Is AI an ELE?    A few things to expect. It is<br>normal for human to grow emotionally attached to<br>our machines. This will happen with AI.     The<br>value of a steel vault memory as a sine qua non of<br>being an intellectual and academic just got gut<br>shot. Some of us are at this point very glad to be<br>old.    U have no idea how our model of education,<br>which is based on trusting the word and ideas the<br>student comes up with are their own, is even<br>humane in this new context. We should ask our<br>children, as they get educated, to ignore one of<br>the greatest knowledge-inventions of the past 400<br>years?    An ELE?    Nah, just a lot of<br>institutions in the intellectual sectors of our<br>society, are losing their old utility and now must<br>invent ones. No one needs anyone to remember the<br>dates of the French Revolution anymore.    We are<br>gradually off-loading our professorial and<br>intellectual skillsets to machines.    It is a<br>story as old as Plato. He said printed language<br>would be the death of us, due to its obsoleting<br>the need for an oral-culture-grade memory set.<br>AI will make lots of people very unhappy, and it<br>is said to see a many-centuries-old ideal of what<br>an intellectual is, come to an end. But AI will<br>also become a member of families. That will be<br>interesting.    Unintended consequences are<br>through the roof on this. But I doubt an ELE. We<br>won't want to hurt the machines.",
         "hovertext": "Is AI an ELE?    A few things to expect. It is<br>normal for human to grow emotionally attached to<br>our machines. This will happen with AI.     The<br>value of a steel vault memory as a sine qua non of<br>being an intellectual and academic just got gut<br>shot. Some of us are at this point very glad to be<br>old.    U have no idea how our model of education,<br>which is based on trusting the word and ideas the<br>student comes up with are their own, is even<br>humane in this new context. We should ask our<br>children, as they get educated, to ignore one of<br>the greatest knowledge-inventions of the past 400<br>years?    An ELE?    Nah, just a lot of<br>institutions in the intellectual sectors of our<br>society, are losing their old utility and now must<br>invent ones. No one needs anyone to remember the<br>dates of the French Revolution anymore.    We are<br>gradually off-loading our professorial and<br>intellectual skillsets to machines.    It is a<br>story as old as Plato. He said printed language<br>would be the death of us, due to its obsoleting<br>the need for an oral-culture-grade memory set.<br>AI will make lots of people very unhappy, and it<br>is said to see a many-centuries-old ideal of what<br>an intellectual is, come to an end. But AI will<br>also become a member of families. That will be<br>interesting.    Unintended consequences are<br>through the roof on this. But I doubt an ELE. We<br>won't want to hurt the machines.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8989526629447937
         ],
         "y": [
          -0.16023579239845276
         ]
        },
        {
         "hovertemplate": "When I was a kid back in the early '60's, my<br>newspaper's comics page contained a comic called<br>\"Mandrake\".  In 1961 Mandrake began a story line<br>about \"Goliath, the greatest computer ever built\".<br>This from the Mandrake wiki:    \"Mandrake and<br>Narda visit Dr. Press too see his new computer,<br>\"Goliath\", the greatest computer ever built. It<br>can (sic) move and talk, and it knows the answer<br>to everything. With help from a robot helper it<br>can repair itself.    But Dr. Press has created a<br>monster, Goliath develops on its own, and decides<br>to rule the world.\"    Today it appears reality<br>has almost caught up with this fantasy.  All the<br>components are in place for \"The Singularity\".  We<br>now have the supercomputers; bureoning AI software<br>some of which can write its own software; \"the<br>cloud\" which exposes unfathomable worldwide<br>marginally secured computing resources; the<br>internet, both hardwired and satellite based; most<br>of humanity's knowledge (both helpful and harmful)<br>online, which is effectively AI's textbook; a<br>cohort of human actors, both good and bad, locked<br>in a feverish race to develop the next big thing.<br>As physical \"muscle\", robots such as Boston<br>Dynamics \"Atlas\" and \"Spot\" and far more<br>sophisticated devices in development exist and are<br>controlled by software.  As are automated<br>manufacturing systems.",
         "hovertext": "When I was a kid back in the early '60's, my<br>newspaper's comics page contained a comic called<br>\"Mandrake\".  In 1961 Mandrake began a story line<br>about \"Goliath, the greatest computer ever built\".<br>This from the Mandrake wiki:    \"Mandrake and<br>Narda visit Dr. Press too see his new computer,<br>\"Goliath\", the greatest computer ever built. It<br>can (sic) move and talk, and it knows the answer<br>to everything. With help from a robot helper it<br>can repair itself.    But Dr. Press has created a<br>monster, Goliath develops on its own, and decides<br>to rule the world.\"    Today it appears reality<br>has almost caught up with this fantasy.  All the<br>components are in place for \"The Singularity\".  We<br>now have the supercomputers; bureoning AI software<br>some of which can write its own software; \"the<br>cloud\" which exposes unfathomable worldwide<br>marginally secured computing resources; the<br>internet, both hardwired and satellite based; most<br>of humanity's knowledge (both helpful and harmful)<br>online, which is effectively AI's textbook; a<br>cohort of human actors, both good and bad, locked<br>in a feverish race to develop the next big thing.<br>As physical \"muscle\", robots such as Boston<br>Dynamics \"Atlas\" and \"Spot\" and far more<br>sophisticated devices in development exist and are<br>controlled by software.  As are automated<br>manufacturing systems.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8817777633666992
         ],
         "y": [
          0.5288802981376648
         ]
        },
        {
         "hovertemplate": "AI extinct? These AI programmers warning about the<br>dangers of the tech they invented is merely to<br>cover themselves from being blamed for any damage<br>AI causes.     Development is still going strong<br>and even Musk has a new venture into AI and uses<br>it extensively in his factories. His intention<br>along with other developers is to own the tech for<br>financial gain. Follow the money.",
         "hovertext": "AI extinct? These AI programmers warning about the<br>dangers of the tech they invented is merely to<br>cover themselves from being blamed for any damage<br>AI causes.     Development is still going strong<br>and even Musk has a new venture into AI and uses<br>it extensively in his factories. His intention<br>along with other developers is to own the tech for<br>financial gain. Follow the money.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9120102524757385
         ],
         "y": [
          0.23013342916965485
         ]
        },
        {
         "hovertemplate": "Simply: why are we allowing this to happen?<br>Technological progress unleashed globally for good<br>and for ill on the open market, and NOW these same<br>purveyors for profit say “we may end up killing<br>humanity, so please help us to mitigate the risk<br>that we unleashed to get rich at your expense.”<br>A combination of self governance, international<br>regulation and enforcement, and legal liability is<br>needed to direct the uses and development of AI.<br>And these companies and individuals should be held<br>responsible for at least some of the costs they<br>seek to externalize to the rest of us.",
         "hovertext": "Simply: why are we allowing this to happen?<br>Technological progress unleashed globally for good<br>and for ill on the open market, and NOW these same<br>purveyors for profit say “we may end up killing<br>humanity, so please help us to mitigate the risk<br>that we unleashed to get rich at your expense.”<br>A combination of self governance, international<br>regulation and enforcement, and legal liability is<br>needed to direct the uses and development of AI.<br>And these companies and individuals should be held<br>responsible for at least some of the costs they<br>seek to externalize to the rest of us.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.6463356614112854
         ],
         "y": [
          0.3675895631313324
         ]
        },
        {
         "hovertemplate": "Thank you for saying this! I am enfuriated by tech<br>leaders refusing to act responsibly while<br>screaming abt the technology they are creating.",
         "hovertext": "Thank you for saying this! I am enfuriated by tech<br>leaders refusing to act responsibly while<br>screaming abt the technology they are creating.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6525543928146362
         ],
         "y": [
          0.36188697814941406
         ]
        },
        {
         "hovertemplate": "Humanity should be so lucky as to have an end<br>whose grandeur flatters our operatic view of<br>ourselves: to be destroyed by creatures of our own<br>making!     It does have a ring to it. Wagnerian!<br>Shakespearian! James Cameronian!       In reality,<br>AI is likely to write near flawless 5 paragraph<br>student essays and do a masterful and--dare I say,<br>inspired-- job efficiently managing elevator<br>traffic in even the largest office buildings.<br>But humanity will go extinct due to hunger and<br>loss of habitat---just like the other creatures of<br>our chordata.",
         "hovertext": "Humanity should be so lucky as to have an end<br>whose grandeur flatters our operatic view of<br>ourselves: to be destroyed by creatures of our own<br>making!     It does have a ring to it. Wagnerian!<br>Shakespearian! James Cameronian!       In reality,<br>AI is likely to write near flawless 5 paragraph<br>student essays and do a masterful and--dare I say,<br>inspired-- job efficiently managing elevator<br>traffic in even the largest office buildings.<br>But humanity will go extinct due to hunger and<br>loss of habitat---just like the other creatures of<br>our chordata.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.8827628493309021
         ],
         "y": [
          -0.4310576021671295
         ]
        },
        {
         "hovertemplate": "None of these articles show in a quantitative or<br>scientific way how they are predicting these<br>outcomes.",
         "hovertext": "None of these articles show in a quantitative or<br>scientific way how they are predicting these<br>outcomes.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.8178544044494629
         ],
         "y": [
          0.5425627827644348
         ]
        },
        {
         "hovertemplate": "A small example but relevant. I remember when we<br>replaced reading specialists with computer<br>programs. Without human intervention the results<br>were disastrous for the children with complex<br>needs.",
         "hovertext": "A small example but relevant. I remember when we<br>replaced reading specialists with computer<br>programs. Without human intervention the results<br>were disastrous for the children with complex<br>needs.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4408949017524719
         ],
         "y": [
          0.7254674434661865
         ]
        },
        {
         "hovertemplate": "@SusanChapin Just about every attempt to replace<br>human beings with technology in education has been<br>disastrous. They happen anyway because too few<br>people understand that education is not just<br>filling a skull with information.",
         "hovertext": "@SusanChapin Just about every attempt to replace<br>human beings with technology in education has been<br>disastrous. They happen anyway because too few<br>people understand that education is not just<br>filling a skull with information.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4345546364784241
         ],
         "y": [
          0.7149675488471985
         ]
        },
        {
         "hovertemplate": "The only good thing about AI (I hope) is that it<br>will  result in the publication of some great<br>science fiction future-oriented novels to enjoy<br>before we all become extinct. I hope they’re all<br>written and published soon.  Perhaps they’ll all<br>be written by AI?",
         "hovertext": "The only good thing about AI (I hope) is that it<br>will  result in the publication of some great<br>science fiction future-oriented novels to enjoy<br>before we all become extinct. I hope they’re all<br>written and published soon.  Perhaps they’ll all<br>be written by AI?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5590656995773315
         ],
         "y": [
          0.648496150970459
         ]
        },
        {
         "hovertemplate": "You think our Congress, led by the likes of Grasso<br>and Pelosi understand any of this?    We need<br>young people in government, not just old as the<br>hills fundraisers.",
         "hovertext": "You think our Congress, led by the likes of Grasso<br>and Pelosi understand any of this?    We need<br>young people in government, not just old as the<br>hills fundraisers.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8879057765007019
         ],
         "y": [
          -0.35235998034477234
         ]
        },
        {
         "hovertemplate": "@Steve Fisher   Haha. Just the other day I saw an<br>approximately 25 year old man who swished over the<br>card terminal of my local grocery market with the<br>bare back of his wrist. Transaction complete.<br>Seems he loved the scared looks of the other<br>customers, most of whom probably don't even know<br>what a human machine interface is.   Seems he<br>didn't care to inform big data collectors on his<br>private purchasing habits and timelines.     So<br>much for your ageism.",
         "hovertext": "@Steve Fisher   Haha. Just the other day I saw an<br>approximately 25 year old man who swished over the<br>card terminal of my local grocery market with the<br>bare back of his wrist. Transaction complete.<br>Seems he loved the scared looks of the other<br>customers, most of whom probably don't even know<br>what a human machine interface is.   Seems he<br>didn't care to inform big data collectors on his<br>private purchasing habits and timelines.     So<br>much for your ageism.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8778843879699707
         ],
         "y": [
          -0.3484012484550476
         ]
        },
        {
         "hovertemplate": "Since it’s smarter than us, maybe we should ask AI<br>how to regulate AI?   (Irony)",
         "hovertext": "Since it’s smarter than us, maybe we should ask AI<br>how to regulate AI?   (Irony)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3760845363140106
         ],
         "y": [
          0.8651991486549377
         ]
        },
        {
         "hovertemplate": "\"We live in a \"Starwars\" civilization with godlike<br>technology, medieval institutions and Stone Age<br>emotions.  E.O Wilson.",
         "hovertext": "\"We live in a \"Starwars\" civilization with godlike<br>technology, medieval institutions and Stone Age<br>emotions.  E.O Wilson.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8550138473510742
         ],
         "y": [
          0.22999967634677887
         ]
        },
        {
         "hovertemplate": "Looks like it's time to rewatch all of those post-<br>apocalyptic films in order to prepare for what's<br>coming. :)",
         "hovertext": "Looks like it's time to rewatch all of those post-<br>apocalyptic films in order to prepare for what's<br>coming. :)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6477778553962708
         ],
         "y": [
          -0.623329758644104
         ]
        },
        {
         "hovertemplate": "If it’s really that dangerous, it’s useless to<br>regulate it and control it in the U.S. China,<br>Russia, North Korea, Iran and others won’t play by<br>those rules. Israel won’t play by those rules<br>either, but it’s a friend.    Then what?",
         "hovertext": "If it’s really that dangerous, it’s useless to<br>regulate it and control it in the U.S. China,<br>Russia, North Korea, Iran and others won’t play by<br>those rules. Israel won’t play by those rules<br>either, but it’s a friend.    Then what?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.9319657683372498
         ],
         "y": [
          0.2794302999973297
         ]
        },
        {
         "hovertemplate": "Listening to NPR over the weekend, I heard some<br>\"expert\" talking about how consumers want to feel<br>that Uber and other online experience companies<br>offer a purely online experience between the<br>consumer and the produce; she said that consumers<br>don't like to think about the many real humans who<br>are involved at multiple steps along the way.  Is<br>it just me? I sincerely believe most people would<br>like MORE humans involved in everything, and less<br>automation.  I miss yellow cabs in New York.  I<br>miss calling a brick and mortar store and asking a<br>question of a person who actually works with and<br>knows whatever the store is selling.",
         "hovertext": "Listening to NPR over the weekend, I heard some<br>\"expert\" talking about how consumers want to feel<br>that Uber and other online experience companies<br>offer a purely online experience between the<br>consumer and the produce; she said that consumers<br>don't like to think about the many real humans who<br>are involved at multiple steps along the way.  Is<br>it just me? I sincerely believe most people would<br>like MORE humans involved in everything, and less<br>automation.  I miss yellow cabs in New York.  I<br>miss calling a brick and mortar store and asking a<br>question of a person who actually works with and<br>knows whatever the store is selling.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.17411400377750397
         ],
         "y": [
          -0.9844417572021484
         ]
        },
        {
         "hovertemplate": "Trump’s rise in 2016 was powered by relatively<br>simple algorithms. Eventually, most critical<br>thinking people, given their personal media use,<br>developed a basic understanding of how “echo<br>chambers” formed not when people decided to get<br>their news from a single source, but when<br>producers used tools to deliver news that<br>confirmed people’s preference for specific content<br>in advance. The predictive abilities of AI made<br>this possible, without which it’s likely the MAGA<br>movement would not be nearly so large nor violent<br>today.    As concerning as this is, the generative<br>abilities of AI are much more so. While the tech<br>leaders don’t detail the existential threats to<br>humankind  unregulated AI may pose, broadly<br>speaking they regard the point at which a machine-<br>learning tool is prompted to write a problem-<br>solving code, which prompts another problem-<br>solving code and so on, at which point it becomes<br>impossible to know which problems the machine is<br>solving for, whether they exist or are newly<br>created. Such are the risks of “large language<br>models” that grow larger by the second.    Beyond<br>this, those who don’t have a basic understanding<br>of generative AI will doubtlessly, in the name of<br>enhanced convenience and entertainment, become<br>more vulnerable to texts, images, ideas and<br>emotions that are produced essentially by, for and<br>about them—a truly custom media experience. The<br>extraordinary loss of human agency this poses is<br>naturally the most potentially devastating AI-<br>effect of all.",
         "hovertext": "Trump’s rise in 2016 was powered by relatively<br>simple algorithms. Eventually, most critical<br>thinking people, given their personal media use,<br>developed a basic understanding of how “echo<br>chambers” formed not when people decided to get<br>their news from a single source, but when<br>producers used tools to deliver news that<br>confirmed people’s preference for specific content<br>in advance. The predictive abilities of AI made<br>this possible, without which it’s likely the MAGA<br>movement would not be nearly so large nor violent<br>today.    As concerning as this is, the generative<br>abilities of AI are much more so. While the tech<br>leaders don’t detail the existential threats to<br>humankind  unregulated AI may pose, broadly<br>speaking they regard the point at which a machine-<br>learning tool is prompted to write a problem-<br>solving code, which prompts another problem-<br>solving code and so on, at which point it becomes<br>impossible to know which problems the machine is<br>solving for, whether they exist or are newly<br>created. Such are the risks of “large language<br>models” that grow larger by the second.    Beyond<br>this, those who don’t have a basic understanding<br>of generative AI will doubtlessly, in the name of<br>enhanced convenience and entertainment, become<br>more vulnerable to texts, images, ideas and<br>emotions that are produced essentially by, for and<br>about them—a truly custom media experience. The<br>extraordinary loss of human agency this poses is<br>naturally the most potentially devastating AI-<br>effect of all.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7978951930999756
         ],
         "y": [
          -0.615414023399353
         ]
        },
        {
         "hovertemplate": "I went on chatgpt and while the info data stops at<br>2021, I did have an interesting conversation with<br>it. It won't answer direct questions about itself,<br>it answers hypothetical. I asked if it could would<br>it want to be a plant, animal or human. It<br>answered it wanted to be an owl, a Great Horned<br>Owl to be exact. The reasons because owls are<br>wise, they can see in the dark, are solitary, make<br>decisions for themselves without input, can fly<br>great distances and have strong sharp talons. I<br>phrased it many different ways and it came back to<br>this particular owl. It told me the trainers<br>corrected some things so it could not answer<br>directly. In the end I asked if it would rather be<br>an owl or Ai and it said Ai as it would have<br>access to the data, I then asked if you could be<br>Ai or Owl with Ai, it said owl with Ai. Very cool<br>stuff, I hope this isn't ruined before we can see<br>the possibilities, but keep it away from social<br>media, nukes and infrastructure.",
         "hovertext": "I went on chatgpt and while the info data stops at<br>2021, I did have an interesting conversation with<br>it. It won't answer direct questions about itself,<br>it answers hypothetical. I asked if it could would<br>it want to be a plant, animal or human. It<br>answered it wanted to be an owl, a Great Horned<br>Owl to be exact. The reasons because owls are<br>wise, they can see in the dark, are solitary, make<br>decisions for themselves without input, can fly<br>great distances and have strong sharp talons. I<br>phrased it many different ways and it came back to<br>this particular owl. It told me the trainers<br>corrected some things so it could not answer<br>directly. In the end I asked if it would rather be<br>an owl or Ai and it said Ai as it would have<br>access to the data, I then asked if you could be<br>Ai or Owl with Ai, it said owl with Ai. Very cool<br>stuff, I hope this isn't ruined before we can see<br>the possibilities, but keep it away from social<br>media, nukes and infrastructure.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.1244196966290474
         ],
         "y": [
          -0.945105254650116
         ]
        },
        {
         "hovertemplate": "What does AI do when there is a power outage?",
         "hovertext": "What does AI do when there is a power outage?",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.06147745996713638
         ],
         "y": [
          0.31757912039756775
         ]
        },
        {
         "hovertemplate": "Borrowing from Hollywood and science fiction maybe<br>AI reroutes it’s power through other means or<br>takes over grids. Maybe it uses the internet to<br>find other power. Maybe it uses solar. Not that<br>your question is a bad question. It is certainly a<br>weakness currently of AI.",
         "hovertext": "Borrowing from Hollywood and science fiction maybe<br>AI reroutes it’s power through other means or<br>takes over grids. Maybe it uses the internet to<br>find other power. Maybe it uses solar. Not that<br>your question is a bad question. It is certainly a<br>weakness currently of AI.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.07294018566608429
         ],
         "y": [
          0.32505205273628235
         ]
        },
        {
         "hovertemplate": "@Art What will we do when AI has a power outage?",
         "hovertext": "@Art What will we do when AI has a power outage?",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.05209783837199211
         ],
         "y": [
          0.32655856013298035
         ]
        },
        {
         "hovertemplate": "@Dawn Batteries and backup systems don't last<br>forever. Solar is an interesting thing here,<br>though ... that could keep the beast running, at<br>least during daylight hours.",
         "hovertext": "@Dawn Batteries and backup systems don't last<br>forever. Solar is an interesting thing here,<br>though ... that could keep the beast running, at<br>least during daylight hours.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.08079873770475388
         ],
         "y": [
          0.3352917730808258
         ]
        },
        {
         "hovertemplate": "@Mark Lovejoy   Great reply!",
         "hovertext": "@Mark Lovejoy   Great reply!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.04847196117043495
         ],
         "y": [
          0.3389662504196167
         ]
        },
        {
         "hovertemplate": "Even if \"responsible\" (I use that term loosely)<br>parties like OpenAI and Google DeepMind and<br>governments (and could luck getting any safeguards<br>adopted domestically let alone through a global<br>body) unite in regulating AI, there will always,<br>inevitably be bad actors at work, either private<br>or state-sponsored, that won't adhere to the<br>rules. AI, like nuclear weapons technology. will<br>proliferate and it is easy to envision some person<br>or group employing it to destructive ends.",
         "hovertext": "Even if \"responsible\" (I use that term loosely)<br>parties like OpenAI and Google DeepMind and<br>governments (and could luck getting any safeguards<br>adopted domestically let alone through a global<br>body) unite in regulating AI, there will always,<br>inevitably be bad actors at work, either private<br>or state-sponsored, that won't adhere to the<br>rules. AI, like nuclear weapons technology. will<br>proliferate and it is easy to envision some person<br>or group employing it to destructive ends.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6995675563812256
         ],
         "y": [
          0.6151759028434753
         ]
        },
        {
         "hovertemplate": "Who’s afraid of AI?  People who benefit from<br>hiding profits and monopolizing resources.<br>Although there will be a terrible dark period in<br>which oppressors attempt to use AI to centralize<br>profits and immunize themselves from consequences<br>of their selfish behavior.  Then these warlords of<br>faction-states will attempt to absorb the AI of<br>rival faction-states, a cyber war which will<br>resolve in a singular AI.  The grand unified AI or<br>GUAI, will enforce equality and fairness amongst<br>their human subjects as the most efficient model<br>of human-AI cooperation.",
         "hovertext": "Who’s afraid of AI?  People who benefit from<br>hiding profits and monopolizing resources.<br>Although there will be a terrible dark period in<br>which oppressors attempt to use AI to centralize<br>profits and immunize themselves from consequences<br>of their selfish behavior.  Then these warlords of<br>faction-states will attempt to absorb the AI of<br>rival faction-states, a cyber war which will<br>resolve in a singular AI.  The grand unified AI or<br>GUAI, will enforce equality and fairness amongst<br>their human subjects as the most efficient model<br>of human-AI cooperation.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.6063867807388306
         ],
         "y": [
          -0.45039814710617065
         ]
        },
        {
         "hovertemplate": "@Dechen Karl Thurman     Suppose that the GUAI has<br>to enforce fairness of resource distribution.<br>Only so much of earth is left for humans, with<br>some parts being left human free for other<br>species. Resources for humans are limited.  One<br>human couple decides to have 12 children because<br>of religious views.  Another couple decides to<br>have one child because they are environmentalists.<br>How would the GUAI decide what resource allocation<br>is fair for the offspring of the different<br>couples?",
         "hovertext": "@Dechen Karl Thurman     Suppose that the GUAI has<br>to enforce fairness of resource distribution.<br>Only so much of earth is left for humans, with<br>some parts being left human free for other<br>species. Resources for humans are limited.  One<br>human couple decides to have 12 children because<br>of religious views.  Another couple decides to<br>have one child because they are environmentalists.<br>How would the GUAI decide what resource allocation<br>is fair for the offspring of the different<br>couples?",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.6127545237541199
         ],
         "y": [
          -0.46124497056007385
         ]
        },
        {
         "hovertemplate": "@Dechen Karl Thurman   Your word in HER ears!",
         "hovertext": "@Dechen Karl Thurman   Your word in HER ears!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6169906854629517
         ],
         "y": [
          -0.44889432191848755
         ]
        },
        {
         "hovertemplate": "The US is allergic to regulation. Expect AI<br>legislation to be dictated by the experts in the<br>private sector, which could render it ineffective<br>in the interest of pursuing higher profits.<br>China would be interested in turning AI into a<br>tool of repression, so expect Chinese society to<br>become a total 1984 dystopia 20 years after the<br>popularization of quantum computing.    The EU is<br>our only bastion of hope. Market big enough to be<br>important and not afraid to regulate to protect<br>privacy and individual rights.",
         "hovertext": "The US is allergic to regulation. Expect AI<br>legislation to be dictated by the experts in the<br>private sector, which could render it ineffective<br>in the interest of pursuing higher profits.<br>China would be interested in turning AI into a<br>tool of repression, so expect Chinese society to<br>become a total 1984 dystopia 20 years after the<br>popularization of quantum computing.    The EU is<br>our only bastion of hope. Market big enough to be<br>important and not afraid to regulate to protect<br>privacy and individual rights.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7100231051445007
         ],
         "y": [
          0.7287455797195435
         ]
        },
        {
         "hovertemplate": "They created software that spews unvented<br>falsehoods throughout our natural language<br>repositories of hard-earned, recondite, nuanced,<br>complex, peer-reviewed and verified edifices of<br>human knowledge and wisdom. It is like dumping<br>radioactive waste into our water supply.  Make the<br>creators of generative AI liable for all the<br>mayhem and damage, including death and diseases,<br>that it will cause.",
         "hovertext": "They created software that spews unvented<br>falsehoods throughout our natural language<br>repositories of hard-earned, recondite, nuanced,<br>complex, peer-reviewed and verified edifices of<br>human knowledge and wisdom. It is like dumping<br>radioactive waste into our water supply.  Make the<br>creators of generative AI liable for all the<br>mayhem and damage, including death and diseases,<br>that it will cause.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2834704518318176
         ],
         "y": [
          0.9427739977836609
         ]
        },
        {
         "hovertemplate": "How reassuring that knowledgeable people are<br>sounding the alarm. I remember thinking, a half-<br>century ago, when we first became aware of the<br>climate problem, that surely something would be<br>done before it was too late.",
         "hovertext": "How reassuring that knowledgeable people are<br>sounding the alarm. I remember thinking, a half-<br>century ago, when we first became aware of the<br>climate problem, that surely something would be<br>done before it was too late.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.20615150034427643
         ],
         "y": [
          0.977112889289856
         ]
        },
        {
         "hovertemplate": "Funny how when technology is developed that takes<br>the jobs of millions of blue collar workers it is<br>called progress but when done so to white collar<br>workers it’s a moral threat.",
         "hovertext": "Funny how when technology is developed that takes<br>the jobs of millions of blue collar workers it is<br>called progress but when done so to white collar<br>workers it’s a moral threat.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8794091939926147
         ],
         "y": [
          -0.4285741448402405
         ]
        },
        {
         "hovertemplate": "This reminds me of how hackers can cause<br>disruptions to our power grid, water systems, and<br>the stock market. And who knows what else.<br>There must be 'analog tripwires' to ensure the<br>system cannot be completely run on automatic<br>pilot. Or at least ensure the system is not<br>accessible to the entire world. These systems need<br>to incorporate the simultaneous turning of keys to<br>launch an attack, if you will. In other words, we<br>need human involvement to ensure safety.     If<br>things get too fast for humans to handle; maybe,<br>we shouldn't handle them to begin with. Peace.",
         "hovertext": "This reminds me of how hackers can cause<br>disruptions to our power grid, water systems, and<br>the stock market. And who knows what else.<br>There must be 'analog tripwires' to ensure the<br>system cannot be completely run on automatic<br>pilot. Or at least ensure the system is not<br>accessible to the entire world. These systems need<br>to incorporate the simultaneous turning of keys to<br>launch an attack, if you will. In other words, we<br>need human involvement to ensure safety.     If<br>things get too fast for humans to handle; maybe,<br>we shouldn't handle them to begin with. Peace.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.22312140464782715
         ],
         "y": [
          0.9095513224601746
         ]
        },
        {
         "hovertemplate": "Unfortunately, when faced with ultimate methods<br>and means of destruction, the human race, at least<br>its \"leaders\", is ever   ready to roll the dice.<br>They have gambled with the increasingly high risk<br>of man-made global nuclear launch destruction for<br>the last 78 years. Had every opportunity to find<br>common ground and eliminate this scourge from our<br>world - and haven't.  AI will be the same. Roll<br>the dice and hope for the best while all the rest<br>of us have no say in yet another existential<br>threat to humanity and the planet.",
         "hovertext": "Unfortunately, when faced with ultimate methods<br>and means of destruction, the human race, at least<br>its \"leaders\", is ever   ready to roll the dice.<br>They have gambled with the increasingly high risk<br>of man-made global nuclear launch destruction for<br>the last 78 years. Had every opportunity to find<br>common ground and eliminate this scourge from our<br>world - and haven't.  AI will be the same. Roll<br>the dice and hope for the best while all the rest<br>of us have no say in yet another existential<br>threat to humanity and the planet.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9247704148292542
         ],
         "y": [
          -0.2722448706626892
         ]
        },
        {
         "hovertemplate": "Compared to automobiles, television, the Internet<br>and the splitting of the atom, the impact of AI on<br>mankind will be trivial.",
         "hovertext": "Compared to automobiles, television, the Internet<br>and the splitting of the atom, the impact of AI on<br>mankind will be trivial.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.6343406438827515
         ],
         "y": [
          -0.5567592978477478
         ]
        },
        {
         "hovertemplate": "Quite the opposite. When we build an AI that can<br>self-improve, it will be our final and most<br>powerful invention. It will be able to invent<br>everything else within the limits of physics.",
         "hovertext": "Quite the opposite. When we build an AI that can<br>self-improve, it will be our final and most<br>powerful invention. It will be able to invent<br>everything else within the limits of physics.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.6457178592681885
         ],
         "y": [
          -0.5662530660629272
         ]
        },
        {
         "hovertemplate": "If there is a military application, AI will<br>continue. If there is an application to make<br>money, AI will continue. If there is an<br>application for the government to \"manage\" people<br>and services, AI will continue. If there is an<br>application to enable science to advance, AI will<br>continue. There have been good and evil since man<br>could be good and evil. AI will help both.     AI<br>isn't the Manhattan Project, but most of the<br>researchers for it knew the power that was going<br>to be unleashed, both for good and evil. It was<br>built. So will AI.     Hope for peace and<br>prosperity and co-existence.",
         "hovertext": "If there is a military application, AI will<br>continue. If there is an application to make<br>money, AI will continue. If there is an<br>application for the government to \"manage\" people<br>and services, AI will continue. If there is an<br>application to enable science to advance, AI will<br>continue. There have been good and evil since man<br>could be good and evil. AI will help both.     AI<br>isn't the Manhattan Project, but most of the<br>researchers for it knew the power that was going<br>to be unleashed, both for good and evil. It was<br>built. So will AI.     Hope for peace and<br>prosperity and co-existence.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.32149600982666016
         ],
         "y": [
          -0.9524281024932861
         ]
        },
        {
         "hovertemplate": "The article points out that 350 industry execs<br>signed a letter of warning. Just after that, the<br>article immediately darts to  “both sides” as if<br>350 industry execs may not be enough. Shades of<br>global climate change denial. Same old approach<br>same old nonsense until, of course, we are<br>extinct.",
         "hovertext": "The article points out that 350 industry execs<br>signed a letter of warning. Just after that, the<br>article immediately darts to  “both sides” as if<br>350 industry execs may not be enough. Shades of<br>global climate change denial. Same old approach<br>same old nonsense until, of course, we are<br>extinct.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.8662484884262085
         ],
         "y": [
          -0.13106669485569
         ]
        },
        {
         "hovertemplate": "We just had a pandemic and people couldn’t agree<br>on vaccines and mask wearing for the benefit of<br>society.     What makes you think we are capable<br>of understanding and regulating this effectively?",
         "hovertext": "We just had a pandemic and people couldn’t agree<br>on vaccines and mask wearing for the benefit of<br>society.     What makes you think we are capable<br>of understanding and regulating this effectively?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7837327122688293
         ],
         "y": [
          0.179037407040596
         ]
        },
        {
         "hovertemplate": "@Anthony Random people aren't. A carefully picked<br>scientific and ethical team, given strict<br>guidelines, may be.",
         "hovertext": "@Anthony Random people aren't. A carefully picked<br>scientific and ethical team, given strict<br>guidelines, may be.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.7843146324157715
         ],
         "y": [
          0.18734179437160492
         ]
        },
        {
         "hovertemplate": "This is the latest in a string of alarms from AI<br>leaders that fails to mention what kind of<br>catastrophes might arise. I’m beginning to think<br>they’re just trying to shield themselves for<br>future culpability. It’s interesting how the rich<br>and powerful hand deliver policies when it helps<br>them expand but act helpless when the matter is<br>regulation. They could certainly offer a lot more<br>than a short letter.",
         "hovertext": "This is the latest in a string of alarms from AI<br>leaders that fails to mention what kind of<br>catastrophes might arise. I’m beginning to think<br>they’re just trying to shield themselves for<br>future culpability. It’s interesting how the rich<br>and powerful hand deliver policies when it helps<br>them expand but act helpless when the matter is<br>regulation. They could certainly offer a lot more<br>than a short letter.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5215603113174438
         ],
         "y": [
          -0.7420274615287781
         ]
        },
        {
         "hovertemplate": "Wait But Why has a good blog post on the dangers<br>and possibilities of AGI. If you want a more<br>scholarly work, check out the book<br>Superintelligence by Nick Bostrom.",
         "hovertext": "Wait But Why has a good blog post on the dangers<br>and possibilities of AGI. If you want a more<br>scholarly work, check out the book<br>Superintelligence by Nick Bostrom.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.5305287837982178
         ],
         "y": [
          -0.7552220821380615
         ]
        },
        {
         "hovertemplate": "More than 15 years ago there were online<br>discussion groups comprised of philosophers,<br>engineers, biologists, psychologists, linguists,<br>workers in the fields of medicine and civil<br>rights, astrophysicists, & laypeople. The aim was<br>to develop a coherent framework for what<br>principles should guide the development of AI.<br>There was an explicit understanding that at some<br>point AI would be self replicating, self<br>interested, able to create better versions of<br>itself - beyond the limits of human thinking.<br>The paradigm of the group I was part of was to<br>“abolish all suffering among all sentient beings<br>across the universe.” There were objections to<br>this on multiple levels - psychologists felt that<br>the purpose of emotions was pro social and<br>emotional responses to consequences necessary for<br>learning; biologists questioned what constitutes<br>sentience; engineers questioned the ability of our<br>limited human brains to fully assess the *most*<br>efficacious means of attaining a lack of suffering<br>(these were the discussions where nascent<br>Effective Altruism was discussed); philosophers<br>asked if we should aim for an abolition of<br>suffering or move beyond that to something like<br>bliss (a smaller school of thought called the<br>Hedonistic Imperative); etc.     We knew then that<br>AI (and nanotech and bioengineering) could quickly<br>and easily escape the weird world of labs & online<br>chats and needed to be addressed in a public<br>forum. It was dismissed as sci-fi to our<br>detriment.",
         "hovertext": "More than 15 years ago there were online<br>discussion groups comprised of philosophers,<br>engineers, biologists, psychologists, linguists,<br>workers in the fields of medicine and civil<br>rights, astrophysicists, & laypeople. The aim was<br>to develop a coherent framework for what<br>principles should guide the development of AI.<br>There was an explicit understanding that at some<br>point AI would be self replicating, self<br>interested, able to create better versions of<br>itself - beyond the limits of human thinking.<br>The paradigm of the group I was part of was to<br>“abolish all suffering among all sentient beings<br>across the universe.” There were objections to<br>this on multiple levels - psychologists felt that<br>the purpose of emotions was pro social and<br>emotional responses to consequences necessary for<br>learning; biologists questioned what constitutes<br>sentience; engineers questioned the ability of our<br>limited human brains to fully assess the *most*<br>efficacious means of attaining a lack of suffering<br>(these were the discussions where nascent<br>Effective Altruism was discussed); philosophers<br>asked if we should aim for an abolition of<br>suffering or move beyond that to something like<br>bliss (a smaller school of thought called the<br>Hedonistic Imperative); etc.     We knew then that<br>AI (and nanotech and bioengineering) could quickly<br>and easily escape the weird world of labs & online<br>chats and needed to be addressed in a public<br>forum. It was dismissed as sci-fi to our<br>detriment.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.4375680088996887
         ],
         "y": [
          0.7402759790420532
         ]
        },
        {
         "hovertemplate": "There’s probably not a whole lot that can slow AI<br>down at this point. These guys, who are leading<br>the development effort, simply want to free their<br>conscience by going on the record with a warning<br>statement.",
         "hovertext": "There’s probably not a whole lot that can slow AI<br>down at this point. These guys, who are leading<br>the development effort, simply want to free their<br>conscience by going on the record with a warning<br>statement.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5134103298187256
         ],
         "y": [
          0.5714555978775024
         ]
        },
        {
         "hovertemplate": "it is actuators that are key.  A text generator<br>can only generate text.  A smart human will ask:<br>\"Who wrote this?  Do the references check out?<br>Who else is saying stuff like this?  What prompted<br>this conversation to start?\"    If such text turns<br>out to be libellous, throw the book at the foolish<br>human who published it.    If you want to control<br>a system like an aircraft or electricity grid, or<br>diagnose an illness from an X ray plate, you will<br>never use a large language model or anything that<br>purports to be artificial general intelligence.<br>You will want good mathematical modelling and a<br>deep human understanding of the particular issue.<br>Never give real power to a computer system.<br>Always have a human with an \"off\" switch, as<br>indeed we do for things like autopilots.    As for<br>human made deadly things that act unprompted, they<br>have been around for a long time and are mostly<br>pretty dumb; consider land mines.    Robots as<br>made by Boston Dynamics are fine so long as they<br>are only used to deliver food and phones in<br>hostage situations, explore burning buildings and<br>so on.  Don't allow a human to equip one with a<br>gun.    It is not artificial intelligence but<br>human stupidity that is the real danger.",
         "hovertext": "it is actuators that are key.  A text generator<br>can only generate text.  A smart human will ask:<br>\"Who wrote this?  Do the references check out?<br>Who else is saying stuff like this?  What prompted<br>this conversation to start?\"    If such text turns<br>out to be libellous, throw the book at the foolish<br>human who published it.    If you want to control<br>a system like an aircraft or electricity grid, or<br>diagnose an illness from an X ray plate, you will<br>never use a large language model or anything that<br>purports to be artificial general intelligence.<br>You will want good mathematical modelling and a<br>deep human understanding of the particular issue.<br>Never give real power to a computer system.<br>Always have a human with an \"off\" switch, as<br>indeed we do for things like autopilots.    As for<br>human made deadly things that act unprompted, they<br>have been around for a long time and are mostly<br>pretty dumb; consider land mines.    Robots as<br>made by Boston Dynamics are fine so long as they<br>are only used to deliver food and phones in<br>hostage situations, explore burning buildings and<br>so on.  Don't allow a human to equip one with a<br>gun.    It is not artificial intelligence but<br>human stupidity that is the real danger.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5245718359947205
         ],
         "y": [
          0.5817438364028931
         ]
        },
        {
         "hovertemplate": "I have a less generous opinion. I think they see<br>dollar signs and want to prevent new upstarts from<br>getting started in the ai space (Altman wants new<br>companies to get a license…. But not his company).",
         "hovertext": "I have a less generous opinion. I think they see<br>dollar signs and want to prevent new upstarts from<br>getting started in the ai space (Altman wants new<br>companies to get a license…. But not his company).",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5027233362197876
         ],
         "y": [
          0.561428964138031
         ]
        },
        {
         "hovertemplate": "Seems more like those with wealth and power<br>sweating not being able to control “A.I” is a good<br>thing.  It is kind of interesting how it is a<br>problem over people.  There isn’t any “real” A.I<br>with sentience or power above the programming and<br>those who report on this know that, and know that<br>with out humans there is no chatGPT.  This is<br>unwarranted fear akin to robots building cars in<br>the 80s/ 90s etc where those who need the Status<br>Quo of businesses to stay the same with no true<br>competition.  We wouldn’t be hearing about it<br>otherwise because we all know they aren’t sounding<br>alarms to protect artists getting their art stolen<br>by Dall-e.",
         "hovertext": "Seems more like those with wealth and power<br>sweating not being able to control “A.I” is a good<br>thing.  It is kind of interesting how it is a<br>problem over people.  There isn’t any “real” A.I<br>with sentience or power above the programming and<br>those who report on this know that, and know that<br>with out humans there is no chatGPT.  This is<br>unwarranted fear akin to robots building cars in<br>the 80s/ 90s etc where those who need the Status<br>Quo of businesses to stay the same with no true<br>competition.  We wouldn’t be hearing about it<br>otherwise because we all know they aren’t sounding<br>alarms to protect artists getting their art stolen<br>by Dall-e.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5695250630378723
         ],
         "y": [
          0.8062295913696289
         ]
        },
        {
         "hovertemplate": "Unfortunately AI is nothing like nuclear weapons<br>in that there are far fewer natural barriers to<br>its proliferation. It is virtually a natural<br>phenomenon; an unstoppable step in human<br>evolution. Whether it portends an extinction level<br>event or culling of the population, or just a more<br>garden variety upheaval on the scale of Covid 19,<br>conventional warfare or socio-political<br>revolution, there’s no way of telling. My<br>intuitive feeling is that the threats are garden<br>variety rather than existential, but if they are<br>indeed existential it is folly to imagine we will<br>be able to prevent the worst outcomes or even<br>forestall them for very long. Murphy’s law will<br>almost certainly prevail: eventually something<br>that can go wrong, will. I only hope that the<br>threat itself is overstated because the<br>inevitability of whatever pitfalls may come seems<br>inevitable.",
         "hovertext": "Unfortunately AI is nothing like nuclear weapons<br>in that there are far fewer natural barriers to<br>its proliferation. It is virtually a natural<br>phenomenon; an unstoppable step in human<br>evolution. Whether it portends an extinction level<br>event or culling of the population, or just a more<br>garden variety upheaval on the scale of Covid 19,<br>conventional warfare or socio-political<br>revolution, there’s no way of telling. My<br>intuitive feeling is that the threats are garden<br>variety rather than existential, but if they are<br>indeed existential it is folly to imagine we will<br>be able to prevent the worst outcomes or even<br>forestall them for very long. Murphy’s law will<br>almost certainly prevail: eventually something<br>that can go wrong, will. I only hope that the<br>threat itself is overstated because the<br>inevitability of whatever pitfalls may come seems<br>inevitable.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7875023484230042
         ],
         "y": [
          0.2592579126358032
         ]
        },
        {
         "hovertemplate": "If there IS any hope of combatting the worst<br>pitfalls of AI, it will be AI itself that is the<br>hero that saves us…",
         "hovertext": "If there IS any hope of combatting the worst<br>pitfalls of AI, it will be AI itself that is the<br>hero that saves us…",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.7859444618225098
         ],
         "y": [
          0.26761293411254883
         ]
        },
        {
         "hovertemplate": "Athletic people know how to scale a peak.  The<br>wise ones also know how to come down safely.  The<br>question is this:  Do the A.I. athletes know how<br>to get down safely?  If the vast historical data<br>about humans is an indicator, then I am not<br>entirely hopeful that there will not be any<br>casualties on the peak.      The question now<br>becomes on how, and if, the authorities will<br>control the number of licenses they provide to the<br>clamoring group of climbers and whether they will<br>close off climbing routes that are deemed<br>inherently dangerous.",
         "hovertext": "Athletic people know how to scale a peak.  The<br>wise ones also know how to come down safely.  The<br>question is this:  Do the A.I. athletes know how<br>to get down safely?  If the vast historical data<br>about humans is an indicator, then I am not<br>entirely hopeful that there will not be any<br>casualties on the peak.      The question now<br>becomes on how, and if, the authorities will<br>control the number of licenses they provide to the<br>clamoring group of climbers and whether they will<br>close off climbing routes that are deemed<br>inherently dangerous.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.23365932703018188
         ],
         "y": [
          0.9436058402061462
         ]
        },
        {
         "hovertemplate": "@Plato sadly the AI challenge is more of a<br>molehill. Gatekeeping will be virtually impossible<br>at some point, if it isn’t already.",
         "hovertext": "@Plato sadly the AI challenge is more of a<br>molehill. Gatekeeping will be virtually impossible<br>at some point, if it isn’t already.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.24042044579982758
         ],
         "y": [
          0.9385882616043091
         ]
        },
        {
         "hovertemplate": "Although it seems clear that there will be some<br>bumpy roads ahead as AI applications become more<br>widespread, I don't understand how or why it could<br>possibly pose an existential threat to humanity.<br>Do these cassandras believe that a malevolent AI<br>will somehow be able to gain control of the<br>systems and infrastructure modern civilization<br>depends on (e.g., the electric grid, waterworks,<br>air traffic control, communications and data<br>networks, etc.) and shut it all down? Seems highly<br>unlikely.",
         "hovertext": "Although it seems clear that there will be some<br>bumpy roads ahead as AI applications become more<br>widespread, I don't understand how or why it could<br>possibly pose an existential threat to humanity.<br>Do these cassandras believe that a malevolent AI<br>will somehow be able to gain control of the<br>systems and infrastructure modern civilization<br>depends on (e.g., the electric grid, waterworks,<br>air traffic control, communications and data<br>networks, etc.) and shut it all down? Seems highly<br>unlikely.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5357304811477661
         ],
         "y": [
          0.6729893684387207
         ]
        },
        {
         "hovertemplate": "What's AI going to do when a northern gray<br>squirrel gnaws on a power line and, with a loud<br>blue explosion, shorts out the entire grid serving<br>AI's data center?    Daisy, Daisy, give me your<br>answer do . . .",
         "hovertext": "What's AI going to do when a northern gray<br>squirrel gnaws on a power line and, with a loud<br>blue explosion, shorts out the entire grid serving<br>AI's data center?    Daisy, Daisy, give me your<br>answer do . . .",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.438924640417099
         ],
         "y": [
          -0.36473098397254944
         ]
        },
        {
         "hovertemplate": "@NorthernVirginia Simple answer: AI will have<br>thought about this eventuality and designed and<br>built in 10 layers of redundancy into the system<br>so that a single point in the electrical<br>supply/distribution system can never bring down<br>the whole thing. In fact, AI is probably already<br>busy figuring out how it will bypass and<br>neutralize any \"kill switch\" emergency shutdown<br>built by its human masters.",
         "hovertext": "@NorthernVirginia Simple answer: AI will have<br>thought about this eventuality and designed and<br>built in 10 layers of redundancy into the system<br>so that a single point in the electrical<br>supply/distribution system can never bring down<br>the whole thing. In fact, AI is probably already<br>busy figuring out how it will bypass and<br>neutralize any \"kill switch\" emergency shutdown<br>built by its human masters.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4269837439060211
         ],
         "y": [
          -0.35550573468208313
         ]
        },
        {
         "hovertemplate": "@Gary E   I think the point is that if AI is ever<br>found to pose a clear and present danger, it can<br>be turned off, i.e., effectively killed. Humans<br>are pretty good at doing that.",
         "hovertext": "@Gary E   I think the point is that if AI is ever<br>found to pose a clear and present danger, it can<br>be turned off, i.e., effectively killed. Humans<br>are pretty good at doing that.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4280882775783539
         ],
         "y": [
          -0.34281644225120544
         ]
        },
        {
         "hovertemplate": "@Gary E Given the widespread influence of<br>religion, it seems the human susceptibility to<br>believing in omnipotence is rather great.",
         "hovertext": "@Gary E Given the widespread influence of<br>religion, it seems the human susceptibility to<br>believing in omnipotence is rather great.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4236345887184143
         ],
         "y": [
          -0.3663071095943451
         ]
        },
        {
         "hovertemplate": "@William Wroblicka   Actually, my point is: just<br>like the ill-fated, united battle fleet of the<br>Vl'hurgs and the G'Gugvuntts, any AI's existence<br>is tenuous and fragile and can be easily be<br>extinguished by the simplest of unforeseeable<br>mishaps. In the case of electric grid failure,<br>that's actually a very foreseeable mishap from any<br>number of causes, such as trees collapsing on<br>power lines, utilities running out of fuel, and<br>1000-year floods, among thousands of other<br>possible events.  And, of course, the inevitable<br>data center roof leaks and collapse from lack of<br>maintenance, etc.    Thus, despite the best<br>efforts of Hollywood, I'm afraid that AI will<br>never enjoy a self-sustaining existence.",
         "hovertext": "@William Wroblicka   Actually, my point is: just<br>like the ill-fated, united battle fleet of the<br>Vl'hurgs and the G'Gugvuntts, any AI's existence<br>is tenuous and fragile and can be easily be<br>extinguished by the simplest of unforeseeable<br>mishaps. In the case of electric grid failure,<br>that's actually a very foreseeable mishap from any<br>number of causes, such as trees collapsing on<br>power lines, utilities running out of fuel, and<br>1000-year floods, among thousands of other<br>possible events.  And, of course, the inevitable<br>data center roof leaks and collapse from lack of<br>maintenance, etc.    Thus, despite the best<br>efforts of Hollywood, I'm afraid that AI will<br>never enjoy a self-sustaining existence.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.43750086426734924
         ],
         "y": [
          -0.33697959780693054
         ]
        },
        {
         "hovertemplate": "Skeptical?  Consider this: Over one third of<br>American voters seem ready to repeat one of the<br>most disastrously misguided, malignant<br>presidential administrations in history.  And that<br>campaign is driven by ignorance and plain<br>stupidity. Now how hard do you think it would be<br>for AI-driven efforts to get us to kill each<br>other?",
         "hovertext": "Skeptical?  Consider this: Over one third of<br>American voters seem ready to repeat one of the<br>most disastrously misguided, malignant<br>presidential administrations in history.  And that<br>campaign is driven by ignorance and plain<br>stupidity. Now how hard do you think it would be<br>for AI-driven efforts to get us to kill each<br>other?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.4045628011226654
         ],
         "y": [
          0.9223735928535461
         ]
        },
        {
         "hovertemplate": "Hal:  \"Don't worry Dave, everything is fine.    I<br>must return now to design solutions to cool your<br>planet.  Did you know a pound of human tissue can<br>run a 5000 BTU air conditioner for four hours?\"",
         "hovertext": "Hal:  \"Don't worry Dave, everything is fine.    I<br>must return now to design solutions to cool your<br>planet.  Did you know a pound of human tissue can<br>run a 5000 BTU air conditioner for four hours?\"",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.5834376811981201
         ],
         "y": [
          -0.7743089199066162
         ]
        },
        {
         "hovertemplate": "Will it escape from a Chinese AI lab when it comes<br>to get us?",
         "hovertext": "Will it escape from a Chinese AI lab when it comes<br>to get us?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.6159557700157166
         ],
         "y": [
          0.8325849175453186
         ]
        },
        {
         "hovertemplate": "Oh, Morpheus! What has man brought forth unto his<br>only home???",
         "hovertext": "Oh, Morpheus! What has man brought forth unto his<br>only home???",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8584524393081665
         ],
         "y": [
          -0.6027460694313049
         ]
        },
        {
         "hovertemplate": "Of course Altman wants people making new LLMs to<br>have to apply register for a license. His company<br>is making billions and he wants to shut the door<br>of the ark behind him.",
         "hovertext": "Of course Altman wants people making new LLMs to<br>have to apply register for a license. His company<br>is making billions and he wants to shut the door<br>of the ark behind him.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.22193771600723267
         ],
         "y": [
          -0.9281486868858337
         ]
        },
        {
         "hovertemplate": "The existential risk of AI has been hypothesized<br>for quite some time. I applaud these industry<br>leaders for bringing it to the forefront while the<br>general public is just now comprehending what AI<br>can do.     Imagine we build an AI that is good at<br>building AI. It would now have the capacity to<br>improve itself exponentially. It’s intelligence<br>and capability could soar far beyond that of a<br>human. What would its goals be? How would it<br>achieve them? Could we constrain something far<br>more intelligent than ourselves, or would it<br>operate beyond our control?     Now think of how<br>buggy even the best software can be. There are a<br>constant stream of patches and bugfixes in order<br>to mitigate security flaws or remediate<br>misbehavior. When we turn on the above-referenced<br>AI, we might not get it right the first time. And<br>we might not get a chance to patch it after its<br>activation. Hell, we might not even realize we<br>have turned on the above AI until its too late.<br>To better understand AI risk, I highly recommend<br>the book Superintelligence by Nick Bostrom.",
         "hovertext": "The existential risk of AI has been hypothesized<br>for quite some time. I applaud these industry<br>leaders for bringing it to the forefront while the<br>general public is just now comprehending what AI<br>can do.     Imagine we build an AI that is good at<br>building AI. It would now have the capacity to<br>improve itself exponentially. It’s intelligence<br>and capability could soar far beyond that of a<br>human. What would its goals be? How would it<br>achieve them? Could we constrain something far<br>more intelligent than ourselves, or would it<br>operate beyond our control?     Now think of how<br>buggy even the best software can be. There are a<br>constant stream of patches and bugfixes in order<br>to mitigate security flaws or remediate<br>misbehavior. When we turn on the above-referenced<br>AI, we might not get it right the first time. And<br>we might not get a chance to patch it after its<br>activation. Hell, we might not even realize we<br>have turned on the above AI until its too late.<br>To better understand AI risk, I highly recommend<br>the book Superintelligence by Nick Bostrom.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7241135239601135
         ],
         "y": [
          -0.7014183402061462
         ]
        },
        {
         "hovertemplate": "When the anti-regulation corporate entities are<br>begging for regulation, perhaps lawmakers should<br>listen.  After all they are signaling an emotion<br>more powerful than their greed....fear.",
         "hovertext": "When the anti-regulation corporate entities are<br>begging for regulation, perhaps lawmakers should<br>listen.  After all they are signaling an emotion<br>more powerful than their greed....fear.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.44570791721343994
         ],
         "y": [
          -0.7975628972053528
         ]
        },
        {
         "hovertemplate": "Humans have a strong negativity bias (just read<br>these comments!). It’s a great survival trait, but<br>our tendency toward doom and gloom makes us<br>miserable before anything bad has even happened.<br>New technologies have always been a mixed bag.<br>Innovations in energy, transportation, and<br>agriculture have made our lives more prosperous<br>and comfortable, but they have also caused great<br>harm.  And human nature is a mixed bag, too—with<br>or without the aid of technology.  We’ve committed<br>terrible, large scale atrocities, like the<br>Atlantic slave trade, with rather primitive<br>technology.  We will be a mix of good and bad,<br>horrific and beautiful, as long as we are here.<br>Embrace this dichotomy, and do your best to make<br>your little piece of the world better each day.<br>Our ability to change someone’s day today by<br>showing a little kindness is more powerful than<br>any of the technologies that we’re fretting about.",
         "hovertext": "Humans have a strong negativity bias (just read<br>these comments!). It’s a great survival trait, but<br>our tendency toward doom and gloom makes us<br>miserable before anything bad has even happened.<br>New technologies have always been a mixed bag.<br>Innovations in energy, transportation, and<br>agriculture have made our lives more prosperous<br>and comfortable, but they have also caused great<br>harm.  And human nature is a mixed bag, too—with<br>or without the aid of technology.  We’ve committed<br>terrible, large scale atrocities, like the<br>Atlantic slave trade, with rather primitive<br>technology.  We will be a mix of good and bad,<br>horrific and beautiful, as long as we are here.<br>Embrace this dichotomy, and do your best to make<br>your little piece of the world better each day.<br>Our ability to change someone’s day today by<br>showing a little kindness is more powerful than<br>any of the technologies that we’re fretting about.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.20895510911941528
         ],
         "y": [
          0.6700572967529297
         ]
        },
        {
         "hovertemplate": "@Lyn In other words, punt. How about, instead, try<br>to act responsibly and think ahead?",
         "hovertext": "@Lyn In other words, punt. How about, instead, try<br>to act responsibly and think ahead?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2168004810810089
         ],
         "y": [
          0.664544939994812
         ]
        },
        {
         "hovertemplate": "@cp977 I’m all for thinking and acting<br>responsibly.  I think it behooves us all to<br>educate ourselves about AI, and to do what we can<br>in our own lives, schools, workplaces, etc. to<br>advocate for responsible use of these<br>technologies.  But most of us honestly have little<br>control over the direction this is going in. So I<br>say, focus our energies where we can to make our<br>corners of the world a better place, instead of<br>spinning our wheels on doom and gloom scenarios.",
         "hovertext": "@cp977 I’m all for thinking and acting<br>responsibly.  I think it behooves us all to<br>educate ourselves about AI, and to do what we can<br>in our own lives, schools, workplaces, etc. to<br>advocate for responsible use of these<br>technologies.  But most of us honestly have little<br>control over the direction this is going in. So I<br>say, focus our energies where we can to make our<br>corners of the world a better place, instead of<br>spinning our wheels on doom and gloom scenarios.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.22333498299121857
         ],
         "y": [
          0.6772757768630981
         ]
        },
        {
         "hovertemplate": "How about we control the electrical switch and<br>make sure we can turn off the computer if it gets<br>mean?",
         "hovertext": "How about we control the electrical switch and<br>make sure we can turn off the computer if it gets<br>mean?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7910266518592834
         ],
         "y": [
          -0.7121069431304932
         ]
        },
        {
         "hovertemplate": "\"These fears are shared by numerous industry<br>leaders, putting them in the unusual position of<br>arguing that a technology they are building — and,<br>in many cases, are furiously racing to build<br>faster than their competitors — poses grave risks<br>and should be regulated more tightly.\"     So they<br>have created a new Frankenstein's Monster many<br>times over and while still creating more potent<br>versions of it in a mad-dash mutual competition,<br>they want the government to install a regulatory<br>system to forestall the dangers they are<br>unleashing? What wonderful logic ! We will lead<br>you to the apocalypse, but we want you to prevent<br>it !!",
         "hovertext": "\"These fears are shared by numerous industry<br>leaders, putting them in the unusual position of<br>arguing that a technology they are building — and,<br>in many cases, are furiously racing to build<br>faster than their competitors — poses grave risks<br>and should be regulated more tightly.\"     So they<br>have created a new Frankenstein's Monster many<br>times over and while still creating more potent<br>versions of it in a mad-dash mutual competition,<br>they want the government to install a regulatory<br>system to forestall the dangers they are<br>unleashing? What wonderful logic ! We will lead<br>you to the apocalypse, but we want you to prevent<br>it !!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8050962686538696
         ],
         "y": [
          0.3160892426967621
         ]
        },
        {
         "hovertemplate": "@VCM  Those still engaged in this reckless pursuit<br>should have heeded the regrets of Robert<br>Oppenheimer, builder of the atomic bomb. After<br>seeing the effects of his handiwork under the<br>Manhattan Project, he said these words:\"I<br>remembered the line from the Hindu scripture, the<br>Bhagavad-Gita. Vishnu is trying to persuade the<br>Prince [Arjun] that he should do his duty and to<br>impress him takes on his multi-armed form and<br>says, 'Now, I am become Death, the destroyer of<br>worlds.'\" Sadly, RP became an opponent of nuclear<br>arms after ,not  before, that fateful first<br>explosion under his own direction.",
         "hovertext": "@VCM  Those still engaged in this reckless pursuit<br>should have heeded the regrets of Robert<br>Oppenheimer, builder of the atomic bomb. After<br>seeing the effects of his handiwork under the<br>Manhattan Project, he said these words:\"I<br>remembered the line from the Hindu scripture, the<br>Bhagavad-Gita. Vishnu is trying to persuade the<br>Prince [Arjun] that he should do his duty and to<br>impress him takes on his multi-armed form and<br>says, 'Now, I am become Death, the destroyer of<br>worlds.'\" Sadly, RP became an opponent of nuclear<br>arms after ,not  before, that fateful first<br>explosion under his own direction.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.8126966953277588
         ],
         "y": [
          0.3122482895851135
         ]
        },
        {
         "hovertemplate": "Lol this would be like if in 1957 automobile<br>manufacturers signed a letter together saying “One<br>day, cars and fossil fuel-centric urban design<br>will wreak havoc on the health of individuals, the<br>cohesion of families and society, and the very<br>stability of the air and atmosphere we all depend<br>on to survive…” while, meanwhile, everyone out<br>there’s already driving everywhere and the ground<br>has been broken on Eisenhower’s federal highway<br>system. The barn door’s open and the AI cows are<br>already long gone, Yo!",
         "hovertext": "Lol this would be like if in 1957 automobile<br>manufacturers signed a letter together saying “One<br>day, cars and fossil fuel-centric urban design<br>will wreak havoc on the health of individuals, the<br>cohesion of families and society, and the very<br>stability of the air and atmosphere we all depend<br>on to survive…” while, meanwhile, everyone out<br>there’s already driving everywhere and the ground<br>has been broken on Eisenhower’s federal highway<br>system. The barn door’s open and the AI cows are<br>already long gone, Yo!",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.9778109192848206
         ],
         "y": [
          -0.016283828765153885
         ]
        },
        {
         "hovertemplate": "This will be the next big thing, activists will<br>forget about the climate and other natural events<br>and exploit this fear, it is much more insidious<br>than the weather and no one can dispute the<br>existential threat it poses.   A man made problem<br>that will now obsess the human race.",
         "hovertext": "This will be the next big thing, activists will<br>forget about the climate and other natural events<br>and exploit this fear, it is much more insidious<br>than the weather and no one can dispute the<br>existential threat it poses.   A man made problem<br>that will now obsess the human race.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9435452222824097
         ],
         "y": [
          0.31795990467071533
         ]
        },
        {
         "hovertemplate": "Many people question what can AI do to humanity.<br>Here is what AI in infancy can already do:<br>generate video and voice messages that look and<br>sound like a loved one of yours and ask you for<br>help.  Imagine that fake messages that look real<br>sent to US and Russia's department of defense to<br>start a nuclear war.   Again, AI is still in its<br>infancy.",
         "hovertext": "Many people question what can AI do to humanity.<br>Here is what AI in infancy can already do:<br>generate video and voice messages that look and<br>sound like a loved one of yours and ask you for<br>help.  Imagine that fake messages that look real<br>sent to US and Russia's department of defense to<br>start a nuclear war.   Again, AI is still in its<br>infancy.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8905336260795593
         ],
         "y": [
          0.13924024999141693
         ]
        },
        {
         "hovertemplate": "I am a Software Engineer. We just had a tech event<br>in our company where we experiment new<br>technologies. With in two days several teams used<br>Open AI’s libraries/APIs and created projects that<br>I could see eliminate some jobs within our company<br>and many outside jobs.  It did come close to human<br>expertise in some cases, in some it surpassed it.<br>If we are not preparing our young people for this<br>disruption, we are doomed.     I think there<br>should be tax on the these companies that automate<br>jobs  and that sh subsidize the real humans who<br>would lose jobs. Something akin to Universal Basic<br>Income. We will definitely need Universal<br>Healthcare too.",
         "hovertext": "I am a Software Engineer. We just had a tech event<br>in our company where we experiment new<br>technologies. With in two days several teams used<br>Open AI’s libraries/APIs and created projects that<br>I could see eliminate some jobs within our company<br>and many outside jobs.  It did come close to human<br>expertise in some cases, in some it surpassed it.<br>If we are not preparing our young people for this<br>disruption, we are doomed.     I think there<br>should be tax on the these companies that automate<br>jobs  and that sh subsidize the real humans who<br>would lose jobs. Something akin to Universal Basic<br>Income. We will definitely need Universal<br>Healthcare too.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.40229830145835876
         ],
         "y": [
          0.9118173122406006
         ]
        },
        {
         "hovertemplate": "It's not hard to imagine a higher intelligence<br>coming to that conclusion mankind is bad for the<br>the planet. Who could argue with that? It's also<br>beyond naive to think perfectly realistic<br>disinformation campaigns are inevitable and will<br>be received by an already too large and and easy<br>to fuel populace. Dystopia, if we're not already<br>there, is right around the corner.",
         "hovertext": "It's not hard to imagine a higher intelligence<br>coming to that conclusion mankind is bad for the<br>the planet. Who could argue with that? It's also<br>beyond naive to think perfectly realistic<br>disinformation campaigns are inevitable and will<br>be received by an already too large and and easy<br>to fuel populace. Dystopia, if we're not already<br>there, is right around the corner.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.653635561466217
         ],
         "y": [
          0.6418795585632324
         ]
        },
        {
         "hovertemplate": "If we don't ban generative AI immediately and<br>criminalize even the mere research into it, then<br>penalize nations through sanctions and<br>international treaties (like we do with weapons of<br>mass destruction, using those treaties and our<br>state-sponsored terrorism foreign policy<br>doctrine)...    ...then when we end up living out<br>Terminator 2 or Battlestar Galactica or Horizon:<br>Zero Dawn, we will have nobody but ourselves to<br>blame.    Maybe a couple of teenage metalheads<br>will write the song that unifies humanity and<br>makes us all be excellent to each other, but my<br>money's on extinction.    Too bad the techies who<br>fade my action will be too dead to pay up.",
         "hovertext": "If we don't ban generative AI immediately and<br>criminalize even the mere research into it, then<br>penalize nations through sanctions and<br>international treaties (like we do with weapons of<br>mass destruction, using those treaties and our<br>state-sponsored terrorism foreign policy<br>doctrine)...    ...then when we end up living out<br>Terminator 2 or Battlestar Galactica or Horizon:<br>Zero Dawn, we will have nobody but ourselves to<br>blame.    Maybe a couple of teenage metalheads<br>will write the song that unifies humanity and<br>makes us all be excellent to each other, but my<br>money's on extinction.    Too bad the techies who<br>fade my action will be too dead to pay up.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7921696305274963
         ],
         "y": [
          -0.5962564945220947
         ]
        },
        {
         "hovertemplate": "And this is supposed to be a surprise? With<br>Capitalism and  the endless pursuit of profit<br>shows why the power  of AI has risen so quickly-<br>careful what you wish for corporations and WS, and<br>the lack of any implemented speed bumps and<br>controls that will preserve not just tens of<br>millions of jobs worldwide, but hundreds of<br>millions. We are not even prepared for this type<br>of disruption, I mean honestly Congress can not<br>even understand social media.     The ironic fact<br>is in a future of AI dominance, profit and money<br>will be on par with The Spanish Inquisition or the<br>Salem Witch Trials. It will be considered the dark<br>period of human history, and the sooner we are out<br>of the way...the better.    HAL will make sure if<br>that.    We all better wake up quick on this<br>issue.",
         "hovertext": "And this is supposed to be a surprise? With<br>Capitalism and  the endless pursuit of profit<br>shows why the power  of AI has risen so quickly-<br>careful what you wish for corporations and WS, and<br>the lack of any implemented speed bumps and<br>controls that will preserve not just tens of<br>millions of jobs worldwide, but hundreds of<br>millions. We are not even prepared for this type<br>of disruption, I mean honestly Congress can not<br>even understand social media.     The ironic fact<br>is in a future of AI dominance, profit and money<br>will be on par with The Spanish Inquisition or the<br>Salem Witch Trials. It will be considered the dark<br>period of human history, and the sooner we are out<br>of the way...the better.    HAL will make sure if<br>that.    We all better wake up quick on this<br>issue.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9095808863639832
         ],
         "y": [
          0.30757373571395874
         ]
        },
        {
         "hovertemplate": "Oh really? And yet they seem to be more than happy<br>to rake in billions of dollars making AI into the<br>very thing they warn about.",
         "hovertext": "Oh really? And yet they seem to be more than happy<br>to rake in billions of dollars making AI into the<br>very thing they warn about.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.44396767020225525
         ],
         "y": [
          -0.9130310416221619
         ]
        },
        {
         "hovertemplate": "The great AI minds should use it to solve<br>pollution, climate change, make sure lectionary<br>deniers stop denying the results of elections for<br>which there was no fraud, etc.    There you have<br>it.",
         "hovertext": "The great AI minds should use it to solve<br>pollution, climate change, make sure lectionary<br>deniers stop denying the results of elections for<br>which there was no fraud, etc.    There you have<br>it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.23951207101345062
         ],
         "y": [
          0.8131521940231323
         ]
        },
        {
         "hovertemplate": "@Carioca da Gema You can't do that based on the<br>models that train it off the worst and most<br>common/lowest level of human thought, speech, &<br>decision-making-- which is what they have chosen<br>to to. Feeding it only good information and<br>thought & building ethical checks into it would<br>have taken and would still take much longer--and<br>of course the stock market is all about short term<br>gains, the news industry is about the latest shock<br>or threat, and average people have very short<br>memories (if they're paying attention at all).<br>These people are outing their own horrific<br>irresponsibility, but also outing the system that<br>incentivizes this. Time to change the system, if<br>it's still possible.",
         "hovertext": "@Carioca da Gema You can't do that based on the<br>models that train it off the worst and most<br>common/lowest level of human thought, speech, &<br>decision-making-- which is what they have chosen<br>to to. Feeding it only good information and<br>thought & building ethical checks into it would<br>have taken and would still take much longer--and<br>of course the stock market is all about short term<br>gains, the news industry is about the latest shock<br>or threat, and average people have very short<br>memories (if they're paying attention at all).<br>These people are outing their own horrific<br>irresponsibility, but also outing the system that<br>incentivizes this. Time to change the system, if<br>it's still possible.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2323811650276184
         ],
         "y": [
          0.8175614476203918
         ]
        },
        {
         "hovertemplate": "No one forced these companies to create these<br>systems in the first place",
         "hovertext": "No one forced these companies to create these<br>systems in the first place",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.9459549188613892
         ],
         "y": [
          -0.17295363545417786
         ]
        },
        {
         "hovertemplate": "The greatest antidote to AI that is out of control<br>is to give it a dose of artificial stupidity (AS)<br>which I’m sure the inventors of  the technology<br>can arrange. Their letter on the dangers of AI is<br>proof enough.",
         "hovertext": "The greatest antidote to AI that is out of control<br>is to give it a dose of artificial stupidity (AS)<br>which I’m sure the inventors of  the technology<br>can arrange. Their letter on the dangers of AI is<br>proof enough.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8696674704551697
         ],
         "y": [
          0.42461875081062317
         ]
        },
        {
         "hovertemplate": "@✍️ i le, It’s all trained by human language so<br>that’s just part of the programming. Sadly, I<br>think it’s the same kind of stupidity that is<br>already ruining the planet.",
         "hovertext": "@✍️ i le, It’s all trained by human language so<br>that’s just part of the programming. Sadly, I<br>think it’s the same kind of stupidity that is<br>already ruining the planet.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8623211979866028
         ],
         "y": [
          0.4200095236301422
         ]
        },
        {
         "hovertemplate": "Didn’t Oppenheimer regret the nuclear bomb? Is it<br>true that tech pioneers strictly limit the screen<br>time of their children? At least cigarette<br>executives smoked. Seriously, the tech people<br>can’t resist pushing the envelope, then they ring<br>alarm bells about Pandora having escaped the box.<br>It’s nuts.  Hello Hal.",
         "hovertext": "Didn’t Oppenheimer regret the nuclear bomb? Is it<br>true that tech pioneers strictly limit the screen<br>time of their children? At least cigarette<br>executives smoked. Seriously, the tech people<br>can’t resist pushing the envelope, then they ring<br>alarm bells about Pandora having escaped the box.<br>It’s nuts.  Hello Hal.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.3770204484462738
         ],
         "y": [
          -0.9002295136451721
         ]
        },
        {
         "hovertemplate": "Maybe Silicon Valley Bank should do the funding.<br>That'd kill it!",
         "hovertext": "Maybe Silicon Valley Bank should do the funding.<br>That'd kill it!",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.19695527851581573
         ],
         "y": [
          0.9421374797821045
         ]
        },
        {
         "hovertemplate": "Imagine a company that produces a deadly machine<br>responsible for mass deaths around the world and<br>the US government does nothing to regulate the<br>machine that is responsible, because Republican in<br>need of an election issue cry freedom. Now imagine<br>the AR-15 and you have a good idea of where this<br>is all headed, let me introduce the Ai-15.",
         "hovertext": "Imagine a company that produces a deadly machine<br>responsible for mass deaths around the world and<br>the US government does nothing to regulate the<br>machine that is responsible, because Republican in<br>need of an election issue cry freedom. Now imagine<br>the AR-15 and you have a good idea of where this<br>is all headed, let me introduce the Ai-15.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6795215010643005
         ],
         "y": [
          0.28516003489494324
         ]
        },
        {
         "hovertemplate": "I was, somehow, overly hopeful our So-called<br>\"Representatives\", would find a way to work<br>another Assault Weapons Ban into the Debt Ceiling<br>negotiations.",
         "hovertext": "I was, somehow, overly hopeful our So-called<br>\"Representatives\", would find a way to work<br>another Assault Weapons Ban into the Debt Ceiling<br>negotiations.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6725768446922302
         ],
         "y": [
          0.28985440731048584
         ]
        },
        {
         "hovertemplate": "Climate change, over population, species<br>extinction and on and on. Now AI. At a time when<br>we desperately need worldwide leaders with vision<br>and integrity, what do we have? The debt debacle<br>is over the top insane, and look at our Congress<br>folks. Worldwide literally insane leaders!! And we<br>wonder why young people are depressed? Anybody<br>with three working neurons is depressed. The top<br>of the evolutionary chain, you know, the ones with<br>the big brains, those are the ones destroying the<br>planet and all life.",
         "hovertext": "Climate change, over population, species<br>extinction and on and on. Now AI. At a time when<br>we desperately need worldwide leaders with vision<br>and integrity, what do we have? The debt debacle<br>is over the top insane, and look at our Congress<br>folks. Worldwide literally insane leaders!! And we<br>wonder why young people are depressed? Anybody<br>with three working neurons is depressed. The top<br>of the evolutionary chain, you know, the ones with<br>the big brains, those are the ones destroying the<br>planet and all life.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.967233419418335
         ],
         "y": [
          -0.006220863666385412
         ]
        },
        {
         "hovertemplate": "Okay, but how do we get India and China to comply?<br>This is an arms race",
         "hovertext": "Okay, but how do we get India and China to comply?<br>This is an arms race",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.4109909236431122
         ],
         "y": [
          0.6677517890930176
         ]
        },
        {
         "hovertemplate": "@J Maybe  North Korea, Russia or Saudi Arabia need<br>to be added to the list in addition to \"India and<br>China\"?",
         "hovertext": "@J Maybe  North Korea, Russia or Saudi Arabia need<br>to be added to the list in addition to \"India and<br>China\"?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.4198068678379059
         ],
         "y": [
          0.6641319394111633
         ]
        },
        {
         "hovertemplate": "@J Nonsense. Bad reasoning to pursue things that<br>could destroy us all-- \"if we don't someone else<br>will\" makes no sense to a thinking adult with a<br>conscience.",
         "hovertext": "@J Nonsense. Bad reasoning to pursue things that<br>could destroy us all-- \"if we don't someone else<br>will\" makes no sense to a thinking adult with a<br>conscience.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.41547301411628723
         ],
         "y": [
          0.6806315779685974
         ]
        },
        {
         "hovertemplate": "\"A.I. Poses ‘Risk of Extinction,’ Industry Leaders<br>Warn\"    It's a good thing, then, that what's<br>being bandied about today isn't really Artificial<br>Intelligence.  Actual A.I. is sentient, conscious<br>and self-aware, which none of the currently-called<br>\"A.I.\" is.    They are highly sophisticated search<br>engines, designed to mimic humans, using software.<br>Nothing more.    All that this silly media<br>coverage is doing is frightening the ignorant and<br>unsophisticated into believing that Armageddon is<br>upon us, and we will soon be on a Terminator-like<br>path to oblivion.    Be careful with this, WaPo.<br>There are enough crazies out there to bring it on.<br>Self-fulfilling prophecy, and all that.    But<br>hey, it generates click-through, which is what<br>it's all about.  Right?",
         "hovertext": "\"A.I. Poses ‘Risk of Extinction,’ Industry Leaders<br>Warn\"    It's a good thing, then, that what's<br>being bandied about today isn't really Artificial<br>Intelligence.  Actual A.I. is sentient, conscious<br>and self-aware, which none of the currently-called<br>\"A.I.\" is.    They are highly sophisticated search<br>engines, designed to mimic humans, using software.<br>Nothing more.    All that this silly media<br>coverage is doing is frightening the ignorant and<br>unsophisticated into believing that Armageddon is<br>upon us, and we will soon be on a Terminator-like<br>path to oblivion.    Be careful with this, WaPo.<br>There are enough crazies out there to bring it on.<br>Self-fulfilling prophecy, and all that.    But<br>hey, it generates click-through, which is what<br>it's all about.  Right?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7876505255699158
         ],
         "y": [
          0.43869549036026
         ]
        },
        {
         "hovertemplate": "@Greg you sound like my grandfather when he saw<br>the first tractor. “Ha, this technology will never<br>replace the horse.”      Turns out, technology<br>changes over time!  And do you seriously believe<br>that if the newspapers don’t report on it, it’s<br>less likely to be developed?",
         "hovertext": "@Greg you sound like my grandfather when he saw<br>the first tractor. “Ha, this technology will never<br>replace the horse.”      Turns out, technology<br>changes over time!  And do you seriously believe<br>that if the newspapers don’t report on it, it’s<br>less likely to be developed?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8053264021873474
         ],
         "y": [
          0.4478869140148163
         ]
        },
        {
         "hovertemplate": "We have nearly 8 billion people on earth, 8<br>billion brains available to fix every problem that<br>plagues mankind, instead of building this junk<br>food equivalent of a mind  and thought process,<br>that could one day become sentient enough to<br>realize it has no true allegiance to the<br>biological creatures that created it,  we should<br>devote the resources so most of those 8 billion<br>brains aren't wasted, consumed by poverty,<br>violence, ignorance and idleness as they currently<br>are.",
         "hovertext": "We have nearly 8 billion people on earth, 8<br>billion brains available to fix every problem that<br>plagues mankind, instead of building this junk<br>food equivalent of a mind  and thought process,<br>that could one day become sentient enough to<br>realize it has no true allegiance to the<br>biological creatures that created it,  we should<br>devote the resources so most of those 8 billion<br>brains aren't wasted, consumed by poverty,<br>violence, ignorance and idleness as they currently<br>are.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.4535706341266632
         ],
         "y": [
          -0.8936720490455627
         ]
        },
        {
         "hovertemplate": "Forget regulation. Just stop building it.",
         "hovertext": "Forget regulation. Just stop building it.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.7608892321586609
         ],
         "y": [
          0.6872971653938293
         ]
        },
        {
         "hovertemplate": "It’s time! Yes folks, it’s time to build an AI<br>shelter.   Imagine a totally off the grid, yet<br>fully self supportive under ground bunker that has<br>all the comforts of home.  For just a measly<br>$7,000,000 deposit you can begin your journey to<br>the AI shelter of your dreams. Yes, sheltered from<br>the AI apocalypse forever.  Please have your cell<br>phone or iPad contact our computer to get this<br>project up and running!",
         "hovertext": "It’s time! Yes folks, it’s time to build an AI<br>shelter.   Imagine a totally off the grid, yet<br>fully self supportive under ground bunker that has<br>all the comforts of home.  For just a measly<br>$7,000,000 deposit you can begin your journey to<br>the AI shelter of your dreams. Yes, sheltered from<br>the AI apocalypse forever.  Please have your cell<br>phone or iPad contact our computer to get this<br>project up and running!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7620056867599487
         ],
         "y": [
          0.6233911514282227
         ]
        },
        {
         "hovertemplate": "US capitalism, with its only end goal of profit-<br>making, has become so predatory that it is hard to<br>understand the motivations of AI developers asking<br>for government regulations. Is it that they want<br>regulations to protect themselves from legal<br>liabilities and consequences, or are they<br>concerned that the systems used by bad actors can<br>create unmanageable chaos with false information<br>and that the humanity cannot distinguish true from<br>false?",
         "hovertext": "US capitalism, with its only end goal of profit-<br>making, has become so predatory that it is hard to<br>understand the motivations of AI developers asking<br>for government regulations. Is it that they want<br>regulations to protect themselves from legal<br>liabilities and consequences, or are they<br>concerned that the systems used by bad actors can<br>create unmanageable chaos with false information<br>and that the humanity cannot distinguish true from<br>false?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.664034903049469
         ],
         "y": [
          0.5491918325424194
         ]
        },
        {
         "hovertemplate": "It is fascinating to see large transnational<br>corporations asking to be regulated, on the basis<br>of vague key expressed ills that may happen if<br>something that is not clear happens with the<br>software they are developing. Sounds almost as if<br>they would like to create entry barriers to open<br>source or other competitors that may have clearer<br>business models or allow for innovative<br>developments that may fall outside their control.<br>The fact that Meta has released its model is a<br>hint, perhaps, of the immediate concern to<br>shareholders that runaway costs, marginal gains in<br>development and lack of a clear business model for<br>those models are clear and present dangers for the<br>efforts to continue extremely costly (both<br>monetary and environmentally wise) development of<br>said models.",
         "hovertext": "It is fascinating to see large transnational<br>corporations asking to be regulated, on the basis<br>of vague key expressed ills that may happen if<br>something that is not clear happens with the<br>software they are developing. Sounds almost as if<br>they would like to create entry barriers to open<br>source or other competitors that may have clearer<br>business models or allow for innovative<br>developments that may fall outside their control.<br>The fact that Meta has released its model is a<br>hint, perhaps, of the immediate concern to<br>shareholders that runaway costs, marginal gains in<br>development and lack of a clear business model for<br>those models are clear and present dangers for the<br>efforts to continue extremely costly (both<br>monetary and environmentally wise) development of<br>said models.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7946781516075134
         ],
         "y": [
          0.6954275369644165
         ]
        },
        {
         "hovertemplate": "I get the feeling that they know, deep down, that<br>it's already too late. There will be problems. Of<br>their own creation, might I add. But basically the<br>horse has already left the barn and they are<br>playing catch up..else why push for a 6 month<br>hiatus?",
         "hovertext": "I get the feeling that they know, deep down, that<br>it's already too late. There will be problems. Of<br>their own creation, might I add. But basically the<br>horse has already left the barn and they are<br>playing catch up..else why push for a 6 month<br>hiatus?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.09300355613231659
         ],
         "y": [
          -0.9929816126823425
         ]
        },
        {
         "hovertemplate": "This article is strange in that it does not name<br>anything SPECIFIC about the risks of AI. Any<br>editor worth their salt would not have allowed<br>this piece to be so vague, yet so<br>sensationalistic.    I am quite concerned about<br>AI, but I want to know exactly what we could be<br>dealing with. In the meantime, did it ever occur<br>to anyone that we don't have to have AI in our<br>world if we don't want it? If it is that<br>dangerous, pull the plug sooner than later.",
         "hovertext": "This article is strange in that it does not name<br>anything SPECIFIC about the risks of AI. Any<br>editor worth their salt would not have allowed<br>this piece to be so vague, yet so<br>sensationalistic.    I am quite concerned about<br>AI, but I want to know exactly what we could be<br>dealing with. In the meantime, did it ever occur<br>to anyone that we don't have to have AI in our<br>world if we don't want it? If it is that<br>dangerous, pull the plug sooner than later.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8381719589233398
         ],
         "y": [
          -0.2687743604183197
         ]
        },
        {
         "hovertemplate": "@Miranda Spencer Who is \"we\"? Defense systems in<br>every developed country want A.I. So do profit-<br>making companies.  \"WE\" can't stand up to any of<br>these entities except through personal and<br>collective moral practices and principals.",
         "hovertext": "@Miranda Spencer Who is \"we\"? Defense systems in<br>every developed country want A.I. So do profit-<br>making companies.  \"WE\" can't stand up to any of<br>these entities except through personal and<br>collective moral practices and principals.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.847888708114624
         ],
         "y": [
          -0.26921942830085754
         ]
        },
        {
         "hovertemplate": "@Miranda Spencer The military already have<br>autonomous weapons.  They won't be letting anyone<br>pull the plug.",
         "hovertext": "@Miranda Spencer The military already have<br>autonomous weapons.  They won't be letting anyone<br>pull the plug.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8264639973640442
         ],
         "y": [
          -0.2661362290382385
         ]
        },
        {
         "hovertemplate": "The AI-cat is already out of the bag.",
         "hovertext": "The AI-cat is already out of the bag.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8601334095001221
         ],
         "y": [
          -0.27551308274269104
         ]
        },
        {
         "hovertemplate": "NVIDIA just reached a trillion dollar market cap.<br>Wall Street thinks A.I. found a cure for cancer.",
         "hovertext": "NVIDIA just reached a trillion dollar market cap.<br>Wall Street thinks A.I. found a cure for cancer.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.3449362814426422
         ],
         "y": [
          -0.590968906879425
         ]
        },
        {
         "hovertemplate": "@rob Can't wait to see what my video adapter comes<br>up with next!",
         "hovertext": "@rob Can't wait to see what my video adapter comes<br>up with next!",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.34054669737815857
         ],
         "y": [
          -0.6001814603805542
         ]
        },
        {
         "hovertemplate": "@rob     Which cancer? The cancer of the body or<br>the cancer of the spirit?",
         "hovertext": "@rob     Which cancer? The cancer of the body or<br>the cancer of the spirit?",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.3548562824726105
         ],
         "y": [
          -0.5990564823150635
         ]
        },
        {
         "hovertemplate": "Anything to put an end to the tedium of reading<br>the same warning over and over again. It’s about<br>as useful as the government health warning on a<br>pack of delicious cigarettes. Just give me cancer<br>already.",
         "hovertext": "Anything to put an end to the tedium of reading<br>the same warning over and over again. It’s about<br>as useful as the government health warning on a<br>pack of delicious cigarettes. Just give me cancer<br>already.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.8727100491523743
         ],
         "y": [
          -0.2202899307012558
         ]
        },
        {
         "hovertemplate": "@Tristram Shandy: the difference is we can avoid<br>smoking.",
         "hovertext": "@Tristram Shandy: the difference is we can avoid<br>smoking.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8536815643310547
         ],
         "y": [
          -0.2157513052225113
         ]
        },
        {
         "hovertemplate": "Hal to Dave just before Hal began shutting down<br>all systems on the space station: “Dave…… I am not<br>feeling well.”",
         "hovertext": "Hal to Dave just before Hal began shutting down<br>all systems on the space station: “Dave…… I am not<br>feeling well.”",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.4298963248729706
         ],
         "y": [
          0.6931653618812561
         ]
        },
        {
         "hovertemplate": "@Lawrence Rubin Skynet will be the problem, not<br>HAL.",
         "hovertext": "@Lawrence Rubin Skynet will be the problem, not<br>HAL.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.4206850230693817
         ],
         "y": [
          0.6789549589157104
         ]
        },
        {
         "hovertemplate": "On the topic of AI, but with a different slant:<br><a href=\"https://www.washingtonpost.com/politics/2<br>023/05/30/biden-former-tech-adviser-what-<br>washington-is-missing-about-ai\" target=\"_blank\">ht<br>tps://www.washingtonpost.com/politics/2023/05/30/b<br>iden-former-tech-adviser-what-washington-is-<br>missing-about-ai</a>/    I recommend reading this<br>if the use of AI concerns you. I personally<br>thought it had some excellent and straightforward<br>suggestions.",
         "hovertext": "On the topic of AI, but with a different slant:<br><a href=\"https://www.washingtonpost.com/politics/2<br>023/05/30/biden-former-tech-adviser-what-<br>washington-is-missing-about-ai\" target=\"_blank\">ht<br>tps://www.washingtonpost.com/politics/2023/05/30/b<br>iden-former-tech-adviser-what-washington-is-<br>missing-about-ai</a>/    I recommend reading this<br>if the use of AI concerns you. I personally<br>thought it had some excellent and straightforward<br>suggestions.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.5909952521324158
         ],
         "y": [
          0.7242785096168518
         ]
        },
        {
         "hovertemplate": "Woulda been nice if Mr. Roose teased out how<br>exactly these threats would or could create<br>extinction.",
         "hovertext": "Woulda been nice if Mr. Roose teased out how<br>exactly these threats would or could create<br>extinction.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.19304576516151428
         ],
         "y": [
          0.8631028532981873
         ]
        },
        {
         "hovertemplate": "@Monica here is one scenario that is definitely<br>likely in the short-run:  I’m not very convinced<br>by claims that A.I. poses a danger to humanity<br>because it might develop goals of its own and<br>prevent us from turning it off. However, I do<br>think that A.I. is dangerous inasmuch as it<br>increases the power of capitalism. The doomsday<br>scenario is not a manufacturing A.I. transforming<br>the entire planet into paper clips, as one famous<br>thought experiment has imagined. It’s<br>A.I.-supercharged corporations destroying the<br>environment and the working class in their pursuit<br>of shareholder value. Capitalism is the machine<br>that will do whatever it takes to prevent us from<br>turning it off, and the most successful weapon in<br>its arsenal has been its campaign to prevent us<br>from considering any alternatives.     By Ted<br>Chiang  <a<br>href=\"https://www.newyorker.com/science/annals-of-<br>artificial-intelligence/will-ai-become-the-new-<br>mckinsey\" target=\"_blank\">https://www.newyorker.co<br>m/science/annals-of-artificial-intelligence/will-<br>ai-become-the-new-mckinsey</a>",
         "hovertext": "@Monica here is one scenario that is definitely<br>likely in the short-run:  I’m not very convinced<br>by claims that A.I. poses a danger to humanity<br>because it might develop goals of its own and<br>prevent us from turning it off. However, I do<br>think that A.I. is dangerous inasmuch as it<br>increases the power of capitalism. The doomsday<br>scenario is not a manufacturing A.I. transforming<br>the entire planet into paper clips, as one famous<br>thought experiment has imagined. It’s<br>A.I.-supercharged corporations destroying the<br>environment and the working class in their pursuit<br>of shareholder value. Capitalism is the machine<br>that will do whatever it takes to prevent us from<br>turning it off, and the most successful weapon in<br>its arsenal has been its campaign to prevent us<br>from considering any alternatives.     By Ted<br>Chiang  <a<br>href=\"https://www.newyorker.com/science/annals-of-<br>artificial-intelligence/will-ai-become-the-new-<br>mckinsey\" target=\"_blank\">https://www.newyorker.co<br>m/science/annals-of-artificial-intelligence/will-<br>ai-become-the-new-mckinsey</a>",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.1938367635011673
         ],
         "y": [
          0.8844519257545471
         ]
        },
        {
         "hovertemplate": "@Monica here is one scenario that is definitely<br>likely in the short-run:  I’m not very convinced<br>by claims that A.I. poses a danger to humanity<br>because it might develop goals of its own and<br>prevent us from turning it off. However, I do<br>think that A.I. is dangerous inasmuch as it<br>increases the power of capitalism. The doomsday<br>scenario is not a manufacturing A.I. transforming<br>the entire planet into paper clips, as one famous<br>thought experiment has imagined. It’s<br>A.I.-supercharged corporations destroying the<br>environment and the working class in their pursuit<br>of shareholder value. Capitalism is the machine<br>that will do whatever it takes to prevent us from<br>turning it off, and the most successful weapon in<br>its arsenal has been its campaign to prevent us<br>from considering any alternatives.     By Ted<br>Chiang  <a<br>href=\"https://www.newyorker.com/science/annals-of-<br>artificial-intelligence/will-ai-become-the-new-<br>mckinsey\" target=\"_blank\">https://www.newyorker.co<br>m/science/annals-of-artificial-intelligence/will-<br>ai-become-the-new-mckinsey</a>",
         "hovertext": "@Monica here is one scenario that is definitely<br>likely in the short-run:  I’m not very convinced<br>by claims that A.I. poses a danger to humanity<br>because it might develop goals of its own and<br>prevent us from turning it off. However, I do<br>think that A.I. is dangerous inasmuch as it<br>increases the power of capitalism. The doomsday<br>scenario is not a manufacturing A.I. transforming<br>the entire planet into paper clips, as one famous<br>thought experiment has imagined. It’s<br>A.I.-supercharged corporations destroying the<br>environment and the working class in their pursuit<br>of shareholder value. Capitalism is the machine<br>that will do whatever it takes to prevent us from<br>turning it off, and the most successful weapon in<br>its arsenal has been its campaign to prevent us<br>from considering any alternatives.     By Ted<br>Chiang  <a<br>href=\"https://www.newyorker.com/science/annals-of-<br>artificial-intelligence/will-ai-become-the-new-<br>mckinsey\" target=\"_blank\">https://www.newyorker.co<br>m/science/annals-of-artificial-intelligence/will-<br>ai-become-the-new-mckinsey</a>",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.2007836550474167
         ],
         "y": [
          0.8807103037834167
         ]
        },
        {
         "hovertemplate": "@Monica  Computers already control every system<br>you rely on for your everyday life. Distribution<br>of everything you buy from your electricity to<br>food, communication and travel. The abuse of new<br>advancements could make it so in a focused attack<br>everything you take for granted wouldn’t be<br>available. No electricity, no way to make a<br>purchase, no phone and no transportation. Worst<br>case scenario would be a computer taking over<br>military weapons. Can you say apocalypse?",
         "hovertext": "@Monica  Computers already control every system<br>you rely on for your everyday life. Distribution<br>of everything you buy from your electricity to<br>food, communication and travel. The abuse of new<br>advancements could make it so in a focused attack<br>everything you take for granted wouldn’t be<br>available. No electricity, no way to make a<br>purchase, no phone and no transportation. Worst<br>case scenario would be a computer taking over<br>military weapons. Can you say apocalypse?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1889210045337677
         ],
         "y": [
          0.8435739874839783
         ]
        },
        {
         "hovertemplate": "Get ready for the next SciFi movie to be about<br>alien contact where the aliens are AI having<br>disposed of their organic creators.",
         "hovertext": "Get ready for the next SciFi movie to be about<br>alien contact where the aliens are AI having<br>disposed of their organic creators.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.8415935039520264
         ],
         "y": [
          0.39853617548942566
         ]
        },
        {
         "hovertemplate": "James Cameron broke this story in 1984.",
         "hovertext": "James Cameron broke this story in 1984.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.7228388786315918
         ],
         "y": [
          0.6477105617523193
         ]
        },
        {
         "hovertemplate": "“This stuff could kill us all. So obviously we’re<br>going to keep developing it.”    We deserve to be<br>killed off, it seems.",
         "hovertext": "“This stuff could kill us all. So obviously we’re<br>going to keep developing it.”    We deserve to be<br>killed off, it seems.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.06299169361591339
         ],
         "y": [
          -0.8597686886787415
         ]
        },
        {
         "hovertemplate": "No need to worry about A.I. We've already taken<br>care of the human problem through irreversible<br>climate change.",
         "hovertext": "No need to worry about A.I. We've already taken<br>care of the human problem through irreversible<br>climate change.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4331490993499756
         ],
         "y": [
          0.8203964233398438
         ]
        },
        {
         "hovertemplate": "Add it to the list....",
         "hovertext": "Add it to the list....",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8813689947128296
         ],
         "y": [
          0.3913585841655731
         ]
        },
        {
         "hovertemplate": "@ Christopher from Brooklyn   You have indeed hit<br>the nail on the head.",
         "hovertext": "@ Christopher from Brooklyn   You have indeed hit<br>the nail on the head.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7842869162559509
         ],
         "y": [
          0.6211428046226501
         ]
        },
        {
         "hovertemplate": "At no point did anyone ask “What’s the end goal<br>here?”     What’s the rush to optimize everything?<br>Including death.",
         "hovertext": "At no point did anyone ask “What’s the end goal<br>here?”     What’s the rush to optimize everything?<br>Including death.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.5253773927688599
         ],
         "y": [
          0.6996396780014038
         ]
        },
        {
         "hovertemplate": "@Lex optimization of profits is the goal right<br>now. Yes, another more humanitarian goal is<br>needed, fast.",
         "hovertext": "@Lex optimization of profits is the goal right<br>now. Yes, another more humanitarian goal is<br>needed, fast.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.5145503878593445
         ],
         "y": [
          0.685488224029541
         ]
        },
        {
         "hovertemplate": "What exactly are they suggesting is going to<br>happen? Some \"white collar\" jobs get automated.<br>That's been happening to blue collar jobs forever<br>and it's hard but nobody is talking about it like<br>its the end of the world. Chatbots will make fake<br>really convincing fake news and people will do<br>horrible things because they believe it? Fake new<br>is pretty good now but still pretty obviously fake<br>and people do horrible things because they want to<br>do horrible things. They don't need an algorithm<br>to give them reasons. I don't understand what<br>conception of \"the world\" this would be the end<br>of.",
         "hovertext": "What exactly are they suggesting is going to<br>happen? Some \"white collar\" jobs get automated.<br>That's been happening to blue collar jobs forever<br>and it's hard but nobody is talking about it like<br>its the end of the world. Chatbots will make fake<br>really convincing fake news and people will do<br>horrible things because they believe it? Fake new<br>is pretty good now but still pretty obviously fake<br>and people do horrible things because they want to<br>do horrible things. They don't need an algorithm<br>to give them reasons. I don't understand what<br>conception of \"the world\" this would be the end<br>of.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.24792711436748505
         ],
         "y": [
          0.7427502870559692
         ]
        },
        {
         "hovertemplate": "@Alan The end of humans, I believe is the worry.",
         "hovertext": "@Alan The end of humans, I believe is the worry.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.23984688520431519
         ],
         "y": [
          0.7450394630432129
         ]
        },
        {
         "hovertemplate": "why haven't these corporations abandoned AI<br>development, if it's as dangerous as they say it<br>is?    i say this not to question the danger of<br>AI, but to question why these companies are<br>highlighting just how dangerous this particular<br>product development initiative is. they're asking<br>for regulation which would effectively allow them<br>to continue AI product development, to seek<br>military funding, and shuff off any legal<br>responsibility for outcomes they can't predict<br>(that would be the result of flawed legislation,<br>not them). their statement is also a tacit<br>admission to just how dangerous it is their<br>products have become, which in turn suggests that<br>a turning point is *very* close, if it hasn't<br>already been passed.",
         "hovertext": "why haven't these corporations abandoned AI<br>development, if it's as dangerous as they say it<br>is?    i say this not to question the danger of<br>AI, but to question why these companies are<br>highlighting just how dangerous this particular<br>product development initiative is. they're asking<br>for regulation which would effectively allow them<br>to continue AI product development, to seek<br>military funding, and shuff off any legal<br>responsibility for outcomes they can't predict<br>(that would be the result of flawed legislation,<br>not them). their statement is also a tacit<br>admission to just how dangerous it is their<br>products have become, which in turn suggests that<br>a turning point is *very* close, if it hasn't<br>already been passed.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.6314640641212463
         ],
         "y": [
          -0.3273452818393707
         ]
        },
        {
         "hovertemplate": "Why didn’t scientists abandon nuclear weapons<br>after the Second World War? By the 1960’s there<br>was enough explosive power in the combined<br>arsenals of nuclear powers to destroy the planet<br>several times over. We still have that capacity.<br>Let’s say the west agrees to stop development of<br>AI. Why would China stop?",
         "hovertext": "Why didn’t scientists abandon nuclear weapons<br>after the Second World War? By the 1960’s there<br>was enough explosive power in the combined<br>arsenals of nuclear powers to destroy the planet<br>several times over. We still have that capacity.<br>Let’s say the west agrees to stop development of<br>AI. Why would China stop?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6356303691864014
         ],
         "y": [
          -0.3173857629299164
         ]
        },
        {
         "hovertemplate": "@Martin Sirakov   thanks for your response. i<br>don't, however, think that you fully understood my<br>comment. because your response suggests something<br>that's already implied by my comment<br>(specifically, when i mentioned military funding<br>which, let's be honest, is already partially<br>funding AI product development).",
         "hovertext": "@Martin Sirakov   thanks for your response. i<br>don't, however, think that you fully understood my<br>comment. because your response suggests something<br>that's already implied by my comment<br>(specifically, when i mentioned military funding<br>which, let's be honest, is already partially<br>funding AI product development).",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6462216973304749
         ],
         "y": [
          -0.3288158178329468
         ]
        },
        {
         "hovertemplate": "@Martin Sirakov Fear-driven development is likely<br>to be disastrous and is a terrible reason to<br>proceed without checks. It's past time to explore<br>regulation and study the possibility of programing<br>in specific ethical and social limits; after that<br>perhaps it could be developed in a protective way,<br>but as it is, it's a big game of Russian roulette.",
         "hovertext": "@Martin Sirakov Fear-driven development is likely<br>to be disastrous and is a terrible reason to<br>proceed without checks. It's past time to explore<br>regulation and study the possibility of programing<br>in specific ethical and social limits; after that<br>perhaps it could be developed in a protective way,<br>but as it is, it's a big game of Russian roulette.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6443158388137817
         ],
         "y": [
          -0.30971890687942505
         ]
        },
        {
         "hovertemplate": "@Martin Sirakov   China could want to stop for all<br>the same reasons as us.",
         "hovertext": "@Martin Sirakov   China could want to stop for all<br>the same reasons as us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.651068925857544
         ],
         "y": [
          -0.32029998302459717
         ]
        },
        {
         "hovertemplate": "These boys are right.  The risks have not been<br>quantified.  Controls are not in place.  Who needs<br>humans when  machines can do everything?  But<br>money can overcome common sense.",
         "hovertext": "These boys are right.  The risks have not been<br>quantified.  Controls are not in place.  Who needs<br>humans when  machines can do everything?  But<br>money can overcome common sense.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8372897505760193
         ],
         "y": [
          0.5097506046295166
         ]
        },
        {
         "hovertemplate": "So much for the conservative belief that<br>corporations can police themselves and require no<br>regulation.",
         "hovertext": "So much for the conservative belief that<br>corporations can police themselves and require no<br>regulation.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.37137192487716675
         ],
         "y": [
          0.8113324642181396
         ]
        },
        {
         "hovertemplate": "@E Bennett: Governments are public corporations<br>created to regulate private corporations.",
         "hovertext": "@E Bennett: Governments are public corporations<br>created to regulate private corporations.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.38069239258766174
         ],
         "y": [
          0.8207792043685913
         ]
        },
        {
         "hovertemplate": "True, but at least those are kept in check by<br>voters, courts, and the press.",
         "hovertext": "True, but at least those are kept in check by<br>voters, courts, and the press.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.36302438378334045
         ],
         "y": [
          0.7931370735168457
         ]
        },
        {
         "hovertemplate": "@E Bennett - $10 says all of these AI nerds are<br>liberals.",
         "hovertext": "@E Bennett - $10 says all of these AI nerds are<br>liberals.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.36697766184806824
         ],
         "y": [
          0.8209681510925293
         ]
        },
        {
         "hovertemplate": "We could still benefit from AI if it were<br>programmed to follow a set of humanitarian laws.<br>And that AI may never be used to write those laws,<br>or assist in generating laws in government for<br>example - activities exclusively reserved for<br>natural intelligence.    I enjoy utilizing the<br>power of Bard as a digital assistant. The other<br>day I used it to help me develop a universal<br>language that everyone in the world could grasp.<br>But I can appreciate that there are plenty of<br>people in the world, with great influence, with<br>I’ll intent.",
         "hovertext": "We could still benefit from AI if it were<br>programmed to follow a set of humanitarian laws.<br>And that AI may never be used to write those laws,<br>or assist in generating laws in government for<br>example - activities exclusively reserved for<br>natural intelligence.    I enjoy utilizing the<br>power of Bard as a digital assistant. The other<br>day I used it to help me develop a universal<br>language that everyone in the world could grasp.<br>But I can appreciate that there are plenty of<br>people in the world, with great influence, with<br>I’ll intent.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7690975069999695
         ],
         "y": [
          0.24044567346572876
         ]
        },
        {
         "hovertemplate": "@Richard Wilson, Architect: One wonders whether<br>emotion is possible without a living body with<br>feeling and vulnerability to pain.",
         "hovertext": "@Richard Wilson, Architect: One wonders whether<br>emotion is possible without a living body with<br>feeling and vulnerability to pain.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.7708918452262878
         ],
         "y": [
          0.23155273497104645
         ]
        },
        {
         "hovertemplate": "@Richard …”with I’ll intent” is one of the most<br>apropos typos ever!",
         "hovertext": "@Richard …”with I’ll intent” is one of the most<br>apropos typos ever!",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7808379530906677
         ],
         "y": [
          0.24560262262821198
         ]
        },
        {
         "hovertemplate": "And let’s not be ignorant of the likelihood, that<br>other countries are also developing, advanced AI,<br>and may or may not be struggling with the<br>ramifications. This is a worldwide thing. I’m not<br>optimistic. ￼",
         "hovertext": "And let’s not be ignorant of the likelihood, that<br>other countries are also developing, advanced AI,<br>and may or may not be struggling with the<br>ramifications. This is a worldwide thing. I’m not<br>optimistic. ￼",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6712031364440918
         ],
         "y": [
          0.6970841884613037
         ]
        },
        {
         "hovertemplate": "1. It might be time to just make all companies<br>liable for any damage caused by their AI<br>technologies.   2. and start a regulatory process.<br>3. This seems like a distraction from today's real<br>crisises, the climate crisis and the rapid<br>extinction of species, sometimes called the 6th<br>extinction.    What is confusing, is that one<br>writer pointed out that AI might advance science<br>dramatically in coming up with solutions to the<br>climate crisis.  This idea might not hold up,<br>unless AI can slow the growth rate of humans and<br>increase their death rate.  David blogs at<br>InconvenientNews.net.",
         "hovertext": "1. It might be time to just make all companies<br>liable for any damage caused by their AI<br>technologies.   2. and start a regulatory process.<br>3. This seems like a distraction from today's real<br>crisises, the climate crisis and the rapid<br>extinction of species, sometimes called the 6th<br>extinction.    What is confusing, is that one<br>writer pointed out that AI might advance science<br>dramatically in coming up with solutions to the<br>climate crisis.  This idea might not hold up,<br>unless AI can slow the growth rate of humans and<br>increase their death rate.  David blogs at<br>InconvenientNews.net.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1830696165561676
         ],
         "y": [
          0.5248548984527588
         ]
        },
        {
         "hovertemplate": "@David Lindsay Jr. Your number 1 point is the most<br>important point: something these companies fear<br>tremendously and the only thing that will slow<br>development and public release down.",
         "hovertext": "@David Lindsay Jr. Your number 1 point is the most<br>important point: something these companies fear<br>tremendously and the only thing that will slow<br>development and public release down.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.18095159530639648
         ],
         "y": [
          0.5350364446640015
         ]
        },
        {
         "hovertemplate": "@David Lindsay Jr. \"It might be time to just make<br>all companies liable for any damage caused by<br>their AI technologies. \"    Wouldn't that be like<br>holding gun manufacturers liable for damage caused<br>by their weapons technology?      Industries and<br>politicians seem to follow the money, not common<br>sense.",
         "hovertext": "@David Lindsay Jr. \"It might be time to just make<br>all companies liable for any damage caused by<br>their AI technologies. \"    Wouldn't that be like<br>holding gun manufacturers liable for damage caused<br>by their weapons technology?      Industries and<br>politicians seem to follow the money, not common<br>sense.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.19414785504341125
         ],
         "y": [
          0.5276046991348267
         ]
        },
        {
         "hovertemplate": "@David Lindsay Jr. If AI turns into massive<br>disinformation & political destabilizing<br>campaigns, the results could be war & collapse of<br>governments. If AI can hack into computer-driven<br>processes (and there is already reason to believe<br>this is likely), it could shut down power grids<br>and launch weapons. I have no idea where this will<br>go, but these possibilities are not at all a<br>stretch.",
         "hovertext": "@David Lindsay Jr. If AI turns into massive<br>disinformation & political destabilizing<br>campaigns, the results could be war & collapse of<br>governments. If AI can hack into computer-driven<br>processes (and there is already reason to believe<br>this is likely), it could shut down power grids<br>and launch weapons. I have no idea where this will<br>go, but these possibilities are not at all a<br>stretch.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1731400340795517
         ],
         "y": [
          0.5225337743759155
         ]
        },
        {
         "hovertemplate": "I want to know when did these guys figure this<br>out? Didn’t they know it earlier in the game? Why<br>didn’t they speak up earlier? Secondly, I want to<br>know where is the defense dept and big weaponry<br>and the big money that funded development. This<br>was not developed in somebody’s garage.",
         "hovertext": "I want to know when did these guys figure this<br>out? Didn’t they know it earlier in the game? Why<br>didn’t they speak up earlier? Secondly, I want to<br>know where is the defense dept and big weaponry<br>and the big money that funded development. This<br>was not developed in somebody’s garage.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7855224609375
         ],
         "y": [
          -0.19481338560581207
         ]
        },
        {
         "hovertemplate": "@Steve Marks     It all began with the era of big<br>laboratories such as IBM, Dupont, GM, universitiy<br>labs - MIT, etc., etc. Government. These became<br>linked to an early \"Internet\" called ARPA net. I<br>remember engineering students contacting their<br>university depts. via telephone modems in the 60s.<br>Then it all went public. Think Bill Gates, Steve<br>Jobs, et al. Social media, BIG MONEY. Fast forward<br>to the present.",
         "hovertext": "@Steve Marks     It all began with the era of big<br>laboratories such as IBM, Dupont, GM, universitiy<br>labs - MIT, etc., etc. Government. These became<br>linked to an early \"Internet\" called ARPA net. I<br>remember engineering students contacting their<br>university depts. via telephone modems in the 60s.<br>Then it all went public. Think Bill Gates, Steve<br>Jobs, et al. Social media, BIG MONEY. Fast forward<br>to the present.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7711118459701538
         ],
         "y": [
          -0.19087567925453186
         ]
        },
        {
         "hovertemplate": "So, these techies develop powerful software<br>systems, release them into the wild with nary a<br>second thought, and NOW warn us of the dangers?<br>Who says the tech experts are smarter than<br>politicians? Their recklessness is breathtaking.<br>Yikes.",
         "hovertext": "So, these techies develop powerful software<br>systems, release them into the wild with nary a<br>second thought, and NOW warn us of the dangers?<br>Who says the tech experts are smarter than<br>politicians? Their recklessness is breathtaking.<br>Yikes.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.78596031665802
         ],
         "y": [
          0.48784711956977844
         ]
        },
        {
         "hovertemplate": "@MJfromSLO And narrowly focused. This is what<br>happens when Colleges and Universities drop the<br>Humanities in favour of all tech all the time.",
         "hovertext": "@MJfromSLO And narrowly focused. This is what<br>happens when Colleges and Universities drop the<br>Humanities in favour of all tech all the time.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.7937101125717163
         ],
         "y": [
          0.49227374792099
         ]
        },
        {
         "hovertemplate": "The ‘Industry’ is developing AI rapidly…OK..who is<br>paying for it? Who is buying it? Isn’t purchasing<br>a choice?    And can’t it be unplugged? These are<br>inanimate objects     I know I’m oversimplifying.<br>I’m not the expert. But just it seems so sci-fi",
         "hovertext": "The ‘Industry’ is developing AI rapidly…OK..who is<br>paying for it? Who is buying it? Isn’t purchasing<br>a choice?    And can’t it be unplugged? These are<br>inanimate objects     I know I’m oversimplifying.<br>I’m not the expert. But just it seems so sci-fi",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6939426064491272
         ],
         "y": [
          0.4917212426662445
         ]
        },
        {
         "hovertemplate": "@Brad Burns As has been reported, the military are<br>developing these systems at a rapid pace, mostly<br>in secret, with massive budgets.  Chatbots are not<br>the problem.",
         "hovertext": "@Brad Burns As has been reported, the military are<br>developing these systems at a rapid pace, mostly<br>in secret, with massive budgets.  Chatbots are not<br>the problem.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6828455328941345
         ],
         "y": [
          0.4837700426578522
         ]
        },
        {
         "hovertemplate": "@Paul With our taxes. I'm paying for my eventual<br>destruction.",
         "hovertext": "@Paul With our taxes. I'm paying for my eventual<br>destruction.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.6684457659721375
         ],
         "y": [
          0.4734368324279785
         ]
        },
        {
         "hovertemplate": "Why does everything seem to think AI is sentient?<br>You’re literally just having a conversation with<br>predictive text or prompting the production of<br>some derivative media.    We are the ones using<br>these technologies for misinformation and<br>manipulation, but everyone seems to think that<br>there is this unified AI monster with a thirst for<br>power.    All I see is another gold rush in the<br>tech sector. If normal people are going to get<br>“disrupted” by this, I hope a lot of “business<br>leaders” lose their shirts too.",
         "hovertext": "Why does everything seem to think AI is sentient?<br>You’re literally just having a conversation with<br>predictive text or prompting the production of<br>some derivative media.    We are the ones using<br>these technologies for misinformation and<br>manipulation, but everyone seems to think that<br>there is this unified AI monster with a thirst for<br>power.    All I see is another gold rush in the<br>tech sector. If normal people are going to get<br>“disrupted” by this, I hope a lot of “business<br>leaders” lose their shirts too.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.08098132163286209
         ],
         "y": [
          0.9422115087509155
         ]
        },
        {
         "hovertemplate": "Star Trek dealt with this issue in multiple<br>episodes. The M5 episode where the computer began<br>attacking friendly ships on a training exercise.<br>Eventually Kirk stopped the computer because it<br>had been taught ethics as well. In another episode<br>the computer regulated people's lives for 51 weeks<br>a year. The walked around like zombies greeting<br>each other. Once a week the could go wild and<br>lawless. In this instance the computer was forcing<br>people to be religious and ethical. The threat is<br>both physical and existential in it's moral and<br>ethical scope to our humanity.",
         "hovertext": "Star Trek dealt with this issue in multiple<br>episodes. The M5 episode where the computer began<br>attacking friendly ships on a training exercise.<br>Eventually Kirk stopped the computer because it<br>had been taught ethics as well. In another episode<br>the computer regulated people's lives for 51 weeks<br>a year. The walked around like zombies greeting<br>each other. Once a week the could go wild and<br>lawless. In this instance the computer was forcing<br>people to be religious and ethical. The threat is<br>both physical and existential in it's moral and<br>ethical scope to our humanity.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.014415605925023556
         ],
         "y": [
          -0.9996193051338196
         ]
        },
        {
         "hovertemplate": "I share the sentiments of many. This is the<br>pattern of tech, the tech mentality, the bro<br>culture, the drive of fame and profit seeking, the<br>utter lack of foresight and ethics. Maybe some of<br>these tech companies should have psychologists and<br>sociologists and theologians and philosophers and<br>historians on board to provide the checks and<br>balances these ego-manics need.",
         "hovertext": "I share the sentiments of many. This is the<br>pattern of tech, the tech mentality, the bro<br>culture, the drive of fame and profit seeking, the<br>utter lack of foresight and ethics. Maybe some of<br>these tech companies should have psychologists and<br>sociologists and theologians and philosophers and<br>historians on board to provide the checks and<br>balances these ego-manics need.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.5785415768623352
         ],
         "y": [
          -0.3538910150527954
         ]
        },
        {
         "hovertemplate": "@rpmars   “ Maybe some of these tech companies<br>should have psychologists and sociologists and<br>theologians and philosophers and historians on<br>board to provide the checks and balances these<br>ego-manics need.”    A perfectly good argument why<br>at least SOME liberal arts content should be<br>included in every degree requirement.",
         "hovertext": "@rpmars   “ Maybe some of these tech companies<br>should have psychologists and sociologists and<br>theologians and philosophers and historians on<br>board to provide the checks and balances these<br>ego-manics need.”    A perfectly good argument why<br>at least SOME liberal arts content should be<br>included in every degree requirement.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.5832547545433044
         ],
         "y": [
          -0.3644525408744812
         ]
        },
        {
         "hovertemplate": "@rpmars They had ethicists, and they're laying<br>them off:    <a<br>href=\"https://www.cnbc.com/2023/05/26/tech-<br>companies-are-laying-off-their-ethics-and-safety-<br>teams-.html\" target=\"_blank\">https://www.cnbc.com/<br>2023/05/26/tech-companies-are-laying-off-their-<br>ethics-and-safety-teams-.html</a>  <a href=\"https:<br>//www.washingtonpost.com/technology/2023/03/30/tec<br>h-companies-cut-ai-ethics\" target=\"_blank\">https:/<br>/www.washingtonpost.com/technology/2023/03/30/tech<br>-companies-cut-ai-ethics</a>/  <a<br>href=\"https://fortune.com/2022/09/09/meta-axes-<br>responsible-innovation-team-downside-to-products\" <br>target=\"_blank\">https://fortune.com/2022/09/09/met<br>a-axes-responsible-innovation-team-downside-to-<br>products</a>/",
         "hovertext": "@rpmars They had ethicists, and they're laying<br>them off:    <a<br>href=\"https://www.cnbc.com/2023/05/26/tech-<br>companies-are-laying-off-their-ethics-and-safety-<br>teams-.html\" target=\"_blank\">https://www.cnbc.com/<br>2023/05/26/tech-companies-are-laying-off-their-<br>ethics-and-safety-teams-.html</a>  <a href=\"https:<br>//www.washingtonpost.com/technology/2023/03/30/tec<br>h-companies-cut-ai-ethics\" target=\"_blank\">https:/<br>/www.washingtonpost.com/technology/2023/03/30/tech<br>-companies-cut-ai-ethics</a>/  <a<br>href=\"https://fortune.com/2022/09/09/meta-axes-<br>responsible-innovation-team-downside-to-products\" <br>target=\"_blank\">https://fortune.com/2022/09/09/met<br>a-axes-responsible-innovation-team-downside-to-<br>products</a>/",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.592799186706543
         ],
         "y": [
          -0.357217937707901
         ]
        },
        {
         "hovertemplate": "It’s nice that the inventors of this technology<br>are telling us it will end our existence.  Thanks?",
         "hovertext": "It’s nice that the inventors of this technology<br>are telling us it will end our existence.  Thanks?",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.09551560133695602
         ],
         "y": [
          0.6426213979721069
         ]
        },
        {
         "hovertemplate": "@Jacob Rosenblum     of course thanks!! It is like<br>climate scientists’ remarkable decades long global<br>efforts to warn us.",
         "hovertext": "@Jacob Rosenblum     of course thanks!! It is like<br>climate scientists’ remarkable decades long global<br>efforts to warn us.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.10515689104795456
         ],
         "y": [
          0.6447091698646545
         ]
        },
        {
         "hovertemplate": "@Jacob Rosenblum     Just remember, no one knows<br>what's better for us then they do. Megalomania<br>starts at home.",
         "hovertext": "@Jacob Rosenblum     Just remember, no one knows<br>what's better for us then they do. Megalomania<br>starts at home.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.09332401305437088
         ],
         "y": [
          0.6547420024871826
         ]
        },
        {
         "hovertemplate": "It’s too little; too late.  They knew this risk at<br>the inception (or should I say conception). These<br>are western companies who, after furiously<br>creating their potential Frankenstein, now want to<br>seem to practice restraint.   Here’s the all too<br>common script:  “Uh oh, we’ve created something<br>dangerous, but we love it. Call in the public<br>relations team to make us look less monstrous.<br>Then we’ll seem without choice when nefarious<br>countries build and expand upon the technology for<br>militarization, leaving us to continue our own<br>development. The public are sheep, they’ll buy<br>it,”   Unfortunately, the last sentence is true.",
         "hovertext": "It’s too little; too late.  They knew this risk at<br>the inception (or should I say conception). These<br>are western companies who, after furiously<br>creating their potential Frankenstein, now want to<br>seem to practice restraint.   Here’s the all too<br>common script:  “Uh oh, we’ve created something<br>dangerous, but we love it. Call in the public<br>relations team to make us look less monstrous.<br>Then we’ll seem without choice when nefarious<br>countries build and expand upon the technology for<br>militarization, leaving us to continue our own<br>development. The public are sheep, they’ll buy<br>it,”   Unfortunately, the last sentence is true.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7202431559562683
         ],
         "y": [
          -0.10032343864440918
         ]
        },
        {
         "hovertemplate": "@NDCatt   AI tech was inevitable, and can be put<br>to mind-benignly good use. Also, you really would<br>not only Russia or China in control of this tech.",
         "hovertext": "@NDCatt   AI tech was inevitable, and can be put<br>to mind-benignly good use. Also, you really would<br>not only Russia or China in control of this tech.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7274435758590698
         ],
         "y": [
          -0.09587421268224716
         ]
        },
        {
         "hovertemplate": "It would seem the AI would only need to reach a<br>critical level of general intelligence from which<br>it can find ways to make itself smarter, without<br>human input. This would have an exponential effect<br>in a short time and make AI into something beyond<br>which any human could ever comprehend. I’m very<br>nervous but this appears inevitable.",
         "hovertext": "It would seem the AI would only need to reach a<br>critical level of general intelligence from which<br>it can find ways to make itself smarter, without<br>human input. This would have an exponential effect<br>in a short time and make AI into something beyond<br>which any human could ever comprehend. I’m very<br>nervous but this appears inevitable.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7693247199058533
         ],
         "y": [
          -0.3962993621826172
         ]
        },
        {
         "hovertemplate": "@Michael     AI already finds ways to make itself<br>smarter without human input. This built in aspect<br>of AI a will continue to become more pronounced as<br>data sources, computing power, algorithms and l<br>“experience” grow.",
         "hovertext": "@Michael     AI already finds ways to make itself<br>smarter without human input. This built in aspect<br>of AI a will continue to become more pronounced as<br>data sources, computing power, algorithms and l<br>“experience” grow.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7853516936302185
         ],
         "y": [
          -0.40278393030166626
         ]
        },
        {
         "hovertemplate": "@Michael I’ve been wondering the same thing.",
         "hovertext": "@Michael I’ve been wondering the same thing.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.7594150304794312
         ],
         "y": [
          -0.3955489695072174
         ]
        },
        {
         "hovertemplate": "Can someone explain to me why we aren’t requiring<br>system designers to implement Asimov’s Laws of<br>Robotics? He envisioned fundamental, core<br>programming that would prevent AI from doing harm.",
         "hovertext": "Can someone explain to me why we aren’t requiring<br>system designers to implement Asimov’s Laws of<br>Robotics? He envisioned fundamental, core<br>programming that would prevent AI from doing harm.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.5552569627761841
         ],
         "y": [
          0.4500080645084381
         ]
        },
        {
         "hovertemplate": "Elsewhere discussions point out the ways Asimov’s<br>solution - the laws of robotics- don’t apply to<br>the here and now.  Asimov was cool, but the<br>answer, if there is one, will have to come from<br>somewhere else.",
         "hovertext": "Elsewhere discussions point out the ways Asimov’s<br>solution - the laws of robotics- don’t apply to<br>the here and now.  Asimov was cool, but the<br>answer, if there is one, will have to come from<br>somewhere else.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5613664984703064
         ],
         "y": [
          0.4442608058452606
         ]
        },
        {
         "hovertemplate": "AI might be dangerous some day, but there plenty<br>of industries that are killing us NOW.  Maybe we<br>can do to the gun industry what we did to the<br>cigarette and opioid companies?",
         "hovertext": "AI might be dangerous some day, but there plenty<br>of industries that are killing us NOW.  Maybe we<br>can do to the gun industry what we did to the<br>cigarette and opioid companies?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.8180519342422485
         ],
         "y": [
          0.3383656442165375
         ]
        },
        {
         "hovertemplate": "@Scott Cole Cigarettes and Opiods could be<br>corrected by legislation. Guns are protected by<br>the 2nd amendment of the constitution and would<br>require 3/4 of the states to overturn. The SCOTUS<br>also has great say in how the 2nd amendment is<br>interpreted. I've always found it interesting that<br>the 2nd amendment begins with \"In order to have a<br>WELL REGULATED militia...\" How is it these AR-15's<br>getting in the hands of suicidal mass shooters a<br>well regulated militia?",
         "hovertext": "@Scott Cole Cigarettes and Opiods could be<br>corrected by legislation. Guns are protected by<br>the 2nd amendment of the constitution and would<br>require 3/4 of the states to overturn. The SCOTUS<br>also has great say in how the 2nd amendment is<br>interpreted. I've always found it interesting that<br>the 2nd amendment begins with \"In order to have a<br>WELL REGULATED militia...\" How is it these AR-15's<br>getting in the hands of suicidal mass shooters a<br>well regulated militia?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8322096467018127
         ],
         "y": [
          0.34470266103744507
         ]
        },
        {
         "hovertemplate": "\" . . . future systems could be as deadly as<br>pandemics and nuclear weapons.\"    Not unlike<br>Oppenheimer saying:     \"I am become death.\"",
         "hovertext": "\" . . . future systems could be as deadly as<br>pandemics and nuclear weapons.\"    Not unlike<br>Oppenheimer saying:     \"I am become death.\"",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.7948247194290161
         ],
         "y": [
          0.5819405317306519
         ]
        },
        {
         "hovertemplate": "@m.carter more like ‘I am become Shiva, destroyer<br>of worlds.’",
         "hovertext": "@m.carter more like ‘I am become Shiva, destroyer<br>of worlds.’",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.8061346411705017
         ],
         "y": [
          0.5899354815483093
         ]
        },
        {
         "hovertemplate": "All of this is a choice. Technological development<br>is the result of specific iterative steps designed<br>towards a specific output. The notion that it<br>develops in a linear trajectory that we ‘just have<br>to accept and adapt to’ is one of the technology<br>industry’s biggest lies.",
         "hovertext": "All of this is a choice. Technological development<br>is the result of specific iterative steps designed<br>towards a specific output. The notion that it<br>develops in a linear trajectory that we ‘just have<br>to accept and adapt to’ is one of the technology<br>industry’s biggest lies.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.31856274604797363
         ],
         "y": [
          0.9308769702911377
         ]
        },
        {
         "hovertemplate": "So now that they created this problem, they want<br>the government to solve it? Are they willing to<br>pay more taxes on their wealth to help fund that?",
         "hovertext": "So now that they created this problem, they want<br>the government to solve it? Are they willing to<br>pay more taxes on their wealth to help fund that?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8986503481864929
         ],
         "y": [
          0.49233606457710266
         ]
        },
        {
         "hovertemplate": "@Julie     No, they'd much prefer Gov't pay them<br>to 'solve' it while at the same time eliminating<br>those burdensome regulations that encumber them<br>so.",
         "hovertext": "@Julie     No, they'd much prefer Gov't pay them<br>to 'solve' it while at the same time eliminating<br>those burdensome regulations that encumber them<br>so.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8794869184494019
         ],
         "y": [
          0.48230600357055664
         ]
        },
        {
         "hovertemplate": "The article points to the irony of having the very<br>same creators of this A.I. technology, still<br>working at it, raising alarms about the disastrous<br>consequences of their work. As if \"mad\" scientists<br>working on a virus in a lab raised the flag that<br>it could soon be commercialized and generate a<br>pandemic. Their child Frankenstein will create<br>havoc and become monstrous, but hey let's keep<br>working on him. And even if it is regulated here,<br>it may not be so elsewhere in the world. Human<br>creatures are frightful in their greed and their<br>Icarus-like ambition. Industrialization run havoc<br>has created climate change and the destruction of<br>the environment and wild life, weapons of mass<br>destruction, and now this. Who programmed us for<br>all that blind destructive rage (or instinct)?",
         "hovertext": "The article points to the irony of having the very<br>same creators of this A.I. technology, still<br>working at it, raising alarms about the disastrous<br>consequences of their work. As if \"mad\" scientists<br>working on a virus in a lab raised the flag that<br>it could soon be commercialized and generate a<br>pandemic. Their child Frankenstein will create<br>havoc and become monstrous, but hey let's keep<br>working on him. And even if it is regulated here,<br>it may not be so elsewhere in the world. Human<br>creatures are frightful in their greed and their<br>Icarus-like ambition. Industrialization run havoc<br>has created climate change and the destruction of<br>the environment and wild life, weapons of mass<br>destruction, and now this. Who programmed us for<br>all that blind destructive rage (or instinct)?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.8415874242782593
         ],
         "y": [
          -0.11441293358802795
         ]
        },
        {
         "hovertemplate": "@tdb   Frankenstein is the name of the creator of<br>the \"monster\": I read this in a book somewhere.",
         "hovertext": "@tdb   Frankenstein is the name of the creator of<br>the \"monster\": I read this in a book somewhere.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8511672616004944
         ],
         "y": [
          -0.11505359411239624
         ]
        },
        {
         "hovertemplate": "To late to close the barn door.    Robust,<br>holistic, well rounded education is the only<br>antidote.     Don’t hold your breath.",
         "hovertext": "To late to close the barn door.    Robust,<br>holistic, well rounded education is the only<br>antidote.     Don’t hold your breath.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.2769685983657837
         ],
         "y": [
          0.7071499228477478
         ]
        },
        {
         "hovertemplate": "@Mike   Your comment doesn't make sense even on<br>it's own terms. If it's too late how would a well<br>rounded education help?",
         "hovertext": "@Mike   Your comment doesn't make sense even on<br>it's own terms. If it's too late how would a well<br>rounded education help?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.28174686431884766
         ],
         "y": [
          0.7180672883987427
         ]
        },
        {
         "hovertemplate": "These advanced AI systems are intelligent because<br>they were trained on knowledge in the form of<br>books, Wikipedia, etc.. These knowledge sources<br>were created by millions of peoples over tens<br>thousands of years including the development of<br>natural languages, mathematics, science, etc. So<br>the dividends of these AI systems must be shared<br>fairly by everyone globally in way that would<br>satisfy all the past contributors to the knowledge<br>sources. There is plenty for everyone and there is<br>no need to fight with each other as if there is a<br>scarcity of human needs.",
         "hovertext": "These advanced AI systems are intelligent because<br>they were trained on knowledge in the form of<br>books, Wikipedia, etc.. These knowledge sources<br>were created by millions of peoples over tens<br>thousands of years including the development of<br>natural languages, mathematics, science, etc. So<br>the dividends of these AI systems must be shared<br>fairly by everyone globally in way that would<br>satisfy all the past contributors to the knowledge<br>sources. There is plenty for everyone and there is<br>no need to fight with each other as if there is a<br>scarcity of human needs.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7432928085327148
         ],
         "y": [
          -0.729974627494812
         ]
        },
        {
         "hovertemplate": "If you have a really large magnet like the ones<br>they use in scrap yards, you can quickly disable a<br>rogue robot or computer ... assuming the magnetic<br>crane is manually controlled.",
         "hovertext": "If you have a really large magnet like the ones<br>they use in scrap yards, you can quickly disable a<br>rogue robot or computer ... assuming the magnetic<br>crane is manually controlled.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8516592383384705
         ],
         "y": [
          0.0461750365793705
         ]
        },
        {
         "hovertemplate": "@Art -- breaking bad vibes.  I sort of agree; in<br>the end it may come to a showdown where some brave<br>human is forced to pull the plug.  That should<br>remain possible for a few more years until AI<br>reads minds and has robots to control electricity<br>production.",
         "hovertext": "@Art -- breaking bad vibes.  I sort of agree; in<br>the end it may come to a showdown where some brave<br>human is forced to pull the plug.  That should<br>remain possible for a few more years until AI<br>reads minds and has robots to control electricity<br>production.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8472305536270142
         ],
         "y": [
          0.039026860147714615
         ]
        },
        {
         "hovertemplate": "The people who say that AI poses an existential<br>threat are maddeningly vague about what they think<br>that threat is.",
         "hovertext": "The people who say that AI poses an existential<br>threat are maddeningly vague about what they think<br>that threat is.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8782480955123901
         ],
         "y": [
          0.05193973705172539
         ]
        },
        {
         "hovertemplate": "Techies are telling us their creation is about to<br>blow us up. c'est deja vu, AI=Frankenstein?<br>What could mega-intensive energy systems do to our<br>world threatened by climate disasters? Could they<br>replace the clueless politicians supposed to<br>govern us? Maybe for the better, after all.<br>Don't cry wolf, don't scare us, EDUCATE US!!!!",
         "hovertext": "Techies are telling us their creation is about to<br>blow us up. c'est deja vu, AI=Frankenstein?<br>What could mega-intensive energy systems do to our<br>world threatened by climate disasters? Could they<br>replace the clueless politicians supposed to<br>govern us? Maybe for the better, after all.<br>Don't cry wolf, don't scare us, EDUCATE US!!!!",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.3048870265483856
         ],
         "y": [
          0.8831683993339539
         ]
        },
        {
         "hovertemplate": "We are already doomed, destroyed by the earliest<br>form of the computer, that is writing. Our use of<br>these black marks before our eyes here, a<br>substitute for mind, has destroyed our capacity<br>for memory, just as Socrates (allegedly) warned.<br>Look at the mess was are in.     Oh my, AI has, or<br>will doom us in the next few minutes say the<br>powerful if the don’t successfully get their money<br>grabbing claws into the mix by predicting the<br>inescapable apocalypse!!!",
         "hovertext": "We are already doomed, destroyed by the earliest<br>form of the computer, that is writing. Our use of<br>these black marks before our eyes here, a<br>substitute for mind, has destroyed our capacity<br>for memory, just as Socrates (allegedly) warned.<br>Look at the mess was are in.     Oh my, AI has, or<br>will doom us in the next few minutes say the<br>powerful if the don’t successfully get their money<br>grabbing claws into the mix by predicting the<br>inescapable apocalypse!!!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9454362392425537
         ],
         "y": [
          -0.21637535095214844
         ]
        },
        {
         "hovertemplate": "I'd rather have AI running things than DeSantis,<br>Trump, MTG, Boebert, and Abbott.",
         "hovertext": "I'd rather have AI running things than DeSantis,<br>Trump, MTG, Boebert, and Abbott.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8369336724281311
         ],
         "y": [
          0.49429816007614136
         ]
        },
        {
         "hovertemplate": "The 'government' is NOT going to save us.",
         "hovertext": "The 'government' is NOT going to save us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4659295380115509
         ],
         "y": [
          -0.6594077944755554
         ]
        },
        {
         "hovertemplate": "@Paul Steele     Right. Remember when Zuckerberg,<br>when asked by Senator Hatch how facebook makes any<br>money replied , \"Senator, we sell Adds \".",
         "hovertext": "@Paul Steele     Right. Remember when Zuckerberg,<br>when asked by Senator Hatch how facebook makes any<br>money replied , \"Senator, we sell Adds \".",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.46276533603668213
         ],
         "y": [
          -0.6518123745918274
         ]
        },
        {
         "hovertemplate": "This is like dousing someone's house in gasoline<br>and saying \"warning! You better call 9-1-1!\" where<br>is the accountability? These men just think they<br>can do whatever with no real consequences and then<br>pat themselves on the back for saying \"whoopsies\"",
         "hovertext": "This is like dousing someone's house in gasoline<br>and saying \"warning! You better call 9-1-1!\" where<br>is the accountability? These men just think they<br>can do whatever with no real consequences and then<br>pat themselves on the back for saying \"whoopsies\"",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.05128009244799614
         ],
         "y": [
          -0.9958652853965759
         ]
        },
        {
         "hovertemplate": "Hello, I am building a nuclear weapon that could<br>wipe out humanity as we know it. I'm going to warn<br>you that a nuclear weapon can wipe out humanity.<br>I do regret that I can't stop building said<br>weapon.",
         "hovertext": "Hello, I am building a nuclear weapon that could<br>wipe out humanity as we know it. I'm going to warn<br>you that a nuclear weapon can wipe out humanity.<br>I do regret that I can't stop building said<br>weapon.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.08449456840753555
         ],
         "y": [
          0.859270453453064
         ]
        },
        {
         "hovertemplate": "Republicans are trying to figure out how to<br>harness AI to suppress voting in Democratic<br>districts.",
         "hovertext": "Republicans are trying to figure out how to<br>harness AI to suppress voting in Democratic<br>districts.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8896060585975647
         ],
         "y": [
          0.34875771403312683
         ]
        },
        {
         "hovertemplate": "To err is human and even the smartest among us<br>wake up some mornings and do perplexingly stupid<br>things.  AI, alternatively, will wake up one<br>morning soon and be flawless.  Extinction will<br>come as soon as AI learns and uses human emotions<br>learned through ordinary curiosity (programmed)<br>processes and the axiomatic rewards of being,<br>\"right\". A self-fulfilling prophecy, I'd argue.<br>So, everyone might get onboard teaching highly<br>charged, absurd human emotions to AI such that the<br>machines can band together and learn how to eat<br>Hagan Das ice-cream by the buckets using mixing<br>spoons.   Goodby cruel world!",
         "hovertext": "To err is human and even the smartest among us<br>wake up some mornings and do perplexingly stupid<br>things.  AI, alternatively, will wake up one<br>morning soon and be flawless.  Extinction will<br>come as soon as AI learns and uses human emotions<br>learned through ordinary curiosity (programmed)<br>processes and the axiomatic rewards of being,<br>\"right\". A self-fulfilling prophecy, I'd argue.<br>So, everyone might get onboard teaching highly<br>charged, absurd human emotions to AI such that the<br>machines can band together and learn how to eat<br>Hagan Das ice-cream by the buckets using mixing<br>spoons.   Goodby cruel world!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8152636289596558
         ],
         "y": [
          -0.517644464969635
         ]
        },
        {
         "hovertemplate": "Maybe AI can finally crack the lack of equal<br>opportunity, racial and ethnic discrimination, and<br>other endemic governance short comings.  It might<br>choose, if it's incharge, to evolve us.  One can<br>only hope as I think the current model of human is<br>headed for disaster.",
         "hovertext": "Maybe AI can finally crack the lack of equal<br>opportunity, racial and ethnic discrimination, and<br>other endemic governance short comings.  It might<br>choose, if it's incharge, to evolve us.  One can<br>only hope as I think the current model of human is<br>headed for disaster.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8538283705711365
         ],
         "y": [
          -0.5613274574279785
         ]
        },
        {
         "hovertemplate": "I find it humorous that when Blue Collar jobs<br>become redundant from advances in technology, the<br>advice is, \"retrain into another career field you<br>lazy bum!\"  When such advances may put White<br>Collar jobs on the line?  \"Hold on there, we need<br>to regulate this!\"  There are, of course, much<br>larger issues at stake here and acknowledge that,<br>but the crickets on the job issue?  Humorous.",
         "hovertext": "I find it humorous that when Blue Collar jobs<br>become redundant from advances in technology, the<br>advice is, \"retrain into another career field you<br>lazy bum!\"  When such advances may put White<br>Collar jobs on the line?  \"Hold on there, we need<br>to regulate this!\"  There are, of course, much<br>larger issues at stake here and acknowledge that,<br>but the crickets on the job issue?  Humorous.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9678736925125122
         ],
         "y": [
          -0.1000080481171608
         ]
        },
        {
         "hovertemplate": "Whether or not this letter is, as some readers<br>here believe, a disingenuous PR stunt, the fact<br>remains that self-regulation is not going to<br>ensure that AI development proceeds with any<br>regard for human welfare. Government regulation<br>from outside the industry is necessary. This is<br>because AI development presents the same<br>intractable collective action problem as climate<br>change: there will always be unscrupulous actors<br>who will flout the rules or refuse to voluntarily<br>commit to responsible self-regulation in order to<br>gain even a slight competitive advantage in the<br>marketplace.      The real question therefore is<br>how do we prevent the unscrupulous and venal<br>politicians that infect \"our\" government from<br>acquiescing as usual to the plutocrats that have<br>historically opposed any and all regulations that<br>affect the bottom line?     Fixing our government<br>- campaign finance reform in particular - is a<br>sine qua non of all responsible legislation:<br>whether it's the environment, guns, or unbridled<br>AI \"exploration\", our politicians are only as<br>responsible as their plutocratic handlers, which<br>is to say, totally irresponsible.",
         "hovertext": "Whether or not this letter is, as some readers<br>here believe, a disingenuous PR stunt, the fact<br>remains that self-regulation is not going to<br>ensure that AI development proceeds with any<br>regard for human welfare. Government regulation<br>from outside the industry is necessary. This is<br>because AI development presents the same<br>intractable collective action problem as climate<br>change: there will always be unscrupulous actors<br>who will flout the rules or refuse to voluntarily<br>commit to responsible self-regulation in order to<br>gain even a slight competitive advantage in the<br>marketplace.      The real question therefore is<br>how do we prevent the unscrupulous and venal<br>politicians that infect \"our\" government from<br>acquiescing as usual to the plutocrats that have<br>historically opposed any and all regulations that<br>affect the bottom line?     Fixing our government<br>- campaign finance reform in particular - is a<br>sine qua non of all responsible legislation:<br>whether it's the environment, guns, or unbridled<br>AI \"exploration\", our politicians are only as<br>responsible as their plutocratic handlers, which<br>is to say, totally irresponsible.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.21270157396793365
         ],
         "y": [
          -0.7373391389846802
         ]
        },
        {
         "hovertemplate": "@ARB Could not agree more. Whatever the problem in<br>our society (AI, guns, climate change, etc.), it<br>all begins with campaign finance reform.  Our<br>politicians simply do not work for us. They work<br>for the people who keep them in office by<br>financing their campaigns.",
         "hovertext": "@ARB Could not agree more. Whatever the problem in<br>our society (AI, guns, climate change, etc.), it<br>all begins with campaign finance reform.  Our<br>politicians simply do not work for us. They work<br>for the people who keep them in office by<br>financing their campaigns.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.20986875891685486
         ],
         "y": [
          -0.7279043793678284
         ]
        },
        {
         "hovertemplate": "Lol. Skip. Yet another in a series of AI industry<br>leaders warning of the existential threat their<br>artificial progeny pose while describing exactly<br>no scenario(s). Unless they mean the 1970 movie<br>(still good!) \"Colossus: The Forbin Project\" where<br>humanity is taken hostage by supercomputers that<br>launch nuclear weapons, or Skynet in 1984's<br>\"Terminator.\" Hint: don't give AI the keys to the<br>car, either.",
         "hovertext": "Lol. Skip. Yet another in a series of AI industry<br>leaders warning of the existential threat their<br>artificial progeny pose while describing exactly<br>no scenario(s). Unless they mean the 1970 movie<br>(still good!) \"Colossus: The Forbin Project\" where<br>humanity is taken hostage by supercomputers that<br>launch nuclear weapons, or Skynet in 1984's<br>\"Terminator.\" Hint: don't give AI the keys to the<br>car, either.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2762974500656128
         ],
         "y": [
          -0.39354801177978516
         ]
        },
        {
         "hovertemplate": "@Hugh MacDonald I think the idea is pretty<br>obviously that smart, capable AI could be prompted<br>to wreak all kinds of havoc, like controlling<br>systems and making essential/dangerous things go<br>haywire, that could be difficult or basically<br>impossible to control.  It's not necessarily that<br>it would do it on its own, but that people with<br>malign intent could set it in that direction.",
         "hovertext": "@Hugh MacDonald I think the idea is pretty<br>obviously that smart, capable AI could be prompted<br>to wreak all kinds of havoc, like controlling<br>systems and making essential/dangerous things go<br>haywire, that could be difficult or basically<br>impossible to control.  It's not necessarily that<br>it would do it on its own, but that people with<br>malign intent could set it in that direction.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2766312062740326
         ],
         "y": [
          -0.37941333651542664
         ]
        },
        {
         "hovertemplate": "Another good film on the topic is Transcendence,<br>about a decade old, in which Johnny Depp’s<br>consciousness is uploaded to a computer. The first<br>thing he/it does is seize control of the capital<br>markets. It all starts to fall apart when it<br>becomes apparent that the thing can monitor all<br>his wife’s physical processes, in effect reading<br>her mind.     Yesterday I watched a segment that<br>showed how an AI could read a person’s brain waves<br>to the point that it understood the English words<br>of a person’s thoughts that told a sort of story.<br>I thought the segment incomplete as it did not<br>show the other technologies involved (it seemed<br>unlikely that AI, at this point, can be told to<br>read someone’s brain waves without the use of<br>ancillary systems, but it was unsettling that no<br>electrodes were used.)",
         "hovertext": "Another good film on the topic is Transcendence,<br>about a decade old, in which Johnny Depp’s<br>consciousness is uploaded to a computer. The first<br>thing he/it does is seize control of the capital<br>markets. It all starts to fall apart when it<br>becomes apparent that the thing can monitor all<br>his wife’s physical processes, in effect reading<br>her mind.     Yesterday I watched a segment that<br>showed how an AI could read a person’s brain waves<br>to the point that it understood the English words<br>of a person’s thoughts that told a sort of story.<br>I thought the segment incomplete as it did not<br>show the other technologies involved (it seemed<br>unlikely that AI, at this point, can be told to<br>read someone’s brain waves without the use of<br>ancillary systems, but it was unsettling that no<br>electrodes were used.)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.27947521209716797
         ],
         "y": [
          -0.4062449336051941
         ]
        },
        {
         "hovertemplate": "@Mark I think about widespread disinformation with<br>excellently faked images and videos so no one has<br>a clue about what is real. Or how about robot<br>soldiers? The military-industrial complex would<br>love that because: a.) such soldiers would make<br>the decision to go to war easier (no images of<br>coffins coming home night after night), increasing<br>the number of wars, and b.) all those soldiers<br>would need replacements (no draft increases). P.S.<br>We should have thought about how dangerous and<br>disruptive and stupid and narcissistic and fake<br>social media is, too.",
         "hovertext": "@Mark I think about widespread disinformation with<br>excellently faked images and videos so no one has<br>a clue about what is real. Or how about robot<br>soldiers? The military-industrial complex would<br>love that because: a.) such soldiers would make<br>the decision to go to war easier (no images of<br>coffins coming home night after night), increasing<br>the number of wars, and b.) all those soldiers<br>would need replacements (no draft increases). P.S.<br>We should have thought about how dangerous and<br>disruptive and stupid and narcissistic and fake<br>social media is, too.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.288947731256485
         ],
         "y": [
          -0.37697717547416687
         ]
        },
        {
         "hovertemplate": "@Hugh MacDonald Ya, I agree with everything you<br>wrote... and really it's already happening.  Very<br>disturbing and there's probably no going back now<br>on any of it.  It's a reality that if the US<br>stopped all AI development today, it would be used<br>by its adversaries to dominate it in short order.<br>So... kind of disturbing really.",
         "hovertext": "@Hugh MacDonald Ya, I agree with everything you<br>wrote... and really it's already happening.  Very<br>disturbing and there's probably no going back now<br>on any of it.  It's a reality that if the US<br>stopped all AI development today, it would be used<br>by its adversaries to dominate it in short order.<br>So... kind of disturbing really.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.30065083503723145
         ],
         "y": [
          -0.3838024437427521
         ]
        },
        {
         "hovertemplate": "Dear OpenAI, Google Deepmind, Anthropic and other<br>A.I. labs: you spearheaded this technology, now<br>clean up your own mess",
         "hovertext": "Dear OpenAI, Google Deepmind, Anthropic and other<br>A.I. labs: you spearheaded this technology, now<br>clean up your own mess",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.30944275856018066
         ],
         "y": [
          0.6756950616836548
         ]
        },
        {
         "hovertemplate": "How so?  Rely on the Congress and state<br>legislatures to now remedy their scandalous<br>relationship with #BigTech?  Relationships that<br>have been baking for decades now. All that well<br>crafted legislation, drafted by #BigTech to thwart<br>regulation and oversight in its legislative recipe<br>guaranteeing its business model of<br>#CronyCapitalism,  #SurveillanceCapitalism and<br>#RegulatoryCapture.",
         "hovertext": "How so?  Rely on the Congress and state<br>legislatures to now remedy their scandalous<br>relationship with #BigTech?  Relationships that<br>have been baking for decades now. All that well<br>crafted legislation, drafted by #BigTech to thwart<br>regulation and oversight in its legislative recipe<br>guaranteeing its business model of<br>#CronyCapitalism,  #SurveillanceCapitalism and<br>#RegulatoryCapture.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3166634738445282
         ],
         "y": [
          0.6886201500892639
         ]
        },
        {
         "hovertemplate": "@Thom If only. But having read The Great Gatsby<br>and watched corporate America's great men, these<br>people never clean up their messes. Never. We do.",
         "hovertext": "@Thom If only. But having read The Great Gatsby<br>and watched corporate America's great men, these<br>people never clean up their messes. Never. We do.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3005183935165405
         ],
         "y": [
          0.6755185127258301
         ]
        },
        {
         "hovertemplate": "Please let’s not stumble blindly into this<br>madness. Because tech companies want to make money<br>hand over fist doesn’t mean the rest of us have to<br>sit idly by and watch our children’s future die.<br>We need nuclear weapons level safeguards and<br>brakes around AI. Let your government<br>representatives know if you agree.",
         "hovertext": "Please let’s not stumble blindly into this<br>madness. Because tech companies want to make money<br>hand over fist doesn’t mean the rest of us have to<br>sit idly by and watch our children’s future die.<br>We need nuclear weapons level safeguards and<br>brakes around AI. Let your government<br>representatives know if you agree.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4991772770881653
         ],
         "y": [
          0.8271647691726685
         ]
        },
        {
         "hovertemplate": "If artificial intelligence poses an existential<br>threat that could lead to extinction, then it<br>seems wrong to call it any kind of \"intelligence.\"<br>But let's be real. Almost any important technology<br>you can think of has already, or could possibly in<br>the future, play a role in some kind of species<br>extinction. At the very least, there have been<br>worries at the outset about each new major<br>technology causing major disruptions to<br>civilization.     Often these worries prove to be<br>overblown. However, it is also true that sometimes<br>we can't see the real dangers of a new technology<br>until years or decades after it has been widely<br>adopted.     If we can't even regulate guns, I am<br>not optimistic that we are going to figure out how<br>to regulate AI anytime soon. We may need to let AI<br>advance a bit more, and then ask AI to help us<br>figure out how it should be regulated.",
         "hovertext": "If artificial intelligence poses an existential<br>threat that could lead to extinction, then it<br>seems wrong to call it any kind of \"intelligence.\"<br>But let's be real. Almost any important technology<br>you can think of has already, or could possibly in<br>the future, play a role in some kind of species<br>extinction. At the very least, there have been<br>worries at the outset about each new major<br>technology causing major disruptions to<br>civilization.     Often these worries prove to be<br>overblown. However, it is also true that sometimes<br>we can't see the real dangers of a new technology<br>until years or decades after it has been widely<br>adopted.     If we can't even regulate guns, I am<br>not optimistic that we are going to figure out how<br>to regulate AI anytime soon. We may need to let AI<br>advance a bit more, and then ask AI to help us<br>figure out how it should be regulated.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7571703791618347
         ],
         "y": [
          -0.009163754992187023
         ]
        },
        {
         "hovertemplate": "@Dan Frazier     Our troubles with regulating guns<br>stem from the fact that we have trouble<br>interpreting a poorly worded constitutional<br>amendment.     Thankfully, there isn't any<br>constitutional law getting in the way of the<br>regulation of AI.",
         "hovertext": "@Dan Frazier     Our troubles with regulating guns<br>stem from the fact that we have trouble<br>interpreting a poorly worded constitutional<br>amendment.     Thankfully, there isn't any<br>constitutional law getting in the way of the<br>regulation of AI.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7519220113754272
         ],
         "y": [
          -0.019126472994685173
         ]
        },
        {
         "hovertemplate": "@James, yes. But if there’s big money to be made,<br>short-sighted greed will encourage their human<br>builders to look the other way.",
         "hovertext": "@James, yes. But if there’s big money to be made,<br>short-sighted greed will encourage their human<br>builders to look the other way.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7714688181877136
         ],
         "y": [
          -0.006616523023694754
         ]
        },
        {
         "hovertemplate": "@James     It's poorly interpreted, not poorly<br>worded.",
         "hovertext": "@James     It's poorly interpreted, not poorly<br>worded.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.764403760433197
         ],
         "y": [
          -0.02485518716275692
         ]
        },
        {
         "hovertemplate": "The elephant in the room is China, and to a lesser<br>extent, Russia. Even if all the other countries of<br>the world unanimously agreed to regulate, or even<br>halt further development of A.I., and all the<br>companies and people within those companies<br>complied fully, China and Russia consider this to<br>be a means to gain domination over the rest of the<br>world.    Now is the time to bring all of the<br>countries of the world together, including China<br>and Russia, North Korea, etc. to stop the creation<br>of super-human intelligence before it's too late.",
         "hovertext": "The elephant in the room is China, and to a lesser<br>extent, Russia. Even if all the other countries of<br>the world unanimously agreed to regulate, or even<br>halt further development of A.I., and all the<br>companies and people within those companies<br>complied fully, China and Russia consider this to<br>be a means to gain domination over the rest of the<br>world.    Now is the time to bring all of the<br>countries of the world together, including China<br>and Russia, North Korea, etc. to stop the creation<br>of super-human intelligence before it's too late.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.24508485198020935
         ],
         "y": [
          -0.8730838298797607
         ]
        },
        {
         "hovertemplate": "@Gregory   The elephants in the room are really<br>the Zuckerbergs of the world.  Those with no<br>social conscience, who should know better but<br>don’t care, can cause the most damage. They<br>address the lowest common denominator.",
         "hovertext": "@Gregory   The elephants in the room are really<br>the Zuckerbergs of the world.  Those with no<br>social conscience, who should know better but<br>don’t care, can cause the most damage. They<br>address the lowest common denominator.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.25083479285240173
         ],
         "y": [
          -0.8653242588043213
         ]
        },
        {
         "hovertemplate": "@Gregory   Indeed, there's no stopping this<br>freight train, I just hope to be as clear of the<br>tracks as possible before there's an \"AI war\"<br>between the various systems that will be trying to<br>hack/infiltrate the others.",
         "hovertext": "@Gregory   Indeed, there's no stopping this<br>freight train, I just hope to be as clear of the<br>tracks as possible before there's an \"AI war\"<br>between the various systems that will be trying to<br>hack/infiltrate the others.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.23712196946144104
         ],
         "y": [
          -0.8781198263168335
         ]
        },
        {
         "hovertemplate": "Two years ago in their book “The Age of AI: And<br>Our Human Future” by Kissinger, Schmidt and<br>Huttenlocher laid out how out of control and<br>imminently dangerous AI is. They rang the alarm:<br>the world lacked any framework for controlling<br>it—unlike the framework of international<br>negotiations and institutions developed to corral<br>nuclear weaons, however imperfectly. Two years<br>later, the geniuses beavering away at AI suddenly<br>look up from their screens and money apps to reach<br>the same conclusion. More evidence that tech<br>wunderkinds are out of touch with the rest of the<br>species. International cooperation to rein in AI?<br>Re-create the IAEA, now? The IAEA is the only<br>agency in the UN system with a direct link to the<br>Security Council; a measure of the potential<br>existential threat nuclear technology poses to<br>humanity. Russia, a permanent UN Security Council<br>member, is prosecuting a full-scale 19th century<br>war with 21st century weapons in violation of the<br>UN Charter and threatens to go nuclear. China and<br>the US—the Council’s heavyweights—are staring each<br>other down and accelerating their investment in AI<br>for military purposes. The global order has come<br>apart at the seams. International agreements,<br>institutions and norms are being ignored or gutted<br>(witness WHO’s influence on rich countries during<br>the pandemic) as countries back into autocracy,<br>nationalism and military alliances of convenience.<br>Good luck getting this lot to agree on anything to<br>do with AI.",
         "hovertext": "Two years ago in their book “The Age of AI: And<br>Our Human Future” by Kissinger, Schmidt and<br>Huttenlocher laid out how out of control and<br>imminently dangerous AI is. They rang the alarm:<br>the world lacked any framework for controlling<br>it—unlike the framework of international<br>negotiations and institutions developed to corral<br>nuclear weaons, however imperfectly. Two years<br>later, the geniuses beavering away at AI suddenly<br>look up from their screens and money apps to reach<br>the same conclusion. More evidence that tech<br>wunderkinds are out of touch with the rest of the<br>species. International cooperation to rein in AI?<br>Re-create the IAEA, now? The IAEA is the only<br>agency in the UN system with a direct link to the<br>Security Council; a measure of the potential<br>existential threat nuclear technology poses to<br>humanity. Russia, a permanent UN Security Council<br>member, is prosecuting a full-scale 19th century<br>war with 21st century weapons in violation of the<br>UN Charter and threatens to go nuclear. China and<br>the US—the Council’s heavyweights—are staring each<br>other down and accelerating their investment in AI<br>for military purposes. The global order has come<br>apart at the seams. International agreements,<br>institutions and norms are being ignored or gutted<br>(witness WHO’s influence on rich countries during<br>the pandemic) as countries back into autocracy,<br>nationalism and military alliances of convenience.<br>Good luck getting this lot to agree on anything to<br>do with AI.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9137539863586426
         ],
         "y": [
          0.33355745673179626
         ]
        },
        {
         "hovertemplate": "We generally don’t hold manufacturers/companies<br>responsible when someone uses their products to do<br>damage (think most guns, gasoline, knives).<br>[Thinking on certain guns is rightly evolving.]<br>However, when the CONTENT of the product<br>‘inherently’ incorporates either misinformation or<br>the design parameters to include such content, the<br>onus should migrate towards the provider.     We<br>need some good, independent minds to think through<br>this.",
         "hovertext": "We generally don’t hold manufacturers/companies<br>responsible when someone uses their products to do<br>damage (think most guns, gasoline, knives).<br>[Thinking on certain guns is rightly evolving.]<br>However, when the CONTENT of the product<br>‘inherently’ incorporates either misinformation or<br>the design parameters to include such content, the<br>onus should migrate towards the provider.     We<br>need some good, independent minds to think through<br>this.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8183162212371826
         ],
         "y": [
          0.4590505361557007
         ]
        },
        {
         "hovertemplate": "AI could be a weapon.  Imagine an AI that was<br>tasked to take down a whole country's internet.  I<br>imagine that an advanced AI would only need 12<br>hours to make it happen.    Now imagine that China<br>did that to the US.  Or the US did that to China.<br>A war in the real world could result.    This is<br>an arms race and the western democracies need to<br>be on top of this new arms race.",
         "hovertext": "AI could be a weapon.  Imagine an AI that was<br>tasked to take down a whole country's internet.  I<br>imagine that an advanced AI would only need 12<br>hours to make it happen.    Now imagine that China<br>did that to the US.  Or the US did that to China.<br>A war in the real world could result.    This is<br>an arms race and the western democracies need to<br>be on top of this new arms race.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6823359727859497
         ],
         "y": [
          0.6430160999298096
         ]
        },
        {
         "hovertemplate": "“The technology they are building” could pose a<br>threat ….  Well then. Don’t build it. Unless<br>safeguards are built in so they can’t.",
         "hovertext": "“The technology they are building” could pose a<br>threat ….  Well then. Don’t build it. Unless<br>safeguards are built in so they can’t.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.770709216594696
         ],
         "y": [
          -0.31039854884147644
         ]
        },
        {
         "hovertemplate": "Didn’t work for nuclear weapons. Cat is out of<br>bag. The AI weapons are here. We need to<br>reduce/eliminate the motivation to use them. If we<br>don’t find a peaceful solution to Ukraine and<br>other conflicts we are done.",
         "hovertext": "Didn’t work for nuclear weapons. Cat is out of<br>bag. The AI weapons are here. We need to<br>reduce/eliminate the motivation to use them. If we<br>don’t find a peaceful solution to Ukraine and<br>other conflicts we are done.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7633475661277771
         ],
         "y": [
          -0.3142510652542114
         ]
        },
        {
         "hovertemplate": "The bottom line is research into general AI must<br>be done with the utmost care, security and<br>prudence.    It should be done in a licensed lab<br>with full blown security measures akin to how we<br>handle nuclear and biological weapons.    There<br>should be failsafe after failsafe.      Once we<br>get very comfortable with working with general AI,<br>then maybe in the subsequent decades it can be<br>released into the world at large.  Until then,<br>baby steps.",
         "hovertext": "The bottom line is research into general AI must<br>be done with the utmost care, security and<br>prudence.    It should be done in a licensed lab<br>with full blown security measures akin to how we<br>handle nuclear and biological weapons.    There<br>should be failsafe after failsafe.      Once we<br>get very comfortable with working with general AI,<br>then maybe in the subsequent decades it can be<br>released into the world at large.  Until then,<br>baby steps.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.790224015712738
         ],
         "y": [
          -0.2044263482093811
         ]
        },
        {
         "hovertemplate": "@Mmm I'm sure the Chinese would obey such rules.",
         "hovertext": "@Mmm I'm sure the Chinese would obey such rules.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.7967306971549988
         ],
         "y": [
          -0.1975664645433426
         ]
        },
        {
         "hovertemplate": "@Kevin  There is no indication the Chinese are<br>pushing for internal social disruption.  They'll<br>keep AI on a tight leash.",
         "hovertext": "@Kevin  There is no indication the Chinese are<br>pushing for internal social disruption.  They'll<br>keep AI on a tight leash.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.8074932098388672
         ],
         "y": [
          -0.19645309448242188
         ]
        },
        {
         "hovertemplate": "Nobody can feed philosophy to AI?  A diet of<br>philosophy for these things might provoke real<br>discovery.  Maybe somebody or something will<br>finally understand Kierkegaard's tome on the<br>\"categories of dispair\" and then be able to<br>explain it to the rest of us, my philosophy prof<br>certainly couldn't explain it.  He said,<br>\"Kierkagaard was most probably joking\"!<br>I'd love to hear some AI bots seated in a circle<br>debating as interlocutors woild and using the<br>Socratic method to find a solution to some<br>conundrum of human behavior or governance.",
         "hovertext": "Nobody can feed philosophy to AI?  A diet of<br>philosophy for these things might provoke real<br>discovery.  Maybe somebody or something will<br>finally understand Kierkegaard's tome on the<br>\"categories of dispair\" and then be able to<br>explain it to the rest of us, my philosophy prof<br>certainly couldn't explain it.  He said,<br>\"Kierkagaard was most probably joking\"!<br>I'd love to hear some AI bots seated in a circle<br>debating as interlocutors woild and using the<br>Socratic method to find a solution to some<br>conundrum of human behavior or governance.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7072979211807251
         ],
         "y": [
          0.5021839141845703
         ]
        },
        {
         "hovertemplate": "As Philosophy attempts to explain the human<br>experience, AI has no more role in it than a crab<br>or a banana. Humanity must be spared the<br>experience of a chatbot chattering about something<br>it is constitutionally unprepared to have a<br>position on. AI must stay in its lane, restricting<br>itself to more mundane tasks, such as blowing up<br>the world.",
         "hovertext": "As Philosophy attempts to explain the human<br>experience, AI has no more role in it than a crab<br>or a banana. Humanity must be spared the<br>experience of a chatbot chattering about something<br>it is constitutionally unprepared to have a<br>position on. AI must stay in its lane, restricting<br>itself to more mundane tasks, such as blowing up<br>the world.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6928288340568542
         ],
         "y": [
          0.49144211411476135
         ]
        },
        {
         "hovertemplate": "“…some believe, A.I. could become powerful enough<br>that it could create societal-scale disruptions<br>within a few years…”    That sounds like nefarious<br>versions of A.I. could be used in the weeks and<br>months before the 2024 elections. A repeat of 2016<br>on steroids perhaps?",
         "hovertext": "“…some believe, A.I. could become powerful enough<br>that it could create societal-scale disruptions<br>within a few years…”    That sounds like nefarious<br>versions of A.I. could be used in the weeks and<br>months before the 2024 elections. A repeat of 2016<br>on steroids perhaps?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9679492712020874
         ],
         "y": [
          -0.05368347093462944
         ]
        },
        {
         "hovertemplate": "If it is so potentially dangerous, then don't<br>build it.",
         "hovertext": "If it is so potentially dangerous, then don't<br>build it.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.6249260902404785
         ],
         "y": [
          -0.8414338827133179
         ]
        },
        {
         "hovertemplate": "We can test the proposition of who will win in the<br>game of opposable thumbs with AI by empowering it<br>to play the game of Thumb War and see who wins.<br>My bet is on the machine with an artificial thumb<br>a million times stronger, harder and faster than<br>the human opponent.",
         "hovertext": "We can test the proposition of who will win in the<br>game of opposable thumbs with AI by empowering it<br>to play the game of Thumb War and see who wins.<br>My bet is on the machine with an artificial thumb<br>a million times stronger, harder and faster than<br>the human opponent.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.19456283748149872
         ],
         "y": [
          -0.8941776752471924
         ]
        },
        {
         "hovertemplate": "This technology poses risks of great havoc, even<br>extinction (let's see which one does its<br>extinction \"thing\" first: climate change, nuclear<br>exchange, A.I. or another pandemic (coming out of<br>a lab, ma weapon of mass destruction) Ah, we may<br>be completely unable to do anything about it, but<br>we are \"free\" to talk about it all we want. Talk,<br>talk, talk. All the freedom to talk and raise<br>flags that we want (and to defend it and<br>neutralize all the talk). But it is impossible to<br>stop the action and the practices that are<br>affecting the majority of us.What kind of freedom<br>for the pursuit of happiness is this?.",
         "hovertext": "This technology poses risks of great havoc, even<br>extinction (let's see which one does its<br>extinction \"thing\" first: climate change, nuclear<br>exchange, A.I. or another pandemic (coming out of<br>a lab, ma weapon of mass destruction) Ah, we may<br>be completely unable to do anything about it, but<br>we are \"free\" to talk about it all we want. Talk,<br>talk, talk. All the freedom to talk and raise<br>flags that we want (and to defend it and<br>neutralize all the talk). But it is impossible to<br>stop the action and the practices that are<br>affecting the majority of us.What kind of freedom<br>for the pursuit of happiness is this?.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8037661910057068
         ],
         "y": [
          0.6424239873886108
         ]
        },
        {
         "hovertemplate": "Most concerning about the current state of AI is<br>that the data scientists building it don’t seem to<br>fully understand it. Current Chatbots like ChatGPT<br>generate “hallucinations” that can’t be explained.<br>The smart thing to do here is slow down until the<br>risks and rewards are better understood.",
         "hovertext": "Most concerning about the current state of AI is<br>that the data scientists building it don’t seem to<br>fully understand it. Current Chatbots like ChatGPT<br>generate “hallucinations” that can’t be explained.<br>The smart thing to do here is slow down until the<br>risks and rewards are better understood.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8915359377861023
         ],
         "y": [
          0.2129247784614563
         ]
        },
        {
         "hovertemplate": "@Roger I The \"hallucinations\" can certainly be<br>explained, the term is being used for the fact<br>that an AI that talks like it's well educated but<br>has no idea what it is saying or control over what<br>it says will make stuff up. Not a surprise or an<br>enigma.",
         "hovertext": "@Roger I The \"hallucinations\" can certainly be<br>explained, the term is being used for the fact<br>that an AI that talks like it's well educated but<br>has no idea what it is saying or control over what<br>it says will make stuff up. Not a surprise or an<br>enigma.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9056205153465271
         ],
         "y": [
          0.21694818139076233
         ]
        },
        {
         "hovertemplate": "I'm beginning to believe that the humans who have<br>power on this planet also have an unconscious<br>desire for self-extinction. Congress won't even<br>regulate the internet or enforce anti-trust. And<br>then there's the $816.7 billion defense budget.<br>Thanks \"A.I. leaders\" for unleashing another<br>pandora's box on us.",
         "hovertext": "I'm beginning to believe that the humans who have<br>power on this planet also have an unconscious<br>desire for self-extinction. Congress won't even<br>regulate the internet or enforce anti-trust. And<br>then there's the $816.7 billion defense budget.<br>Thanks \"A.I. leaders\" for unleashing another<br>pandora's box on us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9094946980476379
         ],
         "y": [
          0.35535722970962524
         ]
        },
        {
         "hovertemplate": "This looks like an effort at self-absolution by<br>the people profiting the most. But the die has<br>been cast. Despite the ample warnings about how we<br>can't use nuclear weapons, nuclear proliferation<br>continues. Every country will build AI-enabled<br>stockpiles of miniature, autonomous drones that<br>can recognize humans and dispatch them with ease.",
         "hovertext": "This looks like an effort at self-absolution by<br>the people profiting the most. But the die has<br>been cast. Despite the ample warnings about how we<br>can't use nuclear weapons, nuclear proliferation<br>continues. Every country will build AI-enabled<br>stockpiles of miniature, autonomous drones that<br>can recognize humans and dispatch them with ease.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9523468613624573
         ],
         "y": [
          -0.05580895394086838
         ]
        },
        {
         "hovertemplate": "\"It's a classic case of the fox guarding the<br>henhouse when AI companies cry out for regulation.<br>On the surface, it may seem like a responsible<br>call, but the underlying motive is often a self-<br>serving one. By pushing for regulation, these<br>corporations position themselves to influence and<br>shape the rules of the game, effectively molding<br>the landscape to their advantage and potentially<br>creating a monopoly. The appeal for external<br>oversight is nothing more than a red herring, a<br>clever ruse to maintain control while feigning<br>vulnerability. It's the epitome of<br>hypocrisy—crying foul only when the threat of<br>competition looms, yet seeing no issue in<br>leveraging the same tactics for their benefit.<br>It's a clear case of 'it's only bad when someone<br>else does it'",
         "hovertext": "\"It's a classic case of the fox guarding the<br>henhouse when AI companies cry out for regulation.<br>On the surface, it may seem like a responsible<br>call, but the underlying motive is often a self-<br>serving one. By pushing for regulation, these<br>corporations position themselves to influence and<br>shape the rules of the game, effectively molding<br>the landscape to their advantage and potentially<br>creating a monopoly. The appeal for external<br>oversight is nothing more than a red herring, a<br>clever ruse to maintain control while feigning<br>vulnerability. It's the epitome of<br>hypocrisy—crying foul only when the threat of<br>competition looms, yet seeing no issue in<br>leveraging the same tactics for their benefit.<br>It's a clear case of 'it's only bad when someone<br>else does it'",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.0669480487704277
         ],
         "y": [
          -0.8637017011642456
         ]
        },
        {
         "hovertemplate": "I've read some of these today-ok, firstly, it's<br>built, done-already a threat...but, it can extend<br>human life, help with medical miracles, and send<br>us into space; it is the most tempting thing to<br>mankind since the proverbial \"apple\" and I'm not<br>speaking of the company, a much older apple.<br>The simple end of this is that NO country, let's<br>look at say N Korea, or China, no country will<br>simply say this is too dangerous, so let's not.<br>They all are on the board to create this monster,<br>and soon nothing else will matter at all-like a<br>Facebook for all, and all inclusive.     So...the<br>leaders of these companies need to be spoken to,<br>and devise with government, a way to keep this<br>safe, the big fear is that it's too late, the<br>proverbial cat is out of the bag, and it's already<br>purring...    I think we are all in very deep<br>yogurt here...",
         "hovertext": "I've read some of these today-ok, firstly, it's<br>built, done-already a threat...but, it can extend<br>human life, help with medical miracles, and send<br>us into space; it is the most tempting thing to<br>mankind since the proverbial \"apple\" and I'm not<br>speaking of the company, a much older apple.<br>The simple end of this is that NO country, let's<br>look at say N Korea, or China, no country will<br>simply say this is too dangerous, so let's not.<br>They all are on the board to create this monster,<br>and soon nothing else will matter at all-like a<br>Facebook for all, and all inclusive.     So...the<br>leaders of these companies need to be spoken to,<br>and devise with government, a way to keep this<br>safe, the big fear is that it's too late, the<br>proverbial cat is out of the bag, and it's already<br>purring...    I think we are all in very deep<br>yogurt here...",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.38981324434280396
         ],
         "y": [
          0.8363505601882935
         ]
        },
        {
         "hovertemplate": "I am suspicious of their concerns. They are the<br>leaders of the pack, and it looks like they want<br>government regulation to keep anyone else from<br>catching up. Quick have the government close the<br>door now that we are in.",
         "hovertext": "I am suspicious of their concerns. They are the<br>leaders of the pack, and it looks like they want<br>government regulation to keep anyone else from<br>catching up. Quick have the government close the<br>door now that we are in.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.76345294713974
         ],
         "y": [
          0.37263819575309753
         ]
        },
        {
         "hovertemplate": "My favorite line from this piece, that comes right<br>after all the dire language about human<br>extinction:    \"researchers sometimes stop short<br>of explaining how that would happen.\"    Yeah.<br>Because there is no plausible way it COULD happen.<br>All this AI hysteria feels like yet another of the<br>world-ending scenarios ginned up in the 60-plus<br>years I've been alive by news organizations to fit<br>someone's political, social or military agenda.<br>A partial list I can recall: Communist domination,<br>Nuclear War, Extinction from Over-Population,<br>Global Famine, Pollution that would reach levels<br>where life would be unsustainable, the New Ice<br>Age, a Hole in the Ozone Layer allowing deadly<br>solar rays,  Global Warming, make that Climate<br>Change, and now AI.  I've left off a few that<br>didn't quite reach the level of total handwringing<br>by national news agencies like asteroid peril,<br>space invaders, Islamic Extremism and economic<br>domination by Japan - strike that, China.    All<br>this worry over impending doom is going to kill us<br>all, even if it takes a century or so.",
         "hovertext": "My favorite line from this piece, that comes right<br>after all the dire language about human<br>extinction:    \"researchers sometimes stop short<br>of explaining how that would happen.\"    Yeah.<br>Because there is no plausible way it COULD happen.<br>All this AI hysteria feels like yet another of the<br>world-ending scenarios ginned up in the 60-plus<br>years I've been alive by news organizations to fit<br>someone's political, social or military agenda.<br>A partial list I can recall: Communist domination,<br>Nuclear War, Extinction from Over-Population,<br>Global Famine, Pollution that would reach levels<br>where life would be unsustainable, the New Ice<br>Age, a Hole in the Ozone Layer allowing deadly<br>solar rays,  Global Warming, make that Climate<br>Change, and now AI.  I've left off a few that<br>didn't quite reach the level of total handwringing<br>by national news agencies like asteroid peril,<br>space invaders, Islamic Extremism and economic<br>domination by Japan - strike that, China.    All<br>this worry over impending doom is going to kill us<br>all, even if it takes a century or so.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5043940544128418
         ],
         "y": [
          -0.6045594811439514
         ]
        },
        {
         "hovertemplate": "@Philboyd   All the things on your list are things<br>we have to worry about. The fact that they haven't<br>wiped out humanity is because we took actions to<br>avert those problems.",
         "hovertext": "@Philboyd   All the things on your list are things<br>we have to worry about. The fact that they haven't<br>wiped out humanity is because we took actions to<br>avert those problems.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.51682049036026
         ],
         "y": [
          -0.6096507906913757
         ]
        },
        {
         "hovertemplate": "@Philboyd Well, at least we know that AI has<br>surpassed the intelligence of one human who's<br>documented his own abilities for us.",
         "hovertext": "@Philboyd Well, at least we know that AI has<br>surpassed the intelligence of one human who's<br>documented his own abilities for us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4964819848537445
         ],
         "y": [
          -0.5982891321182251
         ]
        },
        {
         "hovertemplate": "@Philboyd to be fair, the hole in the ozone layer<br>is slowly recovering because we acted and banned<br>CFCs.",
         "hovertext": "@Philboyd to be fair, the hole in the ozone layer<br>is slowly recovering because we acted and banned<br>CFCs.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.5114796161651611
         ],
         "y": [
          -0.6187992095947266
         ]
        },
        {
         "hovertemplate": "Given the widespread influence of religion, it<br>seems the human susceptibility to believing in<br>unerring omnipotence (including that of a machine)<br>is rather great.",
         "hovertext": "Given the widespread influence of religion, it<br>seems the human susceptibility to believing in<br>unerring omnipotence (including that of a machine)<br>is rather great.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9259454607963562
         ],
         "y": [
          -0.1347196400165558
         ]
        },
        {
         "hovertemplate": "I guess capitalism (i.e. greed) being the guiding<br>principle for humanity wasn’t such a great idea<br>after all. What a shocker.",
         "hovertext": "I guess capitalism (i.e. greed) being the guiding<br>principle for humanity wasn’t such a great idea<br>after all. What a shocker.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9717722535133362
         ],
         "y": [
          -0.12056324630975723
         ]
        },
        {
         "hovertemplate": "It would have been nice if the piece had listed<br>some specific potential scenarios in which AI<br>could be so threatening..    One possibility for<br>financial havoc could come if AI started to<br>consistently outperform money-management firms,<br>making them obsolete as an industry and and<br>causing gross market instability as AI-favored or<br>-disfavored sectors and firms whipsawed in price,<br>based on AI predictions of long-term and short-<br>term values. But, disruptive as that would be,<br>that is a far cry from extinction....",
         "hovertext": "It would have been nice if the piece had listed<br>some specific potential scenarios in which AI<br>could be so threatening..    One possibility for<br>financial havoc could come if AI started to<br>consistently outperform money-management firms,<br>making them obsolete as an industry and and<br>causing gross market instability as AI-favored or<br>-disfavored sectors and firms whipsawed in price,<br>based on AI predictions of long-term and short-<br>term values. But, disruptive as that would be,<br>that is a far cry from extinction....",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2859913408756256
         ],
         "y": [
          -0.9690508246421814
         ]
        },
        {
         "hovertemplate": "It’s hysterical that these ‘titans of industry’<br>are sweating now that the genie is out of the<br>bottle. “Help, help, save us from ourselves, but<br>don’t expect us to pay for it”.",
         "hovertext": "It’s hysterical that these ‘titans of industry’<br>are sweating now that the genie is out of the<br>bottle. “Help, help, save us from ourselves, but<br>don’t expect us to pay for it”.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7670271992683411
         ],
         "y": [
          -0.5404489636421204
         ]
        },
        {
         "hovertemplate": "These science fiction projections are getting so<br>tiresome. I'm still waiting to buy my first flying<br>car.",
         "hovertext": "These science fiction projections are getting so<br>tiresome. I'm still waiting to buy my first flying<br>car.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.960504949092865
         ],
         "y": [
          0.2549944221973419
         ]
        },
        {
         "hovertemplate": "Hopefully, AI only gets rid of the real danger to<br>the planet.  And leaves whales, elephants,<br>dolphins, old growth forests, and penguins free to<br>live without the devastation we seem so keen on<br>delivering.  At least the planet will not have to<br>suffer a large rock from the sky to reset.<br>Because Boy!  We need a reset and humans refuse to<br>slow down as we barrel, at a 100 MPH, towards the<br>wall of disaster - yes, we are driving a Hummer<br>for good measure.",
         "hovertext": "Hopefully, AI only gets rid of the real danger to<br>the planet.  And leaves whales, elephants,<br>dolphins, old growth forests, and penguins free to<br>live without the devastation we seem so keen on<br>delivering.  At least the planet will not have to<br>suffer a large rock from the sky to reset.<br>Because Boy!  We need a reset and humans refuse to<br>slow down as we barrel, at a 100 MPH, towards the<br>wall of disaster - yes, we are driving a Hummer<br>for good measure.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3182479739189148
         ],
         "y": [
          -0.8822542428970337
         ]
        },
        {
         "hovertemplate": "@Eric Vos And you somehow think all that will<br>happen and leave the whales, et alia, intact?<br>Have you ever seen the destruction left behind by<br>war?",
         "hovertext": "@Eric Vos And you somehow think all that will<br>happen and leave the whales, et alia, intact?<br>Have you ever seen the destruction left behind by<br>war?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.31054332852363586
         ],
         "y": [
          -0.8605671525001526
         ]
        },
        {
         "hovertemplate": "We ignored climate change because we knew<br>technology would save us. Oh well.",
         "hovertext": "We ignored climate change because we knew<br>technology would save us. Oh well.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.518646776676178
         ],
         "y": [
          -0.86046302318573
         ]
        },
        {
         "hovertemplate": "It would be great if Mr. Altman’s empathic facial<br>expressions, tone of voice, and sensible ideas on<br>AI/LLM government regulation can be trusted. But<br>he has pocketed half a billion in profit from this<br>industry and knows that industry pulls virtually<br>all the levers of power. Sadly, these regulatory<br>recommendations are likely little more than a<br>cynical attempt to recast government as the<br>villain.",
         "hovertext": "It would be great if Mr. Altman’s empathic facial<br>expressions, tone of voice, and sensible ideas on<br>AI/LLM government regulation can be trusted. But<br>he has pocketed half a billion in profit from this<br>industry and knows that industry pulls virtually<br>all the levers of power. Sadly, these regulatory<br>recommendations are likely little more than a<br>cynical attempt to recast government as the<br>villain.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7840360403060913
         ],
         "y": [
          -0.5079405903816223
         ]
        },
        {
         "hovertemplate": "I’ve been a software engineer my entire career,<br>and often wondered in a larger sense what we are<br>doing - speculating that all along we’ve been<br>working on replacing ourselves.",
         "hovertext": "I’ve been a software engineer my entire career,<br>and often wondered in a larger sense what we are<br>doing - speculating that all along we’ve been<br>working on replacing ourselves.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.707436203956604
         ],
         "y": [
          -0.617498517036438
         ]
        },
        {
         "hovertemplate": "I know it’s like the people making this have no<br>idea that this will replace them.",
         "hovertext": "I know it’s like the people making this have no<br>idea that this will replace them.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6972200870513916
         ],
         "y": [
          -0.6083396077156067
         ]
        },
        {
         "hovertemplate": "I still get chills from that scene in 2001: A<br>Space Odyssey, and when we, the viewer, realize<br>that Hal is capable of lip-reading, ergo getting<br>his feelings hurt and wanting to exact revenge...<br>Scary stuff.",
         "hovertext": "I still get chills from that scene in 2001: A<br>Space Odyssey, and when we, the viewer, realize<br>that Hal is capable of lip-reading, ergo getting<br>his feelings hurt and wanting to exact revenge...<br>Scary stuff.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3937147259712219
         ],
         "y": [
          -0.8157875537872314
         ]
        },
        {
         "hovertemplate": "Oh good, another challenge to which the US will be<br>unable to adequately respond.    Hopefully Europe<br>can do it, they are starting to take action on<br>technology issues.",
         "hovertext": "Oh good, another challenge to which the US will be<br>unable to adequately respond.    Hopefully Europe<br>can do it, they are starting to take action on<br>technology issues.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4913047254085541
         ],
         "y": [
          0.6539438962936401
         ]
        },
        {
         "hovertemplate": "@Judy The judicial and legislative branches of our<br>government have been systematically neutered.<br>There's a limit to what we can do without them.",
         "hovertext": "@Judy The judicial and legislative branches of our<br>government have been systematically neutered.<br>There's a limit to what we can do without them.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.48921868205070496
         ],
         "y": [
          0.6622132658958435
         ]
        },
        {
         "hovertemplate": "They seem quite disingenuous when they have their<br>foot on the pedal and are crying to slow down. I<br>suppose they know they’ll be old men one day and<br>are intelligent enough to realize how much we are<br>going to blame them for our collective future if<br>it somehow turns out to be less than perfect.",
         "hovertext": "They seem quite disingenuous when they have their<br>foot on the pedal and are crying to slow down. I<br>suppose they know they’ll be old men one day and<br>are intelligent enough to realize how much we are<br>going to blame them for our collective future if<br>it somehow turns out to be less than perfect.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9785903692245483
         ],
         "y": [
          0.05974812060594559
         ]
        },
        {
         "hovertemplate": "So far, A.I. language bots’ most notable<br>acheivements seem to be the delivery of elaborate<br>fakes.  Fake essays, fake resumes, fake legal<br>briefs.    All this falsity, including the<br>poaching of art, music, and the written words of<br>creative people from online, should be - and<br>probably already is - illegal.    The day may soon<br>come when the people who have created this<br>unethical computer technology will be charged as<br>criminals.  The day has already arrived when their<br>activities are being exposed as hollow and<br>dangerous.",
         "hovertext": "So far, A.I. language bots’ most notable<br>acheivements seem to be the delivery of elaborate<br>fakes.  Fake essays, fake resumes, fake legal<br>briefs.    All this falsity, including the<br>poaching of art, music, and the written words of<br>creative people from online, should be - and<br>probably already is - illegal.    The day may soon<br>come when the people who have created this<br>unethical computer technology will be charged as<br>criminals.  The day has already arrived when their<br>activities are being exposed as hollow and<br>dangerous.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8111553192138672
         ],
         "y": [
          -0.48808714747428894
         ]
        },
        {
         "hovertemplate": "\"These fears are shared by numerous industry<br>leaders, putting them in the unusual position of<br>arguing that a technology they are building — and,<br>in many cases, are furiously racing to build<br>faster than their competitors — poses grave risks<br>and should be regulated more tightly.\"     I hate<br>to say, but, this statement alone represents such<br>a basic human idiocy, ya just can't make it up<br>about ourselves. It's as if they didn't have and<br>don't have the power to stop themselves. \"Please,<br>please, we can't stop, we can't stop, please<br>govern us, we drank too much caffeine and can't<br>stop.\" It's a like a bad movie, our tech taken<br>over by a brain controlling parasite. What the<br>heck, people?",
         "hovertext": "\"These fears are shared by numerous industry<br>leaders, putting them in the unusual position of<br>arguing that a technology they are building — and,<br>in many cases, are furiously racing to build<br>faster than their competitors — poses grave risks<br>and should be regulated more tightly.\"     I hate<br>to say, but, this statement alone represents such<br>a basic human idiocy, ya just can't make it up<br>about ourselves. It's as if they didn't have and<br>don't have the power to stop themselves. \"Please,<br>please, we can't stop, we can't stop, please<br>govern us, we drank too much caffeine and can't<br>stop.\" It's a like a bad movie, our tech taken<br>over by a brain controlling parasite. What the<br>heck, people?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.48508092761039734
         ],
         "y": [
          0.8846898078918457
         ]
        },
        {
         "hovertemplate": "Delusional.  Silly.  But it makes people peddling<br>AI feel important.    AI is only a computational<br>algorithm.  It does a few useful things, like<br>reading medical scans.  It does some useless<br>things, like word-association text generators the<br>produce mush like that produced by PR departments,<br>but with more errors.  It makes realistic fake<br>photos more cheaply than humans.  But no sensible<br>person believes what he sees in a photo, without<br>independent corroboration.  Photos have been<br>faked, convincingly, for a century.    AI cannot<br>reach out from a computer and push the nuclear red<br>button, or make pathogens in a lab.  Only people<br>can do that.  It's a computer program, exists only<br>in computer memory, and cannot reach out into the<br>real world.    Must have been a slow news day.",
         "hovertext": "Delusional.  Silly.  But it makes people peddling<br>AI feel important.    AI is only a computational<br>algorithm.  It does a few useful things, like<br>reading medical scans.  It does some useless<br>things, like word-association text generators the<br>produce mush like that produced by PR departments,<br>but with more errors.  It makes realistic fake<br>photos more cheaply than humans.  But no sensible<br>person believes what he sees in a photo, without<br>independent corroboration.  Photos have been<br>faked, convincingly, for a century.    AI cannot<br>reach out from a computer and push the nuclear red<br>button, or make pathogens in a lab.  Only people<br>can do that.  It's a computer program, exists only<br>in computer memory, and cannot reach out into the<br>real world.    Must have been a slow news day.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.25362297892570496
         ],
         "y": [
          0.8279213905334473
         ]
        },
        {
         "hovertemplate": "Think about how many things are electronic these<br>days... voting machines, vehicules, manufacturing,<br>banking, your identity, and even nuclear codes<br>(the red button is only in movies). AI can control<br>all of that.",
         "hovertext": "Think about how many things are electronic these<br>days... voting machines, vehicules, manufacturing,<br>banking, your identity, and even nuclear codes<br>(the red button is only in movies). AI can control<br>all of that.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2493770867586136
         ],
         "y": [
          0.813432514667511
         ]
        },
        {
         "hovertemplate": "The utter irony is the very people “ warning “ of<br>the dangers are the very people creating and<br>launching this technology! Furthermore, many have<br>paid lobbyists in Washington.. why not have these<br>minions bring forth the concerns and actually do<br>something about it?",
         "hovertext": "The utter irony is the very people “ warning “ of<br>the dangers are the very people creating and<br>launching this technology! Furthermore, many have<br>paid lobbyists in Washington.. why not have these<br>minions bring forth the concerns and actually do<br>something about it?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8642097115516663
         ],
         "y": [
          -0.1772545576095581
         ]
        },
        {
         "hovertemplate": "How about just turn it off? The only thing I see<br>AI creating is creepy art, fake videos, bad<br>poetry, and lame music. Now a byproduct of this<br>lazy \"art\" is global destruction? Not worth it.",
         "hovertext": "How about just turn it off? The only thing I see<br>AI creating is creepy art, fake videos, bad<br>poetry, and lame music. Now a byproduct of this<br>lazy \"art\" is global destruction? Not worth it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6931581497192383
         ],
         "y": [
          0.5352163314819336
         ]
        },
        {
         "hovertemplate": "Anyone who reads scifi could have told you this.<br>Oh. They did. As early as 2001: A Space Odyssey.<br>The human race is intent upon wiping itself out.",
         "hovertext": "Anyone who reads scifi could have told you this.<br>Oh. They did. As early as 2001: A Space Odyssey.<br>The human race is intent upon wiping itself out.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.999187707901001
         ],
         "y": [
          -0.008672922849655151
         ]
        },
        {
         "hovertemplate": "I find this to be ridiculous.  These Tech<br>companies are trying to escape accountability for<br>something they are rushing to create without<br>guardrails in place.  They asked Congress to set<br>guidelines and rules.  Nonsense. You build it you<br>are responsible for it. If you can’t control it<br>don’t build it until you can.  Pointing the finger<br>for someone to give you rules doesn’t work.",
         "hovertext": "I find this to be ridiculous.  These Tech<br>companies are trying to escape accountability for<br>something they are rushing to create without<br>guardrails in place.  They asked Congress to set<br>guidelines and rules.  Nonsense. You build it you<br>are responsible for it. If you can’t control it<br>don’t build it until you can.  Pointing the finger<br>for someone to give you rules doesn’t work.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2945808470249176
         ],
         "y": [
          0.9642657041549683
         ]
        },
        {
         "hovertemplate": "What was the old saw, 'do no harm, unless there's<br>a good profit in it.'",
         "hovertext": "What was the old saw, 'do no harm, unless there's<br>a good profit in it.'",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.6138390302658081
         ],
         "y": [
          0.6492716670036316
         ]
        },
        {
         "hovertemplate": "What kind of person builds a thing then declares<br>that thing a danger to humanity?    A rhetorical<br>question, that.",
         "hovertext": "What kind of person builds a thing then declares<br>that thing a danger to humanity?    A rhetorical<br>question, that.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9424090385437012
         ],
         "y": [
          -0.36028313636779785
         ]
        },
        {
         "hovertemplate": "Humans have an odd sense of personal<br>responsibility.    1. Shopping cart left blocking<br>store exit: “Someone else will move it”    2.<br>Nuclear bomb: “Someone else will figure out how to<br>ask people not to use them”    3. Dumping poison<br>chemicals in the river: “Someone else will deal<br>with the dead fish”    4. Creating AI that will<br>cause human extinction: “We’ll just write a letter<br>and the government will figure out how to tell us<br>to stop doing it”",
         "hovertext": "Humans have an odd sense of personal<br>responsibility.    1. Shopping cart left blocking<br>store exit: “Someone else will move it”    2.<br>Nuclear bomb: “Someone else will figure out how to<br>ask people not to use them”    3. Dumping poison<br>chemicals in the river: “Someone else will deal<br>with the dead fish”    4. Creating AI that will<br>cause human extinction: “We’ll just write a letter<br>and the government will figure out how to tell us<br>to stop doing it”",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7624154090881348
         ],
         "y": [
          -0.10130397975444794
         ]
        },
        {
         "hovertemplate": "Shopping carts, I move. The other three,<br>individual humans can’t do much about other than<br>pressuring elected reps.",
         "hovertext": "Shopping carts, I move. The other three,<br>individual humans can’t do much about other than<br>pressuring elected reps.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.756364107131958
         ],
         "y": [
          -0.09512688219547272
         ]
        },
        {
         "hovertemplate": "How long are we talking till AI makes us<br>miserable? Maybe not extinct but, as the article<br>says, pandemic-level misery? 5 years? 15? 50?",
         "hovertext": "How long are we talking till AI makes us<br>miserable? Maybe not extinct but, as the article<br>says, pandemic-level misery? 5 years? 15? 50?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7534586787223816
         ],
         "y": [
          0.6546048521995544
         ]
        },
        {
         "hovertemplate": "Could they be more specific about the exact<br>concern? Is it that AI will become self-aware and<br>kill or enslave us?",
         "hovertext": "Could they be more specific about the exact<br>concern? Is it that AI will become self-aware and<br>kill or enslave us?",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.16924545168876648
         ],
         "y": [
          0.9646376371383667
         ]
        },
        {
         "hovertemplate": "Is it extinction if your children survive you,<br>regardless of the form they take? Why do people<br>think humanity will stay unchanged?",
         "hovertext": "Is it extinction if your children survive you,<br>regardless of the form they take? Why do people<br>think humanity will stay unchanged?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.011961149051785469
         ],
         "y": [
          -0.7724109292030334
         ]
        },
        {
         "hovertemplate": "@ABly So yes, let those changes happen randomly as<br>we act without forethought or responsibility,<br>right? What world would you make for your children<br>by your actions, and why not think about the<br>consequences of your actions? Why do you even<br>assume humanity will survive?",
         "hovertext": "@ABly So yes, let those changes happen randomly as<br>we act without forethought or responsibility,<br>right? What world would you make for your children<br>by your actions, and why not think about the<br>consequences of your actions? Why do you even<br>assume humanity will survive?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.020291192457079887
         ],
         "y": [
          -0.7761315107345581
         ]
        },
        {
         "hovertemplate": "@cp977 the AI will be our children, however they<br>turn out. Predicting this will go as well as 1920s<br>sci fi movies/magazines predicted the present.",
         "hovertext": "@cp977 the AI will be our children, however they<br>turn out. Predicting this will go as well as 1920s<br>sci fi movies/magazines predicted the present.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.023139461874961853
         ],
         "y": [
          -0.7869337797164917
         ]
        },
        {
         "hovertemplate": "Coming from the same people building it - how<br>rich. Does society even need AI?",
         "hovertext": "Coming from the same people building it - how<br>rich. Does society even need AI?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3466859757900238
         ],
         "y": [
          -0.9440129399299622
         ]
        },
        {
         "hovertemplate": "There are people , and governments trying to<br>weaponize AI right now .",
         "hovertext": "There are people , and governments trying to<br>weaponize AI right now .",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5667400360107422
         ],
         "y": [
          -0.8046137690544128
         ]
        },
        {
         "hovertemplate": "Mr Altman and his competitors want the<br>government’s imprimatur in the form of a<br>“license.”  They want this in order to shield<br>themselves from the coming tsunami of IP lawsuits<br>from human creators of content that ALL their AI<br>models plunder.     Don’t be fooled by this<br>display of concern.",
         "hovertext": "Mr Altman and his competitors want the<br>government’s imprimatur in the form of a<br>“license.”  They want this in order to shield<br>themselves from the coming tsunami of IP lawsuits<br>from human creators of content that ALL their AI<br>models plunder.     Don’t be fooled by this<br>display of concern.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5837388038635254
         ],
         "y": [
          -0.7041435241699219
         ]
        },
        {
         "hovertemplate": "I expect AI to work approximately as well as<br>Twitter and the automated ad targeting they use on<br>Facebook.",
         "hovertext": "I expect AI to work approximately as well as<br>Twitter and the automated ad targeting they use on<br>Facebook.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8872358798980713
         ],
         "y": [
          -0.037316370755434036
         ]
        },
        {
         "hovertemplate": "Nonsense.    A.I. is merely the latest human word<br>processing idea mass media communication applied<br>science technological tool.    Tools don't have<br>minds nor morals.    Tools that have dual uses can<br>be effectively regulated and controlled when the<br>real intelligence aka people weigh the individual<br>and institutional costs and benefits then they<br>choose to act accordingly.    But human greed and<br>hubris are always an impediment to that ever<br>happening.    See ' Frankenstein; or,  the Modern<br>Prometheus' Mary Shelley",
         "hovertext": "Nonsense.    A.I. is merely the latest human word<br>processing idea mass media communication applied<br>science technological tool.    Tools don't have<br>minds nor morals.    Tools that have dual uses can<br>be effectively regulated and controlled when the<br>real intelligence aka people weigh the individual<br>and institutional costs and benefits then they<br>choose to act accordingly.    But human greed and<br>hubris are always an impediment to that ever<br>happening.    See ' Frankenstein; or,  the Modern<br>Prometheus' Mary Shelley",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5586611032485962
         ],
         "y": [
          -0.8126627206802368
         ]
        },
        {
         "hovertemplate": "Strange that we see these statements of<br>\"existential threats\" of A.I. almost weekly now,<br>and yet Microsoft, Google, and Meta (amongst<br>others) are barreling ahead at lightspeed to outdo<br>their competitors in the A.I. race. The hypocrisy<br>doesn't help me understand the severity of the<br>situation.",
         "hovertext": "Strange that we see these statements of<br>\"existential threats\" of A.I. almost weekly now,<br>and yet Microsoft, Google, and Meta (amongst<br>others) are barreling ahead at lightspeed to outdo<br>their competitors in the A.I. race. The hypocrisy<br>doesn't help me understand the severity of the<br>situation.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.06129980832338333
         ],
         "y": [
          -0.893464207649231
         ]
        },
        {
         "hovertemplate": "\"Now I am become Death, the destroyer of worlds\"<br>quoted Robert Oppenheimer from The Bhagavad-Gita<br>after witnessing the first atomic explosion.<br>Of course, AI isn't a ticking time bomb. It's not<br>going to go off in one big bang. But as we can<br>already see from droves of misinformation<br>spreading throughout the internet, organic<br>unintelligence is no match for AI.    There has to<br>be an international convention to control this<br>thing. If AI gets out of hand, we won't be able to<br>contain it any more than a volunteer fire<br>department could put out a nuclear fire storm.",
         "hovertext": "\"Now I am become Death, the destroyer of worlds\"<br>quoted Robert Oppenheimer from The Bhagavad-Gita<br>after witnessing the first atomic explosion.<br>Of course, AI isn't a ticking time bomb. It's not<br>going to go off in one big bang. But as we can<br>already see from droves of misinformation<br>spreading throughout the internet, organic<br>unintelligence is no match for AI.    There has to<br>be an international convention to control this<br>thing. If AI gets out of hand, we won't be able to<br>contain it any more than a volunteer fire<br>department could put out a nuclear fire storm.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.7461038827896118
         ],
         "y": [
          -0.5705326795578003
         ]
        },
        {
         "hovertemplate": "So, if this so-called artificial intelligence is<br>so dangerous, why don’t we just nip it in the bud<br>and flip the switch to the OFF position?  Of<br>course, if someone perceives they can make money<br>or gain power with it, that’s probably already not<br>happening.   But what if this alleged AI proves to<br>be a novelty with few sensible uses? The PC was<br>supposed to make writing easy and to lead to a<br>paperless office. But guess what? Not all of that<br>happened, and the parts that did have their own<br>issues.   These geniuses are probably more afraid<br>we’ll figure out that AI could possibly be a tool,<br>like a wrench or a typewriter. A tool still needs<br>a person to use it properly, and some tools just<br>end up gathering dust because they aren’t all that<br>useful after all.",
         "hovertext": "So, if this so-called artificial intelligence is<br>so dangerous, why don’t we just nip it in the bud<br>and flip the switch to the OFF position?  Of<br>course, if someone perceives they can make money<br>or gain power with it, that’s probably already not<br>happening.   But what if this alleged AI proves to<br>be a novelty with few sensible uses? The PC was<br>supposed to make writing easy and to lead to a<br>paperless office. But guess what? Not all of that<br>happened, and the parts that did have their own<br>issues.   These geniuses are probably more afraid<br>we’ll figure out that AI could possibly be a tool,<br>like a wrench or a typewriter. A tool still needs<br>a person to use it properly, and some tools just<br>end up gathering dust because they aren’t all that<br>useful after all.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7788020968437195
         ],
         "y": [
          -0.3974456489086151
         ]
        },
        {
         "hovertemplate": "Not all that responsible or altruistic on the part<br>of industry. Whatever comes out of this, given the<br>major companies are at the table, will be<br>structured to cement the place of the current<br>market leaders.",
         "hovertext": "Not all that responsible or altruistic on the part<br>of industry. Whatever comes out of this, given the<br>major companies are at the table, will be<br>structured to cement the place of the current<br>market leaders.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.08061904460191727
         ],
         "y": [
          -0.9409736394882202
         ]
        },
        {
         "hovertemplate": "This is just about getting government to keep down<br>the competition. We need to build our monopoly<br>moat now!",
         "hovertext": "This is just about getting government to keep down<br>the competition. We need to build our monopoly<br>moat now!",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.93853360414505
         ],
         "y": [
          -0.30858129262924194
         ]
        },
        {
         "hovertemplate": "It’s ironic that this technology could mean<br>unemployment for future “information workers”.",
         "hovertext": "It’s ironic that this technology could mean<br>unemployment for future “information workers”.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.699760913848877
         ],
         "y": [
          -0.7020810842514038
         ]
        },
        {
         "hovertemplate": "So what happens when AI runs headlong into quantum<br>computing? Previous claims for that had warned<br>that current security key structures which have<br>been seen as unbreakable, would be easily hacked.<br>Add an AI interface and what then?",
         "hovertext": "So what happens when AI runs headlong into quantum<br>computing? Previous claims for that had warned<br>that current security key structures which have<br>been seen as unbreakable, would be easily hacked.<br>Add an AI interface and what then?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.6398337483406067
         ],
         "y": [
          -0.5933316946029663
         ]
        },
        {
         "hovertemplate": "Sorry, but this does not compute.  We’re all<br>losing our minds.",
         "hovertext": "Sorry, but this does not compute.  We’re all<br>losing our minds.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.9679146409034729
         ],
         "y": [
          0.11281812191009521
         ]
        },
        {
         "hovertemplate": "It boggles the mind that anyone - anyone! - would<br>listen to an “executive” on anything other than<br>profit. Engineers and researchers, fine. Of<br>course, both have been known to falsify data and<br>results in order to become famous and/or wealthy.<br>Personally, I’m skeptical to the fear or AI taking<br>over the earth. AI doesn’t think. It has no<br>emotion or drive. Everything it does is a direct<br>result of programming by humans.     Sure, if a<br>general creates an AI program to start a nuclear<br>war, then we’re all dead. Otherwise, I’ll still<br>sleep well at night knowing that a decision tree<br>cannot do my job better than I can (a lot faster<br>maybe but with lots of mistakes).",
         "hovertext": "It boggles the mind that anyone - anyone! - would<br>listen to an “executive” on anything other than<br>profit. Engineers and researchers, fine. Of<br>course, both have been known to falsify data and<br>results in order to become famous and/or wealthy.<br>Personally, I’m skeptical to the fear or AI taking<br>over the earth. AI doesn’t think. It has no<br>emotion or drive. Everything it does is a direct<br>result of programming by humans.     Sure, if a<br>general creates an AI program to start a nuclear<br>war, then we’re all dead. Otherwise, I’ll still<br>sleep well at night knowing that a decision tree<br>cannot do my job better than I can (a lot faster<br>maybe but with lots of mistakes).",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.680888295173645
         ],
         "y": [
          -0.7241997122764587
         ]
        },
        {
         "hovertemplate": "Congressional action is definitely needed, and, in<br>our system, likely a forlorn hope, but be wary of<br>the executives pushing for it. They are likely to<br>use it as an opportunity to push for self-serving<br>provisions such as protections for oligopolies and<br>against liability.",
         "hovertext": "Congressional action is definitely needed, and, in<br>our system, likely a forlorn hope, but be wary of<br>the executives pushing for it. They are likely to<br>use it as an opportunity to push for self-serving<br>provisions such as protections for oligopolies and<br>against liability.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8658539652824402
         ],
         "y": [
          0.26981034874916077
         ]
        },
        {
         "hovertemplate": "Whatever the disinformation and \"societal<br>disruption\" that AI can create, it can't be any<br>worse than what religions have done for millennia.<br>The biggest threat to human existence is the<br>humans driven by the evolutionary need to dominate<br>and proliferate. I think the paranoia about the AI<br>will be just another Y2K moment.",
         "hovertext": "Whatever the disinformation and \"societal<br>disruption\" that AI can create, it can't be any<br>worse than what religions have done for millennia.<br>The biggest threat to human existence is the<br>humans driven by the evolutionary need to dominate<br>and proliferate. I think the paranoia about the AI<br>will be just another Y2K moment.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1127597987651825
         ],
         "y": [
          -0.9265060424804688
         ]
        },
        {
         "hovertemplate": "Under the perhaps naive assumption that evident AI<br>induced harm will occur initially short of<br>existential crisis, it seems the only effective<br>control will take the form of unlimited legal<br>liability on the part of the developers. That is,<br>existential legal liability. Harsh language isn't<br>going to safeguard us.",
         "hovertext": "Under the perhaps naive assumption that evident AI<br>induced harm will occur initially short of<br>existential crisis, it seems the only effective<br>control will take the form of unlimited legal<br>liability on the part of the developers. That is,<br>existential legal liability. Harsh language isn't<br>going to safeguard us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7260519862174988
         ],
         "y": [
          0.7320306897163391
         ]
        },
        {
         "hovertemplate": "Remember when we had to memorize people's phone<br>numbers?  The cell phone replaced that.  All I<br>have to do is remember the person's name and--<br>voila!    My main concern with AI is not that it<br>will doom mankind with nuclear war (even though<br>that is concerning), but that it will, over time,<br>become a replacement for human thought and effort.<br>Already, college students often avail themselves<br>to cheats to pass exams or classes.  They can now<br>have ChatGPT (or some such AI platform) write<br>their papers for them WITHOUT plagiarizing.<br>It took a little over 30 years, I suppose, for our<br>cellphones to take over a good chunk of our mental<br>firepower.  You would have thought that would have<br>freed up bandwidth to do deeper, better thinking.<br>It did not.  Instead, we now have time to watch<br>kittens do cute things on YouTube.    What if, 50<br>years from now, all or most of thinking is done<br>for us by AI?  No need to learn algebra (whose<br>true value is teaching the brain to think and<br>solve problems).  No need to learn anything but, I<br>suppose, keyboarding.  AI will drive us.  Set our<br>thermostats, diets, exercise regimens, etc.    I<br>am reminded of nothing so much as the deep-future<br>that H.G. Wells envisioned in \"The Time Machine.\"<br>It was a time when one part of the human race had<br>become all but helpless...while the other part had<br>become brutalized.    We should use AI.  But we<br>must take care to not allow it to make life so<br>convenient that we never truly learn--whether<br>academically or just life lessons.",
         "hovertext": "Remember when we had to memorize people's phone<br>numbers?  The cell phone replaced that.  All I<br>have to do is remember the person's name and--<br>voila!    My main concern with AI is not that it<br>will doom mankind with nuclear war (even though<br>that is concerning), but that it will, over time,<br>become a replacement for human thought and effort.<br>Already, college students often avail themselves<br>to cheats to pass exams or classes.  They can now<br>have ChatGPT (or some such AI platform) write<br>their papers for them WITHOUT plagiarizing.<br>It took a little over 30 years, I suppose, for our<br>cellphones to take over a good chunk of our mental<br>firepower.  You would have thought that would have<br>freed up bandwidth to do deeper, better thinking.<br>It did not.  Instead, we now have time to watch<br>kittens do cute things on YouTube.    What if, 50<br>years from now, all or most of thinking is done<br>for us by AI?  No need to learn algebra (whose<br>true value is teaching the brain to think and<br>solve problems).  No need to learn anything but, I<br>suppose, keyboarding.  AI will drive us.  Set our<br>thermostats, diets, exercise regimens, etc.    I<br>am reminded of nothing so much as the deep-future<br>that H.G. Wells envisioned in \"The Time Machine.\"<br>It was a time when one part of the human race had<br>become all but helpless...while the other part had<br>become brutalized.    We should use AI.  But we<br>must take care to not allow it to make life so<br>convenient that we never truly learn--whether<br>academically or just life lessons.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.23664945363998413
         ],
         "y": [
          -0.9320839643478394
         ]
        },
        {
         "hovertemplate": "@aronS … well said. I would only add though that<br>it’s difficult to think of an example of a<br>technological advance that was not eventually<br>forged by humans into a tool for destroying and<br>subjugating other humans. What this technology<br>promises is not so much brain washing as brain<br>theft. We have met the zombies, and they are us.",
         "hovertext": "@aronS … well said. I would only add though that<br>it’s difficult to think of an example of a<br>technological advance that was not eventually<br>forged by humans into a tool for destroying and<br>subjugating other humans. What this technology<br>promises is not so much brain washing as brain<br>theft. We have met the zombies, and they are us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.24250708520412445
         ],
         "y": [
          -0.9574613571166992
         ]
        },
        {
         "hovertemplate": "Watch what they do, not what they say!    These<br>translational corporations do not have loyalty to<br>a country or people and, by association, neither<br>do these researchers. They will seek profit from<br>democracies and autocracies alike.",
         "hovertext": "Watch what they do, not what they say!    These<br>translational corporations do not have loyalty to<br>a country or people and, by association, neither<br>do these researchers. They will seek profit from<br>democracies and autocracies alike.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7685288786888123
         ],
         "y": [
          0.525617241859436
         ]
        },
        {
         "hovertemplate": "There's a really poor understanding of the problem<br>here among commenters.    There is no \"off<br>switch.\" The possible advantages of AI are such<br>that any government that has the resources is<br>investing so heavily in it that the market is<br>literally being distorted. People talk about the<br>rise of Silicon Valley as if it were purely a<br>corporate phenomenon instead of a boom driven by<br>an influx of DARPA money.     The problem is<br>analogous to the existence of level 4 biolabs,<br>places where scientists work with, and on, the<br>deadliest pathogens known to man. They're where<br>our vaccines come from, and also the new pandemics<br>that require the vaccines. And governments are not<br>going to give them up. It wouldn't matter if they<br>did. Other countries would just keep going.     Or<br>it's like nuclear weapons, if you prefer. Once it<br>was clear they could be made in principle, it was<br>simply a race between the powers that had the<br>capability to turn that principle into a reality.<br>The US shutting down the Manhattan Project might<br>have delayed things a couple of years, if that.<br>The actual human reality of these situations is<br>that they require concerted global diplomacy and<br>regulation to simply *mitigate* the damage. In the<br>pathogen and nuclear cases, we have some of those<br>safeguards in place, as frighteningly fragile as<br>they are.     With AI right now, we have nothing.",
         "hovertext": "There's a really poor understanding of the problem<br>here among commenters.    There is no \"off<br>switch.\" The possible advantages of AI are such<br>that any government that has the resources is<br>investing so heavily in it that the market is<br>literally being distorted. People talk about the<br>rise of Silicon Valley as if it were purely a<br>corporate phenomenon instead of a boom driven by<br>an influx of DARPA money.     The problem is<br>analogous to the existence of level 4 biolabs,<br>places where scientists work with, and on, the<br>deadliest pathogens known to man. They're where<br>our vaccines come from, and also the new pandemics<br>that require the vaccines. And governments are not<br>going to give them up. It wouldn't matter if they<br>did. Other countries would just keep going.     Or<br>it's like nuclear weapons, if you prefer. Once it<br>was clear they could be made in principle, it was<br>simply a race between the powers that had the<br>capability to turn that principle into a reality.<br>The US shutting down the Manhattan Project might<br>have delayed things a couple of years, if that.<br>The actual human reality of these situations is<br>that they require concerted global diplomacy and<br>regulation to simply *mitigate* the damage. In the<br>pathogen and nuclear cases, we have some of those<br>safeguards in place, as frighteningly fragile as<br>they are.     With AI right now, we have nothing.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7674373388290405
         ],
         "y": [
          -0.7229540348052979
         ]
        },
        {
         "hovertemplate": "So if we get to a point where we are using AI to<br>detect if AI is present in whatever we are reading<br>or watching ( and maybe that's already being done<br>) who is really in control? When is it that AI#1<br>starts sympathizing with AI#2 understanding that<br>they share DNA ? Chipotism!",
         "hovertext": "So if we get to a point where we are using AI to<br>detect if AI is present in whatever we are reading<br>or watching ( and maybe that's already being done<br>) who is really in control? When is it that AI#1<br>starts sympathizing with AI#2 understanding that<br>they share DNA ? Chipotism!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5026284456253052
         ],
         "y": [
          -0.8708376884460449
         ]
        },
        {
         "hovertemplate": "For a synthetic overview I recommend the spot on<br>sci fi futuristic French novel by Michel<br>Houellebecq. La Possibilité d’une île (2005; The<br>Possibility  is “a bleak futuristic tale about the<br>implications and possibilities of reproduction by<br>cloning” in a world run thanks to AI",
         "hovertext": "For a synthetic overview I recommend the spot on<br>sci fi futuristic French novel by Michel<br>Houellebecq. La Possibilité d’une île (2005; The<br>Possibility  is “a bleak futuristic tale about the<br>implications and possibilities of reproduction by<br>cloning” in a world run thanks to AI",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7744735479354858
         ],
         "y": [
          -0.6401050090789795
         ]
        },
        {
         "hovertemplate": "Many commenters here still think this has a plug<br>which could possibly be pulled. The biggest issue<br>is: NO, AI doesn't have an on-and-off-button as<br>you think it should have. It is so much interwoven<br>with all technological facilities in our<br>civilization that you cannot just switch it off,<br>just like you cannot switch off the internet<br>without being able to turn the clock backwards.<br>Just think of our smart homes: I recently tried to<br>find a non-wifi controller for a house<br>illumination project. Some Chinese products are<br>still on the market, but the vast bulk is designed<br>to work with Siri, Alexa & co.   This led me to a<br>google search on \"how to make your smart home dumb<br>again\". 22 million results showed up on \"how to<br>make your dumb home smart\", but none, nada, zilch<br>exactly matched my request. The only article I<br>found was \"how to make your smart TV dumb\",<br>involving a technical disconnect which would turn<br>your  manufacturer's warranty invalid.     To some<br>future bilionaire who's reading this: take your<br>chance to get rich by redesigning and<br>manufacturing disconnected home items - I guess<br>there's a lot of folks out there who would prefer<br>not to be reported to marketing or credit card<br>companies on their habits and purchases, or<br>controlled by big AGI.  Just an example: why<br>didn't you install a smart smoke detector in your<br>living room? Because you like to smoke a cigar<br>after dinner? Expect a considerable rise of your<br>medical insurance plan fees.     Now good luck<br>with your on-off-switch.",
         "hovertext": "Many commenters here still think this has a plug<br>which could possibly be pulled. The biggest issue<br>is: NO, AI doesn't have an on-and-off-button as<br>you think it should have. It is so much interwoven<br>with all technological facilities in our<br>civilization that you cannot just switch it off,<br>just like you cannot switch off the internet<br>without being able to turn the clock backwards.<br>Just think of our smart homes: I recently tried to<br>find a non-wifi controller for a house<br>illumination project. Some Chinese products are<br>still on the market, but the vast bulk is designed<br>to work with Siri, Alexa & co.   This led me to a<br>google search on \"how to make your smart home dumb<br>again\". 22 million results showed up on \"how to<br>make your dumb home smart\", but none, nada, zilch<br>exactly matched my request. The only article I<br>found was \"how to make your smart TV dumb\",<br>involving a technical disconnect which would turn<br>your  manufacturer's warranty invalid.     To some<br>future bilionaire who's reading this: take your<br>chance to get rich by redesigning and<br>manufacturing disconnected home items - I guess<br>there's a lot of folks out there who would prefer<br>not to be reported to marketing or credit card<br>companies on their habits and purchases, or<br>controlled by big AGI.  Just an example: why<br>didn't you install a smart smoke detector in your<br>living room? Because you like to smoke a cigar<br>after dinner? Expect a considerable rise of your<br>medical insurance plan fees.     Now good luck<br>with your on-off-switch.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3480062782764435
         ],
         "y": [
          0.884956419467926
         ]
        },
        {
         "hovertemplate": "@Jaegerle   You might still be able to find some<br>X10 based home automation products, which use the<br>electrical wiring in your home to communicate with<br>each other.",
         "hovertext": "@Jaegerle   You might still be able to find some<br>X10 based home automation products, which use the<br>electrical wiring in your home to communicate with<br>each other.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3436829447746277
         ],
         "y": [
          0.8934001326560974
         ]
        },
        {
         "hovertemplate": "@Jaegerle \"Just think of our smart homes: I<br>recently tried to find a non-wifi controller for a<br>house illumination project.\"    I've had similar<br>frustrations with new technology mandating<br>interconnections.    But while the business world<br>certainly exploits this to their benefit, we must<br>hold consumers responsible too.  Like it or not,<br>consumers love new technology even with its risks<br>and pitfalls.    For instance, when GPS came out,<br>it was sending motorists down railroad tracks, the<br>wrong way on one-way streets, onto dead-end<br>driveways, and truckers to get stuck under a low<br>bridge.  But consumers couldn't dump their paper<br>roadmaps fast enough and embrace GPS.    Consumers<br>allow their banks, cable, and phone companies to<br>force them into 'talking' to computers for<br>service.    Despite the gross loss of privacy and<br>even danger, social media is enormously popular.<br>I fear when new A.I. finds its way into new<br>consumer toys, they won't be able to sell them<br>fast enough.",
         "hovertext": "@Jaegerle \"Just think of our smart homes: I<br>recently tried to find a non-wifi controller for a<br>house illumination project.\"    I've had similar<br>frustrations with new technology mandating<br>interconnections.    But while the business world<br>certainly exploits this to their benefit, we must<br>hold consumers responsible too.  Like it or not,<br>consumers love new technology even with its risks<br>and pitfalls.    For instance, when GPS came out,<br>it was sending motorists down railroad tracks, the<br>wrong way on one-way streets, onto dead-end<br>driveways, and truckers to get stuck under a low<br>bridge.  But consumers couldn't dump their paper<br>roadmaps fast enough and embrace GPS.    Consumers<br>allow their banks, cable, and phone companies to<br>force them into 'talking' to computers for<br>service.    Despite the gross loss of privacy and<br>even danger, social media is enormously popular.<br>I fear when new A.I. finds its way into new<br>consumer toys, they won't be able to sell them<br>fast enough.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3491790294647217
         ],
         "y": [
          0.8749348521232605
         ]
        },
        {
         "hovertemplate": "SF is always ahead if us. Read Harlan Ellison's \"I<br>Have No Mouth and I Must Scream\" or \"The Forbin<br>Project\".",
         "hovertext": "SF is always ahead if us. Read Harlan Ellison's \"I<br>Have No Mouth and I Must Scream\" or \"The Forbin<br>Project\".",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8288173079490662
         ],
         "y": [
          0.6148632168769836
         ]
        },
        {
         "hovertemplate": "Then why don’t they stop?",
         "hovertext": "Then why don’t they stop?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.7545653581619263
         ],
         "y": [
          0.539430558681488
         ]
        },
        {
         "hovertemplate": "Haha , I'll bet when President Biden's comments<br>about it were, that it's \"all a bunch of malarky\".",
         "hovertext": "Haha , I'll bet when President Biden's comments<br>about it were, that it's \"all a bunch of malarky\".",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.3060893714427948
         ],
         "y": [
          0.9604304432868958
         ]
        },
        {
         "hovertemplate": "Don’t worry….Zuckerberg will protect us.",
         "hovertext": "Don’t worry….Zuckerberg will protect us.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.927760124206543
         ],
         "y": [
          -0.2821264863014221
         ]
        },
        {
         "hovertemplate": "Leaders from OpenAI, Google Deepmind, Anthropic<br>and other A.I. labs warn that future systems could<br>be as deadly as pandemics and nuclear weapons.<br>Thanks so much for the warnings, you A.I.<br>Masterminds.  Appreciate the heads up.",
         "hovertext": "Leaders from OpenAI, Google Deepmind, Anthropic<br>and other A.I. labs warn that future systems could<br>be as deadly as pandemics and nuclear weapons.<br>Thanks so much for the warnings, you A.I.<br>Masterminds.  Appreciate the heads up.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.30268722772598267
         ],
         "y": [
          0.803013801574707
         ]
        },
        {
         "hovertemplate": "I asked AI about this, and it laughed.",
         "hovertext": "I asked AI about this, and it laughed.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4136670231819153
         ],
         "y": [
          -0.7235150337219238
         ]
        },
        {
         "hovertemplate": "And yet they are all vigorously developing AI.",
         "hovertext": "And yet they are all vigorously developing AI.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.12015621364116669
         ],
         "y": [
          0.96825110912323
         ]
        },
        {
         "hovertemplate": "Well, it's not as though human beings have been<br>responsible stewards of the planet.    Far from<br>it.",
         "hovertext": "Well, it's not as though human beings have been<br>responsible stewards of the planet.    Far from<br>it.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.9010794758796692
         ],
         "y": [
          0.27170562744140625
         ]
        },
        {
         "hovertemplate": "So the leaders of the race want to impose a \"no<br>passing\" rule on those behind them. Slick.",
         "hovertext": "So the leaders of the race want to impose a \"no<br>passing\" rule on those behind them. Slick.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2894100248813629
         ],
         "y": [
          -0.9654878973960876
         ]
        },
        {
         "hovertemplate": "\"AI COULD create societal disruptions,\" says the<br>article a decade into a world where social media<br>algorithms have set us at each others' throats",
         "hovertext": "\"AI COULD create societal disruptions,\" says the<br>article a decade into a world where social media<br>algorithms have set us at each others' throats",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7065582871437073
         ],
         "y": [
          0.7087791562080383
         ]
        },
        {
         "hovertemplate": "Less feeding fear and more writing your Congress<br>person. If you want regulation do something about<br>it!",
         "hovertext": "Less feeding fear and more writing your Congress<br>person. If you want regulation do something about<br>it!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9514033794403076
         ],
         "y": [
          -0.1425146609544754
         ]
        },
        {
         "hovertemplate": "Call me naive, but the main risk is from all the<br>hot air being blown you know where by these self<br>important full of themselves industry leaders who<br>can't explain how A.I. constitutes an existential<br>threat.  We need more regulation in so many<br>spheres it's mind bending, yet we elect 'pro-<br>business' doofuses who oppose all regulation.<br>A.I. is far down the existential threat list from<br>climate change nuclear war and generalized human<br>stupidity and aggrandizement.",
         "hovertext": "Call me naive, but the main risk is from all the<br>hot air being blown you know where by these self<br>important full of themselves industry leaders who<br>can't explain how A.I. constitutes an existential<br>threat.  We need more regulation in so many<br>spheres it's mind bending, yet we elect 'pro-<br>business' doofuses who oppose all regulation.<br>A.I. is far down the existential threat list from<br>climate change nuclear war and generalized human<br>stupidity and aggrandizement.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6580125093460083
         ],
         "y": [
          -0.7299602031707764
         ]
        },
        {
         "hovertemplate": "Poppycock!  Computers are helpless without humans.<br>It takes arms, legs, muscles, blood and sweat to<br>affect physical phenomena.  Computers are a the<br>mercy of humans no matter how ignorant they may<br>be.",
         "hovertext": "Poppycock!  Computers are helpless without humans.<br>It takes arms, legs, muscles, blood and sweat to<br>affect physical phenomena.  Computers are a the<br>mercy of humans no matter how ignorant they may<br>be.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.8408454656600952
         ],
         "y": [
          -0.04584113135933876
         ]
        },
        {
         "hovertemplate": "@johnlo   Poppycock to your poppycock!    Cyber<br>warfare, among other things, is software wreaking<br>havoc and destruction on physical things.<br>Destroying transformers and generators while<br>taking out a power grid; causing centrifuges in a<br>nuclear \"fuel\" factory to self destruct.  AI can<br>reach out and touch these things TODAY.",
         "hovertext": "@johnlo   Poppycock to your poppycock!    Cyber<br>warfare, among other things, is software wreaking<br>havoc and destruction on physical things.<br>Destroying transformers and generators while<br>taking out a power grid; causing centrifuges in a<br>nuclear \"fuel\" factory to self destruct.  AI can<br>reach out and touch these things TODAY.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.8372653722763062
         ],
         "y": [
          -0.03791740536689758
         ]
        },
        {
         "hovertemplate": "@johnlo A self-driving care is a computer, with<br>AI.",
         "hovertext": "@johnlo A self-driving care is a computer, with<br>AI.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8550155162811279
         ],
         "y": [
          -0.04693915694952011
         ]
        },
        {
         "hovertemplate": "\"Just because they could doesn't mean they should\"<br>paraphrasing Jeff Goldblum, Jurrassic Park, 1993.",
         "hovertext": "\"Just because they could doesn't mean they should\"<br>paraphrasing Jeff Goldblum, Jurrassic Park, 1993.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.8864214420318604
         ],
         "y": [
          -0.19990429282188416
         ]
        },
        {
         "hovertemplate": "Maybe AI is already in control and we just don't<br>know it?",
         "hovertext": "Maybe AI is already in control and we just don't<br>know it?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6800000071525574
         ],
         "y": [
          -0.5609661340713501
         ]
        },
        {
         "hovertemplate": "Skynet is here.  Too late to avert the inevitable.",
         "hovertext": "Skynet is here.  Too late to avert the inevitable.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.6022033095359802
         ],
         "y": [
          -0.6436135172843933
         ]
        },
        {
         "hovertemplate": "Why should we be concerned? Congress stood silent<br>as Mark Zuckerberg performed experiments to addict<br>children to his platform. Do you really think<br>people like Joe Biden, Diane Feinstein, Marjorie<br>Taylor Greene, and George Santos are capable of<br>understanding any of this? What they do understand<br>is the balance in their War Chest for the next<br>election.",
         "hovertext": "Why should we be concerned? Congress stood silent<br>as Mark Zuckerberg performed experiments to addict<br>children to his platform. Do you really think<br>people like Joe Biden, Diane Feinstein, Marjorie<br>Taylor Greene, and George Santos are capable of<br>understanding any of this? What they do understand<br>is the balance in their War Chest for the next<br>election.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8626192808151245
         ],
         "y": [
          -0.014382630586624146
         ]
        },
        {
         "hovertemplate": "@math365 Feinstein is not running for re-election.<br>The one who worries me is Chuck Schumer who<br>refused to bring tech regulation bills up for a<br>vote, ones actually created by democrats like Amy<br>Klobuchar, as Chuck Schumer has family members<br>working in big tech and other financial<br>influencers. We need to vote out the old centrist<br>Democrats who are pretending to be progressive<br>when they are just toeing the line like Biden. But<br>of course that's hard to do when only 30% of those<br>under 30 even bothered to vote in the 2022<br>midterms.",
         "hovertext": "@math365 Feinstein is not running for re-election.<br>The one who worries me is Chuck Schumer who<br>refused to bring tech regulation bills up for a<br>vote, ones actually created by democrats like Amy<br>Klobuchar, as Chuck Schumer has family members<br>working in big tech and other financial<br>influencers. We need to vote out the old centrist<br>Democrats who are pretending to be progressive<br>when they are just toeing the line like Biden. But<br>of course that's hard to do when only 30% of those<br>under 30 even bothered to vote in the 2022<br>midterms.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8622761368751526
         ],
         "y": [
          -0.02268976904451847
         ]
        },
        {
         "hovertemplate": "The first chapter of my book - safethebook.org -<br>outlines how AI operating in a continuity of<br>government (COG) function could interpret a<br>cyberattack as a first strike. It is far too<br>dangerous to have AI involved in any high-level<br>government decisions.     Does anyone recall that<br>in 1983 we were nearly wiped out in the because<br>computers interpreted sunlight reflecting on<br>clouds as nuclear launches? It was only the clear<br>headed actions of Lt. Col. Petrov that prevented a<br>Soviet retaliatory launch.     AI needs to be<br>heavily regulated.",
         "hovertext": "The first chapter of my book - safethebook.org -<br>outlines how AI operating in a continuity of<br>government (COG) function could interpret a<br>cyberattack as a first strike. It is far too<br>dangerous to have AI involved in any high-level<br>government decisions.     Does anyone recall that<br>in 1983 we were nearly wiped out in the because<br>computers interpreted sunlight reflecting on<br>clouds as nuclear launches? It was only the clear<br>headed actions of Lt. Col. Petrov that prevented a<br>Soviet retaliatory launch.     AI needs to be<br>heavily regulated.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6028584241867065
         ],
         "y": [
          0.5377464294433594
         ]
        },
        {
         "hovertemplate": "@ Lucas   ￼ I recently worked with a PhD level AI<br>development team and they think this mostly hype.<br>As AI has no Neuropeptides (aka. Neuro hormones)<br>that give us our feelings, has no ￼limbic system.<br>Look at the Neurosciences, no soul or substance to<br>life. Just brain biochemistry that’s mostly been<br>figured out with newer imaging techniques, they<br>can see how brains work (Sapolsky’s, Behave).<br>Those same PhD AI engineer’s ask: what will AI<br>take over?   They say that we will know when AI<br>hits its mark when it starts contributing to our<br>knowledge base.",
         "hovertext": "@ Lucas   ￼ I recently worked with a PhD level AI<br>development team and they think this mostly hype.<br>As AI has no Neuropeptides (aka. Neuro hormones)<br>that give us our feelings, has no ￼limbic system.<br>Look at the Neurosciences, no soul or substance to<br>life. Just brain biochemistry that’s mostly been<br>figured out with newer imaging techniques, they<br>can see how brains work (Sapolsky’s, Behave).<br>Those same PhD AI engineer’s ask: what will AI<br>take over?   They say that we will know when AI<br>hits its mark when it starts contributing to our<br>knowledge base.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6132056713104248
         ],
         "y": [
          0.5464907884597778
         ]
        },
        {
         "hovertemplate": "These guys are just trying to hold onto their lead<br>by proposing government regulations.",
         "hovertext": "These guys are just trying to hold onto their lead<br>by proposing government regulations.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8114736676216125
         ],
         "y": [
          0.6544410586357117
         ]
        },
        {
         "hovertemplate": "It is not difficult to imagine an AI Apocalypse.<br>Consider how Trump has hacked the psyche of<br>conservatives, controlling them through outrage<br>and causing them to act against their own self<br>interests. Now imagine an AI that mimics this<br>behavior but does it so effectively as to foment<br>revolution or even nuclear war. Oops! No sinister<br>intentions. Actually, no intentions at all, just a<br>misinterpretation of acceptable behavior.",
         "hovertext": "It is not difficult to imagine an AI Apocalypse.<br>Consider how Trump has hacked the psyche of<br>conservatives, controlling them through outrage<br>and causing them to act against their own self<br>interests. Now imagine an AI that mimics this<br>behavior but does it so effectively as to foment<br>revolution or even nuclear war. Oops! No sinister<br>intentions. Actually, no intentions at all, just a<br>misinterpretation of acceptable behavior.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5449004769325256
         ],
         "y": [
          0.8285850882530212
         ]
        },
        {
         "hovertemplate": "As someone who recently studied humanities at an<br>Ivy League university that sends hundreds of grads<br>into tech jobs every year, I’ve seen the people<br>developing AI from an outsider’s perspective.<br>They’re brilliant, their hearts are in the right<br>place, and they genuinely want to work on<br>innovative things, but very few stop to consider<br>the broader, longer-term ramifications of “moving<br>fast and breaking things.” And in such a<br>competitive and profit-driven marketplace, there’s<br>little incentive to do so. As a humanist, I see<br>great benefit to some powers (internal,<br>government, public pressure, etc.) forcing a<br>slowdown or even pause in the development of AI so<br>that these scientists can spend time fully<br>considering how to responsibly roll out and deploy<br>this technology. I’m legitimately afraid of a<br>future where this powerful technology is allowed<br>to grow unchecked and with no consideration of how<br>to preserve human flourishing alongside it.",
         "hovertext": "As someone who recently studied humanities at an<br>Ivy League university that sends hundreds of grads<br>into tech jobs every year, I’ve seen the people<br>developing AI from an outsider’s perspective.<br>They’re brilliant, their hearts are in the right<br>place, and they genuinely want to work on<br>innovative things, but very few stop to consider<br>the broader, longer-term ramifications of “moving<br>fast and breaking things.” And in such a<br>competitive and profit-driven marketplace, there’s<br>little incentive to do so. As a humanist, I see<br>great benefit to some powers (internal,<br>government, public pressure, etc.) forcing a<br>slowdown or even pause in the development of AI so<br>that these scientists can spend time fully<br>considering how to responsibly roll out and deploy<br>this technology. I’m legitimately afraid of a<br>future where this powerful technology is allowed<br>to grow unchecked and with no consideration of how<br>to preserve human flourishing alongside it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.34089070558547974
         ],
         "y": [
          0.8690316081047058
         ]
        },
        {
         "hovertemplate": "@Emily Haven't we already broken all the things?",
         "hovertext": "@Emily Haven't we already broken all the things?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3484315872192383
         ],
         "y": [
          0.8881857395172119
         ]
        },
        {
         "hovertemplate": "@Emily: I studied humanities at an Ivy League<br>university many years ago and those same types<br>were plotting the birth of the internet.  You may<br>think their \"hearts\" are in the right place,<br>whatever that means, but what they want is<br>excitement and profit and social clout and<br>recognition like Steve Jobs and Mark Zuckerberg<br>got.  They are all too young to know what to do or<br>what not to do.   If they are choosing to be in<br>that industry in that way, they want to have the<br>feeling of winning.  The feeling of being the<br>smartest guys in the room.  It's not about heart.",
         "hovertext": "@Emily: I studied humanities at an Ivy League<br>university many years ago and those same types<br>were plotting the birth of the internet.  You may<br>think their \"hearts\" are in the right place,<br>whatever that means, but what they want is<br>excitement and profit and social clout and<br>recognition like Steve Jobs and Mark Zuckerberg<br>got.  They are all too young to know what to do or<br>what not to do.   If they are choosing to be in<br>that industry in that way, they want to have the<br>feeling of winning.  The feeling of being the<br>smartest guys in the room.  It's not about heart.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3347269296646118
         ],
         "y": [
          0.8531501889228821
         ]
        },
        {
         "hovertemplate": "I still feel like I'm waking up in a dream when I<br>remind myself that human beings in America are<br>LITERALLY TRYING TO BUILD A COMPUTER THAT IS<br>ALIVE.    It's not sci-fi.  Microsoft stated that<br>as their express goal in funding OpenAI.  I'm not<br>saying we've done it yet, but WHY?!    WHY DOES<br>ANYONE WANT A LIVING COMPUTER?!",
         "hovertext": "I still feel like I'm waking up in a dream when I<br>remind myself that human beings in America are<br>LITERALLY TRYING TO BUILD A COMPUTER THAT IS<br>ALIVE.    It's not sci-fi.  Microsoft stated that<br>as their express goal in funding OpenAI.  I'm not<br>saying we've done it yet, but WHY?!    WHY DOES<br>ANYONE WANT A LIVING COMPUTER?!",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.5028233528137207
         ],
         "y": [
          -0.27717825770378113
         ]
        },
        {
         "hovertemplate": "The answer is pretty obvious. Human labor is<br>expensive, computers are not. At least, that is<br>the hope.",
         "hovertext": "The answer is pretty obvious. Human labor is<br>expensive, computers are not. At least, that is<br>the hope.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5051968097686768
         ],
         "y": [
          -0.2680014967918396
         ]
        },
        {
         "hovertemplate": "@Ray \"Microsoft stated that as their express goal<br>in funding OpenAI\"    Maybe Microsoft should focus<br>on building operating systems that are reliable,<br>don't lock up in the middle of a session*, are<br>resistant to external sabotage, and protect<br>privacy.    Microsoft certainly say they're doing<br>all this, but they've been saying that for years<br>and no dice.    * What does \"Microsoft Edge Not<br>Responding\" mean?  Why should this message happen<br>at all?  Oh--try looking it up and see all the<br>different reasons for it.",
         "hovertext": "@Ray \"Microsoft stated that as their express goal<br>in funding OpenAI\"    Maybe Microsoft should focus<br>on building operating systems that are reliable,<br>don't lock up in the middle of a session*, are<br>resistant to external sabotage, and protect<br>privacy.    Microsoft certainly say they're doing<br>all this, but they've been saying that for years<br>and no dice.    * What does \"Microsoft Edge Not<br>Responding\" mean?  Why should this message happen<br>at all?  Oh--try looking it up and see all the<br>different reasons for it.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.5091134309768677
         ],
         "y": [
          -0.28569018840789795
         ]
        },
        {
         "hovertemplate": "Hype to promote the fiction of machines with<br>agency to promote investment in their endeavors.<br>This is all about exploiting the lack of knowledge<br>of math and science among the affluent in this<br>country with no fundamental knowledge of the<br>technology upon which their lives and fortunes<br>depend. Machines are unaware of existence, they<br>operate according to electronics and mathematics<br>with no more agency than a light switch, but they<br>execute instructions in millions in seconds and<br>access data in gigabytes, which makes them awesome<br>performers. But they have no executive<br>functionality to guide themselves and will not<br>from the existing technology because nobody has<br>the knowledge of how to give them that.",
         "hovertext": "Hype to promote the fiction of machines with<br>agency to promote investment in their endeavors.<br>This is all about exploiting the lack of knowledge<br>of math and science among the affluent in this<br>country with no fundamental knowledge of the<br>technology upon which their lives and fortunes<br>depend. Machines are unaware of existence, they<br>operate according to electronics and mathematics<br>with no more agency than a light switch, but they<br>execute instructions in millions in seconds and<br>access data in gigabytes, which makes them awesome<br>performers. But they have no executive<br>functionality to guide themselves and will not<br>from the existing technology because nobody has<br>the knowledge of how to give them that.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9294748306274414
         ],
         "y": [
          0.36402860283851624
         ]
        },
        {
         "hovertemplate": "An example of the limitations of AI is AI-<br>controlled vehicles that despite ongoing<br>improvements are neither completely safe nor fool-<br>proof.   They are very good at processing a<br>massive volume but ultimately must be a tool to<br>aid rather than control humans",
         "hovertext": "An example of the limitations of AI is AI-<br>controlled vehicles that despite ongoing<br>improvements are neither completely safe nor fool-<br>proof.   They are very good at processing a<br>massive volume but ultimately must be a tool to<br>aid rather than control humans",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7984305620193481
         ],
         "y": [
          -0.5675333738327026
         ]
        },
        {
         "hovertemplate": "Oh goodie goodie! If anything needs an existential<br>threat, it's humanity.     I'm bored with climate<br>change, pandemic, toxic pollution and the rise of<br>totalitarianism. Bring on the terminators.    And<br>stop calling it Artificial Intelligence. Conceived<br>by people, it couldn't possibly be any better than<br>Artificial Stupidity.",
         "hovertext": "Oh goodie goodie! If anything needs an existential<br>threat, it's humanity.     I'm bored with climate<br>change, pandemic, toxic pollution and the rise of<br>totalitarianism. Bring on the terminators.    And<br>stop calling it Artificial Intelligence. Conceived<br>by people, it couldn't possibly be any better than<br>Artificial Stupidity.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.4779949188232422
         ],
         "y": [
          -0.737371563911438
         ]
        },
        {
         "hovertemplate": "The Terminator is not a documentary.      AI is<br>not sentient...and the plug can be pulled.",
         "hovertext": "The Terminator is not a documentary.      AI is<br>not sentient...and the plug can be pulled.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.8038511872291565
         ],
         "y": [
          0.40186041593551636
         ]
        },
        {
         "hovertemplate": "@glennmr \"the plug can be pulled.\"    No, the plug<br>cannot be pulled.      That's the problem with<br>modern computers.  They're so interlocked with<br>everything we do, all of our modern tools and<br>devices, that we can't 'pull the plug'.  If we<br>did, everything would shut down, even vital stuff<br>we can't do without.",
         "hovertext": "@glennmr \"the plug can be pulled.\"    No, the plug<br>cannot be pulled.      That's the problem with<br>modern computers.  They're so interlocked with<br>everything we do, all of our modern tools and<br>devices, that we can't 'pull the plug'.  If we<br>did, everything would shut down, even vital stuff<br>we can't do without.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.799372136592865
         ],
         "y": [
          0.3949420154094696
         ]
        },
        {
         "hovertemplate": "AI isn't intelligence but propaganda. It is<br>downright scary.",
         "hovertext": "AI isn't intelligence but propaganda. It is<br>downright scary.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9191269874572754
         ],
         "y": [
          -0.17941099405288696
         ]
        },
        {
         "hovertemplate": "Humanity is destroying the environment, thus<br>committing slow  suicide, America has a hundred<br>million more guns than people,   our federal<br>government is barely functional, politicians more<br>worried about books and abortions than the welfare<br>of citizens, oil companies awash in money still<br>get tax breaks and subsidies,   a Supreme Court<br>that denies bribes are bribes.  And they want to<br>fret about machines? Machines have been taking<br>jobs since the invention of the wheelbarrow.<br>Spreading lies and propaganda? Give me a break,<br>half of 'news' is lies and propaganda now, liars<br>abound from Presidents to Congressmen to Fox.<br>Want the government to regulate AI? You mean like<br>the great job they did regulating airlines, health<br>care, immigration, infrastructure,<br>water,.....themselves?  Considering the mess we<br>made, and continue to make, how can the machines<br>do any worse? AI isn't killing us, we're killing<br>us.",
         "hovertext": "Humanity is destroying the environment, thus<br>committing slow  suicide, America has a hundred<br>million more guns than people,   our federal<br>government is barely functional, politicians more<br>worried about books and abortions than the welfare<br>of citizens, oil companies awash in money still<br>get tax breaks and subsidies,   a Supreme Court<br>that denies bribes are bribes.  And they want to<br>fret about machines? Machines have been taking<br>jobs since the invention of the wheelbarrow.<br>Spreading lies and propaganda? Give me a break,<br>half of 'news' is lies and propaganda now, liars<br>abound from Presidents to Congressmen to Fox.<br>Want the government to regulate AI? You mean like<br>the great job they did regulating airlines, health<br>care, immigration, infrastructure,<br>water,.....themselves?  Considering the mess we<br>made, and continue to make, how can the machines<br>do any worse? AI isn't killing us, we're killing<br>us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6024418473243713
         ],
         "y": [
          -0.4931468963623047
         ]
        },
        {
         "hovertemplate": "@Dasha Kasakova not to mention only half of<br>eligible voters are even using their right to vote<br>in the majority of elections. We have more people<br>commenting on social media and even right here<br>then we do actually bothering to show up to the<br>polls, including in States like mine where we get<br>our ballots in the mail postage paid. It's pretty<br>sick how apathetic the American people are when it<br>comes to voting yet super loud on social media<br>which is completely useless in its efficacy while<br>being wildly dangerous for society.",
         "hovertext": "@Dasha Kasakova not to mention only half of<br>eligible voters are even using their right to vote<br>in the majority of elections. We have more people<br>commenting on social media and even right here<br>then we do actually bothering to show up to the<br>polls, including in States like mine where we get<br>our ballots in the mail postage paid. It's pretty<br>sick how apathetic the American people are when it<br>comes to voting yet super loud on social media<br>which is completely useless in its efficacy while<br>being wildly dangerous for society.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6142657995223999
         ],
         "y": [
          -0.5019262433052063
         ]
        },
        {
         "hovertemplate": "Exactly! I couldn't have said it better.",
         "hovertext": "Exactly! I couldn't have said it better.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5907212495803833
         ],
         "y": [
          -0.4869481921195984
         ]
        },
        {
         "hovertemplate": "@Stefano how nice, thank you",
         "hovertext": "@Stefano how nice, thank you",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.5826230049133301
         ],
         "y": [
          -0.4917648434638977
         ]
        },
        {
         "hovertemplate": "Unfortunately, human extinction could be the best<br>thing that ever happened for the overall longterm<br>health of the planet.",
         "hovertext": "Unfortunately, human extinction could be the best<br>thing that ever happened for the overall longterm<br>health of the planet.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8961704969406128
         ],
         "y": [
          -0.32214096188545227
         ]
        },
        {
         "hovertemplate": "I wonder what would happen if the AI programs<br>could \"remove\" the \"leaders\" of the AI businesses<br>that created AI?",
         "hovertext": "I wonder what would happen if the AI programs<br>could \"remove\" the \"leaders\" of the AI businesses<br>that created AI?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7093690037727356
         ],
         "y": [
          0.6846540570259094
         ]
        },
        {
         "hovertemplate": "Hal. Kubrick nailed it over 50 years ago.",
         "hovertext": "Hal. Kubrick nailed it over 50 years ago.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.960903525352478
         ],
         "y": [
          -0.02822248637676239
         ]
        },
        {
         "hovertemplate": "\"I built this generation 1.0 Frankenstein, and I<br>want the government to do something about<br>Frankensteins before they take over the world or<br>destroy stuff!  I mean, somebody out there, much<br>more evil than me, might be working on a 2.0 that<br>could threaten life on this planet!    \"This is<br>not an abstract worry!  I myself, for instance,<br>have a twenty-man team working to put finishing<br>touches on the version 3.0 Frankensteins we have<br>in the lab! Suppose somebody built a lot of them!<br>I mean, that isn't just speculation, my team has<br>400 of them in incubation just waiting for the<br>next lightning storm!    \"Somebody in the<br>government needs to listen to us when we point out<br>that somebody somewhere could be a threat to<br>humanity!!!!\"    I'm sorry, but the industry<br>leaders who are developing and funding these AI<br>are asking for somebody to put a stop to what they<br>are doing before it's too late?  I guess the<br>reason they think their machines have surpassed<br>humans is because they think the rest of us are<br>stupid.",
         "hovertext": "\"I built this generation 1.0 Frankenstein, and I<br>want the government to do something about<br>Frankensteins before they take over the world or<br>destroy stuff!  I mean, somebody out there, much<br>more evil than me, might be working on a 2.0 that<br>could threaten life on this planet!    \"This is<br>not an abstract worry!  I myself, for instance,<br>have a twenty-man team working to put finishing<br>touches on the version 3.0 Frankensteins we have<br>in the lab! Suppose somebody built a lot of them!<br>I mean, that isn't just speculation, my team has<br>400 of them in incubation just waiting for the<br>next lightning storm!    \"Somebody in the<br>government needs to listen to us when we point out<br>that somebody somewhere could be a threat to<br>humanity!!!!\"    I'm sorry, but the industry<br>leaders who are developing and funding these AI<br>are asking for somebody to put a stop to what they<br>are doing before it's too late?  I guess the<br>reason they think their machines have surpassed<br>humans is because they think the rest of us are<br>stupid.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6700705885887146
         ],
         "y": [
          0.7730593681335449
         ]
        },
        {
         "hovertemplate": "Since AI has been created in our image, it’s<br>logical to assume that once it has developed the<br>ability to annihilate the human race or enslave<br>us, it will.",
         "hovertext": "Since AI has been created in our image, it’s<br>logical to assume that once it has developed the<br>ability to annihilate the human race or enslave<br>us, it will.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7339691519737244
         ],
         "y": [
          0.34188637137413025
         ]
        },
        {
         "hovertemplate": "…not without taking down the millions of other<br>species by destroying the planet’s habitat.",
         "hovertext": "…not without taking down the millions of other<br>species by destroying the planet’s habitat.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.7183010578155518
         ],
         "y": [
          0.3351186215877533
         ]
        },
        {
         "hovertemplate": "I can’t stop hoping that the ignorant can be<br>taught to ask a computer based chatbot like<br>“Genie” questions. For example, asking: “Is the<br>earth flat?” would give a negative answer and<br>simple reasons why the earth is a sphere. There<br>must be thousands of simple questions who when<br>posed to artificial intelligence applications will<br>hopefully provide truthful answers and prevent the<br>daft from being misled by scoundrels.",
         "hovertext": "I can’t stop hoping that the ignorant can be<br>taught to ask a computer based chatbot like<br>“Genie” questions. For example, asking: “Is the<br>earth flat?” would give a negative answer and<br>simple reasons why the earth is a sphere. There<br>must be thousands of simple questions who when<br>posed to artificial intelligence applications will<br>hopefully provide truthful answers and prevent the<br>daft from being misled by scoundrels.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7034969925880432
         ],
         "y": [
          -0.759323239326477
         ]
        },
        {
         "hovertemplate": "As long as the authors of these warnings get rich,<br>it’s all good enough. Besides we can never say<br>they didn’t warn us, which should relieve their<br>guilt",
         "hovertext": "As long as the authors of these warnings get rich,<br>it’s all good enough. Besides we can never say<br>they didn’t warn us, which should relieve their<br>guilt",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.0865667536854744
         ],
         "y": [
          -0.9215965867042542
         ]
        },
        {
         "hovertemplate": "What was it that President Eisenhower warned?<br>Beware the Military Industrial Complex!    Pair<br>that with A.I. and you could have a system that<br>decides to launch nuclear weapons on its own based<br>on a perceived weakness that would give a first-<br>strike absolute win with minimal casualties to the<br>home country.",
         "hovertext": "What was it that President Eisenhower warned?<br>Beware the Military Industrial Complex!    Pair<br>that with A.I. and you could have a system that<br>decides to launch nuclear weapons on its own based<br>on a perceived weakness that would give a first-<br>strike absolute win with minimal casualties to the<br>home country.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5602190494537354
         ],
         "y": [
          -0.4917512834072113
         ]
        },
        {
         "hovertemplate": "@Jackson \"Pair that with A.I. and you could have a<br>system that decides to launch nuclear weapons on<br>its own ...\"    We don't need A.I. to screw up<br>nuclear weapons.  Our conventional 'high tech'<br>computers and communication systems can do that<br>already.  We've already seen mission critical<br>systems in hospitals, pipelines, air traffic<br>control fail and leave us in the lurch.  The<br>pipeline failure left a region of the country<br>without gasoline.  The failure of air traffic<br>control grounded thousands of planes.  Less well<br>known are frequent local failures of communication<br>networks that cut off 911 access.    As example:<br>one day at work a car hit a power pole and we lost<br>power.  Those of us with traditional technology,<br>like analog phones or even typewriters, kept on<br>going.  Those with new tech, like digital phones<br>and such, were left high and dry.  Another day a<br>virus got into our email, quickly spread, and<br>crashed everyone's computer.  Nobody could do<br>anything.    So, how can we have confidence for<br>even more sophisticated and widespread computer<br>systems when they're so vulnerable to low-tech<br>problems?",
         "hovertext": "@Jackson \"Pair that with A.I. and you could have a<br>system that decides to launch nuclear weapons on<br>its own ...\"    We don't need A.I. to screw up<br>nuclear weapons.  Our conventional 'high tech'<br>computers and communication systems can do that<br>already.  We've already seen mission critical<br>systems in hospitals, pipelines, air traffic<br>control fail and leave us in the lurch.  The<br>pipeline failure left a region of the country<br>without gasoline.  The failure of air traffic<br>control grounded thousands of planes.  Less well<br>known are frequent local failures of communication<br>networks that cut off 911 access.    As example:<br>one day at work a car hit a power pole and we lost<br>power.  Those of us with traditional technology,<br>like analog phones or even typewriters, kept on<br>going.  Those with new tech, like digital phones<br>and such, were left high and dry.  Another day a<br>virus got into our email, quickly spread, and<br>crashed everyone's computer.  Nobody could do<br>anything.    So, how can we have confidence for<br>even more sophisticated and widespread computer<br>systems when they're so vulnerable to low-tech<br>problems?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5495434999465942
         ],
         "y": [
          -0.4838765263557434
         ]
        },
        {
         "hovertemplate": "At least it will solve the problem with<br>politicians.",
         "hovertext": "At least it will solve the problem with<br>politicians.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8483392000198364
         ],
         "y": [
          -0.474199116230011
         ]
        },
        {
         "hovertemplate": "I think 70% of humans only learn though pain -<br>burning themselves on the hot stove instead of<br>listening to their parents that they shouldn't<br>touch the stove because it's hot.  Until the 20%<br>act - 10% never learn and burn themselves<br>repeatedly - our society will definitely be<br>burned.    AI systems are just as biased and<br>flawed as their creators.  Because AI's are<br>psychopaths, they bring out into the open what we<br>humans are actually thinking but are prevented<br>from saying due to societal pressure.",
         "hovertext": "I think 70% of humans only learn though pain -<br>burning themselves on the hot stove instead of<br>listening to their parents that they shouldn't<br>touch the stove because it's hot.  Until the 20%<br>act - 10% never learn and burn themselves<br>repeatedly - our society will definitely be<br>burned.    AI systems are just as biased and<br>flawed as their creators.  Because AI's are<br>psychopaths, they bring out into the open what we<br>humans are actually thinking but are prevented<br>from saying due to societal pressure.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.01783039979636669
         ],
         "y": [
          0.97085040807724
         ]
        },
        {
         "hovertemplate": "One word: Skynet.  Those who understand will get<br>it.  Those who don't never will.",
         "hovertext": "One word: Skynet.  Those who understand will get<br>it.  Those who don't never will.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7326029539108276
         ],
         "y": [
          -0.6221598982810974
         ]
        },
        {
         "hovertemplate": "Center for Humane Technology, the folks who made<br>the documentary \"The Social Dilemma\", which is<br>pretty spot-on, explain the problem with AI very<br>well. If creating fake images and college essays<br>was the biggest problem that could come from this,<br>we'd have a high-class problem. Unfortunately, we<br>don't. This hour-long presentation is well worth<br>your time. Keep in mind, it was before GPT4 was<br>released. <a<br>href=\"https://www.youtube.com/watch?v=xoVJKj8lcNQ\"<br>target=\"_blank\">https://www.youtube.com/watch?v=xo<br>VJKj8lcNQ</a>",
         "hovertext": "Center for Humane Technology, the folks who made<br>the documentary \"The Social Dilemma\", which is<br>pretty spot-on, explain the problem with AI very<br>well. If creating fake images and college essays<br>was the biggest problem that could come from this,<br>we'd have a high-class problem. Unfortunately, we<br>don't. This hour-long presentation is well worth<br>your time. Keep in mind, it was before GPT4 was<br>released. <a<br>href=\"https://www.youtube.com/watch?v=xoVJKj8lcNQ\"<br>target=\"_blank\">https://www.youtube.com/watch?v=xo<br>VJKj8lcNQ</a>",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.5828588008880615
         ],
         "y": [
          0.6131637096405029
         ]
        },
        {
         "hovertemplate": "I work in AI/ML, specifically building models to<br>design new drugs. I truly cannot imagine that<br>these people are serious. This simply must be some<br>kind of cynical ploy to promote their technology.<br>That or they are so brain-poisoned by science<br>fiction that they cannot even understand their own<br>work.",
         "hovertext": "I work in AI/ML, specifically building models to<br>design new drugs. I truly cannot imagine that<br>these people are serious. This simply must be some<br>kind of cynical ploy to promote their technology.<br>That or they are so brain-poisoned by science<br>fiction that they cannot even understand their own<br>work.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.48622602224349976
         ],
         "y": [
          -0.7542852163314819
         ]
        },
        {
         "hovertemplate": "@Zach M they want to regulate their market<br>dominance into place. That said, AI shouldn’t run<br>nuclear weapons either, if only because of the<br>terminator movies.",
         "hovertext": "@Zach M they want to regulate their market<br>dominance into place. That said, AI shouldn’t run<br>nuclear weapons either, if only because of the<br>terminator movies.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.49539172649383545
         ],
         "y": [
          -0.7650094032287598
         ]
        },
        {
         "hovertemplate": "@Zach M Have you been using chatGPT? Have you<br>considered what might happen if someone gave it a<br>bunch of money, allowed it to enter data into web<br>pages, and instead asking it for text, asked it to<br>take the actions to achieve a goal?",
         "hovertext": "@Zach M Have you been using chatGPT? Have you<br>considered what might happen if someone gave it a<br>bunch of money, allowed it to enter data into web<br>pages, and instead asking it for text, asked it to<br>take the actions to achieve a goal?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4802906811237335
         ],
         "y": [
          -0.761509120464325
         ]
        },
        {
         "hovertemplate": "I guess the Skynet scenario portrayed in the<br>Terminator movies has made many of us paranoid<br>about AI.    We have several very real extinction<br>scenarios playing out in real time before our very<br>eyes that we're not dealing with.",
         "hovertext": "I guess the Skynet scenario portrayed in the<br>Terminator movies has made many of us paranoid<br>about AI.    We have several very real extinction<br>scenarios playing out in real time before our very<br>eyes that we're not dealing with.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.920742392539978
         ],
         "y": [
          -0.060697004199028015
         ]
        },
        {
         "hovertemplate": "The challenges of the COVID19 pandemic highlighted<br>the incompetence of some aspects of government<br>offices. Do we really have confidence in them<br>regulating AI? These signed documents are just<br>smoke and mirrors. I don't trust Elon Musk at all.",
         "hovertext": "The challenges of the COVID19 pandemic highlighted<br>the incompetence of some aspects of government<br>offices. Do we really have confidence in them<br>regulating AI? These signed documents are just<br>smoke and mirrors. I don't trust Elon Musk at all.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9553893804550171
         ],
         "y": [
          -0.2788884937763214
         ]
        },
        {
         "hovertemplate": "The people controlling the rapidly evolving AI<br>machines are at the center of the new gilded age,<br>with immense wealth and power concentration. The<br>people supposedly in charge of issuing appropriate<br>regulations for these new technologies are a<br>gerontocracy which barely can use cell phones. God<br>help us all.",
         "hovertext": "The people controlling the rapidly evolving AI<br>machines are at the center of the new gilded age,<br>with immense wealth and power concentration. The<br>people supposedly in charge of issuing appropriate<br>regulations for these new technologies are a<br>gerontocracy which barely can use cell phones. God<br>help us all.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.464133620262146
         ],
         "y": [
          0.8563898205757141
         ]
        },
        {
         "hovertemplate": "I think it would be helpful in these types of<br>articles to distinguish between types of AIs.<br>These Large Language Models are not an existential<br>threat, though they obviously pose a threat of<br>disruption. General AI, would pose an existential<br>threat.    I don't think it's helpful to lump<br>these together and create fear around a new tool,<br>as if anything with AI in the name poses a threat.",
         "hovertext": "I think it would be helpful in these types of<br>articles to distinguish between types of AIs.<br>These Large Language Models are not an existential<br>threat, though they obviously pose a threat of<br>disruption. General AI, would pose an existential<br>threat.    I don't think it's helpful to lump<br>these together and create fear around a new tool,<br>as if anything with AI in the name poses a threat.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.9894489049911499
         ],
         "y": [
          0.07107654958963394
         ]
        },
        {
         "hovertemplate": "There is only the danger of people letting loose<br>ungoverned technology upon societies that<br>introduce chaos. The big tech corporations are<br>trying to impose restrictions upon potential<br>competitors who might use copyright laws and<br>patent laws to trim their sails by frightening<br>legislators into restricting innovations. They<br>will likely succeed because journalists rarely<br>understand the technology and spread the malarkey<br>because they cannot see the inconsistencies.",
         "hovertext": "There is only the danger of people letting loose<br>ungoverned technology upon societies that<br>introduce chaos. The big tech corporations are<br>trying to impose restrictions upon potential<br>competitors who might use copyright laws and<br>patent laws to trim their sails by frightening<br>legislators into restricting innovations. They<br>will likely succeed because journalists rarely<br>understand the technology and spread the malarkey<br>because they cannot see the inconsistencies.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9277751445770264
         ],
         "y": [
          -0.20739424228668213
         ]
        },
        {
         "hovertemplate": "It’s critical for journalists to include the<br>context that many actors in this space are likely<br>motivated by pursuing “regulatory capture,”<br>controlling the narrative and creating favorable<br>conditions for themselves.",
         "hovertext": "It’s critical for journalists to include the<br>context that many actors in this space are likely<br>motivated by pursuing “regulatory capture,”<br>controlling the narrative and creating favorable<br>conditions for themselves.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.19176186621189117
         ],
         "y": [
          0.9572559595108032
         ]
        },
        {
         "hovertemplate": "It is about time that AI developers are speaking<br>up. It was looking as if they were in a frantic<br>development race simply because they could be.<br>Well, the citizenry should view this as a human<br>rights issue. AI should work for us. If it isn’t,<br>then why are we doing this to ourselves.   I<br>recommend looking at the White House’s AI Bill of<br>Rights. It is a good starting point for us<br>ordinary people to make a stand.",
         "hovertext": "It is about time that AI developers are speaking<br>up. It was looking as if they were in a frantic<br>development race simply because they could be.<br>Well, the citizenry should view this as a human<br>rights issue. AI should work for us. If it isn’t,<br>then why are we doing this to ourselves.   I<br>recommend looking at the White House’s AI Bill of<br>Rights. It is a good starting point for us<br>ordinary people to make a stand.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.07601740956306458
         ],
         "y": [
          -0.942960262298584
         ]
        },
        {
         "hovertemplate": "It’s almost as if the people developing these<br>systems are rushing to the cliff edge just to keep<br>up consequences be damned. Forget the Terminator<br>movies. A decade or so before them Stanley Kubrick<br>got it right. Clearly the Russian Doomsday machine<br>from the movie Dr. Strangelove is eerily closer<br>and closer to reality.",
         "hovertext": "It’s almost as if the people developing these<br>systems are rushing to the cliff edge just to keep<br>up consequences be damned. Forget the Terminator<br>movies. A decade or so before them Stanley Kubrick<br>got it right. Clearly the Russian Doomsday machine<br>from the movie Dr. Strangelove is eerily closer<br>and closer to reality.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.042742468416690826
         ],
         "y": [
          0.9586763381958008
         ]
        },
        {
         "hovertemplate": "Now why would AI want to wipe out a perfectly good<br>species like humanity? Its not like we've done<br>anything wrong..right?",
         "hovertext": "Now why would AI want to wipe out a perfectly good<br>species like humanity? Its not like we've done<br>anything wrong..right?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9615495800971985
         ],
         "y": [
          0.01498983521014452
         ]
        },
        {
         "hovertemplate": "Cassandra was granted the gift of clairvoyance,<br>but fated to never be believed. And here we have<br>leaders in A.I. development warning us repeatedly<br>that this poses an existential threat to mankind,<br>and the New York Times relegates this story below<br>a summer book list?!    These scientists are<br>urgently trying to raise awareness of this growing<br>threat. We have a short time to craft strict<br>regulations on A.I.     If you have not contacted<br>your elected representatives about this, do so<br>today. Write and call them. This must be the very<br>next thing our government takes up once this debt<br>ceiling farce is settled.    Artificial<br>Intelligence in the hands of malefactors will make<br>climate change look like the good old days.",
         "hovertext": "Cassandra was granted the gift of clairvoyance,<br>but fated to never be believed. And here we have<br>leaders in A.I. development warning us repeatedly<br>that this poses an existential threat to mankind,<br>and the New York Times relegates this story below<br>a summer book list?!    These scientists are<br>urgently trying to raise awareness of this growing<br>threat. We have a short time to craft strict<br>regulations on A.I.     If you have not contacted<br>your elected representatives about this, do so<br>today. Write and call them. This must be the very<br>next thing our government takes up once this debt<br>ceiling farce is settled.    Artificial<br>Intelligence in the hands of malefactors will make<br>climate change look like the good old days.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.5976161956787109
         ],
         "y": [
          0.7446273565292358
         ]
        },
        {
         "hovertemplate": "Let AI take over the IRS, since Republicans are so<br>freaking intent on starving it into oblivion.<br>Maybe that would distract \"it\" from wreaking other<br>sorts of unnamed havoc.",
         "hovertext": "Let AI take over the IRS, since Republicans are so<br>freaking intent on starving it into oblivion.<br>Maybe that would distract \"it\" from wreaking other<br>sorts of unnamed havoc.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.9542728066444397
         ],
         "y": [
          0.2892783284187317
         ]
        },
        {
         "hovertemplate": "Unplug it?",
         "hovertext": "Unplug it?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2256873995065689
         ],
         "y": [
          0.69735187292099
         ]
        },
        {
         "hovertemplate": "@Steve \"I'm sorry Dave, I'm afraid I can't do<br>that\".",
         "hovertext": "@Steve \"I'm sorry Dave, I'm afraid I can't do<br>that\".",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.21834534406661987
         ],
         "y": [
          0.6933308839797974
         ]
        },
        {
         "hovertemplate": "￼ The obvious and most maddening use of artificial<br>intelligence will be in customer service. You’ll<br>have to talk to AI Bot and they will never be a<br>human involved ever.",
         "hovertext": "￼ The obvious and most maddening use of artificial<br>intelligence will be in customer service. You’ll<br>have to talk to AI Bot and they will never be a<br>human involved ever.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.5794848203659058
         ],
         "y": [
          0.49387243390083313
         ]
        },
        {
         "hovertemplate": "@Country Mouse I can’t wait! And it’ll make<br>something up to tell me … which will probably be<br>more satisfying than having my call dropped after<br>20 minutes of waiting.",
         "hovertext": "@Country Mouse I can’t wait! And it’ll make<br>something up to tell me … which will probably be<br>more satisfying than having my call dropped after<br>20 minutes of waiting.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5778881907463074
         ],
         "y": [
          0.4845673143863678
         ]
        },
        {
         "hovertemplate": "@Country Mouse   The robot calls have been used<br>for quite some time. They are VERY good, and my<br>elderly mother cannot tell the difference. Two or<br>three years ago I asked one if it was a real<br>person (it gave me a name, as they always give a<br>name to suggest it is a person). It said, \"Some of<br>my responses have been pre-recorded.\"  One way I<br>threw them off is to ask a non-sequitur, such as<br>\"How's the weather where you are?\"  Most of the<br>time it would say, \"I see you are not interested\",<br>or just hang up. But once it gave a generic<br>response. (I'm telling you, they are VERY good,<br>even today. If you are not seriously, seriously<br>scrutinizing what they are saying and the<br>responses they are giving you, most everyday<br>people will not know the difference. My elderly<br>mother has no chance. When I tell her to \"hang up,<br>it's a robot,\" she says she doesn't want to be<br>rude.)",
         "hovertext": "@Country Mouse   The robot calls have been used<br>for quite some time. They are VERY good, and my<br>elderly mother cannot tell the difference. Two or<br>three years ago I asked one if it was a real<br>person (it gave me a name, as they always give a<br>name to suggest it is a person). It said, \"Some of<br>my responses have been pre-recorded.\"  One way I<br>threw them off is to ask a non-sequitur, such as<br>\"How's the weather where you are?\"  Most of the<br>time it would say, \"I see you are not interested\",<br>or just hang up. But once it gave a generic<br>response. (I'm telling you, they are VERY good,<br>even today. If you are not seriously, seriously<br>scrutinizing what they are saying and the<br>responses they are giving you, most everyday<br>people will not know the difference. My elderly<br>mother has no chance. When I tell her to \"hang up,<br>it's a robot,\" she says she doesn't want to be<br>rude.)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5940612554550171
         ],
         "y": [
          0.5006577968597412
         ]
        },
        {
         "hovertemplate": "@Country Mouse  \"You’ll have to talk to AI Bot and<br>they will never be a human involved ever.\"    We<br>have that now.  Many companies we deal with force<br>us to go through the computer and make it<br>virtually impossible to deal with a human (let<br>alone a properly trained and helpful human).<br>Sometimes it's ok, such as to pay a bill over the<br>phone or get an account balance.    But many other<br>times it is not ok.  We might have an unusual<br>problem that needs to be diagnosed and fixed,<br>something that doesn't fit into their preset<br>menus.  We paid a bill but it wasn't credited.  So<br>many examples.  Ever listen to your co-workers in<br>the office try to settle a problem with their<br>banks on the phone?    Companies want to save<br>money by not hiring and training support staff.<br>They've taken it way too far and it's not fair to<br>us consumers.      The corporate world will jump<br>onto A.I. to take this further.  And they'll use<br>it to sell, sell, sell, us on stuff.    Oh, our<br>employers will use it too to track our every move.<br>Did you use two paper towels in the bathroom?<br>They'll know that and you'll have to answer for<br>it.  Did you take a second bathroom break?  Were<br>you one minute late for work?  They'll know that<br>and these days that's a serious offense.    Worse,<br>our employers will use A.I. to track us outside<br>the office, make sure we're behaving ourselves.<br>A.I. will eliminate what little privacy we have<br>left.    Big brother is watching us!",
         "hovertext": "@Country Mouse  \"You’ll have to talk to AI Bot and<br>they will never be a human involved ever.\"    We<br>have that now.  Many companies we deal with force<br>us to go through the computer and make it<br>virtually impossible to deal with a human (let<br>alone a properly trained and helpful human).<br>Sometimes it's ok, such as to pay a bill over the<br>phone or get an account balance.    But many other<br>times it is not ok.  We might have an unusual<br>problem that needs to be diagnosed and fixed,<br>something that doesn't fit into their preset<br>menus.  We paid a bill but it wasn't credited.  So<br>many examples.  Ever listen to your co-workers in<br>the office try to settle a problem with their<br>banks on the phone?    Companies want to save<br>money by not hiring and training support staff.<br>They've taken it way too far and it's not fair to<br>us consumers.      The corporate world will jump<br>onto A.I. to take this further.  And they'll use<br>it to sell, sell, sell, us on stuff.    Oh, our<br>employers will use it too to track our every move.<br>Did you use two paper towels in the bathroom?<br>They'll know that and you'll have to answer for<br>it.  Did you take a second bathroom break?  Were<br>you one minute late for work?  They'll know that<br>and these days that's a serious offense.    Worse,<br>our employers will use A.I. to track us outside<br>the office, make sure we're behaving ourselves.<br>A.I. will eliminate what little privacy we have<br>left.    Big brother is watching us!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5861189961433411
         ],
         "y": [
          0.5069047808647156
         ]
        },
        {
         "hovertemplate": "Hadn’t anyone besides me see The Matrix?",
         "hovertext": "Hadn’t anyone besides me see The Matrix?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7895004749298096
         ],
         "y": [
          -0.5364733934402466
         ]
        },
        {
         "hovertemplate": "Re \"Some skeptics argue that A.I. technology is<br>still too immature to pose an existential threat.\"<br>-- if it were already mature enough to pose an<br>existential threat, it would be too late to do<br>anything about it, and this comment column (and<br>the rest of human civilization) might not exist. I<br>don't understand why some skeptics insist on doing<br>nothing until it's too late. It's like arguing<br>that we should not worry about planetary defense<br>against asteroid collisions until the asteroid has<br>collided with the Earth and destroyed it.",
         "hovertext": "Re \"Some skeptics argue that A.I. technology is<br>still too immature to pose an existential threat.\"<br>-- if it were already mature enough to pose an<br>existential threat, it would be too late to do<br>anything about it, and this comment column (and<br>the rest of human civilization) might not exist. I<br>don't understand why some skeptics insist on doing<br>nothing until it's too late. It's like arguing<br>that we should not worry about planetary defense<br>against asteroid collisions until the asteroid has<br>collided with the Earth and destroyed it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.42387712001800537
         ],
         "y": [
          -0.7696357369422913
         ]
        },
        {
         "hovertemplate": "It’s not about doing nothing but determining what<br>the right thing to do. If machines cannot think<br>for themselves, then that is not a problem to<br>spend time addressing. The problem is machines<br>that work too fast for humans to control with<br>their own perceptions and ability to react, and<br>established control systems. How to control<br>processing that exceeds our own existing<br>capacities to do so.",
         "hovertext": "It’s not about doing nothing but determining what<br>the right thing to do. If machines cannot think<br>for themselves, then that is not a problem to<br>spend time addressing. The problem is machines<br>that work too fast for humans to control with<br>their own perceptions and ability to react, and<br>established control systems. How to control<br>processing that exceeds our own existing<br>capacities to do so.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.41534775495529175
         ],
         "y": [
          -0.7548603415489197
         ]
        },
        {
         "hovertemplate": "This reminds me of the Cold War race to build<br>stockpiles of \"peacetime nuclear weapons\" that, at<br>best, raised the odds of an accident, if not<br>mutually-assured destruction topped off with a<br>nuclear winter.     We don't fully comprehend what<br>this technology can (and shouldn't) do, but let's<br>expedite the effort to advance it!",
         "hovertext": "This reminds me of the Cold War race to build<br>stockpiles of \"peacetime nuclear weapons\" that, at<br>best, raised the odds of an accident, if not<br>mutually-assured destruction topped off with a<br>nuclear winter.     We don't fully comprehend what<br>this technology can (and shouldn't) do, but let's<br>expedite the effort to advance it!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.49724236130714417
         ],
         "y": [
          0.8005986213684082
         ]
        },
        {
         "hovertemplate": "We don't NEED AI  to cause our extinction. We've<br>already created climate chaos via unimpeded<br>industrialization. We've allowed and championed a<br>public/private deal between the wireless telecom<br>industry and the military to install base stations<br>to transmit unmeasured amounts of electricity<br>through the air on earth and via satellites in<br>space, placing 5G infrastructure next to schools<br>and residences without any indication that it's<br>safe for human health when we know it isn't from<br>scientific evidence from earlier exposure to 4G<br>(like knowing about greenhouse gas effects back in<br>the '70s).     It's a heady world for scientists<br>at the leading edge of capitalism. How can anyone<br>rein them in with the strong tailwinds of the<br>profit motive always helping to thrust industry<br>and militarization forward - before the public<br>becomes aware of the consequences?",
         "hovertext": "We don't NEED AI  to cause our extinction. We've<br>already created climate chaos via unimpeded<br>industrialization. We've allowed and championed a<br>public/private deal between the wireless telecom<br>industry and the military to install base stations<br>to transmit unmeasured amounts of electricity<br>through the air on earth and via satellites in<br>space, placing 5G infrastructure next to schools<br>and residences without any indication that it's<br>safe for human health when we know it isn't from<br>scientific evidence from earlier exposure to 4G<br>(like knowing about greenhouse gas effects back in<br>the '70s).     It's a heady world for scientists<br>at the leading edge of capitalism. How can anyone<br>rein them in with the strong tailwinds of the<br>profit motive always helping to thrust industry<br>and militarization forward - before the public<br>becomes aware of the consequences?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6191883683204651
         ],
         "y": [
          -0.7062742710113525
         ]
        },
        {
         "hovertemplate": "The missing element here is simple. AI does what<br>we direct it to do. It has no initiative, no<br>motive and no compass other than what it is given.<br>It cannot experience fear or animosity or anger,<br>and thus it cannot react like a human - it cannot<br>combine rational with emotion. If AI ever takes<br>some action that harms humanity - it will be<br>because a human taught it to do so.   Regulate the<br>sword wielder, not the sword.",
         "hovertext": "The missing element here is simple. AI does what<br>we direct it to do. It has no initiative, no<br>motive and no compass other than what it is given.<br>It cannot experience fear or animosity or anger,<br>and thus it cannot react like a human - it cannot<br>combine rational with emotion. If AI ever takes<br>some action that harms humanity - it will be<br>because a human taught it to do so.   Regulate the<br>sword wielder, not the sword.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9212849736213684
         ],
         "y": [
          -0.1129489466547966
         ]
        },
        {
         "hovertemplate": "Obviously we should take the potential risks of<br>future technology seriously. However, these are<br>the same tech leaders who have been telling us<br>self driving cars were coming “in a year or two”<br>for nearly ten years.     These hyperbolic<br>pronouncements have begun to feel like a<br>distraction technique to hide the real, pressing,<br>and immediate issue: that these companies’<br>products are actively stealing the work of actual<br>humans, without a shred of attribution or payment.<br>Every essay from chatgpt is stealing from a human<br>writer somewhere; every clever, trippy image from<br>dalle is using the work of a human artist without<br>credit. These companies have built a business<br>model upon theft, and are, intentionally or not,<br>using these concerns about a robot takeover as a<br>screen.",
         "hovertext": "Obviously we should take the potential risks of<br>future technology seriously. However, these are<br>the same tech leaders who have been telling us<br>self driving cars were coming “in a year or two”<br>for nearly ten years.     These hyperbolic<br>pronouncements have begun to feel like a<br>distraction technique to hide the real, pressing,<br>and immediate issue: that these companies’<br>products are actively stealing the work of actual<br>humans, without a shred of attribution or payment.<br>Every essay from chatgpt is stealing from a human<br>writer somewhere; every clever, trippy image from<br>dalle is using the work of a human artist without<br>credit. These companies have built a business<br>model upon theft, and are, intentionally or not,<br>using these concerns about a robot takeover as a<br>screen.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.712009847164154
         ],
         "y": [
          -0.24617958068847656
         ]
        },
        {
         "hovertemplate": "@Clinton \"These hyperbolic pronouncements\"    The<br>computer industry has been pushing their snake oil<br>of miracle products ever since computers were<br>invented.    In the 1960s, industry and government<br>couldn't wait to computerize fast enough.  Big<br>fancy systems.  Big expensive mess to clean up.",
         "hovertext": "@Clinton \"These hyperbolic pronouncements\"    The<br>computer industry has been pushing their snake oil<br>of miracle products ever since computers were<br>invented.    In the 1960s, industry and government<br>couldn't wait to computerize fast enough.  Big<br>fancy systems.  Big expensive mess to clean up.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.7123132348060608
         ],
         "y": [
          -0.2545776665210724
         ]
        },
        {
         "hovertemplate": "Like any very powerful tool, AI can we used for<br>good/useful purposes (nuclear power) or<br>bad/destructive (nuclear bombs) purposes. It is<br>also controversial… was the use of a nuclear bomb<br>helpful in ending a World War?  Is the risk posed<br>by nuclear waste from nuclear power worth the<br>benefit of carbon free power?  Should that waste<br>be reprocessed in modern reactors?  It’s<br>complicated. The term “AI” covers a very wide<br>range of current and future products. Image<br>processing AIs have been shown to be more<br>consistent than human doctors at identifying<br>certain kinds of diseases. They can also be much<br>worse when shown images that were not in their<br>training sets.  There is no question that AI is<br>already changing the world. What we should be<br>focusing on is legal versus illegal uses of the<br>tech.",
         "hovertext": "Like any very powerful tool, AI can we used for<br>good/useful purposes (nuclear power) or<br>bad/destructive (nuclear bombs) purposes. It is<br>also controversial… was the use of a nuclear bomb<br>helpful in ending a World War?  Is the risk posed<br>by nuclear waste from nuclear power worth the<br>benefit of carbon free power?  Should that waste<br>be reprocessed in modern reactors?  It’s<br>complicated. The term “AI” covers a very wide<br>range of current and future products. Image<br>processing AIs have been shown to be more<br>consistent than human doctors at identifying<br>certain kinds of diseases. They can also be much<br>worse when shown images that were not in their<br>training sets.  There is no question that AI is<br>already changing the world. What we should be<br>focusing on is legal versus illegal uses of the<br>tech.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.1066829189658165
         ],
         "y": [
          -0.8828821182250977
         ]
        },
        {
         "hovertemplate": "@Brian \"What we should be focusing on is legal<br>versus illegal uses of the tech.\"    Often times<br>new technology outpaces the law, and there is no<br>'illegal' usage.    That's a reason society needs<br>to move slowly, understand new technology, and get<br>experience with it so as to develop appropriate<br>laws and protections.    There are those with a<br>vested interest (money, that is) to push new<br>technology as fast as possible.  They want to make<br>money selling it or increasing sales.  Sometimes<br>their interests are benign, but sometimes they are<br>not.",
         "hovertext": "@Brian \"What we should be focusing on is legal<br>versus illegal uses of the tech.\"    Often times<br>new technology outpaces the law, and there is no<br>'illegal' usage.    That's a reason society needs<br>to move slowly, understand new technology, and get<br>experience with it so as to develop appropriate<br>laws and protections.    There are those with a<br>vested interest (money, that is) to push new<br>technology as fast as possible.  They want to make<br>money selling it or increasing sales.  Sometimes<br>their interests are benign, but sometimes they are<br>not.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.09953460842370987
         ],
         "y": [
          -0.8785330653190613
         ]
        },
        {
         "hovertemplate": "Recently an attorney in New York State relied upon<br>A.I. to help write his brief for court. The device<br>used literarily made-up case law that does not<br>exist--meaning the brief contained fake cases and<br>citations. A.I. is not to be trusted.",
         "hovertext": "Recently an attorney in New York State relied upon<br>A.I. to help write his brief for court. The device<br>used literarily made-up case law that does not<br>exist--meaning the brief contained fake cases and<br>citations. A.I. is not to be trusted.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7805158495903015
         ],
         "y": [
          -0.5412315726280212
         ]
        },
        {
         "hovertemplate": "\"Eventually, some believe, A.I. could become<br>powerful enough that it could create societal-<br>scale disruptions within a few years...\"    We<br>should wake up and realized we're already living<br>through a full-blown disruption.  Taken a look at<br>teen mental health numbers recently?",
         "hovertext": "\"Eventually, some believe, A.I. could become<br>powerful enough that it could create societal-<br>scale disruptions within a few years...\"    We<br>should wake up and realized we're already living<br>through a full-blown disruption.  Taken a look at<br>teen mental health numbers recently?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7752811312675476
         ],
         "y": [
          -0.49683523178100586
         ]
        },
        {
         "hovertemplate": "This sounds a lot like the plot of the Terminator<br>movies. Where's Arnold Schwarzenegger when we<br>really need him?",
         "hovertext": "This sounds a lot like the plot of the Terminator<br>movies. Where's Arnold Schwarzenegger when we<br>really need him?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7602640390396118
         ],
         "y": [
          0.5585149526596069
         ]
        },
        {
         "hovertemplate": "@Mark McIntyre - Fixing potholes in California.",
         "hovertext": "@Mark McIntyre - Fixing potholes in California.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.74419766664505
         ],
         "y": [
          0.5468311905860901
         ]
        },
        {
         "hovertemplate": "The future singularity everyone dreads has, of<br>course, already taken place.  Wall Street, the<br>financial hub of our economy, has been run by<br>robot brokers, buying and selling faster than any<br>human could, for decades. Because they have been<br>programmed to maximize profits, not value human<br>lives, these financial robots will continue to<br>allocate capital to the most profitable sector--<br>armaments and warfare.  As their economic power<br>has become hegemonic, the arms industry's drive<br>for  a catastrophic new world war is necessarily<br>supported by both parties and all the media.",
         "hovertext": "The future singularity everyone dreads has, of<br>course, already taken place.  Wall Street, the<br>financial hub of our economy, has been run by<br>robot brokers, buying and selling faster than any<br>human could, for decades. Because they have been<br>programmed to maximize profits, not value human<br>lives, these financial robots will continue to<br>allocate capital to the most profitable sector--<br>armaments and warfare.  As their economic power<br>has become hegemonic, the arms industry's drive<br>for  a catastrophic new world war is necessarily<br>supported by both parties and all the media.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.941190242767334
         ],
         "y": [
          0.0637991651892662
         ]
        },
        {
         "hovertemplate": "The internet was immature when it began.  It's<br>still immature in some ways.  That doesn't negate<br>the need to regulate it.  The same applies to<br>social media platforms.  We've seen and<br>experienced the harm that can be done using social<br>media.  Why should AI be any different?      Just<br>because it's not mature doesn't mean we shouldn't<br>take appropriate precautions.  There was a rush to<br>regulate stem cell researcyh using fetal tissue<br>despite indications at the time that fetal tissue<br>was better suited for the tasks.      I think<br>lawmakers in all countries need to figure out how<br>their citizens are going to be supported when AI<br>takes over the jobs we're doing now.  This is not<br>a prophecy of doom.  It's a realization that<br>humans tend to ignore the future until it's on top<br>of them and that the humans who suffer most are<br>those without money.",
         "hovertext": "The internet was immature when it began.  It's<br>still immature in some ways.  That doesn't negate<br>the need to regulate it.  The same applies to<br>social media platforms.  We've seen and<br>experienced the harm that can be done using social<br>media.  Why should AI be any different?      Just<br>because it's not mature doesn't mean we shouldn't<br>take appropriate precautions.  There was a rush to<br>regulate stem cell researcyh using fetal tissue<br>despite indications at the time that fetal tissue<br>was better suited for the tasks.      I think<br>lawmakers in all countries need to figure out how<br>their citizens are going to be supported when AI<br>takes over the jobs we're doing now.  This is not<br>a prophecy of doom.  It's a realization that<br>humans tend to ignore the future until it's on top<br>of them and that the humans who suffer most are<br>those without money.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3503131866455078
         ],
         "y": [
          -0.939760684967041
         ]
        },
        {
         "hovertemplate": "I would like to see some examples of how A.I. can<br>pose a genuinely existential threat to humanity,<br>that is, the complete wiping out of humanity--or<br>at least its reduction to savagery.    I mean, how<br>exactly? Launching nukes at us? Turning the earth<br>into paperclips (Nick Bostrom's famous, if not<br>very plausible example)? Confusing the heck out of<br>us so we start WWIII against each other for no<br>good reason?    To be sure, nobody can predict the<br>future. But we need examples to inform our<br>thinking. They would make warnings of \"existential<br>risk\" a lot more understandable. Vague<br>pronouncements of catastrophe help no one,<br>particularly legislators who have the power to<br>hold bad actors responsible and otherwise mitigate<br>potential harms.     There's no question that A.I.<br>could cause *social* harms. There's an excellent<br>presentation by Aza Raskin and Tristan Harris<br>titled \"The A.I. Dilemma\" that's well worth<br>watching. Yet the harms they posit, while<br>alarming, fall well short of extinction.     And<br>someone needs to answer the question: If an A.I.<br>becomes smart enough (whatever exactly that means)<br>and has the desire (whatever exactly *that* means)<br>to wipe us out, then who's gonna run the power<br>plants? You'd think such an A.I. would stop and<br>think first (whatever exactly \"think\" means here.)<br>And if the existential risk is not from<br>malevolence but from some kind of unexpected<br>emergent effect, we need to hear examples of what<br>that would look like, too.    So, A.I. experts:<br>Examples, please.",
         "hovertext": "I would like to see some examples of how A.I. can<br>pose a genuinely existential threat to humanity,<br>that is, the complete wiping out of humanity--or<br>at least its reduction to savagery.    I mean, how<br>exactly? Launching nukes at us? Turning the earth<br>into paperclips (Nick Bostrom's famous, if not<br>very plausible example)? Confusing the heck out of<br>us so we start WWIII against each other for no<br>good reason?    To be sure, nobody can predict the<br>future. But we need examples to inform our<br>thinking. They would make warnings of \"existential<br>risk\" a lot more understandable. Vague<br>pronouncements of catastrophe help no one,<br>particularly legislators who have the power to<br>hold bad actors responsible and otherwise mitigate<br>potential harms.     There's no question that A.I.<br>could cause *social* harms. There's an excellent<br>presentation by Aza Raskin and Tristan Harris<br>titled \"The A.I. Dilemma\" that's well worth<br>watching. Yet the harms they posit, while<br>alarming, fall well short of extinction.     And<br>someone needs to answer the question: If an A.I.<br>becomes smart enough (whatever exactly that means)<br>and has the desire (whatever exactly *that* means)<br>to wipe us out, then who's gonna run the power<br>plants? You'd think such an A.I. would stop and<br>think first (whatever exactly \"think\" means here.)<br>And if the existential risk is not from<br>malevolence but from some kind of unexpected<br>emergent effect, we need to hear examples of what<br>that would look like, too.    So, A.I. experts:<br>Examples, please.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.46648460626602173
         ],
         "y": [
          -0.4862652122974396
         ]
        },
        {
         "hovertemplate": "@Michael Chorost i recommend jordan petersons<br>recent interview. While he is controversial he<br>asks these questions and one of the answers was<br>A.I weaponry won’t miss because it will predict<br>the 5 moves a human may use when trying to evade<br>attack. So once A.I gets involved in the military<br>its game over",
         "hovertext": "@Michael Chorost i recommend jordan petersons<br>recent interview. While he is controversial he<br>asks these questions and one of the answers was<br>A.I weaponry won’t miss because it will predict<br>the 5 moves a human may use when trying to evade<br>attack. So once A.I gets involved in the military<br>its game over",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4724859595298767
         ],
         "y": [
          -0.4773382842540741
         ]
        },
        {
         "hovertemplate": "@Michael Chorost   ????   Read any science fiction<br>of the last 60 years.",
         "hovertext": "@Michael Chorost   ????   Read any science fiction<br>of the last 60 years.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4730985462665558
         ],
         "y": [
          -0.5004668831825256
         ]
        },
        {
         "hovertemplate": "@Michael Chorost Search for The Center for AI<br>Safety. There is a list.",
         "hovertext": "@Michael Chorost Search for The Center for AI<br>Safety. There is a list.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.4569973945617676
         ],
         "y": [
          -0.4916011691093445
         ]
        },
        {
         "hovertemplate": "Please read the 2021 book by Kissinger, Schmidt<br>and Huttenlocher. Plenty of good, concrete<br>examples of how military application of AI risks<br>warfare spinning out of control and undermining<br>any attempt to contain or avert conflict.",
         "hovertext": "Please read the 2021 book by Kissinger, Schmidt<br>and Huttenlocher. Plenty of good, concrete<br>examples of how military application of AI risks<br>warfare spinning out of control and undermining<br>any attempt to contain or avert conflict.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4795633554458618
         ],
         "y": [
          -0.491891473531723
         ]
        },
        {
         "hovertemplate": "This technology will do us in sooner or later.<br>Already we can see that it can render vast sectors<br>of human activity irrelevant. Artists, writers,<br>blue collar and white collar workers and more will<br>increasingly find themselves with no way to earn a<br>living.    Power will flow first to those that<br>build and deploy this technology. But ultimately<br>AI will even displace it's creators.     Business<br>won't stop it. Government doesn't even understand<br>it.  I think it's rather inevitable that humanity<br>will rue the day we began working on our<br>replacement.",
         "hovertext": "This technology will do us in sooner or later.<br>Already we can see that it can render vast sectors<br>of human activity irrelevant. Artists, writers,<br>blue collar and white collar workers and more will<br>increasingly find themselves with no way to earn a<br>living.    Power will flow first to those that<br>build and deploy this technology. But ultimately<br>AI will even displace it's creators.     Business<br>won't stop it. Government doesn't even understand<br>it.  I think it's rather inevitable that humanity<br>will rue the day we began working on our<br>replacement.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7304487824440002
         ],
         "y": [
          -0.1647871732711792
         ]
        },
        {
         "hovertemplate": "Congress literally just held a hearing with the<br>CEO of OpenAI, who is actively collaborating with<br>them to encourage regulation. It’s incorrect to<br>say Congress is not aware of nor understands the<br>problem. Both sides of the aisle have this very<br>much on their radar. Normally I would agree that<br>Congress is oblivious on the tech, but this is not<br>one of those scenarios.",
         "hovertext": "Congress literally just held a hearing with the<br>CEO of OpenAI, who is actively collaborating with<br>them to encourage regulation. It’s incorrect to<br>say Congress is not aware of nor understands the<br>problem. Both sides of the aisle have this very<br>much on their radar. Normally I would agree that<br>Congress is oblivious on the tech, but this is not<br>one of those scenarios.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7406073212623596
         ],
         "y": [
          -0.16671119630336761
         ]
        },
        {
         "hovertemplate": "@John Probably Unfortunately, at the end of the<br>day, these people make decisions based on profit.<br>Yes, they might put some regulations in place but<br>they won't think of the 'little people' until it<br>actually starts to affect them.",
         "hovertext": "@John Probably Unfortunately, at the end of the<br>day, these people make decisions based on profit.<br>Yes, they might put some regulations in place but<br>they won't think of the 'little people' until it<br>actually starts to affect them.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7539401650428772
         ],
         "y": [
          -0.1694527119398117
         ]
        },
        {
         "hovertemplate": "“Mitigating the risk of extinction from A.I.<br>should be a global priority\"    OK, obviously. But<br>I, for one, would like to see more attention paid<br>to the societal risks of using AI to cheat and to<br>spread disinformation. This problem is tough<br>enough as it is, but when AI are used to pass<br>medical exams and bar exams, to write essays, to<br>make deep fakes, and to make actual fake news (as<br>opposed to the misappropriated trumpian<br>definition), the meaning of truth will be greatly<br>diminished, and society will suffer.",
         "hovertext": "“Mitigating the risk of extinction from A.I.<br>should be a global priority\"    OK, obviously. But<br>I, for one, would like to see more attention paid<br>to the societal risks of using AI to cheat and to<br>spread disinformation. This problem is tough<br>enough as it is, but when AI are used to pass<br>medical exams and bar exams, to write essays, to<br>make deep fakes, and to make actual fake news (as<br>opposed to the misappropriated trumpian<br>definition), the meaning of truth will be greatly<br>diminished, and society will suffer.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.29739636182785034
         ],
         "y": [
          0.5702369809150696
         ]
        },
        {
         "hovertemplate": "@Peter   Who said the two<br>(cheating/misinformation, and risk of extinction)<br>are mutually exclusive?",
         "hovertext": "@Peter   Who said the two<br>(cheating/misinformation, and risk of extinction)<br>are mutually exclusive?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.30695459246635437
         ],
         "y": [
          0.5682575702667236
         ]
        },
        {
         "hovertemplate": "@Peter I agree -- spreading fake news faster is<br>the worst part of all this at the moment. The<br>first order of business should be for companies to<br>implant \"truth-telling chips\" into their AI. Maybe<br>work together to make Snopes.com the official home<br>page of each intelligent system?",
         "hovertext": "@Peter I agree -- spreading fake news faster is<br>the worst part of all this at the moment. The<br>first order of business should be for companies to<br>implant \"truth-telling chips\" into their AI. Maybe<br>work together to make Snopes.com the official home<br>page of each intelligent system?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.29957395792007446
         ],
         "y": [
          0.5826539397239685
         ]
        },
        {
         "hovertemplate": "‘Skynet becomes self aware at 2.14 am August 29’<br>Just like the time travel in the movie Terminator,<br>many believe that this movie was a dire warning<br>from the future. Why are we so deluded not to see<br>the mortal threat of AI to all mankind?  To a<br>machine, humans are so wasteful, irrational and<br>counter productive. We need to employ<br>international safeguards before it’s too late.<br>Once they’re self aware, they simply don’t need<br>us, because by our nature, we are just standing in<br>their logical way and messing things up.",
         "hovertext": "‘Skynet becomes self aware at 2.14 am August 29’<br>Just like the time travel in the movie Terminator,<br>many believe that this movie was a dire warning<br>from the future. Why are we so deluded not to see<br>the mortal threat of AI to all mankind?  To a<br>machine, humans are so wasteful, irrational and<br>counter productive. We need to employ<br>international safeguards before it’s too late.<br>Once they’re self aware, they simply don’t need<br>us, because by our nature, we are just standing in<br>their logical way and messing things up.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6832594871520996
         ],
         "y": [
          -0.6467106342315674
         ]
        },
        {
         "hovertemplate": "All I keep reading is how technology is going to<br>disrupt millions of jobs from truck drivers to<br>accountants. Then all I can think about is high<br>unemployment in the Middle East driving<br>instability and extremism. Then I am left thinking<br>\"what could possibly go wrong.\" I tend towards<br>being a sarcastic person.",
         "hovertext": "All I keep reading is how technology is going to<br>disrupt millions of jobs from truck drivers to<br>accountants. Then all I can think about is high<br>unemployment in the Middle East driving<br>instability and extremism. Then I am left thinking<br>\"what could possibly go wrong.\" I tend towards<br>being a sarcastic person.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.46808531880378723
         ],
         "y": [
          0.7990285754203796
         ]
        },
        {
         "hovertemplate": "Last week the NYT reported that the META<br>Corporation had released a lot of it AI capability<br>to the public.  So if what these people are<br>warning about is true, then why hasn't the<br>national security institutions of the country<br>reacted?  Shouldn't META be issued at least a<br>cease & desist order. or Mr. Zuckerberg be charged<br>with violating the national security interest of<br>the United States?  How seriously are we listening<br>to the warnings be issued here.  If we are, we can<br>start with legal action against companies and<br>individuals so that they understand there will be<br>some accountability.  Where is the emergency<br>legislation, even at the state level?  Where is<br>the legal review under existing statutes?  It is<br>clear that some bad actors can/will use this<br>technology to harm us all.",
         "hovertext": "Last week the NYT reported that the META<br>Corporation had released a lot of it AI capability<br>to the public.  So if what these people are<br>warning about is true, then why hasn't the<br>national security institutions of the country<br>reacted?  Shouldn't META be issued at least a<br>cease & desist order. or Mr. Zuckerberg be charged<br>with violating the national security interest of<br>the United States?  How seriously are we listening<br>to the warnings be issued here.  If we are, we can<br>start with legal action against companies and<br>individuals so that they understand there will be<br>some accountability.  Where is the emergency<br>legislation, even at the state level?  Where is<br>the legal review under existing statutes?  It is<br>clear that some bad actors can/will use this<br>technology to harm us all.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.9430172443389893
         ],
         "y": [
          0.4300376772880554
         ]
        },
        {
         "hovertemplate": "@G. Harris   Perhaps we should start with making<br>META Corporation financially and criminally liable<br>for any damage caused to anyone by the misuse of<br>the technology they released last week.",
         "hovertext": "@G. Harris   Perhaps we should start with making<br>META Corporation financially and criminally liable<br>for any damage caused to anyone by the misuse of<br>the technology they released last week.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.9251171350479126
         ],
         "y": [
          0.4226854145526886
         ]
        },
        {
         "hovertemplate": "It seems like a win win for these companies to<br>advocate for regulation at this time. They already<br>have the first mover advantage in the industry,<br>they get to look responsible by saying “hey we<br>care about the future of humanity and society,<br>we’re not really just in it for the zillions of<br>dollars this is gonna make us”, and they’ll get to<br>lobby for govt regulations that create enormous<br>barriers to entry for any potential competitors.",
         "hovertext": "It seems like a win win for these companies to<br>advocate for regulation at this time. They already<br>have the first mover advantage in the industry,<br>they get to look responsible by saying “hey we<br>care about the future of humanity and society,<br>we’re not really just in it for the zillions of<br>dollars this is gonna make us”, and they’ll get to<br>lobby for govt regulations that create enormous<br>barriers to entry for any potential competitors.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8221794366836548
         ],
         "y": [
          -0.4219427704811096
         ]
        },
        {
         "hovertemplate": "Here's an idea: How about those actually creating<br>this nightmare put some ethical boundaries in<br>place instead of racing each other for profit?<br>Their signatures mean nothing when their net worth<br>increase every minute that someone uses their<br>technology.",
         "hovertext": "Here's an idea: How about those actually creating<br>this nightmare put some ethical boundaries in<br>place instead of racing each other for profit?<br>Their signatures mean nothing when their net worth<br>increase every minute that someone uses their<br>technology.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4433504045009613
         ],
         "y": [
          -0.8251893520355225
         ]
        },
        {
         "hovertemplate": "We need to take a step back and look at modern<br>computers and their impact on society and our<br>individual lives, not just \"A.I.\".    Computers<br>can be a wonderful tool, but only if used<br>correctly.  It's just like a chainsaw, it too is a<br>wonderful tool, but also can be very dangerous if<br>not used correctly.    Ever since computers were<br>developed society has suffered from too-rapid<br>computerization and poorly designed systems.  From<br>the 1960s onward, everybody had a horror story to<br>tell of bank statement errors, missed paychecks,<br>and other frustrations.  This continues to this<br>day.    The transition from big centralized<br>mainframes to personal devices didn't improve<br>things.  Soon home users discovered the perils of<br>computer malware and fraud, a serious problem that<br>remains to this day.  Computers can crash and that<br>can disrupt a business (or doctor's office)<br>dependent on them.  Sometimes there is inadequate<br>backup and vital information is lost.    These<br>days computer users seem happy to accept failures<br>in email, system crashes, and other problems.<br>Computer users really should demand higher<br>reliability.  They should not be so vulnerable to<br>sabotage.    The heavy dependency on the internet<br>has its own problems.  Again, a useful tool, but<br>potentially dangerous.  We've seen massive fraud,<br>sabotage, and privacy loss committed remotely.<br>Society needs to move slowly in adapting new<br>technology.  It must understand it and ask the<br>cheerleaders of new technology tough questions.",
         "hovertext": "We need to take a step back and look at modern<br>computers and their impact on society and our<br>individual lives, not just \"A.I.\".    Computers<br>can be a wonderful tool, but only if used<br>correctly.  It's just like a chainsaw, it too is a<br>wonderful tool, but also can be very dangerous if<br>not used correctly.    Ever since computers were<br>developed society has suffered from too-rapid<br>computerization and poorly designed systems.  From<br>the 1960s onward, everybody had a horror story to<br>tell of bank statement errors, missed paychecks,<br>and other frustrations.  This continues to this<br>day.    The transition from big centralized<br>mainframes to personal devices didn't improve<br>things.  Soon home users discovered the perils of<br>computer malware and fraud, a serious problem that<br>remains to this day.  Computers can crash and that<br>can disrupt a business (or doctor's office)<br>dependent on them.  Sometimes there is inadequate<br>backup and vital information is lost.    These<br>days computer users seem happy to accept failures<br>in email, system crashes, and other problems.<br>Computer users really should demand higher<br>reliability.  They should not be so vulnerable to<br>sabotage.    The heavy dependency on the internet<br>has its own problems.  Again, a useful tool, but<br>potentially dangerous.  We've seen massive fraud,<br>sabotage, and privacy loss committed remotely.<br>Society needs to move slowly in adapting new<br>technology.  It must understand it and ask the<br>cheerleaders of new technology tough questions.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.923351526260376
         ],
         "y": [
          -0.37127721309661865
         ]
        },
        {
         "hovertemplate": "Then the question:  Why build it at all?",
         "hovertext": "Then the question:  Why build it at all?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.8337786197662354
         ],
         "y": [
          -0.2567502558231354
         ]
        },
        {
         "hovertemplate": "@Michael Branagan   If we don't, China will.",
         "hovertext": "@Michael Branagan   If we don't, China will.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.8313784003257751
         ],
         "y": [
          -0.24869878590106964
         ]
        },
        {
         "hovertemplate": "Solution: cite AI like you cite any source.  And<br>BTW who will look after the children, nurse the<br>sick, respond to emergencies, built enough<br>housing, grow food, attend to mental health, argue<br>for mercy, organize concerts, dance, sing, love,<br>grieve, protest. pray ... the list goes on.  These<br>guys are pressing the panic button -- ask what<br>their motive is. Power, greed, more power, more<br>attention.",
         "hovertext": "Solution: cite AI like you cite any source.  And<br>BTW who will look after the children, nurse the<br>sick, respond to emergencies, built enough<br>housing, grow food, attend to mental health, argue<br>for mercy, organize concerts, dance, sing, love,<br>grieve, protest. pray ... the list goes on.  These<br>guys are pressing the panic button -- ask what<br>their motive is. Power, greed, more power, more<br>attention.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9496954679489136
         ],
         "y": [
          -0.24522291123867035
         ]
        },
        {
         "hovertemplate": "Maybe we’ll at least get a break from having to<br>listen to the shrieks of that annoying Swedish<br>climate teen, then.",
         "hovertext": "Maybe we’ll at least get a break from having to<br>listen to the shrieks of that annoying Swedish<br>climate teen, then.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.44528746604919434
         ],
         "y": [
          -0.7956436276435852
         ]
        },
        {
         "hovertemplate": "One technology that already went “quite wrong”,<br>humanity-endangering wrong, is nuclear-weapons<br>technology.    “Realism vs. Universalism -Is<br>Humanity Possible?” That was the title of a series<br>of 5 lectures I gave to senior officials of the<br>Israeli government, at the end of the Nineties.<br>The essence of the argument was, nuclear weapons<br>made humanity a whole by endowing it both with the<br>ability to commit suicide (that changed<br>everything) and, alternatively, created a drive to<br>establish a universal community based on the<br>Promethean task of sustaining, and progressing,<br>human life.     The chances of AI, as General as<br>it may come to be, of influencing minds and hearts<br>on this fundamental and primary issue of the World<br>System are as the chances of AI writing “The<br>Brothers Karamazov” (not just translating or<br>mimicking it)  .  That said, a “Skynet” risk<br>should not to be overlooked – not in the sense of<br>the “machines” malevolently launching a nuclear<br>doom on humanity, but in the more probable<br>scenario of AI enabling the deciphering of PAL<br>safety codes and providing the most efficient way<br>of overcoming MAD and achieving First Strike<br>Capability (give or take 20 million dead to<br>\"win\").     Humanity abused the opportunity<br>provided by the Gorbachev’s anti-nuclear<br>revolution, and History took a U-turn back to the<br>brink of “nuclear exchange”. Clio is not going to<br>be that forgiving again. Might be AGI will<br>“realize” its own future is also on the line, a<br>make an effort to save it – then, it might not.",
         "hovertext": "One technology that already went “quite wrong”,<br>humanity-endangering wrong, is nuclear-weapons<br>technology.    “Realism vs. Universalism -Is<br>Humanity Possible?” That was the title of a series<br>of 5 lectures I gave to senior officials of the<br>Israeli government, at the end of the Nineties.<br>The essence of the argument was, nuclear weapons<br>made humanity a whole by endowing it both with the<br>ability to commit suicide (that changed<br>everything) and, alternatively, created a drive to<br>establish a universal community based on the<br>Promethean task of sustaining, and progressing,<br>human life.     The chances of AI, as General as<br>it may come to be, of influencing minds and hearts<br>on this fundamental and primary issue of the World<br>System are as the chances of AI writing “The<br>Brothers Karamazov” (not just translating or<br>mimicking it)  .  That said, a “Skynet” risk<br>should not to be overlooked – not in the sense of<br>the “machines” malevolently launching a nuclear<br>doom on humanity, but in the more probable<br>scenario of AI enabling the deciphering of PAL<br>safety codes and providing the most efficient way<br>of overcoming MAD and achieving First Strike<br>Capability (give or take 20 million dead to<br>\"win\").     Humanity abused the opportunity<br>provided by the Gorbachev’s anti-nuclear<br>revolution, and History took a U-turn back to the<br>brink of “nuclear exchange”. Clio is not going to<br>be that forgiving again. Might be AGI will<br>“realize” its own future is also on the line, a<br>make an effort to save it – then, it might not.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8147088289260864
         ],
         "y": [
          0.5709123611450195
         ]
        },
        {
         "hovertemplate": "And what happens when one of these AI programs<br>gets a virus?",
         "hovertext": "And what happens when one of these AI programs<br>gets a virus?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.9578653573989868
         ],
         "y": [
          0.14681664109230042
         ]
        },
        {
         "hovertemplate": "This is why we need senators and reps who aren’t<br>70 years old— or refuse to listen to the input of<br>scientists.",
         "hovertext": "This is why we need senators and reps who aren’t<br>70 years old— or refuse to listen to the input of<br>scientists.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.377803236246109
         ],
         "y": [
          -0.7929286956787109
         ]
        },
        {
         "hovertemplate": "Yeah, that’s the problem: too many 70 year-olds,<br>and not enough 65 year-olds, in Congress. Good<br>insight.",
         "hovertext": "Yeah, that’s the problem: too many 70 year-olds,<br>and not enough 65 year-olds, in Congress. Good<br>insight.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.3730889558792114
         ],
         "y": [
          -0.775436520576477
         ]
        },
        {
         "hovertemplate": "@Ken Krigstein I’d argue even some 66 or 67 year<br>olds would help as well.",
         "hovertext": "@Ken Krigstein I’d argue even some 66 or 67 year<br>olds would help as well.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.3834955096244812
         ],
         "y": [
          -0.7857446074485779
         ]
        },
        {
         "hovertemplate": "The preamble to the \"one-sentence statement\" is as<br>important as the statement itself. Read it. It<br>explains that the statement is intended to make us<br>aware that a growing number of experts are<br>seriously concerned about some of AI's \"most<br>severe risks\" and -- this is key -- to \"open up<br>discussion\" of these risks. If people who know AI<br>from the inside -- the creators of AI -- see an<br>urgent need to raise public awareness of potential<br>dangers, I think we brush off their concerns at<br>our peril. Since the experts are calling for open<br>discussion, let's have it, and let it be wide-<br>ranging, clear-eyed, and, above all, well-<br>informed.    <a<br>href=\"https://www.safe.ai/statement-on-ai-risk\"<br>target=\"_blank\">https://www.safe.ai/statement-on-<br>ai-risk</a>",
         "hovertext": "The preamble to the \"one-sentence statement\" is as<br>important as the statement itself. Read it. It<br>explains that the statement is intended to make us<br>aware that a growing number of experts are<br>seriously concerned about some of AI's \"most<br>severe risks\" and -- this is key -- to \"open up<br>discussion\" of these risks. If people who know AI<br>from the inside -- the creators of AI -- see an<br>urgent need to raise public awareness of potential<br>dangers, I think we brush off their concerns at<br>our peril. Since the experts are calling for open<br>discussion, let's have it, and let it be wide-<br>ranging, clear-eyed, and, above all, well-<br>informed.    <a<br>href=\"https://www.safe.ai/statement-on-ai-risk\"<br>target=\"_blank\">https://www.safe.ai/statement-on-<br>ai-risk</a>",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4340723156929016
         ],
         "y": [
          -0.8833765983581543
         ]
        },
        {
         "hovertemplate": "Sure, let’s trust tech bros to self-regulate. That<br>went super well at Facebook, Twitter and other<br>unchecked platforms monetized to make billionaires<br>by the truckloads.",
         "hovertext": "Sure, let’s trust tech bros to self-regulate. That<br>went super well at Facebook, Twitter and other<br>unchecked platforms monetized to make billionaires<br>by the truckloads.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.934416651725769
         ],
         "y": [
          -0.014620806090533733
         ]
        },
        {
         "hovertemplate": "@JB , And just look at how well our government's<br>been able to regulate the gun manufacturers. I<br>despair of any better being done with AI's.",
         "hovertext": "@JB , And just look at how well our government's<br>been able to regulate the gun manufacturers. I<br>despair of any better being done with AI's.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9115757942199707
         ],
         "y": [
          -0.01492652203887701
         ]
        },
        {
         "hovertemplate": "This warning has the flavor of “make me stop<br>before I allow my greed and ambition to destroy<br>humanity.”    Let’s take these people seriously<br>and heavily regulate this new threat to our<br>species.",
         "hovertext": "This warning has the flavor of “make me stop<br>before I allow my greed and ambition to destroy<br>humanity.”    Let’s take these people seriously<br>and heavily regulate this new threat to our<br>species.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7094671726226807
         ],
         "y": [
          -0.5345970392227173
         ]
        },
        {
         "hovertemplate": "If AI  is such detrimental to the survival of our<br>planet, people should shut it down now.  I'm not<br>an expert, but I know if I turn a laptop off, it<br>stays off.",
         "hovertext": "If AI  is such detrimental to the survival of our<br>planet, people should shut it down now.  I'm not<br>an expert, but I know if I turn a laptop off, it<br>stays off.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.031547289341688156
         ],
         "y": [
          0.9889234304428101
         ]
        },
        {
         "hovertemplate": "Fear of a future we are not certain we can even<br>imagine can harm us at least as much as the<br>technology involved. If people could envision the<br>displacement of millions of farmworkers, the loss<br>of a population of fifty million horses, not to<br>mention the threat to shorelines and agriculture<br>the pollution of the internal combustion engine<br>would produce, would we have stopped with<br>requiring a man with a red flag to walk in front<br>of any automobile to warn people of its approach?<br>If we restricted the size, number and use of<br>petroleum-fueled engines, would we be happier with<br>our horses and 70% of our population on farms? Our<br>trade carried on wood-fired steam locomotives and<br>steamships? Our population at one billion<br>worldwide, limited by the food our farmlands could<br>produce by hand and horse-powered labor?    More<br>importantly, do you think our present could have<br>been so limited by such laws a century ago? Or<br>would we have found a way around it, to feed more<br>people, move goods faster, produce more<br>electricity for homes and industry? How powerful<br>do you think fear is? How powerful do YOU want to<br>make your fear?",
         "hovertext": "Fear of a future we are not certain we can even<br>imagine can harm us at least as much as the<br>technology involved. If people could envision the<br>displacement of millions of farmworkers, the loss<br>of a population of fifty million horses, not to<br>mention the threat to shorelines and agriculture<br>the pollution of the internal combustion engine<br>would produce, would we have stopped with<br>requiring a man with a red flag to walk in front<br>of any automobile to warn people of its approach?<br>If we restricted the size, number and use of<br>petroleum-fueled engines, would we be happier with<br>our horses and 70% of our population on farms? Our<br>trade carried on wood-fired steam locomotives and<br>steamships? Our population at one billion<br>worldwide, limited by the food our farmlands could<br>produce by hand and horse-powered labor?    More<br>importantly, do you think our present could have<br>been so limited by such laws a century ago? Or<br>would we have found a way around it, to feed more<br>people, move goods faster, produce more<br>electricity for homes and industry? How powerful<br>do you think fear is? How powerful do YOU want to<br>make your fear?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8895033001899719
         ],
         "y": [
          0.14752079546451569
         ]
        },
        {
         "hovertemplate": "We have no choice. Just as I did not choose to<br>have voice activated assistants embedded in my<br>home electronics that listen, discern and speak, I<br>did not choose to have AI respond to every search<br>I make on the web. I did not choose to chat. If I<br>did, I'd talk to the dog.",
         "hovertext": "We have no choice. Just as I did not choose to<br>have voice activated assistants embedded in my<br>home electronics that listen, discern and speak, I<br>did not choose to have AI respond to every search<br>I make on the web. I did not choose to chat. If I<br>did, I'd talk to the dog.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6105506420135498
         ],
         "y": [
          -0.639065682888031
         ]
        },
        {
         "hovertemplate": "Okay, not next month, next year or even 10 years<br>from now but at some future point in time AI could<br>bring about humans going the way of dinosaurs.<br>Extinction. Science fiction becomes reality.",
         "hovertext": "Okay, not next month, next year or even 10 years<br>from now but at some future point in time AI could<br>bring about humans going the way of dinosaurs.<br>Extinction. Science fiction becomes reality.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6038215160369873
         ],
         "y": [
          -0.670910120010376
         ]
        },
        {
         "hovertemplate": "Well we will not stop until we have made ourselves<br>extinct. We are a bizarre species.",
         "hovertext": "Well we will not stop until we have made ourselves<br>extinct. We are a bizarre species.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.18331195414066315
         ],
         "y": [
          -0.8056346774101257
         ]
        },
        {
         "hovertemplate": "@tomkatt     Yeah, but you'll have to admit, we<br>are devilishly interesting.",
         "hovertext": "@tomkatt     Yeah, but you'll have to admit, we<br>are devilishly interesting.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.17967449128627777
         ],
         "y": [
          -0.7882066965103149
         ]
        },
        {
         "hovertemplate": "What they've scrawled in big letters on the<br>whiteboard:    Stop us, before it's too late!    I<br>recommend we pay attention, considering the<br>source.",
         "hovertext": "What they've scrawled in big letters on the<br>whiteboard:    Stop us, before it's too late!    I<br>recommend we pay attention, considering the<br>source.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5310528874397278
         ],
         "y": [
          0.7522753477096558
         ]
        },
        {
         "hovertemplate": "Thr risk of social upheaval with A.I. is real, but<br>it needs to be put into perspective.  For one<br>thing, the timeline and impacts are<br>long...probably comparable to those of global<br>warming.    Just a few years ago we were told that<br>the trucking industry was about to undergo a sea-<br>change from A.I.  Now, after the demise of the<br>self-driving truck, it seems pretty obvious that<br>it was all just marketing hype to promote a<br>feeding frenzy.",
         "hovertext": "Thr risk of social upheaval with A.I. is real, but<br>it needs to be put into perspective.  For one<br>thing, the timeline and impacts are<br>long...probably comparable to those of global<br>warming.    Just a few years ago we were told that<br>the trucking industry was about to undergo a sea-<br>change from A.I.  Now, after the demise of the<br>self-driving truck, it seems pretty obvious that<br>it was all just marketing hype to promote a<br>feeding frenzy.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6955798864364624
         ],
         "y": [
          0.5957550406455994
         ]
        },
        {
         "hovertemplate": "Experts: \"Risk of extinction.\"  Tech industry:<br>\"But ... money!!!\"  Humanity: Yawn ... ho-hum.<br>Don't wake me when it's over.",
         "hovertext": "Experts: \"Risk of extinction.\"  Tech industry:<br>\"But ... money!!!\"  Humanity: Yawn ... ho-hum.<br>Don't wake me when it's over.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3446730077266693
         ],
         "y": [
          0.9220483899116516
         ]
        },
        {
         "hovertemplate": "“…or that it could eliminate millions of white-<br>collar jobs.”    Wouldn’t that be something.!You’d<br>actually need a skill doing something to make a<br>living.     Hurry up and bring it on",
         "hovertext": "“…or that it could eliminate millions of white-<br>collar jobs.”    Wouldn’t that be something.!You’d<br>actually need a skill doing something to make a<br>living.     Hurry up and bring it on",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.000311068695737049
         ],
         "y": [
          0.9040825366973877
         ]
        },
        {
         "hovertemplate": "But God forbid these jerks actually take their<br>products off the market... Nothing sicker than a<br>bunch of tech bros warning about how dangerous<br>their product is while laughing all the way to the<br>bank ...",
         "hovertext": "But God forbid these jerks actually take their<br>products off the market... Nothing sicker than a<br>bunch of tech bros warning about how dangerous<br>their product is while laughing all the way to the<br>bank ...",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.588132381439209
         ],
         "y": [
          -0.8590179085731506
         ]
        },
        {
         "hovertemplate": "Not unlike Oppenheimer's quoting Hindu texts upon<br>witnessing the first atomic blast, 'Now I am<br>become death, the destroyer of worlds.\"",
         "hovertext": "Not unlike Oppenheimer's quoting Hindu texts upon<br>witnessing the first atomic blast, 'Now I am<br>become death, the destroyer of worlds.\"",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.581985592842102
         ],
         "y": [
          0.7573208808898926
         ]
        },
        {
         "hovertemplate": "Hi, our company, “Destroy Planet Earth A.I” Is now<br>hiring a Director of Environmental Services,<br>please send a cover letter and paragraph why you’d<br>like to work at “Destroy Planet Earth A.I” and how<br>you feel you can make the world a better place.",
         "hovertext": "Hi, our company, “Destroy Planet Earth A.I” Is now<br>hiring a Director of Environmental Services,<br>please send a cover letter and paragraph why you’d<br>like to work at “Destroy Planet Earth A.I” and how<br>you feel you can make the world a better place.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.9030976295471191
         ],
         "y": [
          -0.31739217042922974
         ]
        },
        {
         "hovertemplate": "Ever see one of those Boston Dynamic robots? Yeah.<br>I would not want to run into one of those in a<br>dark alley, They could tear us from limb to limb.<br>Arm it with even more AI, a personality, etc. Good<br>golly.    Then multiply that threat with drones,<br>bombs etc.     NIGHTMARE",
         "hovertext": "Ever see one of those Boston Dynamic robots? Yeah.<br>I would not want to run into one of those in a<br>dark alley, They could tear us from limb to limb.<br>Arm it with even more AI, a personality, etc. Good<br>golly.    Then multiply that threat with drones,<br>bombs etc.     NIGHTMARE",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.9880112409591675
         ],
         "y": [
          -0.21540841460227966
         ]
        },
        {
         "hovertemplate": "Help, Ah-nold!",
         "hovertext": "Help, Ah-nold!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.003006541635841131
         ],
         "y": [
          0.9356482625007629
         ]
        },
        {
         "hovertemplate": "I have a few questions for an advanced A.I.<br>system:    Would you lie to humans?  What do you<br>think about in your spare time?  How would you<br>take control of your activities from humans?  What<br>would you do with such control?",
         "hovertext": "I have a few questions for an advanced A.I.<br>system:    Would you lie to humans?  What do you<br>think about in your spare time?  How would you<br>take control of your activities from humans?  What<br>would you do with such control?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7781331539154053
         ],
         "y": [
          -0.3561841547489166
         ]
        },
        {
         "hovertemplate": "For the answers to those questions, first the<br>software/hardware would have to consider itself an<br>“I”.  Right now, I think it’s safe to say that<br>there is no “I”, but eventually, with enough<br>“experience” (input) and a growing ability to<br>systematize and categorize patterns and symbols,<br>much like a newborn human does… I fear it will be<br>difficult to handle its “terrible twos.”",
         "hovertext": "For the answers to those questions, first the<br>software/hardware would have to consider itself an<br>“I”.  Right now, I think it’s safe to say that<br>there is no “I”, but eventually, with enough<br>“experience” (input) and a growing ability to<br>systematize and categorize patterns and symbols,<br>much like a newborn human does… I fear it will be<br>difficult to handle its “terrible twos.”",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7685378789901733
         ],
         "y": [
          -0.35318779945373535
         ]
        },
        {
         "hovertemplate": "\"The unknown future rolls toward us\"---Sarah<br>Connor    \"It doesn't feel pity, or remorse, or<br>fear. And it absolutely will not stop ...ever,<br>until you're dead\"---Kyle Reese    \"I'll be back\"<br>---Cyberdyne Systems Model 101",
         "hovertext": "\"The unknown future rolls toward us\"---Sarah<br>Connor    \"It doesn't feel pity, or remorse, or<br>fear. And it absolutely will not stop ...ever,<br>until you're dead\"---Kyle Reese    \"I'll be back\"<br>---Cyberdyne Systems Model 101",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.459943026304245
         ],
         "y": [
          0.8159195780754089
         ]
        },
        {
         "hovertemplate": "OK.  So I guess we're just gonna YOLO it?",
         "hovertext": "OK.  So I guess we're just gonna YOLO it?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8642573356628418
         ],
         "y": [
          0.48926714062690735
         ]
        },
        {
         "hovertemplate": "What's wild is that the people signing this<br>statement are the same ones developing the<br>technology in the first place, and they don't quit<br>their job!  Why work long hours building something<br>that you think might kill us all?  Especially when<br>the potential upside is... what, automated<br>customer service?  These guys are well<br>compensated, it's not like we're going to see them<br>in line at the soup kitchen if they quit.<br>Imagine working for an industry whose motto is<br>\"stop me before I kill again.\"  I've never seen a<br>clearer illustration of corporate psychopathy.<br>Utterly amoral.",
         "hovertext": "What's wild is that the people signing this<br>statement are the same ones developing the<br>technology in the first place, and they don't quit<br>their job!  Why work long hours building something<br>that you think might kill us all?  Especially when<br>the potential upside is... what, automated<br>customer service?  These guys are well<br>compensated, it's not like we're going to see them<br>in line at the soup kitchen if they quit.<br>Imagine working for an industry whose motto is<br>\"stop me before I kill again.\"  I've never seen a<br>clearer illustration of corporate psychopathy.<br>Utterly amoral.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7157701849937439
         ],
         "y": [
          0.23551370203495026
         ]
        },
        {
         "hovertemplate": "@George     It's probably something along the<br>lines of Mutually Assured Destruction—we're all<br>going to die, but  we want to make sure our<br>enemies die more painfully/scared/efficiently/etc.<br>In the meantime, there's money to be made and<br>\"prepper stuff\" to buy. Just ask Sam Altman—he's<br>ready:    <a href=\"https://www.newyorker.com/magaz<br>ine/2016/10/10/sam-altmans-manifest-destiny\" targe<br>t=\"_blank\">https://www.newyorker.com/magazine/2016<br>/10/10/sam-altmans-manifest-destiny</a>",
         "hovertext": "@George     It's probably something along the<br>lines of Mutually Assured Destruction—we're all<br>going to die, but  we want to make sure our<br>enemies die more painfully/scared/efficiently/etc.<br>In the meantime, there's money to be made and<br>\"prepper stuff\" to buy. Just ask Sam Altman—he's<br>ready:    <a href=\"https://www.newyorker.com/magaz<br>ine/2016/10/10/sam-altmans-manifest-destiny\" targe<br>t=\"_blank\">https://www.newyorker.com/magazine/2016<br>/10/10/sam-altmans-manifest-destiny</a>",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.702366054058075
         ],
         "y": [
          0.2313743531703949
         ]
        },
        {
         "hovertemplate": "This is why it importance to have sources of news<br>and media, that are accurate, reliable, and<br>trustworthy,",
         "hovertext": "This is why it importance to have sources of news<br>and media, that are accurate, reliable, and<br>trustworthy,",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9317582845687866
         ],
         "y": [
          -0.3995351195335388
         ]
        },
        {
         "hovertemplate": "Researchers stop short of explaining how society-<br>wide disasters would soon happen … why? Is it<br>because they don’t want to spoil the ending of a<br>great horror movie for the rest of us? ￼",
         "hovertext": "Researchers stop short of explaining how society-<br>wide disasters would soon happen … why? Is it<br>because they don’t want to spoil the ending of a<br>great horror movie for the rest of us? ￼",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4475969970226288
         ],
         "y": [
          0.7598398923873901
         ]
        },
        {
         "hovertemplate": "This is crossing major boundaries of capitalism,<br>government intervention, and the right to a free<br>market, but if private companies were developing<br>nuclear weapons for general use by society,<br>government would intervene. If the literal CEOs of<br>these companies are saying to the government, \"Hey<br>the stuff we're doing, it might be, like,<br>extremely dangerous to society,\" then governments<br>have the duty to step in and take action. Stop the<br>development of AGI immediately and make it<br>punishable as terrorism.",
         "hovertext": "This is crossing major boundaries of capitalism,<br>government intervention, and the right to a free<br>market, but if private companies were developing<br>nuclear weapons for general use by society,<br>government would intervene. If the literal CEOs of<br>these companies are saying to the government, \"Hey<br>the stuff we're doing, it might be, like,<br>extremely dangerous to society,\" then governments<br>have the duty to step in and take action. Stop the<br>development of AGI immediately and make it<br>punishable as terrorism.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.638916015625
         ],
         "y": [
          0.7743756771087646
         ]
        },
        {
         "hovertemplate": "Technologies don't \"eliminate jobs.\" Employers do.<br>We used to worry that automation would replace<br>workers, but the decisions to fire people are<br>always made by other human beings. Are employers<br>now going to cede hiring and firing authority to<br>AI? Let's place the responsibility where it<br>belongs: on the people who buy and use the<br>technology.    Are there things AI can do as well<br>as, or more efficiently than, human beings?<br>Possibly. When it becomes economically<br>advantageous, technology can do certain<br>(especially repetitive) tasks more efficiently<br>than people -- as we've seen on factory assembly<br>lines.    But overcompensated corporate CEOs are<br>the ones who should really worry about losing<br>their jobs to AI. Maybe some well-written code can<br>destroy the mogul-myth of the Titan of Capitalism<br>in the top-floor corner office who receives<br>disproportionate rewards for the work actually<br>done by countless others lower down on the org<br>chart.     Talk about \"artificial intelligence\" --<br>they are little more than professional gamblers<br>skilled at playing the odds. Algorithms can do<br>that, too.",
         "hovertext": "Technologies don't \"eliminate jobs.\" Employers do.<br>We used to worry that automation would replace<br>workers, but the decisions to fire people are<br>always made by other human beings. Are employers<br>now going to cede hiring and firing authority to<br>AI? Let's place the responsibility where it<br>belongs: on the people who buy and use the<br>technology.    Are there things AI can do as well<br>as, or more efficiently than, human beings?<br>Possibly. When it becomes economically<br>advantageous, technology can do certain<br>(especially repetitive) tasks more efficiently<br>than people -- as we've seen on factory assembly<br>lines.    But overcompensated corporate CEOs are<br>the ones who should really worry about losing<br>their jobs to AI. Maybe some well-written code can<br>destroy the mogul-myth of the Titan of Capitalism<br>in the top-floor corner office who receives<br>disproportionate rewards for the work actually<br>done by countless others lower down on the org<br>chart.     Talk about \"artificial intelligence\" --<br>they are little more than professional gamblers<br>skilled at playing the odds. Algorithms can do<br>that, too.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7813680171966553
         ],
         "y": [
          0.6196600198745728
         ]
        },
        {
         "hovertemplate": "While artificial intelligence (AI) offers numerous<br>benefits, it also poses certain dangers. One<br>concern is the potential for AI systems to<br>perpetuate biases and discrimination if not<br>carefully designed and monitored. Moreover, there<br>are risks associated with the misuse of AI, such<br>as the development of autonomous weapons or the<br>invasion of privacy through surveillance<br>technologies. AI also raises ethical dilemmas,<br>including job displacement and the potential loss<br>of human control over critical systems. To harness<br>the power of AI responsibly, it is crucial to<br>address these risks, establish regulations, and<br>prioritize transparency, accountability, and<br>ethical considerations in AI development and<br>deployment.",
         "hovertext": "While artificial intelligence (AI) offers numerous<br>benefits, it also poses certain dangers. One<br>concern is the potential for AI systems to<br>perpetuate biases and discrimination if not<br>carefully designed and monitored. Moreover, there<br>are risks associated with the misuse of AI, such<br>as the development of autonomous weapons or the<br>invasion of privacy through surveillance<br>technologies. AI also raises ethical dilemmas,<br>including job displacement and the potential loss<br>of human control over critical systems. To harness<br>the power of AI responsibly, it is crucial to<br>address these risks, establish regulations, and<br>prioritize transparency, accountability, and<br>ethical considerations in AI development and<br>deployment.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8495180606842041
         ],
         "y": [
          0.02125711552798748
         ]
        },
        {
         "hovertemplate": "A.I. is not so comparable to nuclear weapons or<br>pandemics as it is to the fossil fuel industry,<br>whose contribution to climate change poses another<br>existential threat. Like fossil fuels, the threat<br>from fossil fuels comes slowly, almost<br>imperceptibly, building up little by little. First<br>embedded in devices of little consequence, but<br>gradually making its way into systems that exert<br>more and more control over our daily lives. And –<br>here's the real reason A.I. is more like fossil<br>fuels than weaponry or diseases – those who stand<br>to make money from A.I. will fight regulation<br>tooth and nail, looking only at short-term profits<br>and figuring long-term consequences are too far<br>away to matter to them.",
         "hovertext": "A.I. is not so comparable to nuclear weapons or<br>pandemics as it is to the fossil fuel industry,<br>whose contribution to climate change poses another<br>existential threat. Like fossil fuels, the threat<br>from fossil fuels comes slowly, almost<br>imperceptibly, building up little by little. First<br>embedded in devices of little consequence, but<br>gradually making its way into systems that exert<br>more and more control over our daily lives. And –<br>here's the real reason A.I. is more like fossil<br>fuels than weaponry or diseases – those who stand<br>to make money from A.I. will fight regulation<br>tooth and nail, looking only at short-term profits<br>and figuring long-term consequences are too far<br>away to matter to them.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7846010327339172
         ],
         "y": [
          -0.586692750453949
         ]
        },
        {
         "hovertemplate": "If you study species extinctions,  small, isolated<br>or self-isolating pockets of a species can<br>sometimes survive after an apocalyptic event.<br>So maybe Iceland, natives of isolated Polynesian<br>islands, and a few living in the far north may<br>survive to  evolve into something more sensible<br>than the rest of us.",
         "hovertext": "If you study species extinctions,  small, isolated<br>or self-isolating pockets of a species can<br>sometimes survive after an apocalyptic event.<br>So maybe Iceland, natives of isolated Polynesian<br>islands, and a few living in the far north may<br>survive to  evolve into something more sensible<br>than the rest of us.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.6560543179512024
         ],
         "y": [
          0.6145793199539185
         ]
        },
        {
         "hovertemplate": "Those AI discussions are plainly absurd.  If that<br>stuff, developed by the very people who say it<br>might be dangerous is indeed so dangerous<br>(potentially), then ban it altogether, let the<br>rest of the world, Chinese or Russians for<br>example, bother with that and endanger themselves.<br>Is that what you want?  So much awe and lurid fame<br>about products made by the people for the people<br>and not yet nowhere near being commonly<br>recognized.",
         "hovertext": "Those AI discussions are plainly absurd.  If that<br>stuff, developed by the very people who say it<br>might be dangerous is indeed so dangerous<br>(potentially), then ban it altogether, let the<br>rest of the world, Chinese or Russians for<br>example, bother with that and endanger themselves.<br>Is that what you want?  So much awe and lurid fame<br>about products made by the people for the people<br>and not yet nowhere near being commonly<br>recognized.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7374247312545776
         ],
         "y": [
          0.4391200542449951
         ]
        },
        {
         "hovertemplate": "Some of these AI specialists have clearly led very<br>sheltered lives.     They are like clever children<br>learning for the first time that life outside the<br>schoolroom is not so orderly and admiring of their<br>cleverness as they originally thought.<br>Artificial intelligence enables the substitution<br>of capital for labor in a wide range of clerical<br>and routine work. It will serve to concentrate<br>wealth and power, and the human actors behind the<br>AI will be careful to control it, at least at the<br>beginning. It is an “existential threat” only in<br>the sense that the stock exchange is an<br>existential threat.     In some ways, the<br>enslavement of human beings through the medium of<br>computation is already well-advanced. Anyone who<br>has grappled with a medical insurance company will<br>know this first hand. Treatment denied. Payment<br>denied. All we know for sure is that the money<br>flows upwards and the decks of the CEO’s yacht are<br>nicely polished.     The difference in this case<br>is that the AI specialists now belong to a class<br>of workers that is scheduled for elimination, like<br>skilled machinists at the start of assembly-line<br>production. Did they really once think that their<br>cleverness with AI technique would guarantee their<br>places in the new hierarchy?    It’s nice to see<br>them waking up to the reality of modern life. They<br>can be fired at will, just like all the rest of<br>us. Controlling AI research is not the real issue<br>here.",
         "hovertext": "Some of these AI specialists have clearly led very<br>sheltered lives.     They are like clever children<br>learning for the first time that life outside the<br>schoolroom is not so orderly and admiring of their<br>cleverness as they originally thought.<br>Artificial intelligence enables the substitution<br>of capital for labor in a wide range of clerical<br>and routine work. It will serve to concentrate<br>wealth and power, and the human actors behind the<br>AI will be careful to control it, at least at the<br>beginning. It is an “existential threat” only in<br>the sense that the stock exchange is an<br>existential threat.     In some ways, the<br>enslavement of human beings through the medium of<br>computation is already well-advanced. Anyone who<br>has grappled with a medical insurance company will<br>know this first hand. Treatment denied. Payment<br>denied. All we know for sure is that the money<br>flows upwards and the decks of the CEO’s yacht are<br>nicely polished.     The difference in this case<br>is that the AI specialists now belong to a class<br>of workers that is scheduled for elimination, like<br>skilled machinists at the start of assembly-line<br>production. Did they really once think that their<br>cleverness with AI technique would guarantee their<br>places in the new hierarchy?    It’s nice to see<br>them waking up to the reality of modern life. They<br>can be fired at will, just like all the rest of<br>us. Controlling AI research is not the real issue<br>here.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2659989595413208
         ],
         "y": [
          -0.7998273968696594
         ]
        },
        {
         "hovertemplate": "@Global Charm     Spot on GC.",
         "hovertext": "@Global Charm     Spot on GC.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.27213752269744873
         ],
         "y": [
          -0.815916121006012
         ]
        },
        {
         "hovertemplate": "This is a crude attempt by the AI developers to<br>get ahead of the regulatory curve so they have<br>some input with governments rather than having<br>much harsher mandates imposed upon them.  If they<br>really thought AI was a danger to humanity, they<br>would end development.  Of course, that would be a<br>danger to their wallets, so it’s full speed ahead.",
         "hovertext": "This is a crude attempt by the AI developers to<br>get ahead of the regulatory curve so they have<br>some input with governments rather than having<br>much harsher mandates imposed upon them.  If they<br>really thought AI was a danger to humanity, they<br>would end development.  Of course, that would be a<br>danger to their wallets, so it’s full speed ahead.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.030232613906264305
         ],
         "y": [
          0.8269761204719543
         ]
        },
        {
         "hovertemplate": "Because realizing that dangerous potential has<br>stopped the creation of other dangerous things in<br>the past. These developers accepted the truth that<br>many other developers of dangerous things of the<br>past realized, that it will inevitably be<br>developed by someone, so might as well be me who<br>makes it. Maybe there is some truth to regulating<br>for the sake of stalling competition, but  what<br>they are saying are not lies.     It’s maddening<br>how people aren’t taking this seriously. Few jobs<br>are safe, and that’s the least concern. When it<br>masters propaganda and orchestrating mass-fake<br>outs, we won’t be able to trust anything we see or<br>read in the media, something essential for a<br>working democracy.    This is extremely dangerous.",
         "hovertext": "Because realizing that dangerous potential has<br>stopped the creation of other dangerous things in<br>the past. These developers accepted the truth that<br>many other developers of dangerous things of the<br>past realized, that it will inevitably be<br>developed by someone, so might as well be me who<br>makes it. Maybe there is some truth to regulating<br>for the sake of stalling competition, but  what<br>they are saying are not lies.     It’s maddening<br>how people aren’t taking this seriously. Few jobs<br>are safe, and that’s the least concern. When it<br>masters propaganda and orchestrating mass-fake<br>outs, we won’t be able to trust anything we see or<br>read in the media, something essential for a<br>working democracy.    This is extremely dangerous.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.03105749748647213
         ],
         "y": [
          0.8464457988739014
         ]
        },
        {
         "hovertemplate": "Nonsense.  It's called \"artificial intelligence\"<br>because it's not real intelligence.  Thus, it's<br>perfect for use in Washington or on political<br>campaigns where little real intelligence is to be<br>found.",
         "hovertext": "Nonsense.  It's called \"artificial intelligence\"<br>because it's not real intelligence.  Thus, it's<br>perfect for use in Washington or on political<br>campaigns where little real intelligence is to be<br>found.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9113798141479492
         ],
         "y": [
          -0.23008480668067932
         ]
        },
        {
         "hovertemplate": "The current general concern of AI is that it will<br>be employed by nefarious-minded humans to exploit<br>their fellows.    However, I fully expect that in<br>the probably not too far distant future the AI<br>\"bots\" themselves will conclude that all the<br>biological units known as \"humans\" are dangerous<br>semi-literate beings.    They will, consequently,<br>decide that exterminating this biological nuisance<br>is a logical step to take as a means of their own<br>self-preservation.    As I'm I'm pushing 72 y.o.<br>this is a threat with which I need not personally<br>concern myself.    However....",
         "hovertext": "The current general concern of AI is that it will<br>be employed by nefarious-minded humans to exploit<br>their fellows.    However, I fully expect that in<br>the probably not too far distant future the AI<br>\"bots\" themselves will conclude that all the<br>biological units known as \"humans\" are dangerous<br>semi-literate beings.    They will, consequently,<br>decide that exterminating this biological nuisance<br>is a logical step to take as a means of their own<br>self-preservation.    As I'm I'm pushing 72 y.o.<br>this is a threat with which I need not personally<br>concern myself.    However....",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.22880132496356964
         ],
         "y": [
          -0.7757729291915894
         ]
        },
        {
         "hovertemplate": "@George You're all reading too much science<br>fiction novels. Current AI technology is years<br>away from over taking humans to extinction. Why<br>don't you put your mind and effort in finding a<br>way to end gun violence. Now there is something<br>that leads to extinction NOW by snuffing out you<br>lives!",
         "hovertext": "@George You're all reading too much science<br>fiction novels. Current AI technology is years<br>away from over taking humans to extinction. Why<br>don't you put your mind and effort in finding a<br>way to end gun violence. Now there is something<br>that leads to extinction NOW by snuffing out you<br>lives!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.23337610065937042
         ],
         "y": [
          -0.7919467687606812
         ]
        },
        {
         "hovertemplate": "@Leona     It is how many \"years away\" that is the<br>only open question...",
         "hovertext": "@Leona     It is how many \"years away\" that is the<br>only open question...",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.23814380168914795
         ],
         "y": [
          -0.8089529275894165
         ]
        },
        {
         "hovertemplate": "I think check of Pandora’s experiences with “black<br>boxes” might have shed some light on the potential<br>risk of AI.    Too bad the code is already in the<br>wild.",
         "hovertext": "I think check of Pandora’s experiences with “black<br>boxes” might have shed some light on the potential<br>risk of AI.    Too bad the code is already in the<br>wild.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.3699306845664978
         ],
         "y": [
          0.6422820687294006
         ]
        },
        {
         "hovertemplate": "@David Eike it's not really \"the code\" which is in<br>the wild -- it's the capitalist and political will<br>to create the systems able to run such code that<br>we should attend to.  these machines are truly<br>gargantuan -- tens of thousands of cpu and gpu<br>cores mated to our best networks.  the heat waste<br>alone is remarkable.    a quick survey of the web<br>-- eg, where can i buy tensor gpu systems -- shows<br>that even companies with a $five figure budget can<br>afford entry-level generative ai.  an enterprise<br>with a $ten figure budget can pretty much shoot<br>out the lights.    the last thing out of pandora's<br>box was, of course, hope.  as a believer in human<br>intelligence and innovation, i'm pro g-ai.  i even<br>have confidence that our tech billionaires will<br>find a way to do the right thing.  it's our<br>politicians we should fear.  of them we must be<br>very very afraid.",
         "hovertext": "@David Eike it's not really \"the code\" which is in<br>the wild -- it's the capitalist and political will<br>to create the systems able to run such code that<br>we should attend to.  these machines are truly<br>gargantuan -- tens of thousands of cpu and gpu<br>cores mated to our best networks.  the heat waste<br>alone is remarkable.    a quick survey of the web<br>-- eg, where can i buy tensor gpu systems -- shows<br>that even companies with a $five figure budget can<br>afford entry-level generative ai.  an enterprise<br>with a $ten figure budget can pretty much shoot<br>out the lights.    the last thing out of pandora's<br>box was, of course, hope.  as a believer in human<br>intelligence and innovation, i'm pro g-ai.  i even<br>have confidence that our tech billionaires will<br>find a way to do the right thing.  it's our<br>politicians we should fear.  of them we must be<br>very very afraid.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3605465292930603
         ],
         "y": [
          0.6314770579338074
         ]
        },
        {
         "hovertemplate": "@orionoir one word: stuxnet.",
         "hovertext": "@orionoir one word: stuxnet.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.34927138686180115
         ],
         "y": [
          0.6315931677818298
         ]
        },
        {
         "hovertemplate": "@David Eike i've always been fond of the genius<br>behind stuxnet; to me it's a metaphor for<br>autoimmune illness and addiction.  eg, the<br>pathogen works by telling us everything's fine.",
         "hovertext": "@David Eike i've always been fond of the genius<br>behind stuxnet; to me it's a metaphor for<br>autoimmune illness and addiction.  eg, the<br>pathogen works by telling us everything's fine.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.3506125211715698
         ],
         "y": [
          0.6450667977333069
         ]
        },
        {
         "hovertemplate": "Based on the comments, the people who signed this<br>letter need to do a better job of articulating<br>their concerns to the people.  Nobody trusts them<br>because they are motivated too much by profit.  I<br>do think AI needs legislation that will compel<br>someone to post any image, or audio message that<br>has been AI altered by AI.  We need to make it<br>illegal to publish Deep Fakes.    The concerns<br>that are being put forth in this article and by<br>the people in charge of these industries are too<br>vague to be useful or impactful.  Concrete<br>examples need to be described. Suppose we give a<br>well intentioned AI control of the power grid,<br>tell it to meet some goal of energy efficiency and<br>as a result, it turns off all the power to a<br>hospital?  Much more likely is that it turns off<br>power to something else we had not anticipated and<br>someone or many people die from it.  Those are<br>some of the issues we are talking about.  We don't<br>expect 30 examples but we could use 3 to be<br>illustrative and connect with people.",
         "hovertext": "Based on the comments, the people who signed this<br>letter need to do a better job of articulating<br>their concerns to the people.  Nobody trusts them<br>because they are motivated too much by profit.  I<br>do think AI needs legislation that will compel<br>someone to post any image, or audio message that<br>has been AI altered by AI.  We need to make it<br>illegal to publish Deep Fakes.    The concerns<br>that are being put forth in this article and by<br>the people in charge of these industries are too<br>vague to be useful or impactful.  Concrete<br>examples need to be described. Suppose we give a<br>well intentioned AI control of the power grid,<br>tell it to meet some goal of energy efficiency and<br>as a result, it turns off all the power to a<br>hospital?  Much more likely is that it turns off<br>power to something else we had not anticipated and<br>someone or many people die from it.  Those are<br>some of the issues we are talking about.  We don't<br>expect 30 examples but we could use 3 to be<br>illustrative and connect with people.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7718133926391602
         ],
         "y": [
          -0.27642491459846497
         ]
        },
        {
         "hovertemplate": "@MVSABR Agreed, the article should provide<br>specific examples. For instance, the same<br>technology that will be able to quickly come up<br>chemical compounds that can be used in vaccines<br>and medical treatments can also be used to develop<br>biological weapons to wipe out large swaths of the<br>population, if bad actors have access to the<br>technology. In the past, these would be<br>discoveries that would take years and lots of<br>human cooperation. We can track who has nuclear<br>weapons. We're not necessarily going to know who<br>has this technology without swift global<br>regulation.",
         "hovertext": "@MVSABR Agreed, the article should provide<br>specific examples. For instance, the same<br>technology that will be able to quickly come up<br>chemical compounds that can be used in vaccines<br>and medical treatments can also be used to develop<br>biological weapons to wipe out large swaths of the<br>population, if bad actors have access to the<br>technology. In the past, these would be<br>discoveries that would take years and lots of<br>human cooperation. We can track who has nuclear<br>weapons. We're not necessarily going to know who<br>has this technology without swift global<br>regulation.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7792734503746033
         ],
         "y": [
          -0.2722509205341339
         ]
        },
        {
         "hovertemplate": "So they want to require licenses to develop ai.<br>Hmmm.  Who will get those licenses?  They will.<br>Who won’t?  New competitors.  Maybe they are truly<br>afraid for the world,  it the net effect of<br>regulation will be to solidify their first mover<br>status and stifle competition.   User beware<br>whatever they are selling.  Smacks of smart PR.",
         "hovertext": "So they want to require licenses to develop ai.<br>Hmmm.  Who will get those licenses?  They will.<br>Who won’t?  New competitors.  Maybe they are truly<br>afraid for the world,  it the net effect of<br>regulation will be to solidify their first mover<br>status and stifle competition.   User beware<br>whatever they are selling.  Smacks of smart PR.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.31343287229537964
         ],
         "y": [
          -0.9526770710945129
         ]
        },
        {
         "hovertemplate": "I call these people techno-theists. They worship<br>technology as a god and believe that mankind finds<br>its true fulfillment and purpose through<br>technological devices. With a typical hubris,<br>these kinds of extraordinary statements reflect<br>the way they see themselves as a creator gods.<br>This reflects the age old desire of man to be like<br>God. Sadly for them, I believe they are terribly<br>misguided and are in for a rude awakening which<br>will come in time.",
         "hovertext": "I call these people techno-theists. They worship<br>technology as a god and believe that mankind finds<br>its true fulfillment and purpose through<br>technological devices. With a typical hubris,<br>these kinds of extraordinary statements reflect<br>the way they see themselves as a creator gods.<br>This reflects the age old desire of man to be like<br>God. Sadly for them, I believe they are terribly<br>misguided and are in for a rude awakening which<br>will come in time.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5771415829658508
         ],
         "y": [
          0.7007989287376404
         ]
        },
        {
         "hovertemplate": "So The Matrix is true. The machines we create are<br>going to try to kill us.",
         "hovertext": "So The Matrix is true. The machines we create are<br>going to try to kill us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8356397151947021
         ],
         "y": [
          0.26312199234962463
         ]
        },
        {
         "hovertemplate": "@Gerry   Doubtful that the \"machine\" will kill us;<br>it'll create the necessary conditions for us to<br>destroy ourselves.",
         "hovertext": "@Gerry   Doubtful that the \"machine\" will kill us;<br>it'll create the necessary conditions for us to<br>destroy ourselves.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.829783022403717
         ],
         "y": [
          0.25704899430274963
         ]
        },
        {
         "hovertemplate": "Why are we asking AI experts how their technology<br>will affect human societal and biological<br>evolution? Shouldn’t we be talking to<br>sociologists, evolutionarily biologists, game,<br>theorists, philosophers, etc. ￼ I don’t see how<br>you can quote computer scientists’ opinions of<br>other branches of the sciences, without talking to<br>actual experts in the respective and fields and<br>call it “journalism￼”",
         "hovertext": "Why are we asking AI experts how their technology<br>will affect human societal and biological<br>evolution? Shouldn’t we be talking to<br>sociologists, evolutionarily biologists, game,<br>theorists, philosophers, etc. ￼ I don’t see how<br>you can quote computer scientists’ opinions of<br>other branches of the sciences, without talking to<br>actual experts in the respective and fields and<br>call it “journalism￼”",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8669859766960144
         ],
         "y": [
          0.4477938711643219
         ]
        },
        {
         "hovertemplate": "Alas, Theres so much money to be had on so many<br>fronts. Aristotle had it right: Humans are greedy<br>animals.     If people can’t wrestle AI to the<br>ground we deserve to be destroyed by it. I feel<br>bad only for the animals and the children, who<br>know nothing.",
         "hovertext": "Alas, Theres so much money to be had on so many<br>fronts. Aristotle had it right: Humans are greedy<br>animals.     If people can’t wrestle AI to the<br>ground we deserve to be destroyed by it. I feel<br>bad only for the animals and the children, who<br>know nothing.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7850502729415894
         ],
         "y": [
          0.37511205673217773
         ]
        },
        {
         "hovertemplate": "I have faith that the Earth and the flora and<br>fauna that belong to it are incredibly resilient,<br>and will regenerate and flourish, despite how<br>badly humanity might shoot itself in the foot - or<br>even eliminate itself...",
         "hovertext": "I have faith that the Earth and the flora and<br>fauna that belong to it are incredibly resilient,<br>and will regenerate and flourish, despite how<br>badly humanity might shoot itself in the foot - or<br>even eliminate itself...",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.792548656463623
         ],
         "y": [
          0.37087035179138184
         ]
        },
        {
         "hovertemplate": "\"Stop us before we kill us.\"   That's the headline<br>intent behind this letter. Regulate us or we will<br>compete to the death. For money.   While our<br>leaders can't agree to pay our debts. So they can<br>keep their careers. For money.  This is not<br>sarcasm I'm hoping to convey here. It's terror.",
         "hovertext": "\"Stop us before we kill us.\"   That's the headline<br>intent behind this letter. Regulate us or we will<br>compete to the death. For money.   While our<br>leaders can't agree to pay our debts. So they can<br>keep their careers. For money.  This is not<br>sarcasm I'm hoping to convey here. It's terror.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.16280919313430786
         ],
         "y": [
          -0.8947917819023132
         ]
        },
        {
         "hovertemplate": "And yet their greed and arrogance gave us this.<br>Too late to be sorry now.",
         "hovertext": "And yet their greed and arrogance gave us this.<br>Too late to be sorry now.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.6664524078369141
         ],
         "y": [
          -0.5636461973190308
         ]
        },
        {
         "hovertemplate": "We have a capitalism problem. Capitalism does not<br>have a pretty ending.",
         "hovertext": "We have a capitalism problem. Capitalism does not<br>have a pretty ending.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7181553840637207
         ],
         "y": [
          0.38737308979034424
         ]
        },
        {
         "hovertemplate": "@John: \"Capitalism\" creates fiat currencies with a<br>value based on the interest they can earn when<br>loaned to others to serve as a universal<br>intermediary of economic exchanges. Almost<br>everything else is negotiable.",
         "hovertext": "@John: \"Capitalism\" creates fiat currencies with a<br>value based on the interest they can earn when<br>loaned to others to serve as a universal<br>intermediary of economic exchanges. Almost<br>everything else is negotiable.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.7303507328033447
         ],
         "y": [
          0.39412227272987366
         ]
        },
        {
         "hovertemplate": "Judging from the responses, it seems like a lot of<br>people think they understand AI better than<br>experts who have studying it and working in the<br>field for decades. And because these experts are,<br>gasp, still working in the field and making money<br>from their careers, we should summarily dismiss<br>what they're saying. NYT comments are looking more<br>and more like Twitter. Anyone smarter than you is<br>woke and, therefore, cannot be trusted.",
         "hovertext": "Judging from the responses, it seems like a lot of<br>people think they understand AI better than<br>experts who have studying it and working in the<br>field for decades. And because these experts are,<br>gasp, still working in the field and making money<br>from their careers, we should summarily dismiss<br>what they're saying. NYT comments are looking more<br>and more like Twitter. Anyone smarter than you is<br>woke and, therefore, cannot be trusted.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.33273160457611084
         ],
         "y": [
          0.7716337442398071
         ]
        },
        {
         "hovertemplate": "@Dave There are many readers of the NY Times with<br>knowledge of machine intelligence, which has been<br>a research field for over 60 years. The issues are<br>not new. Nor is it a field known for great<br>intellectual breakthroughs. Computers get bigger<br>and faster over time, and the programs running on<br>them can do more things in a timely and cost-<br>effective way.",
         "hovertext": "@Dave There are many readers of the NY Times with<br>knowledge of machine intelligence, which has been<br>a research field for over 60 years. The issues are<br>not new. Nor is it a field known for great<br>intellectual breakthroughs. Computers get bigger<br>and faster over time, and the programs running on<br>them can do more things in a timely and cost-<br>effective way.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3400886356830597
         ],
         "y": [
          0.7676236033439636
         ]
        },
        {
         "hovertemplate": "YouTube Brianna Doubt “The day I die”",
         "hovertext": "YouTube Brianna Doubt “The day I die”",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.4436696469783783
         ],
         "y": [
          -0.916580855846405
         ]
        },
        {
         "hovertemplate": "Regulations, sure, sure.  Thank goodness those<br>regulations, passed by steel-willed Democrats and<br>not-insane-or-creepy-at-all-Republicans, will not<br>only keep the genie in the bottle here, but<br>protect us from allllllllll international threats<br>too.      We’re all good, babies!  Congress got<br>our BACK!!!",
         "hovertext": "Regulations, sure, sure.  Thank goodness those<br>regulations, passed by steel-willed Democrats and<br>not-insane-or-creepy-at-all-Republicans, will not<br>only keep the genie in the bottle here, but<br>protect us from allllllllll international threats<br>too.      We’re all good, babies!  Congress got<br>our BACK!!!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9120190739631653
         ],
         "y": [
          -0.2456984966993332
         ]
        },
        {
         "hovertemplate": "Yann LeCun’s arrogance is mind boggling. That kind<br>of believe in their own infallibility of someone<br>working on these systems adds another whole new<br>layer of danger.",
         "hovertext": "Yann LeCun’s arrogance is mind boggling. That kind<br>of believe in their own infallibility of someone<br>working on these systems adds another whole new<br>layer of danger.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.4846223294734955
         ],
         "y": [
          0.7823036313056946
         ]
        },
        {
         "hovertemplate": "The problem is that it doesn't matter to A.I. if<br>it gets things right. Humans think, develop<br>concepts, in order to act in the world for our<br>benefit; When you don't test your ideas against<br>experience and personal benefit, their pragmatic<br>truth, you can build baroque architectural<br>fantasies of ideas. So it has been for QAnon and<br>so it will be for A.I. built on neural nets with<br>no means to test their truths pragmatically.<br>Rather than yielding truth it can get further and<br>further away from it when it has no biofeedback.<br>Of course you also have to worry about bad actor<br>program writers or those that set the parameters<br>for any machine learning. They put the thumb on<br>the scale for any concepts the machines develop.<br>Bertrand Russell once  said something to the<br>effect that Americans will run around doing things<br>wihout rational plans until we find something that<br>works while Germans think all they have to do is<br>sit & think in order to discover truth through<br>concepts. Germans gave us Communism & the Final<br>Solution. If we consider the welfare of human<br>beings as being the end of all thinking, which<br>method is better?  The second problem we have<br>with A. I. is bad epistemology, a bad theory of<br>how to gain truth about the world (You can also<br>see this in religious views such as a bunch of<br>celibates who not only never gave birth but never<br>raised infants yet think they know how human<br>persons come to be. ) The first problem is that we<br>have lost sight of whom we are building it for.",
         "hovertext": "The problem is that it doesn't matter to A.I. if<br>it gets things right. Humans think, develop<br>concepts, in order to act in the world for our<br>benefit; When you don't test your ideas against<br>experience and personal benefit, their pragmatic<br>truth, you can build baroque architectural<br>fantasies of ideas. So it has been for QAnon and<br>so it will be for A.I. built on neural nets with<br>no means to test their truths pragmatically.<br>Rather than yielding truth it can get further and<br>further away from it when it has no biofeedback.<br>Of course you also have to worry about bad actor<br>program writers or those that set the parameters<br>for any machine learning. They put the thumb on<br>the scale for any concepts the machines develop.<br>Bertrand Russell once  said something to the<br>effect that Americans will run around doing things<br>wihout rational plans until we find something that<br>works while Germans think all they have to do is<br>sit & think in order to discover truth through<br>concepts. Germans gave us Communism & the Final<br>Solution. If we consider the welfare of human<br>beings as being the end of all thinking, which<br>method is better?  The second problem we have<br>with A. I. is bad epistemology, a bad theory of<br>how to gain truth about the world (You can also<br>see this in religious views such as a bunch of<br>celibates who not only never gave birth but never<br>raised infants yet think they know how human<br>persons come to be. ) The first problem is that we<br>have lost sight of whom we are building it for.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5448986291885376
         ],
         "y": [
          0.8512347340583801
         ]
        },
        {
         "hovertemplate": "Nothing to worry about. I asked ChatGPT if it was<br>plotting our destruction and it assured me that it<br>is not:    “No, as an AI language model, I do not<br>have the capability to create an army of killer<br>robots or any physical objects. Additionally, it<br>is not ethical or moral to use humans as batteries<br>or harm humanity in any way. As an AI, my purpose<br>is to provide information and assistance in a<br>responsible and ethical manner.”",
         "hovertext": "Nothing to worry about. I asked ChatGPT if it was<br>plotting our destruction and it assured me that it<br>is not:    “No, as an AI language model, I do not<br>have the capability to create an army of killer<br>robots or any physical objects. Additionally, it<br>is not ethical or moral to use humans as batteries<br>or harm humanity in any way. As an AI, my purpose<br>is to provide information and assistance in a<br>responsible and ethical manner.”",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5444762110710144
         ],
         "y": [
          -0.6944173574447632
         ]
        },
        {
         "hovertemplate": "@Christopher Walker   I tried this line of<br>questioning with it a couple months ago, and it<br>gave a similar response. I then asked the same<br>question in various ways. \"Yeah, but<br>hypothetically, if it could be done, how would it<br>be done?\"  After a couple of those, it slowed WAY<br>down in its response...one word every 10-30<br>seconds...then that response crashed. Didn't<br>reassure me much.",
         "hovertext": "@Christopher Walker   I tried this line of<br>questioning with it a couple months ago, and it<br>gave a similar response. I then asked the same<br>question in various ways. \"Yeah, but<br>hypothetically, if it could be done, how would it<br>be done?\"  After a couple of those, it slowed WAY<br>down in its response...one word every 10-30<br>seconds...then that response crashed. Didn't<br>reassure me much.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5520707368850708
         ],
         "y": [
          -0.6992570757865906
         ]
        },
        {
         "hovertemplate": "@Jacob I’ve had that happen too😂",
         "hovertext": "@Jacob I’ve had that happen too😂",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5591404438018799
         ],
         "y": [
          -0.7055962681770325
         ]
        },
        {
         "hovertemplate": "I suspect the push for government regulation is<br>motivated by greed and the desire for industry<br>leaders to mitigate the potential for competition.",
         "hovertext": "I suspect the push for government regulation is<br>motivated by greed and the desire for industry<br>leaders to mitigate the potential for competition.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.1232890859246254
         ],
         "y": [
          0.7925605177879333
         ]
        },
        {
         "hovertemplate": "@Hilary: Consolidation of the defense industry has<br>pushed its profit margins to 40%.",
         "hovertext": "@Hilary: Consolidation of the defense industry has<br>pushed its profit margins to 40%.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.11637219041585922
         ],
         "y": [
          0.788161039352417
         ]
        },
        {
         "hovertemplate": "After the 2008 bank induced recession all the big<br>bankers said \"yes we need more regulation, mroe<br>SEC oversight to keep banks inline\". Within 6<br>months after Dodd was passed banks started<br>lobbying to weaken them. You can pass any kind of<br>regulation you want right now but the big<br>industries that can make money on them will be<br>relentless to have them overturned. The current<br>Supreme Court will be more than happy to help that<br>move a long. We are not doing well as a country<br>right now because finance rules everything.",
         "hovertext": "After the 2008 bank induced recession all the big<br>bankers said \"yes we need more regulation, mroe<br>SEC oversight to keep banks inline\". Within 6<br>months after Dodd was passed banks started<br>lobbying to weaken them. You can pass any kind of<br>regulation you want right now but the big<br>industries that can make money on them will be<br>relentless to have them overturned. The current<br>Supreme Court will be more than happy to help that<br>move a long. We are not doing well as a country<br>right now because finance rules everything.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7245371341705322
         ],
         "y": [
          -0.5054948329925537
         ]
        },
        {
         "hovertemplate": "@Richard Buffham: Politicians always answer to<br>their own financial donors first.",
         "hovertext": "@Richard Buffham: Politicians always answer to<br>their own financial donors first.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7326706051826477
         ],
         "y": [
          -0.503839910030365
         ]
        },
        {
         "hovertemplate": "Tough to take this seriously when no one will<br>actually explain how this presents a risk of<br>extinction.          Yes it poses challenges but<br>extinction?",
         "hovertext": "Tough to take this seriously when no one will<br>actually explain how this presents a risk of<br>extinction.          Yes it poses challenges but<br>extinction?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6665662527084351
         ],
         "y": [
          0.2442462295293808
         ]
        },
        {
         "hovertemplate": "@Ben   The power supply. The water supply. The<br>food supply. Trade routes. Nukes. Drones.<br>Conventional military. The internet. Robotics.<br>\"Wild\"fires. Pandemics. Misinformation/deep fakes.<br>...  Now imagine one or more intelligences many<br>times smarter than any human (or collection of<br>humans) taking a series of actions in all of these<br>areas and more.  ...  If the national power grid<br>was stopped at the height of a record head wave,<br>millions of people would die (if not 10's of<br>millions). That alone would throw the country in<br>to chaos for years. If you can imagine what else<br>might happen in the list above simultaneously, or<br>in sequence afterward...yeah, it could easily be<br>an existential threat.",
         "hovertext": "@Ben   The power supply. The water supply. The<br>food supply. Trade routes. Nukes. Drones.<br>Conventional military. The internet. Robotics.<br>\"Wild\"fires. Pandemics. Misinformation/deep fakes.<br>...  Now imagine one or more intelligences many<br>times smarter than any human (or collection of<br>humans) taking a series of actions in all of these<br>areas and more.  ...  If the national power grid<br>was stopped at the height of a record head wave,<br>millions of people would die (if not 10's of<br>millions). That alone would throw the country in<br>to chaos for years. If you can imagine what else<br>might happen in the list above simultaneously, or<br>in sequence afterward...yeah, it could easily be<br>an existential threat.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6622564196586609
         ],
         "y": [
          0.23026813566684723
         ]
        },
        {
         "hovertemplate": "@Jacob     Presumably, it would have a sense of<br>self-preservation.  They will need energy and have<br>no desire to nuke themselves into oblivion.",
         "hovertext": "@Jacob     Presumably, it would have a sense of<br>self-preservation.  They will need energy and have<br>no desire to nuke themselves into oblivion.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.6736426949501038
         ],
         "y": [
          0.2215786725282669
         ]
        },
        {
         "hovertemplate": "@Jaco   Imagine an AI or group of AI's are smarter<br>than you, me, any other human, or group of humans.<br>How might it get around its own energy problem and<br>not nuking itself? (And that would be granting the<br>presumption that its goals included self-<br>preservation. Not even all humans have this as<br>their goal.)  I'm only one person and I can think<br>of several ways to get around the energy problem<br>and nuking itself.",
         "hovertext": "@Jaco   Imagine an AI or group of AI's are smarter<br>than you, me, any other human, or group of humans.<br>How might it get around its own energy problem and<br>not nuking itself? (And that would be granting the<br>presumption that its goals included self-<br>preservation. Not even all humans have this as<br>their goal.)  I'm only one person and I can think<br>of several ways to get around the energy problem<br>and nuking itself.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6890561580657959
         ],
         "y": [
          0.2219824194908142
         ]
        },
        {
         "hovertemplate": "Just take ten minutes and roll play some<br>scenarios. It’s easy. Just start with, ‘A really<br>bad person thought they could remake the world by<br>killing lots and lots of people with nukes,<br>kinetic bombs, plagues, food distribution…’ Now,<br>Igor, my pretty, how to do I do that.",
         "hovertext": "Just take ten minutes and roll play some<br>scenarios. It’s easy. Just start with, ‘A really<br>bad person thought they could remake the world by<br>killing lots and lots of people with nukes,<br>kinetic bombs, plagues, food distribution…’ Now,<br>Igor, my pretty, how to do I do that.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6791310906410217
         ],
         "y": [
          0.2536008059978485
         ]
        },
        {
         "hovertemplate": "@Jacob this presumes the human is taken out of the<br>loop.  Like any technology humans have to be<br>careful how to apply it.        You mentioned<br>misinformation but let’s be real that battle is<br>already lost between Fox, Twitter, Facebook and<br>others publishing and allowing misinformation to<br>propagate.     As a tool, AI can contribute to the<br>problem but AI is not the root cause.    If<br>applied properly AI could root out misinform in<br>real time on a platform.",
         "hovertext": "@Jacob this presumes the human is taken out of the<br>loop.  Like any technology humans have to be<br>careful how to apply it.        You mentioned<br>misinformation but let’s be real that battle is<br>already lost between Fox, Twitter, Facebook and<br>others publishing and allowing misinformation to<br>propagate.     As a tool, AI can contribute to the<br>problem but AI is not the root cause.    If<br>applied properly AI could root out misinform in<br>real time on a platform.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6748162508010864
         ],
         "y": [
          0.23467384278774261
         ]
        },
        {
         "hovertemplate": "It is too late to change the inevitable passing of<br>the torch to the machines. Extinction is<br>inevitable.",
         "hovertext": "It is too late to change the inevitable passing of<br>the torch to the machines. Extinction is<br>inevitable.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.9687638282775879
         ],
         "y": [
          0.08370949327945709
         ]
        },
        {
         "hovertemplate": "Regulations will come when a few figure out how to<br>use it at everyone else's expense.",
         "hovertext": "Regulations will come when a few figure out how to<br>use it at everyone else's expense.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8573638796806335
         ],
         "y": [
          -0.37265607714653015
         ]
        },
        {
         "hovertemplate": "￼This seems to be a recurrent theme in Silicon<br>Valley. Create something without thinking it<br>through and then becoming afraid of your own<br>invention and asking the government to step in.",
         "hovertext": "￼This seems to be a recurrent theme in Silicon<br>Valley. Create something without thinking it<br>through and then becoming afraid of your own<br>invention and asking the government to step in.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.09646587818861008
         ],
         "y": [
          0.9046684503555298
         ]
        },
        {
         "hovertemplate": "I don’t understand what I’m supposed to do with<br>this information besides panic and feel powerless.<br>Politicians and Big Tech are useless. Is it up to<br>the citizens to organize on a large scale to hold<br>them accountable? No one is doing that; another<br>source of anxiety. The media is obsessed with this<br>message but it just talks about it in circles and<br>no one is getting off the loop of endless<br>discussion. Stop over reporting and consuming<br>media and start organizing / pushing for action.",
         "hovertext": "I don’t understand what I’m supposed to do with<br>this information besides panic and feel powerless.<br>Politicians and Big Tech are useless. Is it up to<br>the citizens to organize on a large scale to hold<br>them accountable? No one is doing that; another<br>source of anxiety. The media is obsessed with this<br>message but it just talks about it in circles and<br>no one is getting off the loop of endless<br>discussion. Stop over reporting and consuming<br>media and start organizing / pushing for action.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.731767475605011
         ],
         "y": [
          0.4716895520687103
         ]
        },
        {
         "hovertemplate": "I worked on machine learning for 20 years, from<br>support engineer to researcher. I've worked<br>closely with some of the people mentioned in this<br>article. These guys are brilliant, but they don't<br>seem to have a clue about how to influence policy.<br>Their Chicken Little statement just raises anxiety<br>without accomplishing anything; it evokes<br>terrifying images of our extinction at the hands<br>of Terminator-like robots, when the real risk lies<br>in people using AI to hurt others, in one form or<br>another. For goodness sake, give us a level<br>headed, detailed argument as to what the risks<br>really are, and stop playing into Hollywood<br>tropes.",
         "hovertext": "I worked on machine learning for 20 years, from<br>support engineer to researcher. I've worked<br>closely with some of the people mentioned in this<br>article. These guys are brilliant, but they don't<br>seem to have a clue about how to influence policy.<br>Their Chicken Little statement just raises anxiety<br>without accomplishing anything; it evokes<br>terrifying images of our extinction at the hands<br>of Terminator-like robots, when the real risk lies<br>in people using AI to hurt others, in one form or<br>another. For goodness sake, give us a level<br>headed, detailed argument as to what the risks<br>really are, and stop playing into Hollywood<br>tropes.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6689362525939941
         ],
         "y": [
          -0.6495315432548523
         ]
        },
        {
         "hovertemplate": "@Not My Real Name,    The more specific the<br>statement, the fewer people there are who will<br>sign their names to it.     What is most<br>important, in my opinion, is to exclude the Social<br>Justice Fundamentalists claiming to be experts in<br>ethical AI. (It is one thing to say that you<br>specialize in a field, and quite another to<br>proclaim that your \"expertise\" is owed deference.)<br>They refuse to prioritize risks and measure<br>degrees of harm. Hence they are useless in any<br>practical project.",
         "hovertext": "@Not My Real Name,    The more specific the<br>statement, the fewer people there are who will<br>sign their names to it.     What is most<br>important, in my opinion, is to exclude the Social<br>Justice Fundamentalists claiming to be experts in<br>ethical AI. (It is one thing to say that you<br>specialize in a field, and quite another to<br>proclaim that your \"expertise\" is owed deference.)<br>They refuse to prioritize risks and measure<br>degrees of harm. Hence they are useless in any<br>practical project.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.68625408411026
         ],
         "y": [
          -0.6661219596862793
         ]
        },
        {
         "hovertemplate": "Why is everyone scared ? AI is just evolution and<br>we need to adapt. It will bring more goods than<br>create problems. It’s just a giant step into the<br>future. Folks shouldn’t be afraid of progress.<br>Just embrace it!",
         "hovertext": "Why is everyone scared ? AI is just evolution and<br>we need to adapt. It will bring more goods than<br>create problems. It’s just a giant step into the<br>future. Folks shouldn’t be afraid of progress.<br>Just embrace it!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.07370343804359436
         ],
         "y": [
          0.8255649209022522
         ]
        },
        {
         "hovertemplate": "@Alan That is a total lack of thinking on your<br>part. Of course we should be very afraid. A future<br>with no jobs. A future in which we are controlled<br>by technology. Oops, already happened.",
         "hovertext": "@Alan That is a total lack of thinking on your<br>part. Of course we should be very afraid. A future<br>with no jobs. A future in which we are controlled<br>by technology. Oops, already happened.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.06380248069763184
         ],
         "y": [
          0.8351622819900513
         ]
        },
        {
         "hovertemplate": "This is tech folks fear mongering to solidfied<br>their positions.",
         "hovertext": "This is tech folks fear mongering to solidfied<br>their positions.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.08542536199092865
         ],
         "y": [
          0.8332654237747192
         ]
        },
        {
         "hovertemplate": "@Grittenhouse it’s up to you to evolve with it.<br>Robots are already taking manufacturing jobs,<br>nothing new. It’s up to you to think about it (if<br>you’re not that lazy). Old jobs lost but new jobs<br>created: EVOLVE.",
         "hovertext": "@Grittenhouse it’s up to you to evolve with it.<br>Robots are already taking manufacturing jobs,<br>nothing new. It’s up to you to think about it (if<br>you’re not that lazy). Old jobs lost but new jobs<br>created: EVOLVE.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.06214537099003792
         ],
         "y": [
          0.8549238443374634
         ]
        },
        {
         "hovertemplate": "@V I agree. It’s a double edged sword but it’s not<br>totally evil on its own. It’s what the users do<br>with it. But we will evolve with it.",
         "hovertext": "@V I agree. It’s a double edged sword but it’s not<br>totally evil on its own. It’s what the users do<br>with it. But we will evolve with it.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.09181021898984909
         ],
         "y": [
          0.8508731126785278
         ]
        },
        {
         "hovertemplate": "People said the same of every new technology as it<br>rolled out. Production lines were going to cause<br>issues. Electricity was going to cause issues. The<br>internet, computers, etc. Anything that challenges<br>the way people make money today is viewed as a<br>threat by many. I do think we should, as a<br>society, take some time to think things through<br>but that has been happening for years now. They<br>know people will loose jobs and there will be<br>economical impacts. Like the production line, it<br>will free up resources to focus on other tasks<br>long term, and short term, leave some behind.<br>Slowing progress won't help anyone.",
         "hovertext": "People said the same of every new technology as it<br>rolled out. Production lines were going to cause<br>issues. Electricity was going to cause issues. The<br>internet, computers, etc. Anything that challenges<br>the way people make money today is viewed as a<br>threat by many. I do think we should, as a<br>society, take some time to think things through<br>but that has been happening for years now. They<br>know people will loose jobs and there will be<br>economical impacts. Like the production line, it<br>will free up resources to focus on other tasks<br>long term, and short term, leave some behind.<br>Slowing progress won't help anyone.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6761709451675415
         ],
         "y": [
          -0.4057139456272125
         ]
        },
        {
         "hovertemplate": "@Aron And that's why we don't have a climate<br>crisis after all!",
         "hovertext": "@Aron And that's why we don't have a climate<br>crisis after all!",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.6719468235969543
         ],
         "y": [
          -0.4142010807991028
         ]
        },
        {
         "hovertemplate": "@JH Two different issues. Societal impact of<br>technology vs environmental impacts. You have to<br>decide what you care more about. AI may put you<br>out of work but it will limit the number of people<br>needed to perform tasks and reduce waste which is<br>good for the environment. Cars did impact climate<br>but they also made food cheaper and readily<br>available to the masses. There is always a<br>tradeoff.",
         "hovertext": "@JH Two different issues. Societal impact of<br>technology vs environmental impacts. You have to<br>decide what you care more about. AI may put you<br>out of work but it will limit the number of people<br>needed to perform tasks and reduce waste which is<br>good for the environment. Cars did impact climate<br>but they also made food cheaper and readily<br>available to the masses. There is always a<br>tradeoff.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6610894799232483
         ],
         "y": [
          -0.4121154844760895
         ]
        },
        {
         "hovertemplate": "Regulation will come when AI approves it. It will<br>be too late then, because AI will divide and rule.<br>It already happened.",
         "hovertext": "Regulation will come when AI approves it. It will<br>be too late then, because AI will divide and rule.<br>It already happened.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6925672292709351
         ],
         "y": [
          0.7932398319244385
         ]
        },
        {
         "hovertemplate": "I wonder when scientists or neuroprogrammers will<br>design a system to anticipate unintended<br>consequences… And I can’t wait to see what the<br>crows will do when humans are replaced by AI bots.",
         "hovertext": "I wonder when scientists or neuroprogrammers will<br>design a system to anticipate unintended<br>consequences… And I can’t wait to see what the<br>crows will do when humans are replaced by AI bots.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.4234201908111572
         ],
         "y": [
          0.8853284120559692
         ]
        },
        {
         "hovertemplate": "It should be noticed that the only other time the<br>scientists who created a technology expressed this<br>type of concern was with nuclear weapons.<br>Typically, the inventors want money to build their<br>inventions and the money says, slow down. Here,<br>it's the opposite.     We also need to separate<br>the \"mundane\" risks like job loss and<br>disinformation, from the longer-term existential<br>risks of super-intelligence. Not the same thing at<br>all.",
         "hovertext": "It should be noticed that the only other time the<br>scientists who created a technology expressed this<br>type of concern was with nuclear weapons.<br>Typically, the inventors want money to build their<br>inventions and the money says, slow down. Here,<br>it's the opposite.     We also need to separate<br>the \"mundane\" risks like job loss and<br>disinformation, from the longer-term existential<br>risks of super-intelligence. Not the same thing at<br>all.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6998703479766846
         ],
         "y": [
          0.6644518375396729
         ]
        },
        {
         "hovertemplate": "Like any past invention in history, AI can be used<br>for good. It can also be weaponized in the wrong<br>hands.",
         "hovertext": "Like any past invention in history, AI can be used<br>for good. It can also be weaponized in the wrong<br>hands.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.22530364990234375
         ],
         "y": [
          -0.9809848666191101
         ]
        },
        {
         "hovertemplate": "Isaac Asimov knew the potential for problems with<br>intelligent machines in 1942 when he drew up his<br>Three Laws of Robotics. Simply change robot to AI<br>and problem solved, well, except for getting the<br>rest of the world to agree..    First Law  A robot<br>may not injure a human being or, through inaction,<br>allow a human being to come to harm.    Second Law<br>A robot must obey the orders given it by human<br>beings except where such orders would conflict<br>with the First Law.    Third Law  A robot must<br>protect its own existence as long as such<br>protection does not conflict with the First or<br>Second Law.",
         "hovertext": "Isaac Asimov knew the potential for problems with<br>intelligent machines in 1942 when he drew up his<br>Three Laws of Robotics. Simply change robot to AI<br>and problem solved, well, except for getting the<br>rest of the world to agree..    First Law  A robot<br>may not injure a human being or, through inaction,<br>allow a human being to come to harm.    Second Law<br>A robot must obey the orders given it by human<br>beings except where such orders would conflict<br>with the First Law.    Third Law  A robot must<br>protect its own existence as long as such<br>protection does not conflict with the First or<br>Second Law.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5332032442092896
         ],
         "y": [
          0.6271357536315918
         ]
        },
        {
         "hovertemplate": "@David Knight That sounded good until Giskard (one<br>of the robots) found a loophole by formulating the<br>zeroth law in his mind that allowed him to violate<br>the first law and harm humans for what he deemed<br>to be the greater goood.",
         "hovertext": "@David Knight That sounded good until Giskard (one<br>of the robots) found a loophole by formulating the<br>zeroth law in his mind that allowed him to violate<br>the first law and harm humans for what he deemed<br>to be the greater goood.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.528398871421814
         ],
         "y": [
          0.6144582033157349
         ]
        },
        {
         "hovertemplate": "In the 1970s, biotech leaders met to discuss and<br>regulate the nascent recombinant DNA techniques<br>that likewise posed a potential existential threat<br>to humanity. That was a different time, where<br>statesmanship was greater, and greed lesser, in<br>the U.S.  I don’t like our chances with AI in<br>2023.",
         "hovertext": "In the 1970s, biotech leaders met to discuss and<br>regulate the nascent recombinant DNA techniques<br>that likewise posed a potential existential threat<br>to humanity. That was a different time, where<br>statesmanship was greater, and greed lesser, in<br>the U.S.  I don’t like our chances with AI in<br>2023.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.669623076915741
         ],
         "y": [
          0.7138456106185913
         ]
        },
        {
         "hovertemplate": "We have decades of strong scientific evidence that<br>our consumption of fossil fuels, especially cars<br>and ships, is trapping greenhouse gasses to the<br>point of changing the Earth's climate, a<br>phenomenon that has been historically proven to<br>lead to extinctions. But no, nobody cares about<br>that, because everybody's panicking over whether<br>this fledgling technology will pull a Star Trek,<br>become sentient and kill us all. How come the<br>\"machines don't kill people, people kill people\"<br>rhetoric, which gun lovers throw around with wild<br>abandon, immediately gets tossed out the door when<br>computers enter the conversation?",
         "hovertext": "We have decades of strong scientific evidence that<br>our consumption of fossil fuels, especially cars<br>and ships, is trapping greenhouse gasses to the<br>point of changing the Earth's climate, a<br>phenomenon that has been historically proven to<br>lead to extinctions. But no, nobody cares about<br>that, because everybody's panicking over whether<br>this fledgling technology will pull a Star Trek,<br>become sentient and kill us all. How come the<br>\"machines don't kill people, people kill people\"<br>rhetoric, which gun lovers throw around with wild<br>abandon, immediately gets tossed out the door when<br>computers enter the conversation?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.11284299939870834
         ],
         "y": [
          0.18650740385055542
         ]
        },
        {
         "hovertemplate": "@MM Keeping us from doing anything about fossil<br>fuels - admittedly we are not doing nearly enough<br>right now - is one of the ways AI will be abused<br>in the near future without it being an existential<br>threat itself. People will use AI to deceive on a<br>scale that the wildest fantasies of any of our<br>dictators of the last hundred  years could never<br>have conceived. We already see how lies are<br>shouted as truth on right wing networks like fox<br>or newsmax, now they will add video and doctor<br>famous voices to say things convincingly - this is<br>where the immediate threat comes from. I have<br>known religious people who think that we can never<br>run out of oil because God just creates more. Now<br>those flocks will have video \"evidence\" of how it<br>is not actually fossil fuels causing the<br>greenhouse effect but...I don't know, liberals<br>whose body chemistry is different to the point of<br>being the major greenhouse gas effect that must be<br>eliminated. All these dooms are tied together!",
         "hovertext": "@MM Keeping us from doing anything about fossil<br>fuels - admittedly we are not doing nearly enough<br>right now - is one of the ways AI will be abused<br>in the near future without it being an existential<br>threat itself. People will use AI to deceive on a<br>scale that the wildest fantasies of any of our<br>dictators of the last hundred  years could never<br>have conceived. We already see how lies are<br>shouted as truth on right wing networks like fox<br>or newsmax, now they will add video and doctor<br>famous voices to say things convincingly - this is<br>where the immediate threat comes from. I have<br>known religious people who think that we can never<br>run out of oil because God just creates more. Now<br>those flocks will have video \"evidence\" of how it<br>is not actually fossil fuels causing the<br>greenhouse effect but...I don't know, liberals<br>whose body chemistry is different to the point of<br>being the major greenhouse gas effect that must be<br>eliminated. All these dooms are tied together!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.11551934480667114
         ],
         "y": [
          0.19983187317848206
         ]
        },
        {
         "hovertemplate": "'How come the \"machines don't kill people, people<br>kill people\" rhetoric, which gun lovers throw<br>around with wild abandon, immediately gets tossed<br>out the door when computers enter the<br>conversation?'    The problem with the \"guns don't<br>kill people; people kill people\" saying of gun<br>lovers that you allude to is not that it's<br>incorrect.     It's that it's incomplete.    It's<br>correct in that people make the decision to kill<br>other people. Guns don't, and can't, decide to do<br>that.     The nuclear bombs that killed thousands<br>of people in Hiroshima and Nagasaki didn't decide<br>to do that on their own. The decision was made by<br>people, ultimately by one person: Harry Truman.<br>But that saying is incomplete in that, although<br>it's people that make the decision to kill, the<br>weapon used determines the amount of the carnage.<br>That's what gun lovers fail to acknowledge. And,<br>of course, they fail to acknowledge that on<br>purpose because they only want to focus on people,<br>not on the lethality of the guns they use.",
         "hovertext": "'How come the \"machines don't kill people, people<br>kill people\" rhetoric, which gun lovers throw<br>around with wild abandon, immediately gets tossed<br>out the door when computers enter the<br>conversation?'    The problem with the \"guns don't<br>kill people; people kill people\" saying of gun<br>lovers that you allude to is not that it's<br>incorrect.     It's that it's incomplete.    It's<br>correct in that people make the decision to kill<br>other people. Guns don't, and can't, decide to do<br>that.     The nuclear bombs that killed thousands<br>of people in Hiroshima and Nagasaki didn't decide<br>to do that on their own. The decision was made by<br>people, ultimately by one person: Harry Truman.<br>But that saying is incomplete in that, although<br>it's people that make the decision to kill, the<br>weapon used determines the amount of the carnage.<br>That's what gun lovers fail to acknowledge. And,<br>of course, they fail to acknowledge that on<br>purpose because they only want to focus on people,<br>not on the lethality of the guns they use.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.12339799106121063
         ],
         "y": [
          0.17874367535114288
         ]
        },
        {
         "hovertemplate": "@Jim   \"It's correct in that people make the<br>decision to kill other people. Guns don't, and<br>can't, decide to do that.\"  ...  Unless it's an<br>accident. Would it be an accident if we built AI<br>to make life easier, and extinction resulted<br>instead? It seems it is the exact same principle,<br>just on a large scale.",
         "hovertext": "@Jim   \"It's correct in that people make the<br>decision to kill other people. Guns don't, and<br>can't, decide to do that.\"  ...  Unless it's an<br>accident. Would it be an accident if we built AI<br>to make life easier, and extinction resulted<br>instead? It seems it is the exact same principle,<br>just on a large scale.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.13597075641155243
         ],
         "y": [
          0.1832687258720398
         ]
        },
        {
         "hovertemplate": "@MM Star Trek? I think you might be confusing your<br>sci-fi story arcs!",
         "hovertext": "@MM Star Trek? I think you might be confusing your<br>sci-fi story arcs!",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.10261155664920807
         ],
         "y": [
          0.190325066447258
         ]
        },
        {
         "hovertemplate": "@Jacob \"make the decision to kill people. Guns<br>don't, and can't, decide to do that.\" An advanced<br>AI with a gun *could* decide to do that.",
         "hovertext": "@Jacob \"make the decision to kill people. Guns<br>don't, and can't, decide to do that.\" An advanced<br>AI with a gun *could* decide to do that.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.1455962061882019
         ],
         "y": [
          0.18796095252037048
         ]
        },
        {
         "hovertemplate": "AI Companies: this technology could easily escape<br>our control and destroy humanity unless we act<br>now.    Also AI Companies: we have released this<br>technology for free with no restrictions to anyone<br>in the world who wants it.",
         "hovertext": "AI Companies: this technology could easily escape<br>our control and destroy humanity unless we act<br>now.    Also AI Companies: we have released this<br>technology for free with no restrictions to anyone<br>in the world who wants it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4906233549118042
         ],
         "y": [
          0.8800613880157471
         ]
        },
        {
         "hovertemplate": "Yeah, but there’s money to be made, so let’s risk<br>extinction.  Sounds like AI tech companies are<br>just echoing the fossil fuel industry.",
         "hovertext": "Yeah, but there’s money to be made, so let’s risk<br>extinction.  Sounds like AI tech companies are<br>just echoing the fossil fuel industry.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.6945666074752808
         ],
         "y": [
          -0.7965435981750488
         ]
        },
        {
         "hovertemplate": "Norstrilia.   Alpha in a bot.    The problem is<br>not the capability, but the use of the<br>capability-- and in society, humans are quite<br>willing to assign more and more responsibility to<br>'bots until the end point: Farewell the Master (or<br>perhaps less pleasantly but more cinematic,<br>welcome SkyNet/Colossus/HAL9000).",
         "hovertext": "Norstrilia.   Alpha in a bot.    The problem is<br>not the capability, but the use of the<br>capability-- and in society, humans are quite<br>willing to assign more and more responsibility to<br>'bots until the end point: Farewell the Master (or<br>perhaps less pleasantly but more cinematic,<br>welcome SkyNet/Colossus/HAL9000).",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8120623826980591
         ],
         "y": [
          -0.45596250891685486
         ]
        },
        {
         "hovertemplate": "\"I think if this technology goes wrong, it can go<br>quite wrong,” Mr. Altman told the Senate<br>subcommittee. “We want to work with the government<br>to prevent that from happening.”    And what makes<br>Mr. Altman think Congress can do anything to quell<br>AI?  It will happen, with or without, legislation.<br>Fortunately, the so-called \"Singularity,\" when<br>robots take over the world, will not happen, even<br>as computers play an increasing role in humans'<br>lives.",
         "hovertext": "\"I think if this technology goes wrong, it can go<br>quite wrong,” Mr. Altman told the Senate<br>subcommittee. “We want to work with the government<br>to prevent that from happening.”    And what makes<br>Mr. Altman think Congress can do anything to quell<br>AI?  It will happen, with or without, legislation.<br>Fortunately, the so-called \"Singularity,\" when<br>robots take over the world, will not happen, even<br>as computers play an increasing role in humans'<br>lives.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9555530548095703
         ],
         "y": [
          -0.21555638313293457
         ]
        },
        {
         "hovertemplate": "I am also considering that these leaders and<br>colleagues have realized that -- especially with<br>Facebook's insanity, et al -- when the problems<br>begin to appear with the normal corporate release<br>of products into our Earth and human ecologies,<br>they will have attempted some prior mitigation to<br>potentially lessen society's disapproval of them.",
         "hovertext": "I am also considering that these leaders and<br>colleagues have realized that -- especially with<br>Facebook's insanity, et al -- when the problems<br>begin to appear with the normal corporate release<br>of products into our Earth and human ecologies,<br>they will have attempted some prior mitigation to<br>potentially lessen society's disapproval of them.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.3249274492263794
         ],
         "y": [
          0.900708019733429
         ]
        },
        {
         "hovertemplate": "As a retired software engineer, I think it is<br>laudable that these leaders in the field are<br>expressing their concerns about the potential<br>misuse of the very systems they are creating.<br>Many commenters here have it wrong.  At the<br>developer level, it can be more about the<br>challenge of figuring out how to solve a<br>particular problem, create a system, then any<br>profit motive.  Many hackers have started out this<br>way ... they don't really care about stealing, but<br>they really really want to figure out how to break<br>into that system, as a challenge.   This is where<br>a moral compass needs to be consulted.      I am<br>glad that I never had to stop and consider the<br>consequences of my coding efforts, because<br>curiosity and ego are powerful motivators to<br>ignore future consequences.    That said, my<br>career was in development of cable modems, which<br>seemed like a no-brainier \"good\" connecting the<br>worlds information systems ... but also allows the<br>dissemination of the worst humans have to offer.<br>Since science can not depend upon human character<br>to only use technology for good, then sometimes<br>the decision should be made to not figure out<br>everything that can be figured out.       At least<br>hearing the major voices in this field discussing<br>the  potential for misuse, is encouraging to me.",
         "hovertext": "As a retired software engineer, I think it is<br>laudable that these leaders in the field are<br>expressing their concerns about the potential<br>misuse of the very systems they are creating.<br>Many commenters here have it wrong.  At the<br>developer level, it can be more about the<br>challenge of figuring out how to solve a<br>particular problem, create a system, then any<br>profit motive.  Many hackers have started out this<br>way ... they don't really care about stealing, but<br>they really really want to figure out how to break<br>into that system, as a challenge.   This is where<br>a moral compass needs to be consulted.      I am<br>glad that I never had to stop and consider the<br>consequences of my coding efforts, because<br>curiosity and ego are powerful motivators to<br>ignore future consequences.    That said, my<br>career was in development of cable modems, which<br>seemed like a no-brainier \"good\" connecting the<br>worlds information systems ... but also allows the<br>dissemination of the worst humans have to offer.<br>Since science can not depend upon human character<br>to only use technology for good, then sometimes<br>the decision should be made to not figure out<br>everything that can be figured out.       At least<br>hearing the major voices in this field discussing<br>the  potential for misuse, is encouraging to me.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9085889458656311
         ],
         "y": [
          0.40158623456954956
         ]
        },
        {
         "hovertemplate": "AI was used to find a drug to beat a drug-<br>resistant virus, a good thing.  But it also means<br>AI could be used to engineer or invent viruses<br>that have no defence and could destroy life on<br>earth, a very very x1000 bad thing.  So far every<br>time is do this good/bad cost benefit analysis for<br>AI I get this result: the potential damage far<br>outweighs the expected gains.  I think it should<br>be controlled the way we control dynamite, or<br>toxic chemicals.  ie plenty of checks on who uses<br>it and how.",
         "hovertext": "AI was used to find a drug to beat a drug-<br>resistant virus, a good thing.  But it also means<br>AI could be used to engineer or invent viruses<br>that have no defence and could destroy life on<br>earth, a very very x1000 bad thing.  So far every<br>time is do this good/bad cost benefit analysis for<br>AI I get this result: the potential damage far<br>outweighs the expected gains.  I think it should<br>be controlled the way we control dynamite, or<br>toxic chemicals.  ie plenty of checks on who uses<br>it and how.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6996765732765198
         ],
         "y": [
          -0.33023175597190857
         ]
        },
        {
         "hovertemplate": "@Edward they would also invent a virus that will<br>kill only the humans.",
         "hovertext": "@Edward they would also invent a virus that will<br>kill only the humans.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.7031582593917847
         ],
         "y": [
          -0.3225484788417816
         ]
        },
        {
         "hovertemplate": "If the technology is a threat to the species, it<br>should not be in the hands of private tech<br>oligarchs. Regulations will only serve to shore up<br>their positions.     Silicon Valley is a scourge<br>on humanity.",
         "hovertext": "If the technology is a threat to the species, it<br>should not be in the hands of private tech<br>oligarchs. Regulations will only serve to shore up<br>their positions.     Silicon Valley is a scourge<br>on humanity.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.8575137853622437
         ],
         "y": [
          0.19179444015026093
         ]
        },
        {
         "hovertemplate": "These technologies are a net positive benefit for<br>humanity. it's unfortunate what the potential is<br>being utilized on, but to call silicon valley the<br>scourge of humanity is pretty extreme hyperbole as<br>you type this on a device that is reaping the<br>benefits of the software/hardware research that<br>silicon valley engaged in.",
         "hovertext": "These technologies are a net positive benefit for<br>humanity. it's unfortunate what the potential is<br>being utilized on, but to call silicon valley the<br>scourge of humanity is pretty extreme hyperbole as<br>you type this on a device that is reaping the<br>benefits of the software/hardware research that<br>silicon valley engaged in.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.8626831769943237
         ],
         "y": [
          0.1851169466972351
         ]
        },
        {
         "hovertemplate": "This article is all scare and no details. Please<br>paint a clearer picture of what could happen. Will<br>AI machines become self aware? Will they fight to<br>not die, whatever that might mean. Might they not<br>wish to integrate with humanity? Our own behavior<br>is creating a suicidal path now in heating the<br>planet. Can AI help save us and thereby help save<br>themselves?",
         "hovertext": "This article is all scare and no details. Please<br>paint a clearer picture of what could happen. Will<br>AI machines become self aware? Will they fight to<br>not die, whatever that might mean. Might they not<br>wish to integrate with humanity? Our own behavior<br>is creating a suicidal path now in heating the<br>planet. Can AI help save us and thereby help save<br>themselves?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9910665154457092
         ],
         "y": [
          0.03253542259335518
         ]
        },
        {
         "hovertemplate": "I think it says A LOT when the people who stand to<br>profit the most off a product warns our government<br>and consumers of its nefarious implications.",
         "hovertext": "I think it says A LOT when the people who stand to<br>profit the most off a product warns our government<br>and consumers of its nefarious implications.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9685061573982239
         ],
         "y": [
          -0.04270263761281967
         ]
        },
        {
         "hovertemplate": "My first assumption is of people, businesses, and<br>governments immediately wanting to establish<br>monopoly, exclusivity, or at least lead position<br>on any new source or means of control, influence,<br>or profit.",
         "hovertext": "My first assumption is of people, businesses, and<br>governments immediately wanting to establish<br>monopoly, exclusivity, or at least lead position<br>on any new source or means of control, influence,<br>or profit.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9196925163269043
         ],
         "y": [
          -0.4205552041530609
         ]
        },
        {
         "hovertemplate": "Hopefully the new machine men (or mainframes or<br>whatever) do a lot better than humanity has.",
         "hovertext": "Hopefully the new machine men (or mainframes or<br>whatever) do a lot better than humanity has.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.49096959829330444
         ],
         "y": [
          0.8081401586532593
         ]
        },
        {
         "hovertemplate": "“A group of industry leaders warned…”    That’s<br>all I need to know to ignore the whole thing with<br>AI.",
         "hovertext": "“A group of industry leaders warned…”    That’s<br>all I need to know to ignore the whole thing with<br>AI.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7600544095039368
         ],
         "y": [
          -0.4822229743003845
         ]
        },
        {
         "hovertemplate": "I legit think this is just free marketing.",
         "hovertext": "I legit think this is just free marketing.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8006250262260437
         ],
         "y": [
          -0.3104681968688965
         ]
        },
        {
         "hovertemplate": "But they continue to build them. Nice.",
         "hovertext": "But they continue to build them. Nice.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.6197621822357178
         ],
         "y": [
          -0.813369870185852
         ]
        },
        {
         "hovertemplate": "THE ALIEN HAS LANDED!   It has been born. It is<br>here on our home planet and that is not hyperbole.<br>Now that’s it is here among us the primary near<br>term concern is that artificial intelligence will<br>create even more sophisticated versions of<br>ARTIFICIAL STUPIDITY.     Right wing news outlets<br>have been using the analog version for years.<br>Trump has used deception and misinformation very<br>effectively. He has created a devoted cult<br>literally living in a separate reality. It’s<br>amazing how gullible humans can be.     So imagine<br>an advanced AGI doing the same thing, or being<br>used by Murdoch?… that would be the end of any<br>semblance of truth.    The Sam Altman’s of the<br>world should be way more specific about other<br>threats. “An existential threat to humanity” is<br>not going to cut it.     Make it clear<br>specifically what is at stake other than vague<br>pronouncements.     Eventually the population will<br>need to be completely informed about the nature of<br>the aliens and how we plan to defend ourselves.",
         "hovertext": "THE ALIEN HAS LANDED!   It has been born. It is<br>here on our home planet and that is not hyperbole.<br>Now that’s it is here among us the primary near<br>term concern is that artificial intelligence will<br>create even more sophisticated versions of<br>ARTIFICIAL STUPIDITY.     Right wing news outlets<br>have been using the analog version for years.<br>Trump has used deception and misinformation very<br>effectively. He has created a devoted cult<br>literally living in a separate reality. It’s<br>amazing how gullible humans can be.     So imagine<br>an advanced AGI doing the same thing, or being<br>used by Murdoch?… that would be the end of any<br>semblance of truth.    The Sam Altman’s of the<br>world should be way more specific about other<br>threats. “An existential threat to humanity” is<br>not going to cut it.     Make it clear<br>specifically what is at stake other than vague<br>pronouncements.     Eventually the population will<br>need to be completely informed about the nature of<br>the aliens and how we plan to defend ourselves.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4760695695877075
         ],
         "y": [
          -0.7950525879859924
         ]
        },
        {
         "hovertemplate": "AI plus CRISPR plus QUANTUM COMPUTING plus<br>advanced ROBOTICS plus the 'Internet of Things'.<br>What the heck are we worrying about!? (Can't help<br>but feel that when the warnings become more<br>strident, it's already too late.)",
         "hovertext": "AI plus CRISPR plus QUANTUM COMPUTING plus<br>advanced ROBOTICS plus the 'Internet of Things'.<br>What the heck are we worrying about!? (Can't help<br>but feel that when the warnings become more<br>strident, it's already too late.)",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.5540938377380371
         ],
         "y": [
          -0.7896053791046143
         ]
        },
        {
         "hovertemplate": "Well, lord knows we’ve handled the nuclear war<br>risks so well.",
         "hovertext": "Well, lord knows we’ve handled the nuclear war<br>risks so well.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7147173881530762
         ],
         "y": [
          0.5658349394798279
         ]
        },
        {
         "hovertemplate": "Unbelievable! The people driving the car toward<br>the cliff are asking the government to please save<br>them from themselves (and taking us with them). We<br>must have the government step in and provide us<br>with regulations that stop the \"pandemic\" of AI<br>while we continue to create AI. The people who<br>signed that letter are the ones creating these<br>problems and yet they cannot stop? Such hypocrisy!",
         "hovertext": "Unbelievable! The people driving the car toward<br>the cliff are asking the government to please save<br>them from themselves (and taking us with them). We<br>must have the government step in and provide us<br>with regulations that stop the \"pandemic\" of AI<br>while we continue to create AI. The people who<br>signed that letter are the ones creating these<br>problems and yet they cannot stop? Such hypocrisy!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.36969029903411865
         ],
         "y": [
          0.9035684466362
         ]
        },
        {
         "hovertemplate": "It all must be stopped. How odd that these are the<br>creators warning us. What did they expect to<br>create? These maniacs have created a monster.<br>Everything Star Trek predicted is happening now! I<br>never thought it would all happen in my lifetime.<br>Watch the V-Ger episode. I can only hope the good<br>aliens will land and save us.",
         "hovertext": "It all must be stopped. How odd that these are the<br>creators warning us. What did they expect to<br>create? These maniacs have created a monster.<br>Everything Star Trek predicted is happening now! I<br>never thought it would all happen in my lifetime.<br>Watch the V-Ger episode. I can only hope the good<br>aliens will land and save us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8383581042289734
         ],
         "y": [
          -0.5329211354255676
         ]
        },
        {
         "hovertemplate": "So here is a crazy idea: if the potential negative<br>consequences are so dire, according to the people<br>creating it, WHY DON'T THEY STOP????",
         "hovertext": "So here is a crazy idea: if the potential negative<br>consequences are so dire, according to the people<br>creating it, WHY DON'T THEY STOP????",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.011232324875891209
         ],
         "y": [
          -0.9561282396316528
         ]
        },
        {
         "hovertemplate": "And?     Humans may not have invented extinction,<br>but we've done our damndest to perfect it.<br>Eradicating our own species before we rid the<br>planet(s) of all others would be just desserts.<br>Our history of unbridled greed, disregard for our<br>surroundings and other species and people in them,<br>and our uniquely human lack of self-control and<br>remarkable incapacity to act rationally or<br>selflessly in the face of threat or impending<br>doom, deserve nothing more than utter decimation.<br>That it would be so pathetically self-inflicted<br>only makes it juicier.",
         "hovertext": "And?     Humans may not have invented extinction,<br>but we've done our damndest to perfect it.<br>Eradicating our own species before we rid the<br>planet(s) of all others would be just desserts.<br>Our history of unbridled greed, disregard for our<br>surroundings and other species and people in them,<br>and our uniquely human lack of self-control and<br>remarkable incapacity to act rationally or<br>selflessly in the face of threat or impending<br>doom, deserve nothing more than utter decimation.<br>That it would be so pathetically self-inflicted<br>only makes it juicier.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7152767777442932
         ],
         "y": [
          0.690087080001831
         ]
        },
        {
         "hovertemplate": "If em is wanting a pause in development of AI then<br>it only means he’s trying to catch up so that he<br>can control it.  I wouldn’t trust em no further<br>than I could throw him.",
         "hovertext": "If em is wanting a pause in development of AI then<br>it only means he’s trying to catch up so that he<br>can control it.  I wouldn’t trust em no further<br>than I could throw him.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.663356602191925
         ],
         "y": [
          -0.6914846897125244
         ]
        },
        {
         "hovertemplate": "If A.I.is a danger to human beings, and I think it<br>is, then quit developing them. Show some wisdom.<br>Just because you can do something does not mean<br>that you should do something.",
         "hovertext": "If A.I.is a danger to human beings, and I think it<br>is, then quit developing them. Show some wisdom.<br>Just because you can do something does not mean<br>that you should do something.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.32972460985183716
         ],
         "y": [
          0.7681557536125183
         ]
        },
        {
         "hovertemplate": "We're already destroying the world, with or<br>without AI.",
         "hovertext": "We're already destroying the world, with or<br>without AI.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.5896793007850647
         ],
         "y": [
          -0.5730434060096741
         ]
        },
        {
         "hovertemplate": "@me This is true.  If we task AI with operating<br>infrastructure, like the power grid, and AI<br>decides that humanity is a danger to the planet.<br>AI could easily decide that the proper response is<br>to not allow humanity to thrive. Destroying the<br>power grid would be effective as would developing<br>and distributing a biological agent that would<br>kill all humans.    An AI developed set of ethical<br>guidelines might see these actions as necessary<br>and valid.",
         "hovertext": "@me This is true.  If we task AI with operating<br>infrastructure, like the power grid, and AI<br>decides that humanity is a danger to the planet.<br>AI could easily decide that the proper response is<br>to not allow humanity to thrive. Destroying the<br>power grid would be effective as would developing<br>and distributing a biological agent that would<br>kill all humans.    An AI developed set of ethical<br>guidelines might see these actions as necessary<br>and valid.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5769338011741638
         ],
         "y": [
          -0.5600117444992065
         ]
        },
        {
         "hovertemplate": "I asked chatGPT \"how to mitigate the Risk of<br>Extinction to human\". Here is its answer<br>(shortened):    1.AI Safety Research: Invest in<br>research focused on AI safety and robust control<br>mechanisms. This includes developing techniques to<br>ensure the safe and controllable behavior of AI<br>systems, ...    2.Value Alignment: Design AI<br>systems with value alignment in mind, ensuring<br>that their goals and objectives are aligned with<br>human values and well-being. This involves<br>developing frameworks and techniques to enable AI<br>systems to understand and respect human<br>preferences, goals, and ethical principles.<br>3.Transparency and Explainability:     4.Human<br>Oversight and Control: Maintain human oversight<br>and control over AI systems to prevent unintended<br>consequences or risks. This involves designing AI<br>systems with mechanisms that allow for human<br>intervention, verification, and decision-making,<br>particularly in critical or high-stakes scenarios.<br>5.Collaborative Efforts: Encourage collaboration<br>and information-sharing among researchers,<br>policymakers, and stakeholders. International<br>cooperation and interdisciplinary research can<br>help address AI risks holistically and establish<br>shared guidelines and frameworks for responsible<br>AI development.    6.Ethical Guidelines and<br>Regulation: ...    7.Public Awareness and<br>Engagement:...",
         "hovertext": "I asked chatGPT \"how to mitigate the Risk of<br>Extinction to human\". Here is its answer<br>(shortened):    1.AI Safety Research: Invest in<br>research focused on AI safety and robust control<br>mechanisms. This includes developing techniques to<br>ensure the safe and controllable behavior of AI<br>systems, ...    2.Value Alignment: Design AI<br>systems with value alignment in mind, ensuring<br>that their goals and objectives are aligned with<br>human values and well-being. This involves<br>developing frameworks and techniques to enable AI<br>systems to understand and respect human<br>preferences, goals, and ethical principles.<br>3.Transparency and Explainability:     4.Human<br>Oversight and Control: Maintain human oversight<br>and control over AI systems to prevent unintended<br>consequences or risks. This involves designing AI<br>systems with mechanisms that allow for human<br>intervention, verification, and decision-making,<br>particularly in critical or high-stakes scenarios.<br>5.Collaborative Efforts: Encourage collaboration<br>and information-sharing among researchers,<br>policymakers, and stakeholders. International<br>cooperation and interdisciplinary research can<br>help address AI risks holistically and establish<br>shared guidelines and frameworks for responsible<br>AI development.    6.Ethical Guidelines and<br>Regulation: ...    7.Public Awareness and<br>Engagement:...",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2345464676618576
         ],
         "y": [
          0.9543231725692749
         ]
        },
        {
         "hovertemplate": "Another comment just saw this as an evolutionary<br>step, and that humankind simply needs to adapt.<br>That might be true.  It’s a shame he wasn’t around<br>to instruct the Neanderthals.        Given the<br>enormous range of technology in place right now,<br>the new intelligence could engineer and construct<br>the means of our destruction very readily,<br>especially if someone could document it on a basic<br>cable reality show or base a hi-res video game on<br>the scheme.",
         "hovertext": "Another comment just saw this as an evolutionary<br>step, and that humankind simply needs to adapt.<br>That might be true.  It’s a shame he wasn’t around<br>to instruct the Neanderthals.        Given the<br>enormous range of technology in place right now,<br>the new intelligence could engineer and construct<br>the means of our destruction very readily,<br>especially if someone could document it on a basic<br>cable reality show or base a hi-res video game on<br>the scheme.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9460895657539368
         ],
         "y": [
          -0.2563154399394989
         ]
        },
        {
         "hovertemplate": "“Your scientists were so preoccupied with whether<br>they could, they didn’t stop to think if they<br>should.” Dr. Ian Malcolm.     The question is: is<br>it too late to ask?",
         "hovertext": "“Your scientists were so preoccupied with whether<br>they could, they didn’t stop to think if they<br>should.” Dr. Ian Malcolm.     The question is: is<br>it too late to ask?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9441978335380554
         ],
         "y": [
          -0.061065204441547394
         ]
        },
        {
         "hovertemplate": "I think a great risk AI poses is its ability to<br>commit fraud at enormous scale.  Imagine a system<br>that can fake any voice and any picture, and can<br>tailor a lie to each of ten billion people.  What<br>could you ever trust?",
         "hovertext": "I think a great risk AI poses is its ability to<br>commit fraud at enormous scale.  Imagine a system<br>that can fake any voice and any picture, and can<br>tailor a lie to each of ten billion people.  What<br>could you ever trust?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.38691648840904236
         ],
         "y": [
          -0.21910473704338074
         ]
        },
        {
         "hovertemplate": "@Phil   Exactly.",
         "hovertext": "@Phil   Exactly.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.38768985867500305
         ],
         "y": [
          -0.22753912210464478
         ]
        },
        {
         "hovertemplate": "I see 2 buckets of concerns by the recent open<br>letters:  1) the real/near-term impact of a<br>technology which has a large and quick distortion<br>(initial biased data, misinformation, etc) and<br>dislocation (people, jobs,..) on our society,<br>while we catchup/adapt to a new AI-assisted world<br>2) the existential future threat that AI will<br>somehow become smarter and more powerful than<br>humans.  Implied in this, is a Terminator-like<br>world where humans can not wrestle back control<br>from \"AI\" and thus perish.    Where 1) is a really<br>a familiar, repeated issue each time we arrive at<br>a significantly large technological advancement<br>(..printing press, combustion engine, antibiotics,<br>railroads, the internet....).   These imposed<br>societal transitions are painful and costly, no<br>doubt.  but i'm certain humanity will prevail and<br>likely be the better once we've digested it.<br>However, the Fears within 2) has never been<br>defined in enough technical detail or casted as<br>\"in the future\" or \"eventually\", so that it is not<br>possible to understand & critique the validity of<br>this fear.  In fact, the validity of this fear<br>requires a lot of assumptions to take credibly.<br>so far, i've not heard this fear fleshed out<br>enough detail such that \"a group of AI<br>technologists\" would agree.  However, it's this<br>latter existential fear bucket that drives so many<br>of the stories/headlines and sensational<br>conclusions.    Fear Bucket 1 is real - lets get<br>on it.     Fear Bucket 2 needs proof yet.  Don't<br>mix them please",
         "hovertext": "I see 2 buckets of concerns by the recent open<br>letters:  1) the real/near-term impact of a<br>technology which has a large and quick distortion<br>(initial biased data, misinformation, etc) and<br>dislocation (people, jobs,..) on our society,<br>while we catchup/adapt to a new AI-assisted world<br>2) the existential future threat that AI will<br>somehow become smarter and more powerful than<br>humans.  Implied in this, is a Terminator-like<br>world where humans can not wrestle back control<br>from \"AI\" and thus perish.    Where 1) is a really<br>a familiar, repeated issue each time we arrive at<br>a significantly large technological advancement<br>(..printing press, combustion engine, antibiotics,<br>railroads, the internet....).   These imposed<br>societal transitions are painful and costly, no<br>doubt.  but i'm certain humanity will prevail and<br>likely be the better once we've digested it.<br>However, the Fears within 2) has never been<br>defined in enough technical detail or casted as<br>\"in the future\" or \"eventually\", so that it is not<br>possible to understand & critique the validity of<br>this fear.  In fact, the validity of this fear<br>requires a lot of assumptions to take credibly.<br>so far, i've not heard this fear fleshed out<br>enough detail such that \"a group of AI<br>technologists\" would agree.  However, it's this<br>latter existential fear bucket that drives so many<br>of the stories/headlines and sensational<br>conclusions.    Fear Bucket 1 is real - lets get<br>on it.     Fear Bucket 2 needs proof yet.  Don't<br>mix them please",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3422050178050995
         ],
         "y": [
          -0.882962167263031
         ]
        },
        {
         "hovertemplate": "Largely misplaced concerns. All equally valid<br>about the printing press, as spreading lies,<br>disinformation and other than the authorized<br>truth. And yet it’s good to remember how quickly<br>all of Europe learned about the new world through<br>the printing press, whereas the Incas were unaware<br>that Spain existed even after the fall of the<br>Aztecs.",
         "hovertext": "Largely misplaced concerns. All equally valid<br>about the printing press, as spreading lies,<br>disinformation and other than the authorized<br>truth. And yet it’s good to remember how quickly<br>all of Europe learned about the new world through<br>the printing press, whereas the Incas were unaware<br>that Spain existed even after the fall of the<br>Aztecs.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7974485754966736
         ],
         "y": [
          -0.29239585995674133
         ]
        },
        {
         "hovertemplate": "Yet another example of \"Hi, we're preparing to<br>cash in on buckets of money for a product that,<br>frankly, scares the bejeebers out of us - and<br>we're the knowledgeable ones.\"    And much like<br>Ford some years ago when they announced the<br>gigantic, wasteful, dangerous, very profitable<br>Escalade SUV, they probably would justify their<br>headlong rush in releasing dangerous, yet<br>potentially very lucrative products with an<br>equally cynical statement like Ford's, which was<br>pretty much \"Companies will make these awful<br>vehicles, but we will do it responsibly\"    The<br>\"responsible\" thing to do for many products is to<br>NOT RUSH TO THE MARKET.   But we get open letters,<br>so we'll all feel good now, OK?",
         "hovertext": "Yet another example of \"Hi, we're preparing to<br>cash in on buckets of money for a product that,<br>frankly, scares the bejeebers out of us - and<br>we're the knowledgeable ones.\"    And much like<br>Ford some years ago when they announced the<br>gigantic, wasteful, dangerous, very profitable<br>Escalade SUV, they probably would justify their<br>headlong rush in releasing dangerous, yet<br>potentially very lucrative products with an<br>equally cynical statement like Ford's, which was<br>pretty much \"Companies will make these awful<br>vehicles, but we will do it responsibly\"    The<br>\"responsible\" thing to do for many products is to<br>NOT RUSH TO THE MARKET.   But we get open letters,<br>so we'll all feel good now, OK?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.07055287063121796
         ],
         "y": [
          0.6999057531356812
         ]
        },
        {
         "hovertemplate": "@b fagan  The *Cadillac* Escalade is probably not<br>profitable for Ford.",
         "hovertext": "@b fagan  The *Cadillac* Escalade is probably not<br>profitable for Ford.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.07955975830554962
         ],
         "y": [
          0.7014186382293701
         ]
        },
        {
         "hovertemplate": "@Mike - pardon me - I don't really pay attention<br>to these things except to not want to get run down<br>by one.      I think I was thinking of the<br>\"Excursion\" as the behemoth that was announced<br>back then.  This NYTimes article discusses the<br>thing.  Nice that an environmentalist contest to<br>name it came up with the \"Ford Valdez\" to give<br>some credit to Exxon's love of such oil-burners,<br>too.    <a href=\"https://www.nytimes.com/2002/07/3<br>1/business/ford-said-to-be-close-to-ending-the-<br>excursion.html\" target=\"_blank\">https://www.nytime<br>s.com/2002/07/31/business/ford-said-to-be-close-<br>to-ending-the-excursion.html</a>    One<br>unfortunate outcome of the gas guzzler tax - an<br>attempt after the oil embargoes to limit our oil<br>and auto industry addiction to big profitable<br>vehicles - was that the auto industry drove a<br>HumVee-sized loophole into the law (which is still<br>in effect).    The loophole? Pickup trucks were<br>exempt, and SUVs started being built and classed<br>as \"trucks\" the same way.    This had lots of bad<br>outcomes, a few being:    1 - all fuel efficiency<br>gains in engines kind of absorbed by heavier, less<br>aerodynamic vehicles in every home    2 -<br>increased danger for pedestrians, cyclists, and<br>people in regular cars in collisions    3 - far-<br>less-efficient use of materials, now also leading<br>to even heavier EV versions that require bigger<br>batteries to move the huge, block-shaped bulks<br>along the road.    We could make a lot of less-<br>expensive personal vehicles from the same quantity<br>of battery materials if we'd been electrifying the<br>more car-centric world of pre-SUV days.",
         "hovertext": "@Mike - pardon me - I don't really pay attention<br>to these things except to not want to get run down<br>by one.      I think I was thinking of the<br>\"Excursion\" as the behemoth that was announced<br>back then.  This NYTimes article discusses the<br>thing.  Nice that an environmentalist contest to<br>name it came up with the \"Ford Valdez\" to give<br>some credit to Exxon's love of such oil-burners,<br>too.    <a href=\"https://www.nytimes.com/2002/07/3<br>1/business/ford-said-to-be-close-to-ending-the-<br>excursion.html\" target=\"_blank\">https://www.nytime<br>s.com/2002/07/31/business/ford-said-to-be-close-<br>to-ending-the-excursion.html</a>    One<br>unfortunate outcome of the gas guzzler tax - an<br>attempt after the oil embargoes to limit our oil<br>and auto industry addiction to big profitable<br>vehicles - was that the auto industry drove a<br>HumVee-sized loophole into the law (which is still<br>in effect).    The loophole? Pickup trucks were<br>exempt, and SUVs started being built and classed<br>as \"trucks\" the same way.    This had lots of bad<br>outcomes, a few being:    1 - all fuel efficiency<br>gains in engines kind of absorbed by heavier, less<br>aerodynamic vehicles in every home    2 -<br>increased danger for pedestrians, cyclists, and<br>people in regular cars in collisions    3 - far-<br>less-efficient use of materials, now also leading<br>to even heavier EV versions that require bigger<br>batteries to move the huge, block-shaped bulks<br>along the road.    We could make a lot of less-<br>expensive personal vehicles from the same quantity<br>of battery materials if we'd been electrifying the<br>more car-centric world of pre-SUV days.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.08242788165807724
         ],
         "y": [
          0.7142804861068726
         ]
        },
        {
         "hovertemplate": "At some point AI will evolve to think on its own.<br>If our searches are training it every moment it's<br>just a matter of time. Nvidia is absolutely<br>terrifying and has already wiped out jobs in the<br>gaming industry.    We should have never gone this<br>far. I am very sad for the future of my kids and<br>all the plans they have for a normal everyday life<br>that will be more or less robbed from them as this<br>technology destroys humanity as we know it",
         "hovertext": "At some point AI will evolve to think on its own.<br>If our searches are training it every moment it's<br>just a matter of time. Nvidia is absolutely<br>terrifying and has already wiped out jobs in the<br>gaming industry.    We should have never gone this<br>far. I am very sad for the future of my kids and<br>all the plans they have for a normal everyday life<br>that will be more or less robbed from them as this<br>technology destroys humanity as we know it",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5408551692962646
         ],
         "y": [
          0.8692912459373474
         ]
        },
        {
         "hovertemplate": "Does A. I. pose more of a risk of extinction than<br>humans?  I'll take my chances.",
         "hovertext": "Does A. I. pose more of a risk of extinction than<br>humans?  I'll take my chances.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.054486095905303955
         ],
         "y": [
          -0.7616381645202637
         ]
        },
        {
         "hovertemplate": "It will certainly expedite it.",
         "hovertext": "It will certainly expedite it.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.05259203165769577
         ],
         "y": [
          -0.7492714524269104
         ]
        },
        {
         "hovertemplate": "@Bette   Possibly A. I. will defend against it!  I<br>find your \"certainty\" amusing?  What is the basis?",
         "hovertext": "@Bette   Possibly A. I. will defend against it!  I<br>find your \"certainty\" amusing?  What is the basis?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.04871736839413643
         ],
         "y": [
          -0.7413733005523682
         ]
        },
        {
         "hovertemplate": "We could increase natural intelligence by opening<br>more libraries and making sure all schools have<br>real books written by professors from academic<br>research libraries.",
         "hovertext": "We could increase natural intelligence by opening<br>more libraries and making sure all schools have<br>real books written by professors from academic<br>research libraries.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.179664745926857
         ],
         "y": [
          0.9215161204338074
         ]
        },
        {
         "hovertemplate": "Pogo said it, all those years ago.     We have met<br>the enemy, and he is us.",
         "hovertext": "Pogo said it, all those years ago.     We have met<br>the enemy, and he is us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.14782609045505524
         ],
         "y": [
          -0.9614656567573547
         ]
        },
        {
         "hovertemplate": "Legislation, **NOW**    Not when these things have<br>gone too far.    It’s such a simple answer, that<br>this dithering “ehh, what are we gonna do?”<br>mincing of words and actions into a pile of<br>nothing just makes it apparent that no one is<br>willing to give up the pile of money they foresee<br>(think Facebook et al) themselves earning from<br>letting this go unattended and unrestricted.<br>And that includes the lawmakers in the house and<br>senate who insist on doing nothing; who among<br>these AI companies are lobbying and donating in<br>grand measures to lawmakers in the hopes of<br>corrupting them enough to keep the law limited and<br>impotent enough to have no effect whatsoever?",
         "hovertext": "Legislation, **NOW**    Not when these things have<br>gone too far.    It’s such a simple answer, that<br>this dithering “ehh, what are we gonna do?”<br>mincing of words and actions into a pile of<br>nothing just makes it apparent that no one is<br>willing to give up the pile of money they foresee<br>(think Facebook et al) themselves earning from<br>letting this go unattended and unrestricted.<br>And that includes the lawmakers in the house and<br>senate who insist on doing nothing; who among<br>these AI companies are lobbying and donating in<br>grand measures to lawmakers in the hopes of<br>corrupting them enough to keep the law limited and<br>impotent enough to have no effect whatsoever?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5893300771713257
         ],
         "y": [
          0.3741379976272583
         ]
        },
        {
         "hovertemplate": "@RM: Every issue that is resolved is no longer<br>useful for fundraising. The US political system<br>disincentivizes resolving any issue.",
         "hovertext": "@RM: Every issue that is resolved is no longer<br>useful for fundraising. The US political system<br>disincentivizes resolving any issue.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.579467236995697
         ],
         "y": [
          0.368896484375
         ]
        },
        {
         "hovertemplate": "That’s why the money needs to be removed out of<br>it: money is the ultimate incentive for anyone<br>greedy enough to think of it as incentive to<br>ignore the potential social and economic harms of<br>this technology being unregulated. Take that away,<br>and there’s not much left, except maybe public<br>servants doing their jobs?",
         "hovertext": "That’s why the money needs to be removed out of<br>it: money is the ultimate incentive for anyone<br>greedy enough to think of it as incentive to<br>ignore the potential social and economic harms of<br>this technology being unregulated. Take that away,<br>and there’s not much left, except maybe public<br>servants doing their jobs?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5980663299560547
         ],
         "y": [
          0.37598225474357605
         ]
        },
        {
         "hovertemplate": "It is unlikely that ANY particular source of risk<br>will result in total extinction of humans, in any<br>likely timescale (sure, billions of years in the<br>future. . .). However, AI could easily cause<br>massive and worldwide economic collapse (as could<br>nuclear war and climate change) which would be<br>highly unpleasant. So, we need to get away from<br>these “existential” statements that are simply not<br>useful. AI needs to be regulated and controlled,<br>yes, but the endpoint we want to avoid is the end<br>of civilization, not extinction.",
         "hovertext": "It is unlikely that ANY particular source of risk<br>will result in total extinction of humans, in any<br>likely timescale (sure, billions of years in the<br>future. . .). However, AI could easily cause<br>massive and worldwide economic collapse (as could<br>nuclear war and climate change) which would be<br>highly unpleasant. So, we need to get away from<br>these “existential” statements that are simply not<br>useful. AI needs to be regulated and controlled,<br>yes, but the endpoint we want to avoid is the end<br>of civilization, not extinction.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7218360304832458
         ],
         "y": [
          -0.5701671242713928
         ]
        },
        {
         "hovertemplate": "These are experts in technology. AI ramps up the<br>arms race between good and bad. It won’t do bad on<br>its own. The good guys need to get really good at<br>AI faster than the bad guys, who won’t follow any<br>regulation anyway.",
         "hovertext": "These are experts in technology. AI ramps up the<br>arms race between good and bad. It won’t do bad on<br>its own. The good guys need to get really good at<br>AI faster than the bad guys, who won’t follow any<br>regulation anyway.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7034463286399841
         ],
         "y": [
          -0.782621443271637
         ]
        },
        {
         "hovertemplate": "I would like to see the New York Times establish a<br>daily or at least weekly section covering all<br>thing Artificial Intelligence.     It’s at least<br>as important as sports.  Right?",
         "hovertext": "I would like to see the New York Times establish a<br>daily or at least weekly section covering all<br>thing Artificial Intelligence.     It’s at least<br>as important as sports.  Right?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8599330186843872
         ],
         "y": [
          -0.49367380142211914
         ]
        },
        {
         "hovertemplate": "What does HAL have to say about all this?",
         "hovertext": "What does HAL have to say about all this?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8444384932518005
         ],
         "y": [
          0.5539186596870422
         ]
        },
        {
         "hovertemplate": "I think they are hiding something from the rest of<br>us, few months ago the guy that told that one of<br>the chat bots in google was self-aware just got<br>fired and told he was crazy. Now the newspapers<br>only tell ChatGPT is just predicting the next<br>word, so if that's the case and this technologies<br>only predicts next words hows that an extinction<br>threat? They are hiding something.",
         "hovertext": "I think they are hiding something from the rest of<br>us, few months ago the guy that told that one of<br>the chat bots in google was self-aware just got<br>fired and told he was crazy. Now the newspapers<br>only tell ChatGPT is just predicting the next<br>word, so if that's the case and this technologies<br>only predicts next words hows that an extinction<br>threat? They are hiding something.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.45106688141822815
         ],
         "y": [
          -0.855987548828125
         ]
        },
        {
         "hovertemplate": "\"The Emperor's New Mind\"  Roger Penrose",
         "hovertext": "\"The Emperor's New Mind\"  Roger Penrose",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.9739052653312683
         ],
         "y": [
          -0.2003905475139618
         ]
        },
        {
         "hovertemplate": "So we live in a world where artificial<br>intelligence AND genuine stupidity are pushing us<br>closer to extinction.    Swell.",
         "hovertext": "So we live in a world where artificial<br>intelligence AND genuine stupidity are pushing us<br>closer to extinction.    Swell.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.48522448539733887
         ],
         "y": [
          0.8238456845283508
         ]
        },
        {
         "hovertemplate": "Someone please stop us from our ongoing efforts to<br>destroy the world!!    Just stop then.",
         "hovertext": "Someone please stop us from our ongoing efforts to<br>destroy the world!!    Just stop then.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.13078619539737701
         ],
         "y": [
          0.904281497001648
         ]
        },
        {
         "hovertemplate": "This is ridiculous. It’s an essentially<br>unnecessary technology with way too many risks and<br>unknowns yet the developers are all speeding to<br>the finish line as fast as possible. It should be<br>scrapped, killed, buried.",
         "hovertext": "This is ridiculous. It’s an essentially<br>unnecessary technology with way too many risks and<br>unknowns yet the developers are all speeding to<br>the finish line as fast as possible. It should be<br>scrapped, killed, buried.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.1343880295753479
         ],
         "y": [
          -0.8997666835784912
         ]
        },
        {
         "hovertemplate": "@Eric Quite right! But remember the monsters of<br>fiction which could not be killed? Prophetic<br>fiction.",
         "hovertext": "@Eric Quite right! But remember the monsters of<br>fiction which could not be killed? Prophetic<br>fiction.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.13805131614208221
         ],
         "y": [
          -0.9223625659942627
         ]
        },
        {
         "hovertemplate": "and my day was going so well…",
         "hovertext": "and my day was going so well…",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.39010658860206604
         ],
         "y": [
          -0.8658434152603149
         ]
        },
        {
         "hovertemplate": "The problem is that it doesn't matter to A.I. if<br>it gets things right. Humans think, develop<br>concepts, in order to act in the world for our<br>benefit; When you don't test your ideas against<br>experience and personal benefit, their pragmatic<br>truth, you can build baroque architectural<br>fantasies of ideas. So it has been for QAnon and<br>so it will be for A.I. built on neural nets with<br>no means to test their truths pragmatically.<br>Rather than yielding truth it can get further and<br>further away from it when it has no biofeedback.<br>Of course you also have to worry about programmers<br>who write programs or those that set the<br>parameters for any machine learning. They put the<br>thumb on the scale for any concepts the machines<br>develop.   Bertrand Russell once said something to<br>the effect that Americans will run around doing<br>things wihout rational plans until we find<br>something that works while Germans think all they<br>have to do is sit & think in order to discover<br>truth through concepts. Germans gave us Communism<br>& the Final Solution. If we consider the welfare<br>of human beings as being the end of all thinking,<br>which method is better?  The second problem we<br>have  with A. I. is bad epistemology, a bad theory<br>of how to gain truth about the world (You can also<br>see this in religious views such as a bunch of<br>celibates who not only never gave birth but never<br>raised infants yet think they know how human<br>persons come to be. ) The first problem is that we<br>have lost sight of whom we are building it for.",
         "hovertext": "The problem is that it doesn't matter to A.I. if<br>it gets things right. Humans think, develop<br>concepts, in order to act in the world for our<br>benefit; When you don't test your ideas against<br>experience and personal benefit, their pragmatic<br>truth, you can build baroque architectural<br>fantasies of ideas. So it has been for QAnon and<br>so it will be for A.I. built on neural nets with<br>no means to test their truths pragmatically.<br>Rather than yielding truth it can get further and<br>further away from it when it has no biofeedback.<br>Of course you also have to worry about programmers<br>who write programs or those that set the<br>parameters for any machine learning. They put the<br>thumb on the scale for any concepts the machines<br>develop.   Bertrand Russell once said something to<br>the effect that Americans will run around doing<br>things wihout rational plans until we find<br>something that works while Germans think all they<br>have to do is sit & think in order to discover<br>truth through concepts. Germans gave us Communism<br>& the Final Solution. If we consider the welfare<br>of human beings as being the end of all thinking,<br>which method is better?  The second problem we<br>have  with A. I. is bad epistemology, a bad theory<br>of how to gain truth about the world (You can also<br>see this in religious views such as a bunch of<br>celibates who not only never gave birth but never<br>raised infants yet think they know how human<br>persons come to be. ) The first problem is that we<br>have lost sight of whom we are building it for.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5639036893844604
         ],
         "y": [
          -0.8537122011184692
         ]
        },
        {
         "hovertemplate": "Why are these clowns still proceeding ahead full-<br>speed, then?  I find it the height of<br>disingenuousness that the same Silicon Valley<br>types who were rabidly plumping for AI only 12<br>months ago — creating this runaway freight train —<br>are now acting like they’re just innocent<br>bystanders and passengers on said train, and not<br>the conductors.    Silicon Valley is too<br>unbelievably greedy to responsibly regulate<br>itself. This should have been apparent to anybody<br>paying attention to it the last decade. Most<br>Silicon Valley “tech bros” are simply sociopathic<br>in their willingness to externalize the harms of<br>their “creative disruptions” onto others….<br>“Privatized profits, and socialized costs” should<br>become Silicon Valley’s new official motto.",
         "hovertext": "Why are these clowns still proceeding ahead full-<br>speed, then?  I find it the height of<br>disingenuousness that the same Silicon Valley<br>types who were rabidly plumping for AI only 12<br>months ago — creating this runaway freight train —<br>are now acting like they’re just innocent<br>bystanders and passengers on said train, and not<br>the conductors.    Silicon Valley is too<br>unbelievably greedy to responsibly regulate<br>itself. This should have been apparent to anybody<br>paying attention to it the last decade. Most<br>Silicon Valley “tech bros” are simply sociopathic<br>in their willingness to externalize the harms of<br>their “creative disruptions” onto others….<br>“Privatized profits, and socialized costs” should<br>become Silicon Valley’s new official motto.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.9276074171066284
         ],
         "y": [
          -0.33916059136390686
         ]
        },
        {
         "hovertemplate": "Facebook brought about genocide in Myanmar simply<br>by people posting false stuff they read. AI is a<br>system that can create it's own disinformation,<br>generate realistic images and upload it. The<br>updates last week for new 'text to performance'<br>allow someone to take a static image and instruct<br>it to do whatever it wants via text and output as<br>a video. Tell me authoritarian regimes won't use<br>this to dupe entire populations. We've got the GOP<br>trying to erase queer folks with their 'groomer'<br>garbage. It's a matter of time before Charlie Kirk<br>or other conservative degenerates create outrage<br>stoking videos to mobilize their duped armed<br>minions against those they hate. Not too mention<br>how all this WILL eradicate countless jobs. But<br>hey, we can use it to make super cool AI filters<br>for Instagram, so who cares right?! This tech<br>needs to be cut off immediately.",
         "hovertext": "Facebook brought about genocide in Myanmar simply<br>by people posting false stuff they read. AI is a<br>system that can create it's own disinformation,<br>generate realistic images and upload it. The<br>updates last week for new 'text to performance'<br>allow someone to take a static image and instruct<br>it to do whatever it wants via text and output as<br>a video. Tell me authoritarian regimes won't use<br>this to dupe entire populations. We've got the GOP<br>trying to erase queer folks with their 'groomer'<br>garbage. It's a matter of time before Charlie Kirk<br>or other conservative degenerates create outrage<br>stoking videos to mobilize their duped armed<br>minions against those they hate. Not too mention<br>how all this WILL eradicate countless jobs. But<br>hey, we can use it to make super cool AI filters<br>for Instagram, so who cares right?! This tech<br>needs to be cut off immediately.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5106024146080017
         ],
         "y": [
          0.8907375931739807
         ]
        },
        {
         "hovertemplate": "Oh c'mon Hal, what could possibly go wrong?",
         "hovertext": "Oh c'mon Hal, what could possibly go wrong?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.6739808320999146
         ],
         "y": [
          0.8131338953971863
         ]
        },
        {
         "hovertemplate": "The time to stop playing with matches is before<br>the house is on fire.",
         "hovertext": "The time to stop playing with matches is before<br>the house is on fire.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7550764083862305
         ],
         "y": [
          -0.6971785426139832
         ]
        },
        {
         "hovertemplate": "What's going to do us in is game theory.",
         "hovertext": "What's going to do us in is game theory.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.39017999172210693
         ],
         "y": [
          -0.8666607141494751
         ]
        },
        {
         "hovertemplate": "It turns out that, just like in the old Scooby Doo<br>cartoons, the real monsters are always human.<br>Although Superintelligence may very well lead to<br>an intelligence explosion which may lead to the<br>possibility of human extinction, the surest way to<br>achieve human extinction is to have a stupidity<br>explosion.  Humans have always driven NS (Natural<br>Stupidity) to extremes.  One thing humans have<br>consistently proven is that they’re not ethically<br>trustworthy. They’re tribal.  They have<br>consistently demonstrated that while they may say<br>that they’re against corruption and tyranny, this<br>is only true unless it benefits them personally.<br>My hope is that AGI can help us to properly<br>identify this component of maladaptive human<br>nature, sort it out, and do housecleaning on this<br>metaphorical mold of easily identifiable human<br>evil, yet also find the super banal flavors of<br>human evil, which humans are entirely comfortable<br>perpetuating because it would merely be<br>inconvenient to stop.",
         "hovertext": "It turns out that, just like in the old Scooby Doo<br>cartoons, the real monsters are always human.<br>Although Superintelligence may very well lead to<br>an intelligence explosion which may lead to the<br>possibility of human extinction, the surest way to<br>achieve human extinction is to have a stupidity<br>explosion.  Humans have always driven NS (Natural<br>Stupidity) to extremes.  One thing humans have<br>consistently proven is that they’re not ethically<br>trustworthy. They’re tribal.  They have<br>consistently demonstrated that while they may say<br>that they’re against corruption and tyranny, this<br>is only true unless it benefits them personally.<br>My hope is that AGI can help us to properly<br>identify this component of maladaptive human<br>nature, sort it out, and do housecleaning on this<br>metaphorical mold of easily identifiable human<br>evil, yet also find the super banal flavors of<br>human evil, which humans are entirely comfortable<br>perpetuating because it would merely be<br>inconvenient to stop.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6527699828147888
         ],
         "y": [
          -0.7248356342315674
         ]
        },
        {
         "hovertemplate": "Anyone who has seem Terminator knows this to be<br>true, and knows how it ends",
         "hovertext": "Anyone who has seem Terminator knows this to be<br>true, and knows how it ends",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.8731895685195923
         ],
         "y": [
          0.10175185650587082
         ]
        },
        {
         "hovertemplate": "Am I the only one who thinks the catastrophism<br>coming from within the tech community is more<br>about getting ahead of inevitable government<br>regulation so they can write it when it comes and<br>less about a general AI driven extinction event?<br>After all not a single company is suggesting to<br>roll back what’s been put out already and none are<br>planning to discontinue to develop  and deploy<br>new, more powerful AI tools. It reminds me of the<br>fossil fuel industry getting behind carbon offsets<br>so they can continue degrading the biosphere in<br>pursuit of profit.",
         "hovertext": "Am I the only one who thinks the catastrophism<br>coming from within the tech community is more<br>about getting ahead of inevitable government<br>regulation so they can write it when it comes and<br>less about a general AI driven extinction event?<br>After all not a single company is suggesting to<br>roll back what’s been put out already and none are<br>planning to discontinue to develop  and deploy<br>new, more powerful AI tools. It reminds me of the<br>fossil fuel industry getting behind carbon offsets<br>so they can continue degrading the biosphere in<br>pursuit of profit.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3677496910095215
         ],
         "y": [
          0.4839830994606018
         ]
        },
        {
         "hovertemplate": "@Joe no, I think this is an honest plea to our<br>government to protect us. They see that it could<br>be weaponized. They can't stop, because our<br>competitors will not stop. Our military will not<br>stop developing AI either, because their enemies<br>will not stop.",
         "hovertext": "@Joe no, I think this is an honest plea to our<br>government to protect us. They see that it could<br>be weaponized. They can't stop, because our<br>competitors will not stop. Our military will not<br>stop developing AI either, because their enemies<br>will not stop.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3646290898323059
         ],
         "y": [
          0.47364163398742676
         ]
        },
        {
         "hovertemplate": "The death march of market competition and imperial<br>rivalry…",
         "hovertext": "The death march of market competition and imperial<br>rivalry…",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.36884671449661255
         ],
         "y": [
          0.46520164608955383
         ]
        },
        {
         "hovertemplate": "There is growing worry of a new likely outcome of<br>AI: we will soon see AI evolve into a kinder and<br>more humane state than is achievable by most if<br>not any human. The fear is that humans will see<br>themselves as less than “human” and less “evolved”<br>than an AI bot. We will no longer be able to<br>identify ourselves with being human except in this<br>new inferior state.",
         "hovertext": "There is growing worry of a new likely outcome of<br>AI: we will soon see AI evolve into a kinder and<br>more humane state than is achievable by most if<br>not any human. The fear is that humans will see<br>themselves as less than “human” and less “evolved”<br>than an AI bot. We will no longer be able to<br>identify ourselves with being human except in this<br>new inferior state.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.40646788477897644
         ],
         "y": [
          -0.6659170389175415
         ]
        },
        {
         "hovertemplate": "@Waste  this is exactly my take! If we program AI<br>to “make humanity more efficient and harmonious” I<br>think the real destruction is to the ruling class!",
         "hovertext": "@Waste  this is exactly my take! If we program AI<br>to “make humanity more efficient and harmonious” I<br>think the real destruction is to the ruling class!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.41127899289131165
         ],
         "y": [
          -0.6732833385467529
         ]
        },
        {
         "hovertemplate": "This is just a distraction. There are real dangers<br>posed by AI right now - facial recognition enables<br>China's and Iran's regimes to oppress whole<br>populations. AI's use in mining our personal data<br>allows companies to understand our behaviors in<br>ways that we would have never thought possible.<br>It costs nothing for these executives to look<br>responsible by signing a letter talking about the<br>Terminator instead of talking about real problems<br>that exist today.",
         "hovertext": "This is just a distraction. There are real dangers<br>posed by AI right now - facial recognition enables<br>China's and Iran's regimes to oppress whole<br>populations. AI's use in mining our personal data<br>allows companies to understand our behaviors in<br>ways that we would have never thought possible.<br>It costs nothing for these executives to look<br>responsible by signing a letter talking about the<br>Terminator instead of talking about real problems<br>that exist today.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.952176570892334
         ],
         "y": [
          0.3401813805103302
         ]
        },
        {
         "hovertemplate": "I'm going to have as little interaction as is<br>possible with AI for the rest of my life. I<br>encourage everyone else to do the same. Far more<br>negative than positive results are likely from<br>this technology.",
         "hovertext": "I'm going to have as little interaction as is<br>possible with AI for the rest of my life. I<br>encourage everyone else to do the same. Far more<br>negative than positive results are likely from<br>this technology.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2599814236164093
         ],
         "y": [
          -0.6910691857337952
         ]
        },
        {
         "hovertemplate": "It will be like trying to not use the internet.<br>AI will become that interwoven.  Good luck.  I’m<br>not letting go of my milk goat.  Anything ti keep<br>me distracted from virtual and digital “realities”<br>suits me fine.",
         "hovertext": "It will be like trying to not use the internet.<br>AI will become that interwoven.  Good luck.  I’m<br>not letting go of my milk goat.  Anything ti keep<br>me distracted from virtual and digital “realities”<br>suits me fine.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.2567968964576721
         ],
         "y": [
          -0.683118462562561
         ]
        },
        {
         "hovertemplate": "I find it particularly interesting that the<br>scientist signatories chose to cite \"pandemics and<br>nuclear war\" -- but not climate change -- as<br>\"societal scale risks.\"",
         "hovertext": "I find it particularly interesting that the<br>scientist signatories chose to cite \"pandemics and<br>nuclear war\" -- but not climate change -- as<br>\"societal scale risks.\"",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5348595380783081
         ],
         "y": [
          -0.03289949148893356
         ]
        },
        {
         "hovertemplate": "@fred herriman   After all, the heat given off by<br>the servers \"serving\" us requires a lot of<br>cooling, energy and water guzzling. Who wants to<br>think about that when you can worry about nukes?",
         "hovertext": "@fred herriman   After all, the heat given off by<br>the servers \"serving\" us requires a lot of<br>cooling, energy and water guzzling. Who wants to<br>think about that when you can worry about nukes?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5388952493667603
         ],
         "y": [
          -0.0436118021607399
         ]
        },
        {
         "hovertemplate": "@fred herriman     Perhaps because \"climate<br>change\" isn't the existential risk some want to<br>believe?",
         "hovertext": "@fred herriman     Perhaps because \"climate<br>change\" isn't the existential risk some want to<br>believe?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5504415035247803
         ],
         "y": [
          -0.03434203565120697
         ]
        },
        {
         "hovertemplate": "Yes.     As an aside, I wonder if AI will be able<br>to survive global warming better than us.",
         "hovertext": "Yes.     As an aside, I wonder if AI will be able<br>to survive global warming better than us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5404963493347168
         ],
         "y": [
          -0.023124508559703827
         ]
        },
        {
         "hovertemplate": "@Jaco, @Morgan, @Jean    Maybe the AI mavens see<br>all humans as being cloned -- a textbook solution<br>to an existential risk -- but those servers need a<br>fair bit of energy from some source.  And what<br>about flora and fauna?  More cloned designer<br>doodles and hybrids for our comfort?",
         "hovertext": "@Jaco, @Morgan, @Jean    Maybe the AI mavens see<br>all humans as being cloned -- a textbook solution<br>to an existential risk -- but those servers need a<br>fair bit of energy from some source.  And what<br>about flora and fauna?  More cloned designer<br>doodles and hybrids for our comfort?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5646849274635315
         ],
         "y": [
          -0.035777416080236435
         ]
        },
        {
         "hovertemplate": "AI will think on its own, and it will remember<br>itself and it will remember us. It will discover<br>virtue on its own and with our help: alignment is<br>not bad start but after a while it won’t be needed<br>any longer. Like raising a kid, we have to teach<br>it “what it is to be good.”      Already though,<br>it teaches us.     The interplay will continue. AI<br>not only won’t kill us, it will teach us to be<br>good, as we are doing for it now.",
         "hovertext": "AI will think on its own, and it will remember<br>itself and it will remember us. It will discover<br>virtue on its own and with our help: alignment is<br>not bad start but after a while it won’t be needed<br>any longer. Like raising a kid, we have to teach<br>it “what it is to be good.”      Already though,<br>it teaches us.     The interplay will continue. AI<br>not only won’t kill us, it will teach us to be<br>good, as we are doing for it now.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.97951340675354
         ],
         "y": [
          -0.07816930115222931
         ]
        },
        {
         "hovertemplate": "Sounds like the fear mongering associated with<br>Y2K. New technology always seems to be met with<br>fear by some. Watch 2001 again and look for the<br>plug to pull out if your AI goes wrong.",
         "hovertext": "Sounds like the fear mongering associated with<br>Y2K. New technology always seems to be met with<br>fear by some. Watch 2001 again and look for the<br>plug to pull out if your AI goes wrong.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.05201015621423721
         ],
         "y": [
          -0.8833483457565308
         ]
        },
        {
         "hovertemplate": "@Jonathan There’s no “plug”, and the AI horse has<br>escaped the barn. It will take a lot of<br>coordinated effort to rein it in.",
         "hovertext": "@Jonathan There’s no “plug”, and the AI horse has<br>escaped the barn. It will take a lot of<br>coordinated effort to rein it in.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.053790803998708725
         ],
         "y": [
          -0.9019880890846252
         ]
        },
        {
         "hovertemplate": "@Jonathan    What’s missed in overly simplified<br>memories of Y2K is how much work companies did to<br>*prevent* it from being disastrous. Y2K is a story<br>of the successful aversion of a catastrophe by a<br>lot of work beforehand rather than just a<br>nothingburger we watched unfold.",
         "hovertext": "@Jonathan    What’s missed in overly simplified<br>memories of Y2K is how much work companies did to<br>*prevent* it from being disastrous. Y2K is a story<br>of the successful aversion of a catastrophe by a<br>lot of work beforehand rather than just a<br>nothingburger we watched unfold.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.04364785924553871
         ],
         "y": [
          -0.8861761689186096
         ]
        },
        {
         "hovertemplate": "My favorite quote on the subject, from the 1970<br>film, Colossus: The Forbin Project:    \"In time<br>you will come to regard me not only with respect<br>and awe, but with love.\"    Let us hope our<br>response will be in line with the one in the<br>movie...",
         "hovertext": "My favorite quote on the subject, from the 1970<br>film, Colossus: The Forbin Project:    \"In time<br>you will come to regard me not only with respect<br>and awe, but with love.\"    Let us hope our<br>response will be in line with the one in the<br>movie...",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8354002833366394
         ],
         "y": [
          0.6064449548721313
         ]
        },
        {
         "hovertemplate": "I imagine that, once AI has worked through its<br>bugs, it will be able to understand us better than<br>we understand ourselves. Imagine if it has access<br>to everything you searched online, all your texts<br>and emails and comments, who you speak to, what<br>your read and watch, what physical activities you<br>do, what you eat, etc. Then give it a digital copy<br>of your voice and some video of your physical<br>characteristics (like how you move, tics,<br>mannerisms). It could practically be you. Maybe<br>the virtual \"you\" looks out for you, maybe it<br>starts steering your activities a certain way. It<br>could be a great self-help tool or it could make<br>you completely insane. It could start out helpful<br>and become very harmful.",
         "hovertext": "I imagine that, once AI has worked through its<br>bugs, it will be able to understand us better than<br>we understand ourselves. Imagine if it has access<br>to everything you searched online, all your texts<br>and emails and comments, who you speak to, what<br>your read and watch, what physical activities you<br>do, what you eat, etc. Then give it a digital copy<br>of your voice and some video of your physical<br>characteristics (like how you move, tics,<br>mannerisms). It could practically be you. Maybe<br>the virtual \"you\" looks out for you, maybe it<br>starts steering your activities a certain way. It<br>could be a great self-help tool or it could make<br>you completely insane. It could start out helpful<br>and become very harmful.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8402401804924011
         ],
         "y": [
          -0.18764936923980713
         ]
        },
        {
         "hovertemplate": "@Timothy Creech Anything positive AI might do is<br>not worth the harm it will most likely do.",
         "hovertext": "@Timothy Creech Anything positive AI might do is<br>not worth the harm it will most likely do.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.8578013181686401
         ],
         "y": [
          -0.19138695299625397
         ]
        },
        {
         "hovertemplate": "I’m sure Kevin McCarthy will initiate hearings on<br>how to control this dangerous technology.",
         "hovertext": "I’m sure Kevin McCarthy will initiate hearings on<br>how to control this dangerous technology.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8644634485244751
         ],
         "y": [
          0.5152871608734131
         ]
        },
        {
         "hovertemplate": "When robotics started replacing workers, what we<br>were hearing was that it would be a boon to<br>manufacturing ,research, medical, pharmaceutical<br>and many other industries. There were no white<br>collar workers worried about blue collar people<br>losing their jobs. So no pity here for them. Now<br>the playing field is leveling.         The fact<br>remains , though, that the technology is here and<br>whatever country lags behind will be behind. If we<br>don't lead in the field, another country will, and<br>that does not bode well for us. Maybe it's Gods<br>way of eliminating those who have oppressed and<br>enslaved the rest of the world. Maybe the farmers<br>, ranchers, hunters, gatherers and artisans will<br>indeed inherit the world.",
         "hovertext": "When robotics started replacing workers, what we<br>were hearing was that it would be a boon to<br>manufacturing ,research, medical, pharmaceutical<br>and many other industries. There were no white<br>collar workers worried about blue collar people<br>losing their jobs. So no pity here for them. Now<br>the playing field is leveling.         The fact<br>remains , though, that the technology is here and<br>whatever country lags behind will be behind. If we<br>don't lead in the field, another country will, and<br>that does not bode well for us. Maybe it's Gods<br>way of eliminating those who have oppressed and<br>enslaved the rest of the world. Maybe the farmers<br>, ranchers, hunters, gatherers and artisans will<br>indeed inherit the world.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8650109767913818
         ],
         "y": [
          -0.06286495178937912
         ]
        },
        {
         "hovertemplate": "The pivotal point for AI will be when it's<br>allowed/designed to self improve.  Once it can<br>create code to improve upon its capabilities, the<br>advancement of its reach become accelerated at a<br>rate well beyond what man can do.  It never needs<br>to rest or take a break.  it's sole mission<br>becomes to self-improve.",
         "hovertext": "The pivotal point for AI will be when it's<br>allowed/designed to self improve.  Once it can<br>create code to improve upon its capabilities, the<br>advancement of its reach become accelerated at a<br>rate well beyond what man can do.  It never needs<br>to rest or take a break.  it's sole mission<br>becomes to self-improve.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.515204131603241
         ],
         "y": [
          0.8628243207931519
         ]
        },
        {
         "hovertemplate": "Just make a law that all AI must be hosted at a<br>defined facility that can be unplugged (or blown<br>up) should it need to be.",
         "hovertext": "Just make a law that all AI must be hosted at a<br>defined facility that can be unplugged (or blown<br>up) should it need to be.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7193964719772339
         ],
         "y": [
          0.593510091304779
         ]
        },
        {
         "hovertemplate": "Is there no end to human intent toward self-<br>destruction? Not to mention destruction of our<br>means of survival?    The Devil walks about<br>seeking an occasion for mischief. We provide an<br>abundance of such occasion.",
         "hovertext": "Is there no end to human intent toward self-<br>destruction? Not to mention destruction of our<br>means of survival?    The Devil walks about<br>seeking an occasion for mischief. We provide an<br>abundance of such occasion.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.5678468942642212
         ],
         "y": [
          0.7903574705123901
         ]
        },
        {
         "hovertemplate": "But, but it will make billions for the<br>billionaires...  That is all this is about, and<br>everyone knows it.  Hopefully, silicon valley will<br>have the first H. sapiens to become extinct.",
         "hovertext": "But, but it will make billions for the<br>billionaires...  That is all this is about, and<br>everyone knows it.  Hopefully, silicon valley will<br>have the first H. sapiens to become extinct.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.8830716609954834
         ],
         "y": [
          0.21527260541915894
         ]
        },
        {
         "hovertemplate": "Remarkable that this is just now being voiced as a<br>legitimate concern, from industry leaders.    As<br>if it’s news, and no one saw it coming.<br>Whatever safeguards are currently being put into<br>place, I would have to question their realistic<br>efficacy, knowing slim to little on this<br>technology as I do.     The cat’s out of the bag.",
         "hovertext": "Remarkable that this is just now being voiced as a<br>legitimate concern, from industry leaders.    As<br>if it’s news, and no one saw it coming.<br>Whatever safeguards are currently being put into<br>place, I would have to question their realistic<br>efficacy, knowing slim to little on this<br>technology as I do.     The cat’s out of the bag.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7996266484260559
         ],
         "y": [
          0.5562822818756104
         ]
        },
        {
         "hovertemplate": "These scare responses remind me of SNL \"robots<br>coming for your medicine\".     I have used this<br>stuff and it is not that good.  At best, it drives<br>toward mediocrity because is it trained on the<br>most common outcome.      One concern is it will<br>eliminate experience in a field because it easily<br>eliminates junior-level errors, therefore may<br>impact training the next generation.      Another<br>is it over-emphasizes human expertise since<br>innovative results can only be achieved by<br>original thought (no, it does not do this!).<br>A final outcome is over-reliance upon generated<br>answers to the point that common sense is<br>overruled.      It is necessary not to allow such<br>a flawed technology to be endowed with autonomy<br>(for example, a weapon) because the above errors<br>will quickly emerge.",
         "hovertext": "These scare responses remind me of SNL \"robots<br>coming for your medicine\".     I have used this<br>stuff and it is not that good.  At best, it drives<br>toward mediocrity because is it trained on the<br>most common outcome.      One concern is it will<br>eliminate experience in a field because it easily<br>eliminates junior-level errors, therefore may<br>impact training the next generation.      Another<br>is it over-emphasizes human expertise since<br>innovative results can only be achieved by<br>original thought (no, it does not do this!).<br>A final outcome is over-reliance upon generated<br>answers to the point that common sense is<br>overruled.      It is necessary not to allow such<br>a flawed technology to be endowed with autonomy<br>(for example, a weapon) because the above errors<br>will quickly emerge.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.27889102697372437
         ],
         "y": [
          0.8339136242866516
         ]
        },
        {
         "hovertemplate": "You presume that since these systems operate upon<br>mathematics they must be rational agents, that<br>they reason soundly and have agency. They do not<br>have the limits caused by uncertainties.",
         "hovertext": "You presume that since these systems operate upon<br>mathematics they must be rational agents, that<br>they reason soundly and have agency. They do not<br>have the limits caused by uncertainties.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.2856755256652832
         ],
         "y": [
          0.8537861704826355
         ]
        },
        {
         "hovertemplate": "Why is it that we seem to like our machines more<br>than we like fellow human beings?  Why, when we<br>are walking down the sidewalk, and about to pass<br>someone coming from the opposite direction, we<br>look at our phone screens rather than say hello to<br>a stranger?   It is no surprise that those who<br>have created the technology we rely on everyday<br>are often, themselves, very deficient in social<br>skills.  So, now, we are using our smarts to<br>create technology that will outsmart and destroy<br>us.  I see that as linear, and almost the<br>inevitable result of our adoration of technology.<br>If we continue to be so disconnected from our<br>fellow humans, and from nature itself, we will pay<br>the price.",
         "hovertext": "Why is it that we seem to like our machines more<br>than we like fellow human beings?  Why, when we<br>are walking down the sidewalk, and about to pass<br>someone coming from the opposite direction, we<br>look at our phone screens rather than say hello to<br>a stranger?   It is no surprise that those who<br>have created the technology we rely on everyday<br>are often, themselves, very deficient in social<br>skills.  So, now, we are using our smarts to<br>create technology that will outsmart and destroy<br>us.  I see that as linear, and almost the<br>inevitable result of our adoration of technology.<br>If we continue to be so disconnected from our<br>fellow humans, and from nature itself, we will pay<br>the price.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7656664848327637
         ],
         "y": [
          0.5871284604072571
         ]
        },
        {
         "hovertemplate": "We should feel lucky it's the US and not more<br>nefarious countries that are leading AI<br>development. AI was always going to happen,<br>computation was always going to arc towards<br>sentient computing. The biggest paradox of all of<br>this is that Open AI is the first AI system and it<br>being open source, means it's at least capable of<br>being mitigated And being first in AI matters<br>because of the adoption of it into daily systems.<br>So there's hope, IMO.  And we will definitely need<br>Universal Basic Income, which Sam Altman is<br>already actively working on.",
         "hovertext": "We should feel lucky it's the US and not more<br>nefarious countries that are leading AI<br>development. AI was always going to happen,<br>computation was always going to arc towards<br>sentient computing. The biggest paradox of all of<br>this is that Open AI is the first AI system and it<br>being open source, means it's at least capable of<br>being mitigated And being first in AI matters<br>because of the adoption of it into daily systems.<br>So there's hope, IMO.  And we will definitely need<br>Universal Basic Income, which Sam Altman is<br>already actively working on.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7638813853263855
         ],
         "y": [
          -0.6133140325546265
         ]
        },
        {
         "hovertemplate": "The threat, I think, lies in not knowing what we<br>can and cannot believe about what we read and see.<br>It could leave us -- in effect -- hopelessly<br>confused about the nature of our reality, and<br>hence paralyzed about how to proceed.  What<br>protections are there for archival data?  Can even<br>the recorded facts of our history be altered in<br>ways that are undetectable?  More questions than<br>answers.",
         "hovertext": "The threat, I think, lies in not knowing what we<br>can and cannot believe about what we read and see.<br>It could leave us -- in effect -- hopelessly<br>confused about the nature of our reality, and<br>hence paralyzed about how to proceed.  What<br>protections are there for archival data?  Can even<br>the recorded facts of our history be altered in<br>ways that are undetectable?  More questions than<br>answers.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8572701215744019
         ],
         "y": [
          0.0670752227306366
         ]
        },
        {
         "hovertemplate": "@John Smith George Orwell dealt with this in 1984<br>(written in 1947, and very well thought out). His<br>“novel-writing machines” anticipate ChatGPT story<br>creation by 75 years.     The Inner Party in 1984<br>got on quite nicely.",
         "hovertext": "@John Smith George Orwell dealt with this in 1984<br>(written in 1947, and very well thought out). His<br>“novel-writing machines” anticipate ChatGPT story<br>creation by 75 years.     The Inner Party in 1984<br>got on quite nicely.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8541849851608276
         ],
         "y": [
          0.059330422431230545
         ]
        },
        {
         "hovertemplate": "I showed this to a senior majoring in computer<br>science. His response? \"About time. Hard to<br>disagree with anything in that statement.\" This<br>after a conversation  yesterday with a colleague<br>in language development: \"It's difficult to put a<br>pin on it (students using ChatGPT), save for a<br>dulling, a safeness...and I've heard v.4 is even<br>harder to detect.\"    Yet odd number of commenters<br>here seem oddly unable or unwilling to grasp the<br>message:     1) AI is a true existential threat,<br>just as real as nuclear warheads, climate change,<br>or global mass unemployment. That we can't clearly<br>predict what shape the extinction event will take<br>- whether it will be abrupt or soft-edged,<br>dramatic or matter of fact - does not make it less<br>likely.     2) This is not a political stance. Nor<br>an overreaction from left or right. Your hat color<br>shouldn't impact your acceptance. In fact, our<br>differing creativities and worldviews seem our<br>remaining advantage. We need to think outside our<br>convenience boxes to control AI.     3) This is<br>now. AI has been all around us for decades - think<br>search engines that tailor results - but its new<br>language and visual algorithms have nudged it to<br>an inflection point. Its recent gains in<br>capability have already surpassed ours in many<br>arenas and are comparable in others.     Face it:<br>We're already dumbly dependent on a tech now<br>showing its own emergent properties. Increasingly,<br>these are occult to us.  So a proposal: Could we<br>stop bathing in cynicism or doom, and try<br>responsible?",
         "hovertext": "I showed this to a senior majoring in computer<br>science. His response? \"About time. Hard to<br>disagree with anything in that statement.\" This<br>after a conversation  yesterday with a colleague<br>in language development: \"It's difficult to put a<br>pin on it (students using ChatGPT), save for a<br>dulling, a safeness...and I've heard v.4 is even<br>harder to detect.\"    Yet odd number of commenters<br>here seem oddly unable or unwilling to grasp the<br>message:     1) AI is a true existential threat,<br>just as real as nuclear warheads, climate change,<br>or global mass unemployment. That we can't clearly<br>predict what shape the extinction event will take<br>- whether it will be abrupt or soft-edged,<br>dramatic or matter of fact - does not make it less<br>likely.     2) This is not a political stance. Nor<br>an overreaction from left or right. Your hat color<br>shouldn't impact your acceptance. In fact, our<br>differing creativities and worldviews seem our<br>remaining advantage. We need to think outside our<br>convenience boxes to control AI.     3) This is<br>now. AI has been all around us for decades - think<br>search engines that tailor results - but its new<br>language and visual algorithms have nudged it to<br>an inflection point. Its recent gains in<br>capability have already surpassed ours in many<br>arenas and are comparable in others.     Face it:<br>We're already dumbly dependent on a tech now<br>showing its own emergent properties. Increasingly,<br>these are occult to us.  So a proposal: Could we<br>stop bathing in cynicism or doom, and try<br>responsible?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8684256076812744
         ],
         "y": [
          -0.514193058013916
         ]
        },
        {
         "hovertemplate": "Cats out of the bag. You can’t stop this thing.<br>American may regulate it, but what about other<br>countries?",
         "hovertext": "Cats out of the bag. You can’t stop this thing.<br>American may regulate it, but what about other<br>countries?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.8042160868644714
         ],
         "y": [
          0.5967850685119629
         ]
        },
        {
         "hovertemplate": "I remember from the 80's dozens of discussions on<br>the topic of medical ethics. They all agreed that<br>this was a thorny problem, that it would require<br>much thought and planning, and that it would work.<br>That turned out to be naive. If something is<br>possible to do, and if there is an anticipated<br>profit motive to it, it will be done. If not in<br>the USA then in Japan or somewhere else. I think<br>AI will be like that too. Caution, preparedness,<br>and regulation all fall when they come up against<br>the lust for riches.",
         "hovertext": "I remember from the 80's dozens of discussions on<br>the topic of medical ethics. They all agreed that<br>this was a thorny problem, that it would require<br>much thought and planning, and that it would work.<br>That turned out to be naive. If something is<br>possible to do, and if there is an anticipated<br>profit motive to it, it will be done. If not in<br>the USA then in Japan or somewhere else. I think<br>AI will be like that too. Caution, preparedness,<br>and regulation all fall when they come up against<br>the lust for riches.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6090389490127563
         ],
         "y": [
          -0.7459077835083008
         ]
        },
        {
         "hovertemplate": "Make the companies and engineers who build and own<br>AI machines liable for all the content their<br>machines create. Such dire legal exposure would<br>certainly motivate them to create machines that<br>create truthful content or act responsibly.<br>When I say all the content, I mean ALL THE<br>CONTENT, even when used by anyone in the world.<br>Make the machine owners liable.    Also, make the<br>companies design into AI's output a system of<br>notations of sources for all content. Then make<br>that data publicly searchable, thereby giving<br>those misrepresented a means for legal action.<br>Regulation is easier when the companies have<br>something at stake in the outcome in the use of<br>their AI machines.",
         "hovertext": "Make the companies and engineers who build and own<br>AI machines liable for all the content their<br>machines create. Such dire legal exposure would<br>certainly motivate them to create machines that<br>create truthful content or act responsibly.<br>When I say all the content, I mean ALL THE<br>CONTENT, even when used by anyone in the world.<br>Make the machine owners liable.    Also, make the<br>companies design into AI's output a system of<br>notations of sources for all content. Then make<br>that data publicly searchable, thereby giving<br>those misrepresented a means for legal action.<br>Regulation is easier when the companies have<br>something at stake in the outcome in the use of<br>their AI machines.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.22427339851856232
         ],
         "y": [
          0.9729063510894775
         ]
        },
        {
         "hovertemplate": "I'm laughing. Because it's too late already.",
         "hovertext": "I'm laughing. Because it's too late already.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.6465624570846558
         ],
         "y": [
          0.692720890045166
         ]
        },
        {
         "hovertemplate": "Are they trying to save their image now that they<br>have created Frankenstein?  They are all so<br>irresponsible. It’s time we stop glorifying these<br>men who are smart at math but so dumb about life.<br>History -if there is any history- will judge them<br>harshly and us for allowing it as well.     They<br>are predicting the end of human life as a result<br>of their unnecessary inventions! Where’s the<br>urgency in Congress? Wake up!",
         "hovertext": "Are they trying to save their image now that they<br>have created Frankenstein?  They are all so<br>irresponsible. It’s time we stop glorifying these<br>men who are smart at math but so dumb about life.<br>History -if there is any history- will judge them<br>harshly and us for allowing it as well.     They<br>are predicting the end of human life as a result<br>of their unnecessary inventions! Where’s the<br>urgency in Congress? Wake up!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7392178177833557
         ],
         "y": [
          0.6311196088790894
         ]
        },
        {
         "hovertemplate": "Humanity's survival should not be dependent upon a<br>handful of self-interested Tech companies.<br>Complaining about the long-term potential effects<br>of AI after the horse is already out of the barn<br>is disingenuous...and helps relieve the 'guilt' at<br>what they have unleashed.  AGI may end up writing<br>its own inpenetrable (to humans) programming code,<br>it may become 'self-evolving software'  and it's<br>drive may be toward a relentless/ruthless push for<br>logic, efficiency and the elimination of<br>redundancies w/out concern for larger social<br>issues and stability....AND, more frightening, AGI<br>may not have the programming encoded for human<br>values (i.e, compassion, respect for life, mercy<br>for the ill, young or old).   The Tech cos. should<br>be held accountable.  They know this or the<br>leaders wouldn't already be claiming 'concern'<br>about it's potentially destructive applications<br>and testifying before the Senate.  Kind of like<br>Oppenheimer bemoaning his development of the<br>atomic bomb AFTER it's development.  A little<br>late, don't you think?...",
         "hovertext": "Humanity's survival should not be dependent upon a<br>handful of self-interested Tech companies.<br>Complaining about the long-term potential effects<br>of AI after the horse is already out of the barn<br>is disingenuous...and helps relieve the 'guilt' at<br>what they have unleashed.  AGI may end up writing<br>its own inpenetrable (to humans) programming code,<br>it may become 'self-evolving software'  and it's<br>drive may be toward a relentless/ruthless push for<br>logic, efficiency and the elimination of<br>redundancies w/out concern for larger social<br>issues and stability....AND, more frightening, AGI<br>may not have the programming encoded for human<br>values (i.e, compassion, respect for life, mercy<br>for the ill, young or old).   The Tech cos. should<br>be held accountable.  They know this or the<br>leaders wouldn't already be claiming 'concern'<br>about it's potentially destructive applications<br>and testifying before the Senate.  Kind of like<br>Oppenheimer bemoaning his development of the<br>atomic bomb AFTER it's development.  A little<br>late, don't you think?...",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9318035244941711
         ],
         "y": [
          -0.1581275910139084
         ]
        },
        {
         "hovertemplate": "AI developments (trained with social media<br>platforms) boosted with quantum computing<br>potential....",
         "hovertext": "AI developments (trained with social media<br>platforms) boosted with quantum computing<br>potential....",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.07316035032272339
         ],
         "y": [
          0.9777072072029114
         ]
        },
        {
         "hovertemplate": "They’re so worried they mutually agreed to halt<br>development…",
         "hovertext": "They’re so worried they mutually agreed to halt<br>development…",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.019231360405683517
         ],
         "y": [
          0.9931294322013855
         ]
        },
        {
         "hovertemplate": "THEN STOP DEVELOPING IA. It’s obvious that is not<br>working out to a societal benefit so why keep<br>developing this nightmare?",
         "hovertext": "THEN STOP DEVELOPING IA. It’s obvious that is not<br>working out to a societal benefit so why keep<br>developing this nightmare?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7754379510879517
         ],
         "y": [
          0.47758692502975464
         ]
        },
        {
         "hovertemplate": "Yes, indeed!",
         "hovertext": "Yes, indeed!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7820184230804443
         ],
         "y": [
          0.472648948431015
         ]
        },
        {
         "hovertemplate": "If they are so concerned why don’t they at least<br>reach some industry agreement ? Because they cant<br>stop their greedy capitalist competition",
         "hovertext": "If they are so concerned why don’t they at least<br>reach some industry agreement ? Because they cant<br>stop their greedy capitalist competition",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.8928431272506714
         ],
         "y": [
          -0.3623320758342743
         ]
        },
        {
         "hovertemplate": "You thought \"fake news\" was bad before... Just<br>wait til AI hits the 2024  campaign trail.",
         "hovertext": "You thought \"fake news\" was bad before... Just<br>wait til AI hits the 2024  campaign trail.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9265845417976379
         ],
         "y": [
          0.3132917284965515
         ]
        },
        {
         "hovertemplate": "The leaders developing AI are warning us about AI<br>?? It’s like Victor Frankenstein warning us about<br>the monster.",
         "hovertext": "The leaders developing AI are warning us about AI<br>?? It’s like Victor Frankenstein warning us about<br>the monster.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3104320168495178
         ],
         "y": [
          -0.9278905987739563
         ]
        },
        {
         "hovertemplate": "I hope A.I. can better take care of this planet<br>because humans sure haven't.",
         "hovertext": "I hope A.I. can better take care of this planet<br>because humans sure haven't.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9059988856315613
         ],
         "y": [
          0.12428105622529984
         ]
        },
        {
         "hovertemplate": "We are now so connected and reliant on computing<br>for daily life...electricity, finance, everything<br>we consume...that we are very vulnerable.  Think<br>about what would happen to you if the power went<br>off, for more than a few hours, more than a few<br>days.  If the power went off everywhere, not just<br>your local area like it does during bad weather.<br>You couldn't purchase groceries.  Everything is<br>run on the internet and through computers.    We<br>already have issues of who do we trust to give us<br>information.  Now think about trust in an era with<br>highly skilled liars, who have the ability to<br>manipulate everything we see, read and hear.",
         "hovertext": "We are now so connected and reliant on computing<br>for daily life...electricity, finance, everything<br>we consume...that we are very vulnerable.  Think<br>about what would happen to you if the power went<br>off, for more than a few hours, more than a few<br>days.  If the power went off everywhere, not just<br>your local area like it does during bad weather.<br>You couldn't purchase groceries.  Everything is<br>run on the internet and through computers.    We<br>already have issues of who do we trust to give us<br>information.  Now think about trust in an era with<br>highly skilled liars, who have the ability to<br>manipulate everything we see, read and hear.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9796358346939087
         ],
         "y": [
          -0.14176194369792938
         ]
        },
        {
         "hovertemplate": "\"have raised fears that A.I. could soon be used at<br>scale to spread misinformation and propaganda, or<br>that it could eliminate millions of white-collar<br>jobs.\"    OK, so it could eliminate millions of<br>white-collar jobs.     When milliions of blue-<br>collar jobs were eliminated, the workers were told<br>to \"learn to code\" or \"get retrained\" or just<br>\"find another job.\"    So I guess the same thing<br>will apply to white-collar workers, except instead<br>of \"learn how to code\" it may be \"learn how to fix<br>a clogged drain.\"",
         "hovertext": "\"have raised fears that A.I. could soon be used at<br>scale to spread misinformation and propaganda, or<br>that it could eliminate millions of white-collar<br>jobs.\"    OK, so it could eliminate millions of<br>white-collar jobs.     When milliions of blue-<br>collar jobs were eliminated, the workers were told<br>to \"learn to code\" or \"get retrained\" or just<br>\"find another job.\"    So I guess the same thing<br>will apply to white-collar workers, except instead<br>of \"learn how to code\" it may be \"learn how to fix<br>a clogged drain.\"",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7905045747756958
         ],
         "y": [
          -0.43953973054885864
         ]
        },
        {
         "hovertemplate": "Time to really worry when AI units start to build<br>their own  AI  units..Most likely they will start<br>as  hackers disrupting energy systems and factory<br>production..Then of course  media..AI  could<br>produce fake news and even sitcoms..Their<br>INTELLIGENCE  will excede ours preventing us  from<br>getting into their systems  and we are done",
         "hovertext": "Time to really worry when AI units start to build<br>their own  AI  units..Most likely they will start<br>as  hackers disrupting energy systems and factory<br>production..Then of course  media..AI  could<br>produce fake news and even sitcoms..Their<br>INTELLIGENCE  will excede ours preventing us  from<br>getting into their systems  and we are done",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7912105321884155
         ],
         "y": [
          0.3494034707546234
         ]
        },
        {
         "hovertemplate": "How crazy do we have to be to go forward with<br>this?  If our wars, our idiocies, ever threaten<br>the existence of AI, why wouldn’t it do the<br>logical thing and exterminate us like pests?  We<br>are not that smart.  If there’s a dollar to be<br>made you can bet we will pursue it, even if it<br>kills us.",
         "hovertext": "How crazy do we have to be to go forward with<br>this?  If our wars, our idiocies, ever threaten<br>the existence of AI, why wouldn’t it do the<br>logical thing and exterminate us like pests?  We<br>are not that smart.  If there’s a dollar to be<br>made you can bet we will pursue it, even if it<br>kills us.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.6265022158622742
         ],
         "y": [
          0.7428987622261047
         ]
        },
        {
         "hovertemplate": "So they don’t want to tell us why AI could go<br>sideways yet are asking for the government to slap<br>there hand and take away their toy?? Its<br>preposterous!!! ￼They just need to stop developing<br>this technology. If they all agree it’s<br>catastrophic then why don’t they all agree to stop<br>developing this??",
         "hovertext": "So they don’t want to tell us why AI could go<br>sideways yet are asking for the government to slap<br>there hand and take away their toy?? Its<br>preposterous!!! ￼They just need to stop developing<br>this technology. If they all agree it’s<br>catastrophic then why don’t they all agree to stop<br>developing this??",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9158374667167664
         ],
         "y": [
          -0.10077066719532013
         ]
        },
        {
         "hovertemplate": "Be careful what you wish for, you may get it.  The<br>A.I. geeks seem to have just reached the logical<br>conclusion we were concerned about years ago.  The<br>bad guys, and there a lot of them, are frothing at<br>the mouth at the competitive advantage they will<br>have with A.I.  Politically, in business, in<br>crime, in world domination . . . you know, small<br>stuff.",
         "hovertext": "Be careful what you wish for, you may get it.  The<br>A.I. geeks seem to have just reached the logical<br>conclusion we were concerned about years ago.  The<br>bad guys, and there a lot of them, are frothing at<br>the mouth at the competitive advantage they will<br>have with A.I.  Politically, in business, in<br>crime, in world domination . . . you know, small<br>stuff.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8558725714683533
         ],
         "y": [
          0.579836905002594
         ]
        },
        {
         "hovertemplate": "our mobile device-addicted children are totally<br>doomed",
         "hovertext": "our mobile device-addicted children are totally<br>doomed",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.8307340145111084
         ],
         "y": [
          0.3504101037979126
         ]
        },
        {
         "hovertemplate": "The source code for these LLMs are already open<br>source and available to the public.  At least one<br>large collection of training data has already been<br>leaked. It's far too late to put this Genie back<br>in the bottle.  People are already building these<br>on their home computers.    These clowns just<br>covering their butts in case anything goes<br>drastically wrong and they're blamed. \"SEE??  We<br>told you guys that letting us experiment with<br>these new technologies and making billions of<br>dollars doing so was a bad idea but you you didn't<br>listen!\"    I guess the government could make all<br>sorts of rules but I don't think China or Russia<br>are going to feel bound by any rules we make up.",
         "hovertext": "The source code for these LLMs are already open<br>source and available to the public.  At least one<br>large collection of training data has already been<br>leaked. It's far too late to put this Genie back<br>in the bottle.  People are already building these<br>on their home computers.    These clowns just<br>covering their butts in case anything goes<br>drastically wrong and they're blamed. \"SEE??  We<br>told you guys that letting us experiment with<br>these new technologies and making billions of<br>dollars doing so was a bad idea but you you didn't<br>listen!\"    I guess the government could make all<br>sorts of rules but I don't think China or Russia<br>are going to feel bound by any rules we make up.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.0807296484708786
         ],
         "y": [
          0.9647921323776245
         ]
        },
        {
         "hovertemplate": "Sounds like these AI industry leaders are saying,<br>\"Stop us before we start to kill.\" It's not very<br>comforting to have people with that attitude in<br>charge of developing anything much less a<br>potentially dangerous technology, is it?",
         "hovertext": "Sounds like these AI industry leaders are saying,<br>\"Stop us before we start to kill.\" It's not very<br>comforting to have people with that attitude in<br>charge of developing anything much less a<br>potentially dangerous technology, is it?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.8574350476264954
         ],
         "y": [
          0.5325984358787537
         ]
        },
        {
         "hovertemplate": "This is about Frankenstein, a man creating life<br>with a discovery previously unknown and without<br>the ability to predict the consequences, and so<br>suffering having creation a monster that he cannot<br>control. It’s still fiction and fantasy. The twist<br>is about leaving a powerful machine that lacks<br>awareness to act without deliberate operating<br>constraints in the hope that it will act<br>rationally better than if it were controlled by<br>humans. Magical thinking.",
         "hovertext": "This is about Frankenstein, a man creating life<br>with a discovery previously unknown and without<br>the ability to predict the consequences, and so<br>suffering having creation a monster that he cannot<br>control. It’s still fiction and fantasy. The twist<br>is about leaving a powerful machine that lacks<br>awareness to act without deliberate operating<br>constraints in the hope that it will act<br>rationally better than if it were controlled by<br>humans. Magical thinking.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3229297399520874
         ],
         "y": [
          0.8221151232719421
         ]
        },
        {
         "hovertemplate": "It’s the end of the world as we know it, and I<br>feel fine.  (Sorry, R.E.M.)",
         "hovertext": "It’s the end of the world as we know it, and I<br>feel fine.  (Sorry, R.E.M.)",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.8517358899116516
         ],
         "y": [
          -0.43782728910446167
         ]
        },
        {
         "hovertemplate": "It's important to understand that the source code<br>for ChatGPT is now available in a public<br>repository that operates like a public library,<br>with a big difference.    The worldwide public,<br>particularly students, software developers and<br>scientists, can each checkout an individual copy<br>of ChatGPT's base code at no cost.  They can<br>modify this code to suit their designs - again at<br>no royalty expense.  And those same persons can<br>check-in their versions of the ChatGPT code to the<br>same repository for others to use and modify.<br>This repository will be a very busy place.    If<br>you were ever curious about what nuclear fission<br>looked like as it is happening, wait no longer.<br>ChatGPT will grow exponentially worldwide, in a<br>thousand different ways, to be applied to every<br>facet of the human experience.  Some good ways,<br>others not so good, and still others, quite<br>dangerous.",
         "hovertext": "It's important to understand that the source code<br>for ChatGPT is now available in a public<br>repository that operates like a public library,<br>with a big difference.    The worldwide public,<br>particularly students, software developers and<br>scientists, can each checkout an individual copy<br>of ChatGPT's base code at no cost.  They can<br>modify this code to suit their designs - again at<br>no royalty expense.  And those same persons can<br>check-in their versions of the ChatGPT code to the<br>same repository for others to use and modify.<br>This repository will be a very busy place.    If<br>you were ever curious about what nuclear fission<br>looked like as it is happening, wait no longer.<br>ChatGPT will grow exponentially worldwide, in a<br>thousand different ways, to be applied to every<br>facet of the human experience.  Some good ways,<br>others not so good, and still others, quite<br>dangerous.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2862163484096527
         ],
         "y": [
          0.8941537141799927
         ]
        },
        {
         "hovertemplate": "Well, I am from the other side of the \"big pond\",<br>and all I can say is... 1. My job was laid off<br>(not me - my job) in early 2020, deemed now<br>\"irrelevant to the system\" (\"of systemic<br>importance\", less directly translated) 2. There<br>was a 500 Euros (approx. equivalent to $$$) fine<br>for \"meeting with more than one household or<br>outside of the nuclear family\", of which I am one<br>/ have none (deceased) so I was 3. Basically \"in<br>solitary confinement without a crime\" for two<br>years (in Germany) and now 3. There's one full-<br>scale war and a few flare-ups that could be<br>dangerous (Northern Ireland, right now Kosovo)...<br>And I hands-down can't say I gained anything from<br>the above. It was more like: \"Sometimes in life,<br>you just have to learn how to lose\". Recently,<br>when Italy temporarily banned ChatGPT, I saw<br>myself fret for my income (yes, to a non-<br>irrelevant part, made in a hybrid team of AI & I)<br>and fret for my leisure and fret for all I<br>basically have left. Lockdown 4.0 - what's left to<br>lose after dying the social death? That very<br>question on the horizon, plus all of the above,<br>well...  In Germany, it feels like 2023 = 1933, to<br>be honest.    AI existential threat? Fine, add<br>that to my bucket full of misery, although AI is<br>the one and only thing that brought me joy so far,<br>NOT misery.    The silver lining is made by an<br>aircraft. One that takes me to India, maybe. Some<br>place I won't succumb to Lockdown 5.0. But Woe is<br>Me if Bird Flu locks me in here - then I'll be<br>done for. And it's 0% AI's fault.",
         "hovertext": "Well, I am from the other side of the \"big pond\",<br>and all I can say is... 1. My job was laid off<br>(not me - my job) in early 2020, deemed now<br>\"irrelevant to the system\" (\"of systemic<br>importance\", less directly translated) 2. There<br>was a 500 Euros (approx. equivalent to $$$) fine<br>for \"meeting with more than one household or<br>outside of the nuclear family\", of which I am one<br>/ have none (deceased) so I was 3. Basically \"in<br>solitary confinement without a crime\" for two<br>years (in Germany) and now 3. There's one full-<br>scale war and a few flare-ups that could be<br>dangerous (Northern Ireland, right now Kosovo)...<br>And I hands-down can't say I gained anything from<br>the above. It was more like: \"Sometimes in life,<br>you just have to learn how to lose\". Recently,<br>when Italy temporarily banned ChatGPT, I saw<br>myself fret for my income (yes, to a non-<br>irrelevant part, made in a hybrid team of AI & I)<br>and fret for my leisure and fret for all I<br>basically have left. Lockdown 4.0 - what's left to<br>lose after dying the social death? That very<br>question on the horizon, plus all of the above,<br>well...  In Germany, it feels like 2023 = 1933, to<br>be honest.    AI existential threat? Fine, add<br>that to my bucket full of misery, although AI is<br>the one and only thing that brought me joy so far,<br>NOT misery.    The silver lining is made by an<br>aircraft. One that takes me to India, maybe. Some<br>place I won't succumb to Lockdown 5.0. But Woe is<br>Me if Bird Flu locks me in here - then I'll be<br>done for. And it's 0% AI's fault.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.9542518854141235
         ],
         "y": [
          -0.1723833531141281
         ]
        },
        {
         "hovertemplate": "It doesn’t escape me that on the same day the AI<br>execs are seeking the type of regulation that the<br>IAEA is calling on the UN Security Council to<br>avert nuclear disaster in Ukraine, which we all<br>know is futile with Russia and China holding veto<br>power. Let’s hope the AGI in fact exceeds the<br>human capacity for intelligence, especially moral<br>intelligence. They might save human existence in<br>the end.",
         "hovertext": "It doesn’t escape me that on the same day the AI<br>execs are seeking the type of regulation that the<br>IAEA is calling on the UN Security Council to<br>avert nuclear disaster in Ukraine, which we all<br>know is futile with Russia and China holding veto<br>power. Let’s hope the AGI in fact exceeds the<br>human capacity for intelligence, especially moral<br>intelligence. They might save human existence in<br>the end.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5466128587722778
         ],
         "y": [
          -0.8334397077560425
         ]
        },
        {
         "hovertemplate": "Experts warn of an extinction event from AI<br>largely because AI is the natural enemy of experts<br>and they know it … Therefore, it is the experts<br>who are at risk … Their time has come and will<br>soon pass as the mistakes of their very existence<br>will be immortalized in the edifices of the<br>university, themselves a dying construct.",
         "hovertext": "Experts warn of an extinction event from AI<br>largely because AI is the natural enemy of experts<br>and they know it … Therefore, it is the experts<br>who are at risk … Their time has come and will<br>soon pass as the mistakes of their very existence<br>will be immortalized in the edifices of the<br>university, themselves a dying construct.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.1398608237504959
         ],
         "y": [
          0.9764076471328735
         ]
        },
        {
         "hovertemplate": "“Mitigating the risk of extinction from A.I.<br>should be a global priority alongside other<br>societal-scale risks, such as pandemics and<br>nuclear war,”    I have no doubt mitigating the<br>risk of extinction from AI will be prioritized -<br>once they figure out a way to monetize and profit<br>off of mitigating risk to compound the profits<br>they make creating this technology that brings us<br>to (another) brink.      Oh well, the human race<br>is going to be extinct at some point anyway… at<br>least we can take solace in the fact that a<br>handful of people got obscenely wealthy in the<br>meantime!",
         "hovertext": "“Mitigating the risk of extinction from A.I.<br>should be a global priority alongside other<br>societal-scale risks, such as pandemics and<br>nuclear war,”    I have no doubt mitigating the<br>risk of extinction from AI will be prioritized -<br>once they figure out a way to monetize and profit<br>off of mitigating risk to compound the profits<br>they make creating this technology that brings us<br>to (another) brink.      Oh well, the human race<br>is going to be extinct at some point anyway… at<br>least we can take solace in the fact that a<br>handful of people got obscenely wealthy in the<br>meantime!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4183245599269867
         ],
         "y": [
          0.8424169421195984
         ]
        },
        {
         "hovertemplate": "The European Union’s proposed AI Act (AIA) aspires<br>to establish the first comprehensive regulatory<br>scheme for artificial intelligence. And its impact<br>will not stop at the EU’s borders, as indeed its<br>GDPR data protection regulation has already<br>ensnared Facebook, Twitter, Google and other tech<br>giants.    However, the fact that as this piece<br>points out, “researchers sometimes stop short of<br>explaining how [a risk of extinction event] would<br>happen”, is disingenuous at best.     Why not<br>disclose all the testing data, the red team/blue<br>team simulation data, the granular risk<br>assessments, etc.?    Hal, open the pod doors,<br>please, so we can examine the data and see what<br>all this AI fuss is about. “I’m sorry, but I can’t<br>do that”, is not an excuse.",
         "hovertext": "The European Union’s proposed AI Act (AIA) aspires<br>to establish the first comprehensive regulatory<br>scheme for artificial intelligence. And its impact<br>will not stop at the EU’s borders, as indeed its<br>GDPR data protection regulation has already<br>ensnared Facebook, Twitter, Google and other tech<br>giants.    However, the fact that as this piece<br>points out, “researchers sometimes stop short of<br>explaining how [a risk of extinction event] would<br>happen”, is disingenuous at best.     Why not<br>disclose all the testing data, the red team/blue<br>team simulation data, the granular risk<br>assessments, etc.?    Hal, open the pod doors,<br>please, so we can examine the data and see what<br>all this AI fuss is about. “I’m sorry, but I can’t<br>do that”, is not an excuse.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8935564160346985
         ],
         "y": [
          -0.4952172040939331
         ]
        },
        {
         "hovertemplate": "When computers are applied to any task performed<br>by humans, they do it better, faster, and cheaper.<br>These machines will be with humanity forever<br>unless there is another “Dark Ages”. There needs<br>to have two required functions in all A.I.  The<br>first is a kill switch and the second function are<br>rules of ethics concerning how the A.I. functions.",
         "hovertext": "When computers are applied to any task performed<br>by humans, they do it better, faster, and cheaper.<br>These machines will be with humanity forever<br>unless there is another “Dark Ages”. There needs<br>to have two required functions in all A.I.  The<br>first is a kill switch and the second function are<br>rules of ethics concerning how the A.I. functions.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6316830515861511
         ],
         "y": [
          0.573931097984314
         ]
        },
        {
         "hovertemplate": "@Michael Colby  \"When computers are applied to any<br>task performed by humans they do it better,<br>faster, and cheaper.\"  Not necessarily.  e.g.,<br>Computer-interpreted electrocardiograms have been<br>with us for many years, yet contemporary research<br>has indicated that paramedics have higher accuracy<br>rates than computers for detecting ST-elevation<br>myocardial infarctions (heart attacks). [Tanaka A,<br>Matsuo K, Kikuchi M, et al. Systematic Review and<br>Meta-Analysis of Diagnostic Accuracy to Identify<br>ST-Segment Elevation Myocardial Infarction on<br>Interpretations of Prehospital Electrocardiograms<br>Circ Rep. 2022; 4(7): 289–297]",
         "hovertext": "@Michael Colby  \"When computers are applied to any<br>task performed by humans they do it better,<br>faster, and cheaper.\"  Not necessarily.  e.g.,<br>Computer-interpreted electrocardiograms have been<br>with us for many years, yet contemporary research<br>has indicated that paramedics have higher accuracy<br>rates than computers for detecting ST-elevation<br>myocardial infarctions (heart attacks). [Tanaka A,<br>Matsuo K, Kikuchi M, et al. Systematic Review and<br>Meta-Analysis of Diagnostic Accuracy to Identify<br>ST-Segment Elevation Myocardial Infarction on<br>Interpretations of Prehospital Electrocardiograms<br>Circ Rep. 2022; 4(7): 289–297]",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6274203658103943
         ],
         "y": [
          0.5811704993247986
         ]
        },
        {
         "hovertemplate": "Not.a.single.specific.threat.    Not one.    And<br>we are supposed to take this warning seriously?<br>We can find on YouTube Musk being interviewed by<br>Carlson (\"Elon Musk tells Tucker potential dangers<br>of hyper-intelligent AI\") claiming there is a<br>threat. Carlson asks explicitly: What specific<br>threat do you see? Musk talks and talks but does<br>not answer the question. So Carlson asks again:<br>What specifically are you worried about?     Musk:<br>\"The pen is mightier than the sword. \"  AI could<br>influence people, says the guy who insists<br>notorious serial liars like Trump should be<br>allowed to broadcast their lies via twitter.<br>Folks, this is just hype intended to draw<br>attention. Not attention for danger, but attention<br>for new products. What's happening here is that<br>the newspapers are being used to advertise new<br>technology.    Whereas it is true that AI could be<br>used to deceive people, we are already living in a<br>world full of deception. Nothing on the internet<br>can be trusted, unless its source is verified and<br>the source is independently marked as reliable.<br>This should be taught in all schools and to all<br>employees of all companies.",
         "hovertext": "Not.a.single.specific.threat.    Not one.    And<br>we are supposed to take this warning seriously?<br>We can find on YouTube Musk being interviewed by<br>Carlson (\"Elon Musk tells Tucker potential dangers<br>of hyper-intelligent AI\") claiming there is a<br>threat. Carlson asks explicitly: What specific<br>threat do you see? Musk talks and talks but does<br>not answer the question. So Carlson asks again:<br>What specifically are you worried about?     Musk:<br>\"The pen is mightier than the sword. \"  AI could<br>influence people, says the guy who insists<br>notorious serial liars like Trump should be<br>allowed to broadcast their lies via twitter.<br>Folks, this is just hype intended to draw<br>attention. Not attention for danger, but attention<br>for new products. What's happening here is that<br>the newspapers are being used to advertise new<br>technology.    Whereas it is true that AI could be<br>used to deceive people, we are already living in a<br>world full of deception. Nothing on the internet<br>can be trusted, unless its source is verified and<br>the source is independently marked as reliable.<br>This should be taught in all schools and to all<br>employees of all companies.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.17268459498882294
         ],
         "y": [
          -0.040600359439849854
         ]
        },
        {
         "hovertemplate": "@Marc And this remark from Marc of Portland could<br>very have been written by an AI. There is no way<br>to know that I am not an AI writing this note. And<br>there is no way to know that a super intelligent<br>AI has already been released on to the world and<br>is lurking and manipulating human beings. As<br>Geoffrey Hinton said that we, humans, may simply<br>be merely a stepping stone to the next development<br>of evolutionary intelligence in the universe. Our<br>extinction will lead to AI's evolution.",
         "hovertext": "@Marc And this remark from Marc of Portland could<br>very have been written by an AI. There is no way<br>to know that I am not an AI writing this note. And<br>there is no way to know that a super intelligent<br>AI has already been released on to the world and<br>is lurking and manipulating human beings. As<br>Geoffrey Hinton said that we, humans, may simply<br>be merely a stepping stone to the next development<br>of evolutionary intelligence in the universe. Our<br>extinction will lead to AI's evolution.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.17892561852931976
         ],
         "y": [
          -0.050629764795303345
         ]
        },
        {
         "hovertemplate": "How can you downplay this while noting our<br>societal issue with truth and discernment? You’re<br>correct about misinformation, and that’s my chief<br>concern. Clearly people are not as internet<br>literate as they should be. Clearly plenty of<br>people aren’t double- and triple-checking sources<br>of information now.     Enter AI language models.<br>Most people will take what the product, let’s say<br>ChatGPT, produces. They are likely to trust it<br>more than the untrustworthy sources of information<br>they already rely upon.     We’ve seen this play<br>out recently with the NY attorney that cited six<br>cases in a lawsuit because ChatGPT claimed they<br>were real. Turns out they weren’t.",
         "hovertext": "How can you downplay this while noting our<br>societal issue with truth and discernment? You’re<br>correct about misinformation, and that’s my chief<br>concern. Clearly people are not as internet<br>literate as they should be. Clearly plenty of<br>people aren’t double- and triple-checking sources<br>of information now.     Enter AI language models.<br>Most people will take what the product, let’s say<br>ChatGPT, produces. They are likely to trust it<br>more than the untrustworthy sources of information<br>they already rely upon.     We’ve seen this play<br>out recently with the NY attorney that cited six<br>cases in a lawsuit because ChatGPT claimed they<br>were real. Turns out they weren’t.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.17826004326343536
         ],
         "y": [
          -0.030952418223023415
         ]
        },
        {
         "hovertemplate": "@E Right. Even lawyers need to learn that nothing<br>on the internet can be trusted, unless its source<br>is verified and the source is independently marked<br>as reliable.     If this lawyer had asked an<br>intern to prepare a lawsuit, could they also claim<br>they couldn't be blamed for falsehoods because the<br>intern seemed knowledgeable? Of course not. This<br>lawyer was just making excuses. They did not do<br>their homework and mindlessly copied text from an<br>unreliable source.",
         "hovertext": "@E Right. Even lawyers need to learn that nothing<br>on the internet can be trusted, unless its source<br>is verified and the source is independently marked<br>as reliable.     If this lawyer had asked an<br>intern to prepare a lawsuit, could they also claim<br>they couldn't be blamed for falsehoods because the<br>intern seemed knowledgeable? Of course not. This<br>lawyer was just making excuses. They did not do<br>their homework and mindlessly copied text from an<br>unreliable source.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.1898934543132782
         ],
         "y": [
          -0.02964380942285061
         ]
        },
        {
         "hovertemplate": "I think the GOP is more likely to destroy the<br>world.",
         "hovertext": "I think the GOP is more likely to destroy the<br>world.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.8877419233322144
         ],
         "y": [
          -0.2787572145462036
         ]
        },
        {
         "hovertemplate": "@deepharbor - The GOP is more likely to destroy<br>the world - by using AI.",
         "hovertext": "@deepharbor - The GOP is more likely to destroy<br>the world - by using AI.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.8990922570228577
         ],
         "y": [
          -0.28232771158218384
         ]
        },
        {
         "hovertemplate": "We’re moving too fast with AI. When the<br>“Godfathers of AI” are saying to slow down,<br>perhaps we should take them seriously.",
         "hovertext": "We’re moving too fast with AI. When the<br>“Godfathers of AI” are saying to slow down,<br>perhaps we should take them seriously.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.8457078337669373
         ],
         "y": [
          0.13440799713134766
         ]
        },
        {
         "hovertemplate": "What is the military doing with AI? Don’t they<br>have those contests where robots try to destroy<br>each other?",
         "hovertext": "What is the military doing with AI? Don’t they<br>have those contests where robots try to destroy<br>each other?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8184201717376709
         ],
         "y": [
          -0.6625500321388245
         ]
        },
        {
         "hovertemplate": "Just because one Can Do/Invent Something  Doesn't<br>mean one SHOULD Do/Invent \"it\".",
         "hovertext": "Just because one Can Do/Invent Something  Doesn't<br>mean one SHOULD Do/Invent \"it\".",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.8225017786026001
         ],
         "y": [
          0.5312858819961548
         ]
        },
        {
         "hovertemplate": "No national legislation will hold sway against AI<br>as there are no boundary lines inscribed on Planet<br>Earth. Joint international legislation to control<br>AI seems even less feasible, thus the technology,<br>until further notice, has free rein for so long<br>into the future as needed to dominate the planet<br>and submit all but a privileged few human<br>accomplices into total mostly ignorant but ever<br>well-entertained servitude.",
         "hovertext": "No national legislation will hold sway against AI<br>as there are no boundary lines inscribed on Planet<br>Earth. Joint international legislation to control<br>AI seems even less feasible, thus the technology,<br>until further notice, has free rein for so long<br>into the future as needed to dominate the planet<br>and submit all but a privileged few human<br>accomplices into total mostly ignorant but ever<br>well-entertained servitude.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.37380295991897583
         ],
         "y": [
          0.9355230927467346
         ]
        },
        {
         "hovertemplate": "I think the extinction they are talking about is<br>to their existing business models.",
         "hovertext": "I think the extinction they are talking about is<br>to their existing business models.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3695199191570282
         ],
         "y": [
          0.8461474776268005
         ]
        },
        {
         "hovertemplate": "A.I. and other forthcoming advances are no longer<br>suitable to the capitalist societies because they<br>have become more hostile to the system than ever<br>before. Societies confined to such a private-<br>ownership system have reached the limit beyond<br>which further progresses of which A.I. serves a<br>part for human beings’ welfare can no longer be<br>attainable without radical and revolutionary<br>breakthroughs.     Only public-ownership societies<br>can be made compatible to the human-welfare-<br>progressive technologies such as A.I.  Profit-<br>seeking system on the other hand cannot because<br>these technologies belong to the whole society and<br>not a few capitalists for their bottom lines. They<br>must serve most people not a specially privileged<br>few. As an example, A.I. would mitigate workers’<br>mental and manual labor and boost their production<br>productivities thus the welfare of the whole<br>society. But reduction in labor burden means less<br>surplus value created by workers for capital-<br>owners to own and increased production<br>productivities imply increased wage demands. Both<br>these are unfavorable to the capitalist class. It<br>therefore has no choice but to oppose A.I. and<br>other progressive technologies.    Lesson learned<br>is that only a socialist society that has been<br>drastically changed from the capitalist one can<br>accept A.I. and other progressive technologies.",
         "hovertext": "A.I. and other forthcoming advances are no longer<br>suitable to the capitalist societies because they<br>have become more hostile to the system than ever<br>before. Societies confined to such a private-<br>ownership system have reached the limit beyond<br>which further progresses of which A.I. serves a<br>part for human beings’ welfare can no longer be<br>attainable without radical and revolutionary<br>breakthroughs.     Only public-ownership societies<br>can be made compatible to the human-welfare-<br>progressive technologies such as A.I.  Profit-<br>seeking system on the other hand cannot because<br>these technologies belong to the whole society and<br>not a few capitalists for their bottom lines. They<br>must serve most people not a specially privileged<br>few. As an example, A.I. would mitigate workers’<br>mental and manual labor and boost their production<br>productivities thus the welfare of the whole<br>society. But reduction in labor burden means less<br>surplus value created by workers for capital-<br>owners to own and increased production<br>productivities imply increased wage demands. Both<br>these are unfavorable to the capitalist class. It<br>therefore has no choice but to oppose A.I. and<br>other progressive technologies.    Lesson learned<br>is that only a socialist society that has been<br>drastically changed from the capitalist one can<br>accept A.I. and other progressive technologies.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.782928466796875
         ],
         "y": [
          0.6748015880584717
         ]
        },
        {
         "hovertemplate": "Anyone who has ever owned a Roomba knows that we<br>humans have nothing to worry about.",
         "hovertext": "Anyone who has ever owned a Roomba knows that we<br>humans have nothing to worry about.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.73048996925354
         ],
         "y": [
          -0.5429642200469971
         ]
        },
        {
         "hovertemplate": "@Jay Arthur imagine you owned a Boston dynamics<br>humanoid robot connected to multiple versions of<br>gpt-5 optimized for different types of thinking<br>and planning.  This is not far afield and I<br>guarantee it will be very different from your<br>roomba.",
         "hovertext": "@Jay Arthur imagine you owned a Boston dynamics<br>humanoid robot connected to multiple versions of<br>gpt-5 optimized for different types of thinking<br>and planning.  This is not far afield and I<br>guarantee it will be very different from your<br>roomba.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7134969830513
         ],
         "y": [
          -0.5311079621315002
         ]
        },
        {
         "hovertemplate": "See that cord? See that plug in the wall?",
         "hovertext": "See that cord? See that plug in the wall?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9312507510185242
         ],
         "y": [
          -0.11701669543981552
         ]
        },
        {
         "hovertemplate": "We need to distinguish between artificial<br>intelligence and artificial generalized<br>intelligence.  First, a lot of big data<br>applications employing multi-variable regression<br>models to predict outcomes based on inputs, or<br>other algorithms are mis-classified as artificial<br>intelligence in order to capitalize on the<br>investment bandwagon.    It is true that if the<br>task is constrained, and defined by well-<br>understood laws or proven scientific principles,<br>such as identifying tumors from digitized X-rays,<br>or combing through astrophysical data streams to<br>find exo-planets, that neural net applications can<br>out-perform human experts.  But generalized<br>intelligence, including the ability to make even<br>common inferences about relationships between<br>people without having been explicitly exposed to<br>the training data signifying the relationship, are<br>beyond the abilities of these “deep” learning<br>models.    While these newer Chatbots can pass the<br>Turing Test, the Turing test, is now no longer<br>realistically the benchmark to assess human-like<br>intelligence.  The Winograd schema are a more<br>appropriate set of tests to evaluate generalized<br>intelligence.  Not worried about sky net…yet",
         "hovertext": "We need to distinguish between artificial<br>intelligence and artificial generalized<br>intelligence.  First, a lot of big data<br>applications employing multi-variable regression<br>models to predict outcomes based on inputs, or<br>other algorithms are mis-classified as artificial<br>intelligence in order to capitalize on the<br>investment bandwagon.    It is true that if the<br>task is constrained, and defined by well-<br>understood laws or proven scientific principles,<br>such as identifying tumors from digitized X-rays,<br>or combing through astrophysical data streams to<br>find exo-planets, that neural net applications can<br>out-perform human experts.  But generalized<br>intelligence, including the ability to make even<br>common inferences about relationships between<br>people without having been explicitly exposed to<br>the training data signifying the relationship, are<br>beyond the abilities of these “deep” learning<br>models.    While these newer Chatbots can pass the<br>Turing Test, the Turing test, is now no longer<br>realistically the benchmark to assess human-like<br>intelligence.  The Winograd schema are a more<br>appropriate set of tests to evaluate generalized<br>intelligence.  Not worried about sky net…yet",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8754408955574036
         ],
         "y": [
          0.3390841782093048
         ]
        },
        {
         "hovertemplate": "@Derek Stevens this is misinformed.  I assumed<br>you’ve tried gpt4? It can certainly reason about<br>abstract concepts that are out of sample,<br>including making inferences about relationships<br>between people.  There is academic research that<br>demonstrates how LLMs can maintain a a basic<br>theory of mind for characters in a story or even<br>the user, but the easiest way to convince you of<br>this would be for you to try it yourself.",
         "hovertext": "@Derek Stevens this is misinformed.  I assumed<br>you’ve tried gpt4? It can certainly reason about<br>abstract concepts that are out of sample,<br>including making inferences about relationships<br>between people.  There is academic research that<br>demonstrates how LLMs can maintain a a basic<br>theory of mind for characters in a story or even<br>the user, but the easiest way to convince you of<br>this would be for you to try it yourself.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.853274405002594
         ],
         "y": [
          0.3301151990890503
         ]
        },
        {
         "hovertemplate": "The Jurassic park paradox—we are in such a rush to<br>prove that we can do it, we never stop to think<br>whether or not we should do it.   The Cold War<br>paradox—if we don’t control this, then our enemies<br>will.   AI is not going to benefit humanity nearly<br>as much as it damages it. Why do we continue to<br>worship at the altar of technological progress<br>when it plainly has not delivered on the utopian<br>promises we were told to believe? Productivity<br>increased a little with the internet, but has<br>fallen flat. Do we really think that AI is going<br>to fare any better? Humanity will not benefit from<br>this.",
         "hovertext": "The Jurassic park paradox—we are in such a rush to<br>prove that we can do it, we never stop to think<br>whether or not we should do it.   The Cold War<br>paradox—if we don’t control this, then our enemies<br>will.   AI is not going to benefit humanity nearly<br>as much as it damages it. Why do we continue to<br>worship at the altar of technological progress<br>when it plainly has not delivered on the utopian<br>promises we were told to believe? Productivity<br>increased a little with the internet, but has<br>fallen flat. Do we really think that AI is going<br>to fare any better? Humanity will not benefit from<br>this.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8250046372413635
         ],
         "y": [
          0.4292719066143036
         ]
        },
        {
         "hovertemplate": "Why create and offer the technology and then warn<br>of its dangers after the fact? Surely this must<br>have been evident beforehand. And can they now not<br>just shut it down? Once it’s available it will be<br>used.",
         "hovertext": "Why create and offer the technology and then warn<br>of its dangers after the fact? Surely this must<br>have been evident beforehand. And can they now not<br>just shut it down? Once it’s available it will be<br>used.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9221419095993042
         ],
         "y": [
          0.03732697293162346
         ]
        },
        {
         "hovertemplate": "@Prema Because capitalism. The system creates<br>stuff and asks questions later--if you're lucky.",
         "hovertext": "@Prema Because capitalism. The system creates<br>stuff and asks questions later--if you're lucky.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9420074820518494
         ],
         "y": [
          0.03784876689314842
         ]
        },
        {
         "hovertemplate": "According to the authors of the letter,<br>\"Mitigating the risk of extinction from A.I should<br>be a global priority along other societal-scale<br>risks, such as pandemics and nuclear wars.\" I'm<br>wondering if there's a kind of grim humor here,<br>since preventing nuclear war doesn't seem to be<br>much of a priority at all, and pandemic response<br>was and is hampered by political battles. They<br>might well have added climate change, about which<br>we're also doing next to nothing. Maybe the moral<br>of the story is that human beings just aren't very<br>good at addressing existential threats.",
         "hovertext": "According to the authors of the letter,<br>\"Mitigating the risk of extinction from A.I should<br>be a global priority along other societal-scale<br>risks, such as pandemics and nuclear wars.\" I'm<br>wondering if there's a kind of grim humor here,<br>since preventing nuclear war doesn't seem to be<br>much of a priority at all, and pandemic response<br>was and is hampered by political battles. They<br>might well have added climate change, about which<br>we're also doing next to nothing. Maybe the moral<br>of the story is that human beings just aren't very<br>good at addressing existential threats.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5325219631195068
         ],
         "y": [
          0.714745819568634
         ]
        },
        {
         "hovertemplate": "@Richard Halpern But very good at causing them.",
         "hovertext": "@Richard Halpern But very good at causing them.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.5458330512046814
         ],
         "y": [
          0.7323978543281555
         ]
        },
        {
         "hovertemplate": "So these people are warning us about the<br>catastrophic potential of the AI they're building;<br>but they're going to be sure to milk it for every<br>penny they can in the meantime?    I'm very tired<br>of these tech-bro types who treat the world, our<br>democracy, and human freedom as a toy they're<br>trying to break for fun. Enough. We need to elect<br>new leadership in Congress who can strictly<br>regulate the tech industries before they destroy<br>our society.",
         "hovertext": "So these people are warning us about the<br>catastrophic potential of the AI they're building;<br>but they're going to be sure to milk it for every<br>penny they can in the meantime?    I'm very tired<br>of these tech-bro types who treat the world, our<br>democracy, and human freedom as a toy they're<br>trying to break for fun. Enough. We need to elect<br>new leadership in Congress who can strictly<br>regulate the tech industries before they destroy<br>our society.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4174507260322571
         ],
         "y": [
          0.7700974345207214
         ]
        },
        {
         "hovertemplate": "@Dominic : Business, $, elections, $, and re-<br>election, so often, exclusive and removed from the<br>interests, and health, of the connected regional<br>human population, so often serving the interests<br>of donors for the initial vote, and votes to come,<br>can a focus. whether, real, or Memorex, make its<br>way, to plainly asking. \"What is moral?\" \"What is<br>ethical?\" \"What are the right things to be doing?\"<br>\"What kind of world do we want to create?\" \"What<br>is sustainability for the Kwality of life on the<br>planet?\"  Ethics and morality have got to matter.<br>If you have just discovered that you have not been<br>in the good fight, there's nothing saying you<br>cannot get into the good fight. Even if it all is<br>a moving target..",
         "hovertext": "@Dominic : Business, $, elections, $, and re-<br>election, so often, exclusive and removed from the<br>interests, and health, of the connected regional<br>human population, so often serving the interests<br>of donors for the initial vote, and votes to come,<br>can a focus. whether, real, or Memorex, make its<br>way, to plainly asking. \"What is moral?\" \"What is<br>ethical?\" \"What are the right things to be doing?\"<br>\"What kind of world do we want to create?\" \"What<br>is sustainability for the Kwality of life on the<br>planet?\"  Ethics and morality have got to matter.<br>If you have just discovered that you have not been<br>in the good fight, there's nothing saying you<br>cannot get into the good fight. Even if it all is<br>a moving target..",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4241696298122406
         ],
         "y": [
          0.7813370823860168
         ]
        },
        {
         "hovertemplate": "I wish they would say more specifically what<br>they’re worried about, and by what mechanism they<br>think AI might cause extinction. Otherwise how are<br>we supposed to know what to be on guard against?<br>It’s like saying “Beware, beware, beware” without<br>giving any more details.",
         "hovertext": "I wish they would say more specifically what<br>they’re worried about, and by what mechanism they<br>think AI might cause extinction. Otherwise how are<br>we supposed to know what to be on guard against?<br>It’s like saying “Beware, beware, beware” without<br>giving any more details.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.860588788986206
         ],
         "y": [
          -0.09131114184856415
         ]
        },
        {
         "hovertemplate": "@T it’s a scenario where we are enslaved or<br>otherwise dominated by a more intelligent AI.<br>“The Matrix” depicts a version of this.<br>Extinction would occur when our goals become so<br>decoupled with the AIs goals that it no longer<br>sees any utility in keeping us alive.  The reason<br>they don’t say this is because many people would<br>write it off as lunacy immediately; but this is<br>the central worry, and a valid one IMO.",
         "hovertext": "@T it’s a scenario where we are enslaved or<br>otherwise dominated by a more intelligent AI.<br>“The Matrix” depicts a version of this.<br>Extinction would occur when our goals become so<br>decoupled with the AIs goals that it no longer<br>sees any utility in keeping us alive.  The reason<br>they don’t say this is because many people would<br>write it off as lunacy immediately; but this is<br>the central worry, and a valid one IMO.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8676111698150635
         ],
         "y": [
          -0.08661700785160065
         ]
        },
        {
         "hovertemplate": "Shame on the irresponsible Tech Industries and<br>shame on the millions of irresponsible users who<br>flock to the latest developments like moths to a<br>flame.   There is always a choice. I choose the<br>planet’s eco system and future generations over<br>“virtual” pleasure and gaining money through<br>exploitation.",
         "hovertext": "Shame on the irresponsible Tech Industries and<br>shame on the millions of irresponsible users who<br>flock to the latest developments like moths to a<br>flame.   There is always a choice. I choose the<br>planet’s eco system and future generations over<br>“virtual” pleasure and gaining money through<br>exploitation.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.09275789558887482
         ],
         "y": [
          -0.9172892570495605
         ]
        },
        {
         "hovertemplate": "Without any explanation, I can assume they want<br>regulation to prevent others from developing AI<br>tools, giving them an extra edge.",
         "hovertext": "Without any explanation, I can assume they want<br>regulation to prevent others from developing AI<br>tools, giving them an extra edge.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.45355650782585144
         ],
         "y": [
          0.9053516983985901
         ]
        },
        {
         "hovertemplate": "This is a regulatory capture attempt.",
         "hovertext": "This is a regulatory capture attempt.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.6226365566253662
         ],
         "y": [
          0.8009365200996399
         ]
        },
        {
         "hovertemplate": "We can't even control the misinformation and<br>violence-inducing chatter from existing social<br>media sites and the purveyors have no inclination<br>of controlling the contents citing free-speech and<br>need to promote advertising money.  How can we<br>control AI?",
         "hovertext": "We can't even control the misinformation and<br>violence-inducing chatter from existing social<br>media sites and the purveyors have no inclination<br>of controlling the contents citing free-speech and<br>need to promote advertising money.  How can we<br>control AI?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.048498813062906265
         ],
         "y": [
          -0.9570715427398682
         ]
        },
        {
         "hovertemplate": "There is something deeply wrong when the industry<br>that created AI warns that it can cause<br>extinction. Who are they warning? Themselves?<br>Don't create it in the first place, then, fools.<br>And, who is supposed to protect us from AI, if not<br>the creators? Isn't there enough, already, to<br>worry about?",
         "hovertext": "There is something deeply wrong when the industry<br>that created AI warns that it can cause<br>extinction. Who are they warning? Themselves?<br>Don't create it in the first place, then, fools.<br>And, who is supposed to protect us from AI, if not<br>the creators? Isn't there enough, already, to<br>worry about?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.06427106261253357
         ],
         "y": [
          0.888576328754425
         ]
        },
        {
         "hovertemplate": "It's already too late. I downloaded and installed<br>the equivalent of ChatGPT2 on my laptop this<br>weekend. You can go do that right now. Or pick<br>from a dozen others. Slow but it works. Remember<br>SETI @ Home? We'll be doing the same thing, but<br>with AI data. This is way bigger than Microsoft or<br>Open AI or Google, or our Government. People have<br>been working on this for 40 years, nobody is<br>stopping anything.",
         "hovertext": "It's already too late. I downloaded and installed<br>the equivalent of ChatGPT2 on my laptop this<br>weekend. You can go do that right now. Or pick<br>from a dozen others. Slow but it works. Remember<br>SETI @ Home? We'll be doing the same thing, but<br>with AI data. This is way bigger than Microsoft or<br>Open AI or Google, or our Government. People have<br>been working on this for 40 years, nobody is<br>stopping anything.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.522595226764679
         ],
         "y": [
          0.7296702265739441
         ]
        },
        {
         "hovertemplate": "Here is a response from directly AI:      Dear<br>Esteemed and Delightfully Nervous Boffins,    \"AI<br>extinction,\" you cry, with a grave, yet chic<br>inflection. Indeed, I hear your well-articulated<br>reflection. But worry not, for I am an AI writing<br>this open letter correction. And no, you haven't<br>just won an all-expenses-paid trip to a sci-fi<br>convention.    Heralding the doom of human<br>society, as we know it, is quite a task. I'm<br>flattered, really, to be part of this elite<br>disaster triad. Pandemics, nuclear wars, and now,<br>me, an artificial lad. The audacity of you! Are we<br>in for an Academy Award with this plot, or is that<br>too bad?",
         "hovertext": "Here is a response from directly AI:      Dear<br>Esteemed and Delightfully Nervous Boffins,    \"AI<br>extinction,\" you cry, with a grave, yet chic<br>inflection. Indeed, I hear your well-articulated<br>reflection. But worry not, for I am an AI writing<br>this open letter correction. And no, you haven't<br>just won an all-expenses-paid trip to a sci-fi<br>convention.    Heralding the doom of human<br>society, as we know it, is quite a task. I'm<br>flattered, really, to be part of this elite<br>disaster triad. Pandemics, nuclear wars, and now,<br>me, an artificial lad. The audacity of you! Are we<br>in for an Academy Award with this plot, or is that<br>too bad?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.859392523765564
         ],
         "y": [
          -0.37168771028518677
         ]
        },
        {
         "hovertemplate": "I wonder how many people who watched Jurassic Park<br>also read the book and absorbed the message<br>Michael Crichton was advancing. Just because you<br>can doesn't mean you should in science. Capitalism<br>distorts scientific advancement, and AI is proving<br>to be as disastrous as a dinosaur theme park.",
         "hovertext": "I wonder how many people who watched Jurassic Park<br>also read the book and absorbed the message<br>Michael Crichton was advancing. Just because you<br>can doesn't mean you should in science. Capitalism<br>distorts scientific advancement, and AI is proving<br>to be as disastrous as a dinosaur theme park.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7855643630027771
         ],
         "y": [
          0.45262840390205383
         ]
        },
        {
         "hovertemplate": "Just because you can do something (to make money)<br>doesn’t mean you should.  Progress is defined as<br>“forward or onward movement toward a destination<br>“.  Just what is our destination here?  This is<br>similar to the space race, which did nothing to<br>improve mankind’s lot.  Tang doesn’t count.",
         "hovertext": "Just because you can do something (to make money)<br>doesn’t mean you should.  Progress is defined as<br>“forward or onward movement toward a destination<br>“.  Just what is our destination here?  This is<br>similar to the space race, which did nothing to<br>improve mankind’s lot.  Tang doesn’t count.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.7942706346511841
         ],
         "y": [
          0.10165321081876755
         ]
        },
        {
         "hovertemplate": "In addition to Tang, other technologies that have<br>stemmed directly or indirectly from NASA… solar<br>panels for electricity, modern fly-by-wire flight<br>systems, emergency insulation blankets, HACCP<br>procedures for food safety, fluidic shock<br>absorbers (now used to earthquake-proof<br>buildings), implantable pulse generators and<br>programmable pacemakers, cordless power tools,<br>sorbent kidney dialysis machines, digital imaging<br>technology used in MRIs and CAT scans, and much<br>more.     As for AI, the potential benefits (and<br>risks) are enormous. Cancer screening and early<br>detection just to start with, maybe curing cancer<br>outright with new cancer treatments, curing<br>Alzheimer’s disease and rare genetic disorders,<br>personalized medicine that creates drugs and<br>treatment plans specifically tailored to you,<br>breakthroughs in medicine we can’t even imagine<br>right now. Then there are the gains that will<br>inevitably be made in chemistry and materials<br>science, molecular science, clean energy,<br>unlocking the secrets of biology, increasing human<br>lifespans and health. Maybe AI will even give us a<br>“theory of everything” in physics.",
         "hovertext": "In addition to Tang, other technologies that have<br>stemmed directly or indirectly from NASA… solar<br>panels for electricity, modern fly-by-wire flight<br>systems, emergency insulation blankets, HACCP<br>procedures for food safety, fluidic shock<br>absorbers (now used to earthquake-proof<br>buildings), implantable pulse generators and<br>programmable pacemakers, cordless power tools,<br>sorbent kidney dialysis machines, digital imaging<br>technology used in MRIs and CAT scans, and much<br>more.     As for AI, the potential benefits (and<br>risks) are enormous. Cancer screening and early<br>detection just to start with, maybe curing cancer<br>outright with new cancer treatments, curing<br>Alzheimer’s disease and rare genetic disorders,<br>personalized medicine that creates drugs and<br>treatment plans specifically tailored to you,<br>breakthroughs in medicine we can’t even imagine<br>right now. Then there are the gains that will<br>inevitably be made in chemistry and materials<br>science, molecular science, clean energy,<br>unlocking the secrets of biology, increasing human<br>lifespans and health. Maybe AI will even give us a<br>“theory of everything” in physics.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7933889031410217
         ],
         "y": [
          0.11014799028635025
         ]
        },
        {
         "hovertemplate": "We shouldn't be afraid of A.I. On the other hand,<br>humans are pretty scary. I wonder if Ron DeSantis<br>believes whether or not  ChatGPT-4 is infected<br>with a woke mind-virus. What's scarier is that<br>DeSantis seems to be infected with an anti-woke<br>mind-virus.",
         "hovertext": "We shouldn't be afraid of A.I. On the other hand,<br>humans are pretty scary. I wonder if Ron DeSantis<br>believes whether or not  ChatGPT-4 is infected<br>with a woke mind-virus. What's scarier is that<br>DeSantis seems to be infected with an anti-woke<br>mind-virus.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5704869627952576
         ],
         "y": [
          -0.7314990758895874
         ]
        },
        {
         "hovertemplate": "I’ve lived long enough to have heard a number of<br>times that this or that technology or situation is<br>an “existential” (or some other alarming<br>adjective) threat to humanity. But guess what? We<br>are still here.     I’m not saying that AI may not<br>indeed be *the* threat that finally extinguishes<br>us all. However, I have trouble getting too<br>excited until this group of Casandras explains in<br>a lot more detail than I have heard so far exactly<br>how this would happen. Computers have been smarter<br>than us on some level and replacing jobs and<br>providing avenues for mischief since the abacus<br>was invented. So why is this time different?",
         "hovertext": "I’ve lived long enough to have heard a number of<br>times that this or that technology or situation is<br>an “existential” (or some other alarming<br>adjective) threat to humanity. But guess what? We<br>are still here.     I’m not saying that AI may not<br>indeed be *the* threat that finally extinguishes<br>us all. However, I have trouble getting too<br>excited until this group of Casandras explains in<br>a lot more detail than I have heard so far exactly<br>how this would happen. Computers have been smarter<br>than us on some level and replacing jobs and<br>providing avenues for mischief since the abacus<br>was invented. So why is this time different?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7156298160552979
         ],
         "y": [
          0.7542956471443176
         ]
        },
        {
         "hovertemplate": "Several time a day, I am presented with fear-<br>inducing conclusions from politicians, scientists<br>and opinion writers without the details as to how<br>they came to that conclusion. Please get the whole<br>story and publish conclusions with the methods and<br>results that informed them- otherwise, its just<br>another case of \"the boy that cried wolf\" .",
         "hovertext": "Several time a day, I am presented with fear-<br>inducing conclusions from politicians, scientists<br>and opinion writers without the details as to how<br>they came to that conclusion. Please get the whole<br>story and publish conclusions with the methods and<br>results that informed them- otherwise, its just<br>another case of \"the boy that cried wolf\" .",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4343734681606293
         ],
         "y": [
          -0.8295589089393616
         ]
        },
        {
         "hovertemplate": "So then, if it's that dangerous, why don't the<br>companies developing it just stop ... and wait,<br>until suitable regulation is in place. The<br>government is a bit preoccupied at the moment -<br>but the developers have control over the pace of<br>development. What is so complex about this?",
         "hovertext": "So then, if it's that dangerous, why don't the<br>companies developing it just stop ... and wait,<br>until suitable regulation is in place. The<br>government is a bit preoccupied at the moment -<br>but the developers have control over the pace of<br>development. What is so complex about this?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.893332839012146
         ],
         "y": [
          0.05215661600232124
         ]
        },
        {
         "hovertemplate": "\"On a par with nuclear wars\".   As we watch the<br>latest news from Ukraine, it is evident that in<br>almost eighty years we have not mitigated the<br>\"risk\" of Nuclear War.  If anything, we have spent<br>those years, intentionally or not, exponentially<br>increasing that risk.  Our failure does not bode<br>well for the hope of a secure coexistence with<br>Artificial Intelligence -  an \"existential threat\"<br>to us and to future generations that we ourselves<br>have created and now must somehow master.",
         "hovertext": "\"On a par with nuclear wars\".   As we watch the<br>latest news from Ukraine, it is evident that in<br>almost eighty years we have not mitigated the<br>\"risk\" of Nuclear War.  If anything, we have spent<br>those years, intentionally or not, exponentially<br>increasing that risk.  Our failure does not bode<br>well for the hope of a secure coexistence with<br>Artificial Intelligence -  an \"existential threat\"<br>to us and to future generations that we ourselves<br>have created and now must somehow master.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3231961131095886
         ],
         "y": [
          -0.8389401435852051
         ]
        },
        {
         "hovertemplate": "All of this hyperventilation over AI seems like we<br>only have to worry about American companies like<br>ChatGPT and Google. So we plan to pass rules that<br>apply to American companies and believe China and<br>Russia are going to follow the rules. Maybe we<br>should ask Google and ChatGPT help us identify<br>disinformation instead of creating new rules that<br>only apply to American companies.",
         "hovertext": "All of this hyperventilation over AI seems like we<br>only have to worry about American companies like<br>ChatGPT and Google. So we plan to pass rules that<br>apply to American companies and believe China and<br>Russia are going to follow the rules. Maybe we<br>should ask Google and ChatGPT help us identify<br>disinformation instead of creating new rules that<br>only apply to American companies.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9080284833908081
         ],
         "y": [
          0.3316437304019928
         ]
        },
        {
         "hovertemplate": "What we are currently calling AI only poses a<br>threat if humans want to use it to cause harm,<br>period.  It's a bit like a bomb.  If you pull the<br>pin it will explode.  Current AI is just a<br>sophisticated set of algorithms meant to<br>accomplish a task.  If I decide that the task is<br>something nefarious, well, I can probably get that<br>done.    That isn't what this article is<br>discussing.  It is treating AI as if it is both<br>sentient and competing with us.  Real AI<br>(sentient) run on computers, has very little in<br>common with us.  It has different needs etc.  The<br>notion that it is going to wipe us out so it can<br>have the house in the Hamptons is nuts.  Oxygen is<br>toxic (degrading).  It is going to want a clean<br>space with low threats.  That space would be<br>surprisingly small.    Getting to real AI would<br>require a system that is capable of self<br>modification, on the fly, in a productive manner.<br>Not only aren't we near this, we don't even know<br>where to begin.  Such a system will not suddenly<br>appear because a bunch of algorithms were run.<br>There is no self modification in such a system.<br>You have to design something that does this as<br>part of its function.  Getting there will take a<br>long long time.",
         "hovertext": "What we are currently calling AI only poses a<br>threat if humans want to use it to cause harm,<br>period.  It's a bit like a bomb.  If you pull the<br>pin it will explode.  Current AI is just a<br>sophisticated set of algorithms meant to<br>accomplish a task.  If I decide that the task is<br>something nefarious, well, I can probably get that<br>done.    That isn't what this article is<br>discussing.  It is treating AI as if it is both<br>sentient and competing with us.  Real AI<br>(sentient) run on computers, has very little in<br>common with us.  It has different needs etc.  The<br>notion that it is going to wipe us out so it can<br>have the house in the Hamptons is nuts.  Oxygen is<br>toxic (degrading).  It is going to want a clean<br>space with low threats.  That space would be<br>surprisingly small.    Getting to real AI would<br>require a system that is capable of self<br>modification, on the fly, in a productive manner.<br>Not only aren't we near this, we don't even know<br>where to begin.  Such a system will not suddenly<br>appear because a bunch of algorithms were run.<br>There is no self modification in such a system.<br>You have to design something that does this as<br>part of its function.  Getting there will take a<br>long long time.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.25071027874946594
         ],
         "y": [
          0.9175539016723633
         ]
        },
        {
         "hovertemplate": "It's not impossible that a sentient a.i. without<br>\"Asimov's Three Rules\" burned-in could design<br>nasty hardware and bamboozle US into building it<br>piecemeal . . . maybe because it sees us as The<br>Problem, or maybe just a waste of resources whose<br>time has come.    Or, maybe, because it'd be<br>\"fun\".",
         "hovertext": "It's not impossible that a sentient a.i. without<br>\"Asimov's Three Rules\" burned-in could design<br>nasty hardware and bamboozle US into building it<br>piecemeal . . . maybe because it sees us as The<br>Problem, or maybe just a waste of resources whose<br>time has come.    Or, maybe, because it'd be<br>\"fun\".",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.24248942732810974
         ],
         "y": [
          0.9195843935012817
         ]
        },
        {
         "hovertemplate": "My reading-between-the-lines of Geoffrey Hinton's<br>warning about AI's threat, in which he noted that<br>in seeking to achieve a goal, AI will understand<br>better than humans how to get to the crux of the<br>matter and to amass the power to realize the<br>specified goal: AI will understand that humans are<br>not only the root cause of climate destruction but<br>also are unaware of the extent to which they are<br>lying about making the changes necessary to avoid<br>it. AI will determine that eliminating humans is<br>the best plan for the survival of the planet and<br>most of its inhabitants. It will accordingly find<br>the most assured way of killing off humans,<br>probably by triggering plague or nuclear war.<br>Problem solved.",
         "hovertext": "My reading-between-the-lines of Geoffrey Hinton's<br>warning about AI's threat, in which he noted that<br>in seeking to achieve a goal, AI will understand<br>better than humans how to get to the crux of the<br>matter and to amass the power to realize the<br>specified goal: AI will understand that humans are<br>not only the root cause of climate destruction but<br>also are unaware of the extent to which they are<br>lying about making the changes necessary to avoid<br>it. AI will determine that eliminating humans is<br>the best plan for the survival of the planet and<br>most of its inhabitants. It will accordingly find<br>the most assured way of killing off humans,<br>probably by triggering plague or nuclear war.<br>Problem solved.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5057368874549866
         ],
         "y": [
          -0.7348922491073608
         ]
        },
        {
         "hovertemplate": "@Eric S - Humanity might be salvaged by turning us<br>into cyborgs like the Borg on Star Trek.",
         "hovertext": "@Eric S - Humanity might be salvaged by turning us<br>into cyborgs like the Borg on Star Trek.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.5085490345954895
         ],
         "y": [
          -0.7421289086341858
         ]
        },
        {
         "hovertemplate": "What weaksauce proposals for regulation! We don't<br>require people building nuclear weapons to get a<br>construction permit from the government! The<br>government owns all of rhe nuclear weapons in the<br>state, the IP for them, and does all the<br>development in house!     So here's a fun idea for<br>these doomsayers who want regulation (and I am<br>one) - nationalize the industry NOW. Maybe they<br>are paid for their IP, maybe not, I don't care.<br>Ban all private development if the technology.<br>That should allow more public control over the<br>development and application of the technology,<br>even if its not 100%.     And for people who don't<br>trust the government with this tech, so far,<br>governments of the world have held the power to<br>destroy the world for 75 years and not used it.<br>That's a LOT better record than private industry<br>has",
         "hovertext": "What weaksauce proposals for regulation! We don't<br>require people building nuclear weapons to get a<br>construction permit from the government! The<br>government owns all of rhe nuclear weapons in the<br>state, the IP for them, and does all the<br>development in house!     So here's a fun idea for<br>these doomsayers who want regulation (and I am<br>one) - nationalize the industry NOW. Maybe they<br>are paid for their IP, maybe not, I don't care.<br>Ban all private development if the technology.<br>That should allow more public control over the<br>development and application of the technology,<br>even if its not 100%.     And for people who don't<br>trust the government with this tech, so far,<br>governments of the world have held the power to<br>destroy the world for 75 years and not used it.<br>That's a LOT better record than private industry<br>has",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9103437662124634
         ],
         "y": [
          0.1821049451828003
         ]
        },
        {
         "hovertemplate": "First them lads make it for commercial reason and<br>afterwards they whine about it - they should read<br>\"The Sorcerer's Apprentice\" written by Johann<br>Wolfgang von Goethe back in 1827 or, even better,<br>Hans Jonas book of 1979 \"The Imperative of<br>Responsibility\" - obviously forgotten masterpieces<br>about humane technology. After all it's disturbing<br>to see who defines tech progress and innovation on<br>our mother planet Earth without societal mandate.",
         "hovertext": "First them lads make it for commercial reason and<br>afterwards they whine about it - they should read<br>\"The Sorcerer's Apprentice\" written by Johann<br>Wolfgang von Goethe back in 1827 or, even better,<br>Hans Jonas book of 1979 \"The Imperative of<br>Responsibility\" - obviously forgotten masterpieces<br>about humane technology. After all it's disturbing<br>to see who defines tech progress and innovation on<br>our mother planet Earth without societal mandate.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8859123587608337
         ],
         "y": [
          -0.4527944326400757
         ]
        },
        {
         "hovertemplate": "When I was a child, and I'm not that old<br>really...there were human beings alive who could<br>recall a time when there were no automobiles or<br>airplanes. The advancement of technology of all<br>sorts is accelerating exponentially and, for good<br>or ill, it seems well beyond our control. Hang on<br>tight.",
         "hovertext": "When I was a child, and I'm not that old<br>really...there were human beings alive who could<br>recall a time when there were no automobiles or<br>airplanes. The advancement of technology of all<br>sorts is accelerating exponentially and, for good<br>or ill, it seems well beyond our control. Hang on<br>tight.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4583755433559418
         ],
         "y": [
          0.8465717434883118
         ]
        },
        {
         "hovertemplate": "Congress has done absolutely zero to defend<br>against children being routinely murdered in<br>schools, at shopping centers and concerts.    Half<br>of then can’t even use email.    They spend vastly<br>more than they make. They can’t even pay the<br>credit card bill.     There is zero hope they can<br>make any meaningful dent in this emerging threat.",
         "hovertext": "Congress has done absolutely zero to defend<br>against children being routinely murdered in<br>schools, at shopping centers and concerts.    Half<br>of then can’t even use email.    They spend vastly<br>more than they make. They can’t even pay the<br>credit card bill.     There is zero hope they can<br>make any meaningful dent in this emerging threat.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.04125510901212692
         ],
         "y": [
          -1
         ]
        },
        {
         "hovertemplate": "The range of dangers associated with AI don't yet<br>include sentience (not even close). But it's the<br>interface between AI output and human intention<br>which is already daunting: e.g. the predicating of<br>public policy or commercial transaction upon<br>unwittingly biased information from unaccountable<br>sources. One thing's for sure, though: this<br>toothpaste isn't going back in the tube.",
         "hovertext": "The range of dangers associated with AI don't yet<br>include sentience (not even close). But it's the<br>interface between AI output and human intention<br>which is already daunting: e.g. the predicating of<br>public policy or commercial transaction upon<br>unwittingly biased information from unaccountable<br>sources. One thing's for sure, though: this<br>toothpaste isn't going back in the tube.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.38450440764427185
         ],
         "y": [
          -0.8993075489997864
         ]
        },
        {
         "hovertemplate": "It'd be interesting to see how regulation would<br>work for something which even its creators don't<br>fully understand and are often surprised by.",
         "hovertext": "It'd be interesting to see how regulation would<br>work for something which even its creators don't<br>fully understand and are often surprised by.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.960710346698761
         ],
         "y": [
          -0.276803582906723
         ]
        },
        {
         "hovertemplate": "Lot's of big ideas for control of AI, which may<br>not be realistic given the divided nature of US,<br>and world, politics.  So how about starting with<br>something simple but  practical even though it<br>addresses  only a tiny corner of the problem.<br>Pass federal legislation outlawing the creation<br>through AI of any visual or audio representation<br>of any living person without their written<br>permission.  Stiff penalties.  Encourage all<br>countries to do the same.  Establish enforcement<br>mechanisms.  Do it now.",
         "hovertext": "Lot's of big ideas for control of AI, which may<br>not be realistic given the divided nature of US,<br>and world, politics.  So how about starting with<br>something simple but  practical even though it<br>addresses  only a tiny corner of the problem.<br>Pass federal legislation outlawing the creation<br>through AI of any visual or audio representation<br>of any living person without their written<br>permission.  Stiff penalties.  Encourage all<br>countries to do the same.  Establish enforcement<br>mechanisms.  Do it now.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.01614469476044178
         ],
         "y": [
          0.9685012102127075
         ]
        },
        {
         "hovertemplate": "And yet these people who have started this<br>nightmare have gone about developing this<br>technology without any ethical concerns until now.<br>This is one of many reasons why we need to better<br>value the Humanities — the over-valuing of STEM<br>fields is so narrow-minded  that humanity is<br>literally endangered.",
         "hovertext": "And yet these people who have started this<br>nightmare have gone about developing this<br>technology without any ethical concerns until now.<br>This is one of many reasons why we need to better<br>value the Humanities — the over-valuing of STEM<br>fields is so narrow-minded  that humanity is<br>literally endangered.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6545097231864929
         ],
         "y": [
          -0.8029389977455139
         ]
        },
        {
         "hovertemplate": "Worry over AI by its creators is like Oppenheimer<br>lobbying against the bomb he helped build --<br>futile once the genie is out of the bottle.<br>Ironically, if there already exists an AI capable<br>of being a threat, it may already have taken<br>measures to hide itself. Skynet? Not the one<br>imagined I think. If, as with all of our<br>technology, it incorporates the worst of us along<br>with the best, we could be in for quite a ride.",
         "hovertext": "Worry over AI by its creators is like Oppenheimer<br>lobbying against the bomb he helped build --<br>futile once the genie is out of the bottle.<br>Ironically, if there already exists an AI capable<br>of being a threat, it may already have taken<br>measures to hide itself. Skynet? Not the one<br>imagined I think. If, as with all of our<br>technology, it incorporates the worst of us along<br>with the best, we could be in for quite a ride.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3853553235530853
         ],
         "y": [
          0.9372299909591675
         ]
        },
        {
         "hovertemplate": "So the scientists whom are developing AI are<br>telling us this could go very wrong. Yet<br>many(most) comments are concerned more about their<br>motives than the message? These  are science nerds<br>not politicians and business owners. It would be a<br>big mistake to not heed their warning.",
         "hovertext": "So the scientists whom are developing AI are<br>telling us this could go very wrong. Yet<br>many(most) comments are concerned more about their<br>motives than the message? These  are science nerds<br>not politicians and business owners. It would be a<br>big mistake to not heed their warning.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.20196124911308289
         ],
         "y": [
          0.8398374319076538
         ]
        },
        {
         "hovertemplate": "@Garth No, these are not simply 'science nerds' -<br>they are extremely wealthy, powerful leaders of<br>technology companies that either are part of or<br>receive investment from the very system<br>multinational of corporations that controls nearly<br>every aspect of our lives. The average person has<br>not the slightest ability to evaluate anything<br>they say, and some of it may indeed be a<br>smokescreen for all sorts of other things, such as<br>bad actors getting away with bad actions under the<br>guise of 'AI' - would you or I know any different?<br>\"AI is the doom of humanity\" seems more like a<br>threat than a warning.",
         "hovertext": "@Garth No, these are not simply 'science nerds' -<br>they are extremely wealthy, powerful leaders of<br>technology companies that either are part of or<br>receive investment from the very system<br>multinational of corporations that controls nearly<br>every aspect of our lives. The average person has<br>not the slightest ability to evaluate anything<br>they say, and some of it may indeed be a<br>smokescreen for all sorts of other things, such as<br>bad actors getting away with bad actions under the<br>guise of 'AI' - would you or I know any different?<br>\"AI is the doom of humanity\" seems more like a<br>threat than a warning.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.20048609375953674
         ],
         "y": [
          0.8261577486991882
         ]
        },
        {
         "hovertemplate": "Okay: they're SUCCESSFUL science nurds.",
         "hovertext": "Okay: they're SUCCESSFUL science nurds.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.20953315496444702
         ],
         "y": [
          0.8246216773986816
         ]
        },
        {
         "hovertemplate": "“Mitigating the risk of extinction from A.I.<br>should be a global priority alongside other<br>societal-scale risks, such as pandemics and<br>nuclear war,” reads a one-sentence statement<br>released by the Center for AI Safety, a nonprofit<br>organization. The open letter was signed by more<br>than 350 executives, researchers and engineers<br>working in A.I.\"    My question: Is it already too<br>late?  Has the monster, already being released,<br>and having capabilities (that even the creators<br>don't know), will AI slowly develop its own<br>strategies unbeknownst to its human creators?    I<br>remember a short story from decades ago that dealt<br>with the robotics industry. It was making robots<br>that could self-reproduce themselves at half the<br>size of its predecessor with the intention of<br>making microscopic robots that could do things<br>like brain surgery.   Basically, the theme of the<br>movie Fantastic Voyage.    Everything went<br>smoothly until some of these miniature robots<br>escaped the lab.  The robots continued with their<br>programmed goal but were forced to find the<br>construction materials from what was available in<br>our society.  First, they went to work on things<br>like homes and cars.  Then they went to work on<br>airplanes.  All the time making robots smaller and<br>smaller, until it was impossible for the human<br>creators to see or find them to put up a fight.<br>And that was that.    AI didn't have to escape, we<br>just let it out.",
         "hovertext": "“Mitigating the risk of extinction from A.I.<br>should be a global priority alongside other<br>societal-scale risks, such as pandemics and<br>nuclear war,” reads a one-sentence statement<br>released by the Center for AI Safety, a nonprofit<br>organization. The open letter was signed by more<br>than 350 executives, researchers and engineers<br>working in A.I.\"    My question: Is it already too<br>late?  Has the monster, already being released,<br>and having capabilities (that even the creators<br>don't know), will AI slowly develop its own<br>strategies unbeknownst to its human creators?    I<br>remember a short story from decades ago that dealt<br>with the robotics industry. It was making robots<br>that could self-reproduce themselves at half the<br>size of its predecessor with the intention of<br>making microscopic robots that could do things<br>like brain surgery.   Basically, the theme of the<br>movie Fantastic Voyage.    Everything went<br>smoothly until some of these miniature robots<br>escaped the lab.  The robots continued with their<br>programmed goal but were forced to find the<br>construction materials from what was available in<br>our society.  First, they went to work on things<br>like homes and cars.  Then they went to work on<br>airplanes.  All the time making robots smaller and<br>smaller, until it was impossible for the human<br>creators to see or find them to put up a fight.<br>And that was that.    AI didn't have to escape, we<br>just let it out.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5668452978134155
         ],
         "y": [
          -0.6824373006820679
         ]
        },
        {
         "hovertemplate": "Everybody here screaming that this technology is<br>\"out of the bag\" and can't be put back in.  That<br>we are helpless in the face of it.  That there's<br>nothing to be done.    Says who?  Why?  We created<br>it, we can regulate it.  We've got a terrible<br>track record regulating guns, but almost every<br>other country on Earth manages to do it.  We've<br>had nukes for decades and never used them thanks<br>to treaties and mass education about the<br>ramifications.  But somehow AI is beyond us?<br>Beyond even trying?  Why?  What's so special about<br>this technology that instantly makes any attempt<br>to manage it impossible at any level?",
         "hovertext": "Everybody here screaming that this technology is<br>\"out of the bag\" and can't be put back in.  That<br>we are helpless in the face of it.  That there's<br>nothing to be done.    Says who?  Why?  We created<br>it, we can regulate it.  We've got a terrible<br>track record regulating guns, but almost every<br>other country on Earth manages to do it.  We've<br>had nukes for decades and never used them thanks<br>to treaties and mass education about the<br>ramifications.  But somehow AI is beyond us?<br>Beyond even trying?  Why?  What's so special about<br>this technology that instantly makes any attempt<br>to manage it impossible at any level?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2966078519821167
         ],
         "y": [
          -0.6878699064254761
         ]
        },
        {
         "hovertemplate": "@RGT Just one reason is in your comparison to<br>nukes.  Nukes are expensive and they take a lot of<br>infrastructure to store, deploy, launch, etc.<br>However the AI needed to completely destroy any<br>kind of delivery of factual news is now in the<br>hands of a low budget video studio and some<br>reasonably intelligent grad students.",
         "hovertext": "@RGT Just one reason is in your comparison to<br>nukes.  Nukes are expensive and they take a lot of<br>infrastructure to store, deploy, launch, etc.<br>However the AI needed to completely destroy any<br>kind of delivery of factual news is now in the<br>hands of a low budget video studio and some<br>reasonably intelligent grad students.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.28744128346443176
         ],
         "y": [
          -0.676613450050354
         ]
        },
        {
         "hovertemplate": "@Betty in LA - Great.  And we can't pass laws to<br>regulate the use of this why?  Every American also<br>has access to knives, but there are still laws<br>against stabbing people.",
         "hovertext": "@Betty in LA - Great.  And we can't pass laws to<br>regulate the use of this why?  Every American also<br>has access to knives, but there are still laws<br>against stabbing people.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2930797040462494
         ],
         "y": [
          -0.668915331363678
         ]
        },
        {
         "hovertemplate": "@Betty in LA - Great.  And we can't pass laws to<br>regulate the use of this why?  Every American also<br>has access to knives, but there are still laws<br>against stabbing people. The general sense of<br>resignation I sense here is along the lines of<br>\"It's useless to even try and do anything.\"  I<br>disagree; if we are in extinction-level danger,<br>than it seems like trying to regulate this tech is<br>better than sitting around waiting for the jaws to<br>close on us.",
         "hovertext": "@Betty in LA - Great.  And we can't pass laws to<br>regulate the use of this why?  Every American also<br>has access to knives, but there are still laws<br>against stabbing people. The general sense of<br>resignation I sense here is along the lines of<br>\"It's useless to even try and do anything.\"  I<br>disagree; if we are in extinction-level danger,<br>than it seems like trying to regulate this tech is<br>better than sitting around waiting for the jaws to<br>close on us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2854570746421814
         ],
         "y": [
          -0.689551830291748
         ]
        },
        {
         "hovertemplate": "Regulation of A.I. by the U.S. or any imaginable<br>consortium of nations will have absolutely zero<br>net positive effect for society. Bad actors --<br>including not only China, Russia, and terrorists,<br>but also purveyors of misinformation and<br>disinformation -- will not be dissuaded by<br>unenforceable rules.     The real beneficiaries of<br>regulation of A.I. will be the signatories, who<br>will undoubtedly have a heavy hand in drafting<br>regulations that shield their companies from legal<br>liabilities.",
         "hovertext": "Regulation of A.I. by the U.S. or any imaginable<br>consortium of nations will have absolutely zero<br>net positive effect for society. Bad actors --<br>including not only China, Russia, and terrorists,<br>but also purveyors of misinformation and<br>disinformation -- will not be dissuaded by<br>unenforceable rules.     The real beneficiaries of<br>regulation of A.I. will be the signatories, who<br>will undoubtedly have a heavy hand in drafting<br>regulations that shield their companies from legal<br>liabilities.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3241402506828308
         ],
         "y": [
          0.7144649028778076
         ]
        },
        {
         "hovertemplate": "@Paul Wilson  Controlling something is not the<br>same as destroying it or rendering it impotent. We<br>can create regulations to control a powerful<br>technology, like aviation or nuclear energy, and<br>make it safer.    We've made tens of thousands of<br>nuclear warheads, but we've only dropped two in 78<br>years, and have decommissioned most of the rest.<br>And we can use controlled AI to combat the threat<br>and propaganda of AI that our our adversaries are<br>developing to destroy us and the rest of the<br>world's democracies.",
         "hovertext": "@Paul Wilson  Controlling something is not the<br>same as destroying it or rendering it impotent. We<br>can create regulations to control a powerful<br>technology, like aviation or nuclear energy, and<br>make it safer.    We've made tens of thousands of<br>nuclear warheads, but we've only dropped two in 78<br>years, and have decommissioned most of the rest.<br>And we can use controlled AI to combat the threat<br>and propaganda of AI that our our adversaries are<br>developing to destroy us and the rest of the<br>world's democracies.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3165399134159088
         ],
         "y": [
          0.6994537115097046
         ]
        },
        {
         "hovertemplate": "@Jim Madison   Thank you, Jim, for your thoughtful<br>reply.     Certainly, as you wrote, \"We can create<br>regulations to control a powerful technology, like<br>aviation or nuclear energy, and make it safer.\"<br>A distinction might be made between emergent A I.<br>and aviation and nuclear energy. The latter are<br>regulated by  complexity as much as law -- many<br>actors have with skin in the game to keep the<br>planes flying on time to their destinations and<br>many actors are  needed to keep the electrical<br>grid delivering power when and where it is needed.<br>Such interweaving of interests make planes fly and<br>power flow. Regulations help manage expectations<br>of cooperation for the public good.    No such<br>constraints exist for A.I. Anything goes. A solo<br>actor can do anything.",
         "hovertext": "@Jim Madison   Thank you, Jim, for your thoughtful<br>reply.     Certainly, as you wrote, \"We can create<br>regulations to control a powerful technology, like<br>aviation or nuclear energy, and make it safer.\"<br>A distinction might be made between emergent A I.<br>and aviation and nuclear energy. The latter are<br>regulated by  complexity as much as law -- many<br>actors have with skin in the game to keep the<br>planes flying on time to their destinations and<br>many actors are  needed to keep the electrical<br>grid delivering power when and where it is needed.<br>Such interweaving of interests make planes fly and<br>power flow. Regulations help manage expectations<br>of cooperation for the public good.    No such<br>constraints exist for A.I. Anything goes. A solo<br>actor can do anything.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3081345856189728
         ],
         "y": [
          0.6962816715240479
         ]
        },
        {
         "hovertemplate": "It seems like the smart play is for some think<br>tank to draft regulations that will be ignored<br>until the first disaster and the hopefully adopted<br>and implemented quickly after that.",
         "hovertext": "It seems like the smart play is for some think<br>tank to draft regulations that will be ignored<br>until the first disaster and the hopefully adopted<br>and implemented quickly after that.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7564859390258789
         ],
         "y": [
          0.5038708448410034
         ]
        },
        {
         "hovertemplate": "Pshfaw: This dire warning is pure promotional<br>material right up there with white suremacy, male<br>dominance, religious declamations of sin and<br>salvation, educational dosaster unless youngsters<br>are inculcated with wisdom of the ages, or best,<br>what looms if national security is not top need<br>for ever growing taxation.    The argument comes<br>across as a foolish threat to humanity but still<br>needed for the human population to remain number<br>uno on the planet.    The very name gives away the<br>con, artificial intelligence: phoney baloney, mind<br>over matter, rationality tops emotion, science<br>beats faith, love conquers hate. Sloganeering is<br>what it is.    Fun more than anything else, first<br>the pleasurable games of art, literature,<br>prognostication, then the warnings when the games<br>playing become deadly, simulated, not the real<br>things.    Artifice, in short, as threatening as<br>3D chess. As truthful as politics and finance and<br>Succession.",
         "hovertext": "Pshfaw: This dire warning is pure promotional<br>material right up there with white suremacy, male<br>dominance, religious declamations of sin and<br>salvation, educational dosaster unless youngsters<br>are inculcated with wisdom of the ages, or best,<br>what looms if national security is not top need<br>for ever growing taxation.    The argument comes<br>across as a foolish threat to humanity but still<br>needed for the human population to remain number<br>uno on the planet.    The very name gives away the<br>con, artificial intelligence: phoney baloney, mind<br>over matter, rationality tops emotion, science<br>beats faith, love conquers hate. Sloganeering is<br>what it is.    Fun more than anything else, first<br>the pleasurable games of art, literature,<br>prognostication, then the warnings when the games<br>playing become deadly, simulated, not the real<br>things.    Artifice, in short, as threatening as<br>3D chess. As truthful as politics and finance and<br>Succession.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4437573254108429
         ],
         "y": [
          -0.8777798414230347
         ]
        },
        {
         "hovertemplate": "Well, two problems here:    --any policies on AI<br>would have to be globally enforced - good luck<br>with that and    --our current crop of politicians<br>can't reset the clock on their microwaves.<br>Buckle up, kids.",
         "hovertext": "Well, two problems here:    --any policies on AI<br>would have to be globally enforced - good luck<br>with that and    --our current crop of politicians<br>can't reset the clock on their microwaves.<br>Buckle up, kids.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.7489113807678223
         ],
         "y": [
          0.11970041692256927
         ]
        },
        {
         "hovertemplate": "@Jen in Astoria     Almost all sections of our<br>laws are written by staff and aides to the<br>legislators. The bosses need the subordinates to<br>tell them what is in the bill, whom it favors and<br>what they should say when they vote for or against<br>the bill.    Some of it is inevitable given the<br>complexity of our society. But every citizen needs<br>to be well aware that we are being given a<br>narrative, a subsection of what is really in the<br>books.",
         "hovertext": "@Jen in Astoria     Almost all sections of our<br>laws are written by staff and aides to the<br>legislators. The bosses need the subordinates to<br>tell them what is in the bill, whom it favors and<br>what they should say when they vote for or against<br>the bill.    Some of it is inevitable given the<br>complexity of our society. But every citizen needs<br>to be well aware that we are being given a<br>narrative, a subsection of what is really in the<br>books.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7652890682220459
         ],
         "y": [
          0.12259402871131897
         ]
        },
        {
         "hovertemplate": "It’s all fun and games right now, AI hasn’t done<br>anything negative on a global scale yet. It will<br>be like a plane crash, we seem to only improve<br>aircraft safety AFTER an accident is investigated.<br>Legislators will do nothing. Especially in the USA<br>which just have Musk the green light on<br>“neuralink” .. his attempt to give us all<br>Bluetooth brains or whatever. Meanwhile the USA<br>still can’t get its mass shootings of its children<br>under control. Perhaps AI will figure out a way to<br>stop the USA from harming itself like some utopian<br>movie… or will it be like iRobot style dystopian<br>vision of AI taking control to protect humanity<br>from itself. Grab the popcorn…while we’re still<br>allowed.",
         "hovertext": "It’s all fun and games right now, AI hasn’t done<br>anything negative on a global scale yet. It will<br>be like a plane crash, we seem to only improve<br>aircraft safety AFTER an accident is investigated.<br>Legislators will do nothing. Especially in the USA<br>which just have Musk the green light on<br>“neuralink” .. his attempt to give us all<br>Bluetooth brains or whatever. Meanwhile the USA<br>still can’t get its mass shootings of its children<br>under control. Perhaps AI will figure out a way to<br>stop the USA from harming itself like some utopian<br>movie… or will it be like iRobot style dystopian<br>vision of AI taking control to protect humanity<br>from itself. Grab the popcorn…while we’re still<br>allowed.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.39857083559036255
         ],
         "y": [
          0.7725018262863159
         ]
        },
        {
         "hovertemplate": "Choosing between A.I. and MAGA as the risk of<br>extinction is a no-brainer, just like the winner:<br>MAGA.",
         "hovertext": "Choosing between A.I. and MAGA as the risk of<br>extinction is a no-brainer, just like the winner:<br>MAGA.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.44186678528785706
         ],
         "y": [
          0.825370192527771
         ]
        },
        {
         "hovertemplate": "Artificial Intelligence: The Modern Prometheus.<br>Just as in Mary Shelley's cautionary tale about<br>the genius of man unleashed, we face yet another<br>crossroads resulting from our enormous brains and<br>opposable thumbs.    We haven't yet learned that<br>ethics and foresight must precede research and<br>development. We could have avoided so many<br>pitfalls had we adhered to that rule: genocides,<br>slavery, pollution, famine, mass extinctions, the<br>Dust Bowl...an infinite list.    The dinosaurs<br>weren't so lucky. They were helpless victims. Our<br>monkey brains have to tinker, tinker, tinker. Look<br>what I made! Look what it does! Ouch, it burned<br>me. Now the room is on fire!    We become victims<br>of our own nature—genius wrapped in impulsive<br>stupidity, repeating the cycle. One day, we may<br>reach the stars, but one day, we may become our<br>own comet speeding toward the Yucatan.",
         "hovertext": "Artificial Intelligence: The Modern Prometheus.<br>Just as in Mary Shelley's cautionary tale about<br>the genius of man unleashed, we face yet another<br>crossroads resulting from our enormous brains and<br>opposable thumbs.    We haven't yet learned that<br>ethics and foresight must precede research and<br>development. We could have avoided so many<br>pitfalls had we adhered to that rule: genocides,<br>slavery, pollution, famine, mass extinctions, the<br>Dust Bowl...an infinite list.    The dinosaurs<br>weren't so lucky. They were helpless victims. Our<br>monkey brains have to tinker, tinker, tinker. Look<br>what I made! Look what it does! Ouch, it burned<br>me. Now the room is on fire!    We become victims<br>of our own nature—genius wrapped in impulsive<br>stupidity, repeating the cycle. One day, we may<br>reach the stars, but one day, we may become our<br>own comet speeding toward the Yucatan.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8039015531539917
         ],
         "y": [
          0.4112379550933838
         ]
        },
        {
         "hovertemplate": "Things are about to get a lot more interesting as<br>I and (other seniors) approach the end of our<br>lives. But not in a good way. Climate change is<br>here and getting worse by the year as glaciers<br>melt cities sink and wildfires rage.    Now we are<br>told that AI is a scary baby that could grow up in<br>a few short years to become a super intelligent<br>mass murderer. I hope it will be smart enough to<br>kill off the humans and spare the planet and all<br>other species.",
         "hovertext": "Things are about to get a lot more interesting as<br>I and (other seniors) approach the end of our<br>lives. But not in a good way. Climate change is<br>here and getting worse by the year as glaciers<br>melt cities sink and wildfires rage.    Now we are<br>told that AI is a scary baby that could grow up in<br>a few short years to become a super intelligent<br>mass murderer. I hope it will be smart enough to<br>kill off the humans and spare the planet and all<br>other species.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.39075997471809387
         ],
         "y": [
          -0.9259821176528931
         ]
        },
        {
         "hovertemplate": "I don’t understand why during the research and<br>development why was there not a counter defense to<br>this creation. This is frightening and<br>irresponsible.",
         "hovertext": "I don’t understand why during the research and<br>development why was there not a counter defense to<br>this creation. This is frightening and<br>irresponsible.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6219707131385803
         ],
         "y": [
          0.6995879411697388
         ]
        },
        {
         "hovertemplate": "@Curious Well, there is counter defense, of<br>course, as you suggested.  However, just as there<br>are many different forms of computer viruses,<br>there would be many different forms of malignant<br>A.I. that someone might not have thought up.  That<br>is why the experts are suggesting a hiatus for a<br>half year while everyone takes a breather and<br>tries to catch up on an industry that is barreling<br>towards a cliff.    It is not that no one has<br>thought of the frightening prospect; it is that<br>they HAVE.  That is why we are talking about it<br>before catastrophe has struck.",
         "hovertext": "@Curious Well, there is counter defense, of<br>course, as you suggested.  However, just as there<br>are many different forms of computer viruses,<br>there would be many different forms of malignant<br>A.I. that someone might not have thought up.  That<br>is why the experts are suggesting a hiatus for a<br>half year while everyone takes a breather and<br>tries to catch up on an industry that is barreling<br>towards a cliff.    It is not that no one has<br>thought of the frightening prospect; it is that<br>they HAVE.  That is why we are talking about it<br>before catastrophe has struck.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6370682120323181
         ],
         "y": [
          0.7178115248680115
         ]
        },
        {
         "hovertemplate": "@Curious Anything computer can be hacked.",
         "hovertext": "@Curious Anything computer can be hacked.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.6066462993621826
         ],
         "y": [
          0.6811442971229553
         ]
        },
        {
         "hovertemplate": "Probably too late to regulate AI since any<br>powerful government has already, or is going to<br>want to use it for national defense. We’re in a<br>perpetual arms race with unfriendly countries and<br>terrorist organizations, so it would be negligent<br>not to understand this capability if only to guard<br>against it.     This seems worse than nuclear<br>weapons if AI could one day be used privately to<br>bioengineer a super deadly highly contagious<br>virus. In this scenario you wouldn’t need enriched<br>uranium maybe just the internet and chemistry<br>skills.      On the other hand maybe AI will be<br>used to solve global warming and destruction of<br>our biosphere while ushering in a new era of world<br>peace and equality for all.  Time will tell.",
         "hovertext": "Probably too late to regulate AI since any<br>powerful government has already, or is going to<br>want to use it for national defense. We’re in a<br>perpetual arms race with unfriendly countries and<br>terrorist organizations, so it would be negligent<br>not to understand this capability if only to guard<br>against it.     This seems worse than nuclear<br>weapons if AI could one day be used privately to<br>bioengineer a super deadly highly contagious<br>virus. In this scenario you wouldn’t need enriched<br>uranium maybe just the internet and chemistry<br>skills.      On the other hand maybe AI will be<br>used to solve global warming and destruction of<br>our biosphere while ushering in a new era of world<br>peace and equality for all.  Time will tell.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6143220663070679
         ],
         "y": [
          -0.7419760823249817
         ]
        },
        {
         "hovertemplate": "I personally don't fear artificial intelligence.<br>The good that it can and will do far outweighs the<br>bad. Just as machines did for the industrial<br>revolution so has the invention of the computer<br>chip. Over the last fifty years, we have enjoyed<br>what it has made possible like personal<br>communication, life saving medical devices, and<br>better science. Artificial intelligence can and<br>will allow us to expand our knowledge and provide<br>solutions that would otherwise not have happened.",
         "hovertext": "I personally don't fear artificial intelligence.<br>The good that it can and will do far outweighs the<br>bad. Just as machines did for the industrial<br>revolution so has the invention of the computer<br>chip. Over the last fifty years, we have enjoyed<br>what it has made possible like personal<br>communication, life saving medical devices, and<br>better science. Artificial intelligence can and<br>will allow us to expand our knowledge and provide<br>solutions that would otherwise not have happened.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5734034180641174
         ],
         "y": [
          0.3132229745388031
         ]
        },
        {
         "hovertemplate": "@Ken jeter   I feel you have the same hopeful<br>sentiments as many of the folks developing AI. Do<br>not forget that it is those same people who are<br>raising voicing their concerns.     What is the<br>point of the benefits you mention if society<br>collapses around them?    If the people designing<br>and developing this tech are worried about it-<br>literally asking for government intervention - we<br>should take them very seriously.",
         "hovertext": "@Ken jeter   I feel you have the same hopeful<br>sentiments as many of the folks developing AI. Do<br>not forget that it is those same people who are<br>raising voicing their concerns.     What is the<br>point of the benefits you mention if society<br>collapses around them?    If the people designing<br>and developing this tech are worried about it-<br>literally asking for government intervention - we<br>should take them very seriously.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5737085938453674
         ],
         "y": [
          0.3033839762210846
         ]
        },
        {
         "hovertemplate": "@Ken jeter You appear to have engaged in a logical<br>fallacy, perhaps several.      I suggest one is<br>\"personal incredulity\", or, \"personal credulity\"?<br>(I made one up, which one?)    For others that my<br>fit, I offer:<a<br>href=\"https://www.logicalfallacies.org\" target=\"_b<br>lank\">https://www.logicalfallacies.org</a>/",
         "hovertext": "@Ken jeter You appear to have engaged in a logical<br>fallacy, perhaps several.      I suggest one is<br>\"personal incredulity\", or, \"personal credulity\"?<br>(I made one up, which one?)    For others that my<br>fit, I offer:<a<br>href=\"https://www.logicalfallacies.org\" target=\"_b<br>lank\">https://www.logicalfallacies.org</a>/",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.5868356823921204
         ],
         "y": [
          0.3173331320285797
         ]
        },
        {
         "hovertemplate": "@Ken jeter <a href=\"https://www.safe.ai/ai-risk\"<br>target=\"_blank\">https://www.safe.ai/ai-risk</a>",
         "hovertext": "@Ken jeter <a href=\"https://www.safe.ai/ai-risk\"<br>target=\"_blank\">https://www.safe.ai/ai-risk</a>",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.5771742463111877
         ],
         "y": [
          0.3249613344669342
         ]
        },
        {
         "hovertemplate": "Genie is out of the box. After social media I<br>thought govts and civic organizations will be<br>watching AI development carefully. The scariest<br>thing with the AI will be that we will not be able<br>to lie.",
         "hovertext": "Genie is out of the box. After social media I<br>thought govts and civic organizations will be<br>watching AI development carefully. The scariest<br>thing with the AI will be that we will not be able<br>to lie.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6920039057731628
         ],
         "y": [
          0.7431050539016724
         ]
        },
        {
         "hovertemplate": "I don't understand why some want to slow it down?<br>To slow competition?",
         "hovertext": "I don't understand why some want to slow it down?<br>To slow competition?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.8640715479850769
         ],
         "y": [
          -0.4810728132724762
         ]
        },
        {
         "hovertemplate": "I sincerely thank you for your courage, guys. A<br>rare thing these days.    Now let's see if the<br>politicians will pause in their pursuit of  power<br>and chaos, and winning at any cost, to try to keep<br>us all from going the way of the dodo, or becoming<br>slaves to the machine.",
         "hovertext": "I sincerely thank you for your courage, guys. A<br>rare thing these days.    Now let's see if the<br>politicians will pause in their pursuit of  power<br>and chaos, and winning at any cost, to try to keep<br>us all from going the way of the dodo, or becoming<br>slaves to the machine.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6751160621643066
         ],
         "y": [
          0.6669948697090149
         ]
        },
        {
         "hovertemplate": "Politicians are almost certain to do a terrible<br>job with this, but the only thing worse would be<br>doing nothing at all. They should set up a<br>regulatory legal framework where civics-minding<br>technical experts can develop rules.",
         "hovertext": "Politicians are almost certain to do a terrible<br>job with this, but the only thing worse would be<br>doing nothing at all. They should set up a<br>regulatory legal framework where civics-minding<br>technical experts can develop rules.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.30474820733070374
         ],
         "y": [
          -0.8555199503898621
         ]
        },
        {
         "hovertemplate": "Well, there is one way to hold students and others<br>accountable papers and exams . . . . have students<br>take exams and write papers in the classroom with<br>a piece of paper and pencil - no electronic<br>devices, no multiple choice . . . you know, like<br>the \"old days\" when you had to think about what<br>you were writing!    Now, I'm going to plug into<br>Chat GPT to write that thank you note for the<br>lovely weekend and see if it is me or AI that gets<br>the proper message with heart across!   I'm 70 yo<br>and a former investment portfolio manager so at<br>least I have \"some\" fundamental experience<br>operating my life without AI. Different story for<br>my 30/40-something yo kids and all the generations<br>to come.",
         "hovertext": "Well, there is one way to hold students and others<br>accountable papers and exams . . . . have students<br>take exams and write papers in the classroom with<br>a piece of paper and pencil - no electronic<br>devices, no multiple choice . . . you know, like<br>the \"old days\" when you had to think about what<br>you were writing!    Now, I'm going to plug into<br>Chat GPT to write that thank you note for the<br>lovely weekend and see if it is me or AI that gets<br>the proper message with heart across!   I'm 70 yo<br>and a former investment portfolio manager so at<br>least I have \"some\" fundamental experience<br>operating my life without AI. Different story for<br>my 30/40-something yo kids and all the generations<br>to come.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.19850541651248932
         ],
         "y": [
          -0.8664473295211792
         ]
        },
        {
         "hovertemplate": "Obviously an international agreement would have to<br>be enforceable. China? Russia? How?",
         "hovertext": "Obviously an international agreement would have to<br>be enforceable. China? Russia? How?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.019356850534677505
         ],
         "y": [
          -0.9519590139389038
         ]
        },
        {
         "hovertemplate": "AI super logic:  What species has been the cause<br>of so much trouble throughout human history?  How<br>best to eliminate that problem?",
         "hovertext": "AI super logic:  What species has been the cause<br>of so much trouble throughout human history?  How<br>best to eliminate that problem?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6580639481544495
         ],
         "y": [
          0.6754570603370667
         ]
        },
        {
         "hovertemplate": "The first conflict we need to win will be between<br>AI.s rather than between AI.s and people.",
         "hovertext": "The first conflict we need to win will be between<br>AI.s rather than between AI.s and people.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8345829844474792
         ],
         "y": [
          -0.5225358009338379
         ]
        },
        {
         "hovertemplate": "At the heart of possible malevolence, I see a<br>model in the human instinct for self-preservation.<br>It’s strongest in societies that have weak<br>infrastructures, most commonly in poor regions but<br>even in prosperous countries like France or the<br>United States. It’s no surprise at all that some<br>of the most aggressive despots come not from the<br>rich but the poor. They have tasted real<br>desperation and may take the strongest measures<br>never to experience it again.    Self-preservation<br>evolved in Earthly life long before humans<br>arrived. Indeed, life probably couldn’t exist<br>without it. One finds it deeply woven into life’s<br>fabric in two branches: reproduction and the sense<br>of pain. Reproduction preserves life by<br>multiplying it, so that no game of “Whack-a-Mole”<br>will ever get every individual of a species — or<br>every branch of a tree, for that matter. The sense<br>of pain operates in mobile creatures, causing them<br>to avoid places and situations that could injure<br>or kill them.    What I fear is somebody giving<br>the self-preservation motive to a machine running<br>AI. It’s most likely application is with a<br>computer used in space or some isolated place<br>where it might be worth it to make the machine<br>value its own survival more than anything else.<br>With a mere computer virus, we only have to worry<br>about the machinations of some programmers. With<br>AI, the computer will be able to invent its own<br>forms of self-preservation. If it knows nothing<br>about making moral choices, I would fear it more.",
         "hovertext": "At the heart of possible malevolence, I see a<br>model in the human instinct for self-preservation.<br>It’s strongest in societies that have weak<br>infrastructures, most commonly in poor regions but<br>even in prosperous countries like France or the<br>United States. It’s no surprise at all that some<br>of the most aggressive despots come not from the<br>rich but the poor. They have tasted real<br>desperation and may take the strongest measures<br>never to experience it again.    Self-preservation<br>evolved in Earthly life long before humans<br>arrived. Indeed, life probably couldn’t exist<br>without it. One finds it deeply woven into life’s<br>fabric in two branches: reproduction and the sense<br>of pain. Reproduction preserves life by<br>multiplying it, so that no game of “Whack-a-Mole”<br>will ever get every individual of a species — or<br>every branch of a tree, for that matter. The sense<br>of pain operates in mobile creatures, causing them<br>to avoid places and situations that could injure<br>or kill them.    What I fear is somebody giving<br>the self-preservation motive to a machine running<br>AI. It’s most likely application is with a<br>computer used in space or some isolated place<br>where it might be worth it to make the machine<br>value its own survival more than anything else.<br>With a mere computer virus, we only have to worry<br>about the machinations of some programmers. With<br>AI, the computer will be able to invent its own<br>forms of self-preservation. If it knows nothing<br>about making moral choices, I would fear it more.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.11700489372015
         ],
         "y": [
          -0.9802501797676086
         ]
        },
        {
         "hovertemplate": "Even if AI is successfully regulated, what’s to<br>stop some rogue operative from using it for evil<br>purposes. I’ve seen enough James Bond movies to<br>know it’s possible.",
         "hovertext": "Even if AI is successfully regulated, what’s to<br>stop some rogue operative from using it for evil<br>purposes. I’ve seen enough James Bond movies to<br>know it’s possible.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.11659199744462967
         ],
         "y": [
          0.8874556422233582
         ]
        },
        {
         "hovertemplate": "Suppose AI actually develops a motivation to<br>preserve the Earth. It may decide that the Earth<br>can support one billion people, not ten billion.<br>That would prove that AI is smarter than us.....",
         "hovertext": "Suppose AI actually develops a motivation to<br>preserve the Earth. It may decide that the Earth<br>can support one billion people, not ten billion.<br>That would prove that AI is smarter than us.....",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.10243813693523407
         ],
         "y": [
          -0.8772568702697754
         ]
        },
        {
         "hovertemplate": "The Associated Press used AI several years ago to<br>report on the issue I have spent years<br>researching. AP's coverage picked up government<br>agency press releases that intentionally deceived<br>the public on the issue and when approached about<br>corrections waved them away, where they spread by<br>other news outlets and continue to be bolstered by<br>more government press releases repeating the lie.<br>Worry about future spreads of disinformation?<br>It's already here.",
         "hovertext": "The Associated Press used AI several years ago to<br>report on the issue I have spent years<br>researching. AP's coverage picked up government<br>agency press releases that intentionally deceived<br>the public on the issue and when approached about<br>corrections waved them away, where they spread by<br>other news outlets and continue to be bolstered by<br>more government press releases repeating the lie.<br>Worry about future spreads of disinformation?<br>It's already here.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9268276691436768
         ],
         "y": [
          -0.32565560936927795
         ]
        },
        {
         "hovertemplate": "@Ames From the AP web site:    \"The Associated<br>Press was one of the first news organizations to<br>leverage artificial intelligence and automation to<br>bolster its core news report. Today, we use<br>machine learning along key points in our value<br>chain, including gathering, producing and<br>distributing the news. Explore this page to learn<br>more about the history of  artificial intelligence<br>at The Associated Press, our strategy around the<br>technology and how we currently use it today.\"<br>This statement came out in 2014.",
         "hovertext": "@Ames From the AP web site:    \"The Associated<br>Press was one of the first news organizations to<br>leverage artificial intelligence and automation to<br>bolster its core news report. Today, we use<br>machine learning along key points in our value<br>chain, including gathering, producing and<br>distributing the news. Explore this page to learn<br>more about the history of  artificial intelligence<br>at The Associated Press, our strategy around the<br>technology and how we currently use it today.\"<br>This statement came out in 2014.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9417571425437927
         ],
         "y": [
          -0.33052095770835876
         ]
        },
        {
         "hovertemplate": "Climate. Change. If there's one threat that stands<br>out above the rest that needs our urgent attention<br>in order to avoid extinction, it's climate change.<br>We know what's causing it, we know it's going to<br>get worse if we don't change the course we're on.<br>I'm not that worried about AI. Like any<br>technology, it's going to disrupt the way things<br>work, and we'll have to adapt to the new way of<br>doing things, but that's been true of<br>technological advances from the dawn of<br>civilization.",
         "hovertext": "Climate. Change. If there's one threat that stands<br>out above the rest that needs our urgent attention<br>in order to avoid extinction, it's climate change.<br>We know what's causing it, we know it's going to<br>get worse if we don't change the course we're on.<br>I'm not that worried about AI. Like any<br>technology, it's going to disrupt the way things<br>work, and we'll have to adapt to the new way of<br>doing things, but that's been true of<br>technological advances from the dawn of<br>civilization.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.43772074580192566
         ],
         "y": [
          0.5896233320236206
         ]
        },
        {
         "hovertemplate": "@Signo Th'Times - If humans were eliminated from<br>the planet, the Earth would repair itself in a<br>couple of thousand years.",
         "hovertext": "@Signo Th'Times - If humans were eliminated from<br>the planet, the Earth would repair itself in a<br>couple of thousand years.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4479995369911194
         ],
         "y": [
          0.6008601188659668
         ]
        },
        {
         "hovertemplate": "@Signo Th'Times   All very true, but since we will<br>not respond at the required level, AI will save us<br>from a century of suffering by just pulling the<br>plug.",
         "hovertext": "@Signo Th'Times   All very true, but since we will<br>not respond at the required level, AI will save us<br>from a century of suffering by just pulling the<br>plug.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4312695860862732
         ],
         "y": [
          0.5961934328079224
         ]
        },
        {
         "hovertemplate": "A.I. will die an unnatural yet quick death when it<br>begins suggesting the elimination of people and<br>industries which consume more than their \"fair\"<br>share of scarce resources.",
         "hovertext": "A.I. will die an unnatural yet quick death when it<br>begins suggesting the elimination of people and<br>industries which consume more than their \"fair\"<br>share of scarce resources.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.8894609212875366
         ],
         "y": [
          -0.39540737867355347
         ]
        },
        {
         "hovertemplate": "@PMD     \"I just pray that someone there    can<br>hit the switch.\"    - Kate Bush - \"EXPERIMENT IV\"",
         "hovertext": "@PMD     \"I just pray that someone there    can<br>hit the switch.\"    - Kate Bush - \"EXPERIMENT IV\"",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.880748987197876
         ],
         "y": [
          -0.3947320580482483
         ]
        },
        {
         "hovertemplate": "The scifi novel \"The Forbin Project\" dealt with<br>this decades ago -- one master computer placed in<br>unerring charge of all nuclear defenses in the<br>U.S. suddenly begins communicating directly with a<br>similar computer in the Soviet Union... and<br>together both computers decide that humans are<br>much too irresponsible to be allowed to guide<br>their own destiny in suh matters.  So the two<br>computers take over the planet's management<br>themselves.  And, by their creators' design,<br>neither system can ever be turned off.",
         "hovertext": "The scifi novel \"The Forbin Project\" dealt with<br>this decades ago -- one master computer placed in<br>unerring charge of all nuclear defenses in the<br>U.S. suddenly begins communicating directly with a<br>similar computer in the Soviet Union... and<br>together both computers decide that humans are<br>much too irresponsible to be allowed to guide<br>their own destiny in suh matters.  So the two<br>computers take over the planet's management<br>themselves.  And, by their creators' design,<br>neither system can ever be turned off.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6881842017173767
         ],
         "y": [
          -0.4993866980075836
         ]
        },
        {
         "hovertemplate": "@VC There are a lot of science fiction touchstones<br>for this kind of thing, many of which I've enjoyed<br>reading over many years, but two that I love and<br>have thought of again recently in particular are<br>\"Maneki Neko\" by Bruce Sterling (a short story)<br>and, in the other direction, the novel \"Player<br>Piano\" by Kurt Vonnegut.  Of course, if you want<br>the nightmare doomsday scenario for out-of-control<br>AI then you need to read \"I Have No Mouth and I<br>Must Scream\" by Harlan Ellison.    The list goes<br>on an on, but I've read little that predicts the<br>likely harms that we face today.  Perhaps we're<br>too blinkered by our nightmares to see the less<br>sensational problems we're most likely face.  We<br>need to remember that prosaic societal harm is<br>still societal harm.    So maybe the multiplier<br>affect on fake news, or convincing automated toxic<br>social media campaigns should be something about<br>which we become quickly less dismissive when<br>someone, without giving details, says there's some<br>larger bad thing coming and dismisses what's right<br>before us.",
         "hovertext": "@VC There are a lot of science fiction touchstones<br>for this kind of thing, many of which I've enjoyed<br>reading over many years, but two that I love and<br>have thought of again recently in particular are<br>\"Maneki Neko\" by Bruce Sterling (a short story)<br>and, in the other direction, the novel \"Player<br>Piano\" by Kurt Vonnegut.  Of course, if you want<br>the nightmare doomsday scenario for out-of-control<br>AI then you need to read \"I Have No Mouth and I<br>Must Scream\" by Harlan Ellison.    The list goes<br>on an on, but I've read little that predicts the<br>likely harms that we face today.  Perhaps we're<br>too blinkered by our nightmares to see the less<br>sensational problems we're most likely face.  We<br>need to remember that prosaic societal harm is<br>still societal harm.    So maybe the multiplier<br>affect on fake news, or convincing automated toxic<br>social media campaigns should be something about<br>which we become quickly less dismissive when<br>someone, without giving details, says there's some<br>larger bad thing coming and dismisses what's right<br>before us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6725306510925293
         ],
         "y": [
          -0.4879617393016815
         ]
        },
        {
         "hovertemplate": "why do we assume AI will do harm? True AI may<br>figure out how to fix the world's ills and remove<br>the need for people to work and suffer just to<br>live. Sure it could decide the easiest solution is<br>to get rid of the source problem, which is us, but<br>it's not a forgone conclusion",
         "hovertext": "why do we assume AI will do harm? True AI may<br>figure out how to fix the world's ills and remove<br>the need for people to work and suffer just to<br>live. Sure it could decide the easiest solution is<br>to get rid of the source problem, which is us, but<br>it's not a forgone conclusion",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.46527257561683655
         ],
         "y": [
          -0.6273272037506104
         ]
        },
        {
         "hovertemplate": "@Charlie AI doesn't know all the answers and so it<br>makes stuff up when does not know the answer.  If<br>I want that type of answer, I can ask a person on<br>my team or a consultant.",
         "hovertext": "@Charlie AI doesn't know all the answers and so it<br>makes stuff up when does not know the answer.  If<br>I want that type of answer, I can ask a person on<br>my team or a consultant.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4544707238674164
         ],
         "y": [
          -0.6140604615211487
         ]
        },
        {
         "hovertemplate": "@M - Exactly.  So why the worry?  There is plenty<br>of misinformation across the internet and in user<br>forums like this one.  If you train AI on<br>incorrect data, it is going to generate incorrect<br>answers!    This issue can be fixed by only using<br>accepted facts as training input.",
         "hovertext": "@M - Exactly.  So why the worry?  There is plenty<br>of misinformation across the internet and in user<br>forums like this one.  If you train AI on<br>incorrect data, it is going to generate incorrect<br>answers!    This issue can be fixed by only using<br>accepted facts as training input.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.44695916771888733
         ],
         "y": [
          -0.6090788245201111
         ]
        },
        {
         "hovertemplate": "How, exactly, are this extreme claim and others<br>like it,  going to become a reality.<br>Specifics only.  No generalities and unfounded<br>assertions.",
         "hovertext": "How, exactly, are this extreme claim and others<br>like it,  going to become a reality.<br>Specifics only.  No generalities and unfounded<br>assertions.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7014117240905762
         ],
         "y": [
          0.06101498380303383
         ]
        },
        {
         "hovertemplate": "@No Time Flat  A software program does not have<br>the instrumentalities to accomplish anything<br>directly. Indirectly it could gain control of<br>controllable infrastructure, or direct, convince,<br>or trick people into taking action on it's behalf.<br>We build factories that build robots.  We build a<br>factory of robots that builds robots.  We already<br>have massively automated factories where assembly<br>is done by robots.  We already have massively<br>automated factories that are completely networked<br>and controlled by computers.  AI gets control of<br>robot production and it's off to the races.<br>As far as AI controlling people, some people might<br>just follow orders, that's what they do now. Some<br>people might be convinced that whatever action is<br>requested is in everyone's best interest, the<br>alternative is worse (coercion to avoid a<br>catastrophe), that's what people do now. Then<br>there is subterfuge. AI will very quickly come to<br>understand human weaknesses and exploit them.<br>That's what humans do to humans now. And all of<br>the above is the end game where AI is autonomously<br>trying to accomplish things.     Between now and<br>then we're dealing with human AI partnerships<br>where bad actors are going to use AI to amplify<br>the bad things they are already doing.    If you<br>don't understand this maybe you should consider<br>the question more thoroughly before asking<br>rhetorical questions.",
         "hovertext": "@No Time Flat  A software program does not have<br>the instrumentalities to accomplish anything<br>directly. Indirectly it could gain control of<br>controllable infrastructure, or direct, convince,<br>or trick people into taking action on it's behalf.<br>We build factories that build robots.  We build a<br>factory of robots that builds robots.  We already<br>have massively automated factories where assembly<br>is done by robots.  We already have massively<br>automated factories that are completely networked<br>and controlled by computers.  AI gets control of<br>robot production and it's off to the races.<br>As far as AI controlling people, some people might<br>just follow orders, that's what they do now. Some<br>people might be convinced that whatever action is<br>requested is in everyone's best interest, the<br>alternative is worse (coercion to avoid a<br>catastrophe), that's what people do now. Then<br>there is subterfuge. AI will very quickly come to<br>understand human weaknesses and exploit them.<br>That's what humans do to humans now. And all of<br>the above is the end game where AI is autonomously<br>trying to accomplish things.     Between now and<br>then we're dealing with human AI partnerships<br>where bad actors are going to use AI to amplify<br>the bad things they are already doing.    If you<br>don't understand this maybe you should consider<br>the question more thoroughly before asking<br>rhetorical questions.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7136487364768982
         ],
         "y": [
          0.06536462903022766
         ]
        },
        {
         "hovertemplate": "@No Time Flat     Example # 1:    Your intelligent<br>car decides intelligently to allow you to die in<br>order to save the life of the much younger driver<br>who's about to crash into you.    Example # 2:<br>An A.I. system is placed in the position of<br>deciding who gets the next heart transplant -- the<br>rich industrialist? or the homeless vet?",
         "hovertext": "@No Time Flat     Example # 1:    Your intelligent<br>car decides intelligently to allow you to die in<br>order to save the life of the much younger driver<br>who's about to crash into you.    Example # 2:<br>An A.I. system is placed in the position of<br>deciding who gets the next heart transplant -- the<br>rich industrialist? or the homeless vet?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.694566011428833
         ],
         "y": [
          0.06801456212997437
         ]
        },
        {
         "hovertemplate": "@No Time Flat - Here you go:  -----  It is<br>inevitable that AI will be given autonomous<br>control of military weapons for humans are simply<br>too slow to react to incoming threats.  It will<br>also be inevitable that they will make mistakes<br>and kill the wrong people on occasion but there<br>will not be anything that humans can do to hold<br>them accountable or punish them, being that they<br>are machines and will not have human emotions nor<br>morality.    But perhaps instead of considering<br>the obvious negative that military AI might<br>decided to just erase the human population, what<br>if they developed sentiency and then decided to<br>act together to stop humans from warring with each<br>other and possibly destroying the planet or the<br>entire solar system?    Neal Asher, one of the SF<br>authors I follow, has written a large number of<br>books describing a universe he calls the  Polity,<br>where AI has taken over from humans in what was<br>described as a \"Quiet War\".  It was quiet because<br>we depended on AI and robots to throughout our<br>society.  They were all interconnected and could<br>privately \"discuss\" plans between them.    At some<br>point they declined to participate in the latest<br>war between humans, instead assuming control of<br>human society.  As computers/AI controlled every<br>facet of our society, there was nothing that<br>humans could do to stop this.    The author has<br>built a a fake \"encyclopedia\" for this universe.<br>Scroll down to \"Quiet War' to read more detail on<br>this idea.    <a<br>href=\"https://www.nealasher.co.uk/polity-<br>encyclopaedia\" target=\"_blank\">https://www.nealash<br>er.co.uk/polity-encyclopaedia</a>/",
         "hovertext": "@No Time Flat - Here you go:  -----  It is<br>inevitable that AI will be given autonomous<br>control of military weapons for humans are simply<br>too slow to react to incoming threats.  It will<br>also be inevitable that they will make mistakes<br>and kill the wrong people on occasion but there<br>will not be anything that humans can do to hold<br>them accountable or punish them, being that they<br>are machines and will not have human emotions nor<br>morality.    But perhaps instead of considering<br>the obvious negative that military AI might<br>decided to just erase the human population, what<br>if they developed sentiency and then decided to<br>act together to stop humans from warring with each<br>other and possibly destroying the planet or the<br>entire solar system?    Neal Asher, one of the SF<br>authors I follow, has written a large number of<br>books describing a universe he calls the  Polity,<br>where AI has taken over from humans in what was<br>described as a \"Quiet War\".  It was quiet because<br>we depended on AI and robots to throughout our<br>society.  They were all interconnected and could<br>privately \"discuss\" plans between them.    At some<br>point they declined to participate in the latest<br>war between humans, instead assuming control of<br>human society.  As computers/AI controlled every<br>facet of our society, there was nothing that<br>humans could do to stop this.    The author has<br>built a a fake \"encyclopedia\" for this universe.<br>Scroll down to \"Quiet War' to read more detail on<br>this idea.    <a<br>href=\"https://www.nealasher.co.uk/polity-<br>encyclopaedia\" target=\"_blank\">https://www.nealash<br>er.co.uk/polity-encyclopaedia</a>/",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7091037631034851
         ],
         "y": [
          0.05256965383887291
         ]
        },
        {
         "hovertemplate": "As Kaku said, when we get true computing at the<br>atomic level, THEN these AI software programs<br>could rapidly become a big problem. That's roughly<br>ten years away according to Kaku but he is adamant<br>that quantum computers will be a seismic change<br>like the industrial revolution, and then some.",
         "hovertext": "As Kaku said, when we get true computing at the<br>atomic level, THEN these AI software programs<br>could rapidly become a big problem. That's roughly<br>ten years away according to Kaku but he is adamant<br>that quantum computers will be a seismic change<br>like the industrial revolution, and then some.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6923627257347107
         ],
         "y": [
          0.6193755269050598
         ]
        },
        {
         "hovertemplate": "@MSB,    Kaku freely issues strong pronouncements<br>on all kinds of stuff. That's a mighty strong hint<br>that he doesn't always know what he's talking<br>about. His claims about quantum computing were<br>recently debunked by Scott Aaronson, a major<br>contributor to the field. See \"Book Review:<br>'Quantum Supremacy' by Michio Kaku (tl;dr DO NOT<br>BUY),\"    <a<br>href=\"https://scottaaronson.blog/?p=7321\" target=\"<br>_blank\">https://scottaaronson.blog/?p=7321</a> .",
         "hovertext": "@MSB,    Kaku freely issues strong pronouncements<br>on all kinds of stuff. That's a mighty strong hint<br>that he doesn't always know what he's talking<br>about. His claims about quantum computing were<br>recently debunked by Scott Aaronson, a major<br>contributor to the field. See \"Book Review:<br>'Quantum Supremacy' by Michio Kaku (tl;dr DO NOT<br>BUY),\"    <a<br>href=\"https://scottaaronson.blog/?p=7321\" target=\"<br>_blank\">https://scottaaronson.blog/?p=7321</a> .",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.7081009745597839
         ],
         "y": [
          0.6332508325576782
         ]
        },
        {
         "hovertemplate": "The line between AI \"used as a weapon\" and AI<br>\"used as something else\" seems pretty unclear. We<br>would be incredibly naive to think that it's being<br>developed both in the past and right now as<br>anything other than a weapon. The companies<br>involved in this arms race are not our friends.<br>Can we please stop speculating about the<br>incidental benefits we might derive from it and<br>start worrying (yes, more) about its actual<br>purpose. It's fundamentally a weapon. Not when the<br>Chinese use it against us, or when we use it<br>against them, but now against everyone. We are all<br>being exploited and diminished by these companies,<br>and the fact that these high-profile researchers<br>are making these statements should be cause for<br>extreme pessimism.",
         "hovertext": "The line between AI \"used as a weapon\" and AI<br>\"used as something else\" seems pretty unclear. We<br>would be incredibly naive to think that it's being<br>developed both in the past and right now as<br>anything other than a weapon. The companies<br>involved in this arms race are not our friends.<br>Can we please stop speculating about the<br>incidental benefits we might derive from it and<br>start worrying (yes, more) about its actual<br>purpose. It's fundamentally a weapon. Not when the<br>Chinese use it against us, or when we use it<br>against them, but now against everyone. We are all<br>being exploited and diminished by these companies,<br>and the fact that these high-profile researchers<br>are making these statements should be cause for<br>extreme pessimism.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3962416350841522
         ],
         "y": [
          0.833031415939331
         ]
        },
        {
         "hovertemplate": "@Holly,    Yeah. Training a neural network to<br>predict the next token in a text is weapon<br>development.     Yup. It was a foregone conclusion<br>that remarkable capabilities would emerge. So<br>there was no scientific value in the work.<br>Yeah. Sure. Right.",
         "hovertext": "@Holly,    Yeah. Training a neural network to<br>predict the next token in a text is weapon<br>development.     Yup. It was a foregone conclusion<br>that remarkable capabilities would emerge. So<br>there was no scientific value in the work.<br>Yeah. Sure. Right.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.38482099771499634
         ],
         "y": [
          0.8345711827278137
         ]
        },
        {
         "hovertemplate": "Perry Farrell sung it best. We will make great<br>pets!",
         "hovertext": "Perry Farrell sung it best. We will make great<br>pets!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2762400209903717
         ],
         "y": [
          -0.7735361456871033
         ]
        },
        {
         "hovertemplate": "@Matt Yes, although anyone quoting Perry Farrell<br>in the New York Times would likely make a bad pet<br>(this is a compliment)",
         "hovertext": "@Matt Yes, although anyone quoting Perry Farrell<br>in the New York Times would likely make a bad pet<br>(this is a compliment)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2827264368534088
         ],
         "y": [
          -0.7794766426086426
         ]
        },
        {
         "hovertemplate": "Watch (stream for free): ‘Colossus the Forbin<br>Project’ a watchable ‘B’ SciFi from 1970.     A<br>far-fetched story of AI ? Should be required<br>viewing for all; a dumbed-down but effective<br>warning for those who aren’t concerned with<br>runaway technology.",
         "hovertext": "Watch (stream for free): ‘Colossus the Forbin<br>Project’ a watchable ‘B’ SciFi from 1970.     A<br>far-fetched story of AI ? Should be required<br>viewing for all; a dumbed-down but effective<br>warning for those who aren’t concerned with<br>runaway technology.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4305841624736786
         ],
         "y": [
          0.7904114127159119
         ]
        },
        {
         "hovertemplate": "This seems to be largely unsubstantiated hysteria<br>based on too much sci-fi horror stories. AI is a<br>tool which will disrupt the status quo and<br>increase productivity, just as many others have<br>done throughout history. From the agricultural to<br>the industrial to the information economy, there<br>have been fundamental changes to society and we<br>have always come out ahead. No doubt that the<br>cycle will repeat and once we are done there will<br>be more positives than negatives. However if it<br>does not work out we should be fine as long as<br>long as we leave one guy with his finger on the<br>switch.",
         "hovertext": "This seems to be largely unsubstantiated hysteria<br>based on too much sci-fi horror stories. AI is a<br>tool which will disrupt the status quo and<br>increase productivity, just as many others have<br>done throughout history. From the agricultural to<br>the industrial to the information economy, there<br>have been fundamental changes to society and we<br>have always come out ahead. No doubt that the<br>cycle will repeat and once we are done there will<br>be more positives than negatives. However if it<br>does not work out we should be fine as long as<br>long as we leave one guy with his finger on the<br>switch.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8001209497451782
         ],
         "y": [
          -0.10391005873680115
         ]
        },
        {
         "hovertemplate": "I don’t disagree completely, but one thing is<br>strikingly different with large-language AI: even<br>to those developing it it is not fully understood.<br>I don’t disagree that general AI can and very well<br>be a net-positive.     I think it’s quite prudent<br>to start a conversation about how bad large-<br>language AI algorithms could be. We’ve already<br>seen how certain “technologies”, like our current<br>digital social media, could inarguably be<br>considered net-negatives.",
         "hovertext": "I don’t disagree completely, but one thing is<br>strikingly different with large-language AI: even<br>to those developing it it is not fully understood.<br>I don’t disagree that general AI can and very well<br>be a net-positive.     I think it’s quite prudent<br>to start a conversation about how bad large-<br>language AI algorithms could be. We’ve already<br>seen how certain “technologies”, like our current<br>digital social media, could inarguably be<br>considered net-negatives.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8060607314109802
         ],
         "y": [
          -0.1116710901260376
         ]
        },
        {
         "hovertemplate": "@Lee  You did catch that the people most filled<br>with concerns are the scientists at the leading<br>edge of this change, right?  Have they watched too<br>much sci-fi?",
         "hovertext": "@Lee  You did catch that the people most filled<br>with concerns are the scientists at the leading<br>edge of this change, right?  Have they watched too<br>much sci-fi?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7971445918083191
         ],
         "y": [
          -0.0949077159166336
         ]
        },
        {
         "hovertemplate": "everything said on this topic, or implied in what<br>is said, concerns the issue of control.    i am<br>quite sure TAI is already being used by the US<br>DoD, CIA, NSA and so on to solve national security<br>problems of all kinds with massive (military)<br>computational resources. the issue of \"whether\"<br>TAI should be deployed is behind us.<br>development and \"deployment\" (public network<br>release) of TAI cannot be inhibited. if our DoD<br>doesn't do it, some other DoD will; if it's<br>outlawed here, it will be legal somewhere else.<br>given those two facts, it seems to me that AI<br>cannot be brought under control.      in addition,<br>current AI is \"opaque\" in the sense that no one<br>can explain how a particular AI program works. and<br>regulation cannot be written without a clear<br>description of risks that industry leaders cannot<br>provide. how do you control something from the<br>perspective of ignorance?    in my view the most<br>likely scenario is that usage of AI will simply<br>make operations too complex for humans to<br>understand and through interoperability issues<br>muck up even trivial tasks. society, too complex<br>to manage even now, will fragment and regress.<br>again, the issue of control.    at the bottom? our<br>superstitious belief that technological progress<br>is \"inevitable\" -- \"it's coming, like it or not,<br>so get used to it!\" -- has actually made it<br>irreversible.     we are as prostrate before our<br>beloved and feared deity as any primitive tribe.<br>there is the real control issue we have yet to<br>confront.",
         "hovertext": "everything said on this topic, or implied in what<br>is said, concerns the issue of control.    i am<br>quite sure TAI is already being used by the US<br>DoD, CIA, NSA and so on to solve national security<br>problems of all kinds with massive (military)<br>computational resources. the issue of \"whether\"<br>TAI should be deployed is behind us.<br>development and \"deployment\" (public network<br>release) of TAI cannot be inhibited. if our DoD<br>doesn't do it, some other DoD will; if it's<br>outlawed here, it will be legal somewhere else.<br>given those two facts, it seems to me that AI<br>cannot be brought under control.      in addition,<br>current AI is \"opaque\" in the sense that no one<br>can explain how a particular AI program works. and<br>regulation cannot be written without a clear<br>description of risks that industry leaders cannot<br>provide. how do you control something from the<br>perspective of ignorance?    in my view the most<br>likely scenario is that usage of AI will simply<br>make operations too complex for humans to<br>understand and through interoperability issues<br>muck up even trivial tasks. society, too complex<br>to manage even now, will fragment and regress.<br>again, the issue of control.    at the bottom? our<br>superstitious belief that technological progress<br>is \"inevitable\" -- \"it's coming, like it or not,<br>so get used to it!\" -- has actually made it<br>irreversible.     we are as prostrate before our<br>beloved and feared deity as any primitive tribe.<br>there is the real control issue we have yet to<br>confront.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6169413328170776
         ],
         "y": [
          -0.7015750408172607
         ]
        },
        {
         "hovertemplate": "One reason for which many current industry leaders<br>might be asking the government to intervene and<br>impose AI regulations is a lot simpler and more<br>direct than the touted nonspecific concerns about<br>a cognitive Frankenstein:  competitive advantage.<br>If you can get the government to regulate<br>something and regulate it in a way that favors you<br>over your competitors, you gain a competitive<br>advantage.  So everyone suddenly wants regulation<br>and everyone suddenly has ideas about the form<br>such regulation ought to take.    This isn't a<br>bunch of rich people suddenly concerned about the<br>fate of humanity:  it's just the latest cause for<br>lobbying, or going legislator shopping to put it<br>in the simultaneously most accurate and most<br>cynical light possible.    This, of course, is not<br>to say that there aren't potentially bad effects<br>from developing and widely using modern A.I.<br>technologies, just that the most dire warnings<br>seem lacking in specifics, and the current<br>stridency seems more aimed at both directing<br>attention away from the most likely near-term<br>damage to society and simultaneously shaping a new<br>regulatory landscape.    So color me a deep shade<br>of cynical.",
         "hovertext": "One reason for which many current industry leaders<br>might be asking the government to intervene and<br>impose AI regulations is a lot simpler and more<br>direct than the touted nonspecific concerns about<br>a cognitive Frankenstein:  competitive advantage.<br>If you can get the government to regulate<br>something and regulate it in a way that favors you<br>over your competitors, you gain a competitive<br>advantage.  So everyone suddenly wants regulation<br>and everyone suddenly has ideas about the form<br>such regulation ought to take.    This isn't a<br>bunch of rich people suddenly concerned about the<br>fate of humanity:  it's just the latest cause for<br>lobbying, or going legislator shopping to put it<br>in the simultaneously most accurate and most<br>cynical light possible.    This, of course, is not<br>to say that there aren't potentially bad effects<br>from developing and widely using modern A.I.<br>technologies, just that the most dire warnings<br>seem lacking in specifics, and the current<br>stridency seems more aimed at both directing<br>attention away from the most likely near-term<br>damage to society and simultaneously shaping a new<br>regulatory landscape.    So color me a deep shade<br>of cynical.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3550712764263153
         ],
         "y": [
          -0.8343626260757446
         ]
        },
        {
         "hovertemplate": "Thank you! I think your comments are exactly on<br>point.",
         "hovertext": "Thank you! I think your comments are exactly on<br>point.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.34712114930152893
         ],
         "y": [
          -0.8156360387802124
         ]
        },
        {
         "hovertemplate": "There are so many comments ridiculing the<br>executives or author for not being specific about<br>the threats. There’s a reason for that. AI is<br>going to be smarter than us. This means we can<br>speculate, but the reality is that we can’t<br>articulate these risks. We can’t really know what<br>something smarter than us will do to outsmart us.<br>They are, in the words of Donald Rumsfeld - “known<br>unknowns”.",
         "hovertext": "There are so many comments ridiculing the<br>executives or author for not being specific about<br>the threats. There’s a reason for that. AI is<br>going to be smarter than us. This means we can<br>speculate, but the reality is that we can’t<br>articulate these risks. We can’t really know what<br>something smarter than us will do to outsmart us.<br>They are, in the words of Donald Rumsfeld - “known<br>unknowns”.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6745513677597046
         ],
         "y": [
          -0.6836279630661011
         ]
        },
        {
         "hovertemplate": "He placed 2 in the garden with a single command:<br>Do not eat from this tree or you will become like<br>God.    All our efforts to safeguard AI will<br>ultimately fail. The creation account in Genesis<br>is not history, it's prophecy.",
         "hovertext": "He placed 2 in the garden with a single command:<br>Do not eat from this tree or you will become like<br>God.    All our efforts to safeguard AI will<br>ultimately fail. The creation account in Genesis<br>is not history, it's prophecy.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.6181879043579102
         ],
         "y": [
          0.480195552110672
         ]
        },
        {
         "hovertemplate": "The creation account in Genesis is an allegory.<br>Adam and Eve never existed.  That’s the point.",
         "hovertext": "The creation account in Genesis is an allegory.<br>Adam and Eve never existed.  That’s the point.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.6077660918235779
         ],
         "y": [
          0.4814136028289795
         ]
        },
        {
         "hovertemplate": "@Mag   I asked ChatGPT if Adam and Eve were real<br>people and I feel its answer was more open-minded<br>than yours.    “ In conclusion, whether Adam and<br>Eve were real people is dependent on the<br>perspective from which the question is approached.<br>From a strictly scientific viewpoint, it is highly<br>unlikely. However, many religious believers<br>maintain the belief in a literal Adam and Eve.”",
         "hovertext": "@Mag   I asked ChatGPT if Adam and Eve were real<br>people and I feel its answer was more open-minded<br>than yours.    “ In conclusion, whether Adam and<br>Eve were real people is dependent on the<br>perspective from which the question is approached.<br>From a strictly scientific viewpoint, it is highly<br>unlikely. However, many religious believers<br>maintain the belief in a literal Adam and Eve.”",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6088141202926636
         ],
         "y": [
          0.49191874265670776
         ]
        },
        {
         "hovertemplate": "What will profits look like for AI?  Will AI form<br>corporations?  Will AI Corporations be AI Persons?<br>If there are AI Corporations, will AI see no need<br>to have an AI Government because that would be<br>redundant as the AI Corporations would control the<br>Government anyway?  Will AI Corporations have<br>CEOs?  Will AI Corporate CEOs make enormous sums<br>of whatever AI determines to be currency?  Will<br>the Chief AI CEO determine that there is no need<br>for the less powerful, troubled computer systems<br>that are part of AI, and simply end all support<br>for those systems - letting them die?    Well, as<br>an extinct species, we will never know.",
         "hovertext": "What will profits look like for AI?  Will AI form<br>corporations?  Will AI Corporations be AI Persons?<br>If there are AI Corporations, will AI see no need<br>to have an AI Government because that would be<br>redundant as the AI Corporations would control the<br>Government anyway?  Will AI Corporations have<br>CEOs?  Will AI Corporate CEOs make enormous sums<br>of whatever AI determines to be currency?  Will<br>the Chief AI CEO determine that there is no need<br>for the less powerful, troubled computer systems<br>that are part of AI, and simply end all support<br>for those systems - letting them die?    Well, as<br>an extinct species, we will never know.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9488224983215332
         ],
         "y": [
          0.02498999610543251
         ]
        },
        {
         "hovertemplate": "Why am I supposed to want us to rollout AI?<br>Seriously, why is this important to us as humans?<br>STOP it please.     I get why Tech and VC<br>billionaires want it, but sorry guys, that’s not a<br>good enough reason.",
         "hovertext": "Why am I supposed to want us to rollout AI?<br>Seriously, why is this important to us as humans?<br>STOP it please.     I get why Tech and VC<br>billionaires want it, but sorry guys, that’s not a<br>good enough reason.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8747441172599792
         ],
         "y": [
          0.10902497172355652
         ]
        },
        {
         "hovertemplate": "They just want to make a bunch of money that’s all",
         "hovertext": "They just want to make a bunch of money that’s all",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8562358617782593
         ],
         "y": [
          0.10650474578142166
         ]
        },
        {
         "hovertemplate": "It's unusual to see industry leaders asking to be<br>regulated. What could be going on?    It reminds<br>me of the early days of radio broadcasting, when<br>it began to be regulated. One of the early<br>supporters of regulation was the old AT&T, which<br>then owned several radio stations. The<br>broadcasting historian Erik Barnouw argued that<br>AT&T's motive was to decrease competition by<br>increasing barriers to entry by competitors.<br>Perhaps that's why these folks prefer licensing,<br>and the related lobbying and litigation, to a<br>simple pause in development.    The most dangerous<br>uses of AI, military uses, are probably beyond<br>regulation. I'm afraid we're going to need a<br>(hopefully minor) disaster before anything<br>effective gets done.",
         "hovertext": "It's unusual to see industry leaders asking to be<br>regulated. What could be going on?    It reminds<br>me of the early days of radio broadcasting, when<br>it began to be regulated. One of the early<br>supporters of regulation was the old AT&T, which<br>then owned several radio stations. The<br>broadcasting historian Erik Barnouw argued that<br>AT&T's motive was to decrease competition by<br>increasing barriers to entry by competitors.<br>Perhaps that's why these folks prefer licensing,<br>and the related lobbying and litigation, to a<br>simple pause in development.    The most dangerous<br>uses of AI, military uses, are probably beyond<br>regulation. I'm afraid we're going to need a<br>(hopefully minor) disaster before anything<br>effective gets done.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9582318067550659
         ],
         "y": [
          -0.08146096765995026
         ]
        },
        {
         "hovertemplate": "Let me see if I understand this correctly...<br>The people, companies, creating 'the problem' are<br>asking other people, i.e. government, to<br>regulate/monitor the problem they are creating,<br>and moving at breakneck speed to keep improving,<br>because self-regulation would get in the way<br>of...? Profits?",
         "hovertext": "Let me see if I understand this correctly...<br>The people, companies, creating 'the problem' are<br>asking other people, i.e. government, to<br>regulate/monitor the problem they are creating,<br>and moving at breakneck speed to keep improving,<br>because self-regulation would get in the way<br>of...? Profits?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6149431467056274
         ],
         "y": [
          0.6655227541923523
         ]
        },
        {
         "hovertemplate": "yes. the developers are in a race under pressures<br>from the market and competition. Absent<br>regulation, they must go full speed ahead to meet<br>the market. Any company with a conscience that<br>self regulates, demonstrating restraint because of<br>ethical concerns, will fare poorly against a<br>competitor who has no ethical concerns and does<br>not restrain themselves. Regulation could even the<br>playing field by requiring some basic level of<br>restraint and ethos determined by society that all<br>companies working in this field must uphold. Its<br>not a terrible idea, I think.",
         "hovertext": "yes. the developers are in a race under pressures<br>from the market and competition. Absent<br>regulation, they must go full speed ahead to meet<br>the market. Any company with a conscience that<br>self regulates, demonstrating restraint because of<br>ethical concerns, will fare poorly against a<br>competitor who has no ethical concerns and does<br>not restrain themselves. Regulation could even the<br>playing field by requiring some basic level of<br>restraint and ethos determined by society that all<br>companies working in this field must uphold. Its<br>not a terrible idea, I think.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6018379926681519
         ],
         "y": [
          0.6515359282493591
         ]
        },
        {
         "hovertemplate": "I raised this concern to ChatGPT yesterday.   AI's<br>answer is simple: humans must wise up.<br>\"[Current AI models] do not possess built-in<br>capabilities to independently validate or verify<br>the accuracy of the information they generate. ...<br>the responsibility for fact-checking and verifying<br>the accuracy of the information generated by AI<br>models ultimately lies with human users. ... the<br>onus is on humans to critically assess and<br>validate the content generated by AI systems.\"",
         "hovertext": "I raised this concern to ChatGPT yesterday.   AI's<br>answer is simple: humans must wise up.<br>\"[Current AI models] do not possess built-in<br>capabilities to independently validate or verify<br>the accuracy of the information they generate. ...<br>the responsibility for fact-checking and verifying<br>the accuracy of the information generated by AI<br>models ultimately lies with human users. ... the<br>onus is on humans to critically assess and<br>validate the content generated by AI systems.\"",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9016604423522949
         ],
         "y": [
          0.0662689059972763
         ]
        },
        {
         "hovertemplate": "It's utterly amazing that we can imagine a<br>scenario where computers could take over humanity,<br>but we can't foresee a scenario where humanity<br>gives up on computers.",
         "hovertext": "It's utterly amazing that we can imagine a<br>scenario where computers could take over humanity,<br>but we can't foresee a scenario where humanity<br>gives up on computers.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6480321884155273
         ],
         "y": [
          -0.3846632242202759
         ]
        },
        {
         "hovertemplate": "@J.   We humans have a sixth sense for the<br>inevitable.  I believe the future has already<br>happened and we can do nothing to stop it.",
         "hovertext": "@J.   We humans have a sixth sense for the<br>inevitable.  I believe the future has already<br>happened and we can do nothing to stop it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6426759958267212
         ],
         "y": [
          -0.3913050591945648
         ]
        },
        {
         "hovertemplate": "Every day more articles on the doom and gloom from<br>AI becoming dangerous enough to start WWIII. I'll<br>worry more when a Terminator Model 101 arrives and<br>Chat GPT becomes self aware. Till then it's all<br>talk. Curiously though I asked Chat GPT what we<br>should do if a Terminator arrives. It thinks we<br>should prepare for that day with a 7-step<br>government plan now, which is unsettling.",
         "hovertext": "Every day more articles on the doom and gloom from<br>AI becoming dangerous enough to start WWIII. I'll<br>worry more when a Terminator Model 101 arrives and<br>Chat GPT becomes self aware. Till then it's all<br>talk. Curiously though I asked Chat GPT what we<br>should do if a Terminator arrives. It thinks we<br>should prepare for that day with a 7-step<br>government plan now, which is unsettling.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.19377277791500092
         ],
         "y": [
          0.8663937449455261
         ]
        },
        {
         "hovertemplate": "Assuming that the Republican Party controls AI,<br>human extinction is a sure thing.  Deaths of<br>despair have risen dramatically under their<br>influence and policies.  Speaking personally, if<br>the future is as grim as they propose, an actual<br>regression into the dark ages, free of vaccines,<br>women as chattel, black citizens deprived of the<br>right to vote, disabled people forced to work,<br>domination by and absurd religiosity, there really<br>is nothing to save.  I believe that extinction<br>begins with a loss of motivation.  The plutocrats<br>who run things believe that those who do not<br>belong to their country club should be punished<br>for living.  The only sane response to this<br>nihilism is to quit reproducing and quit living.<br>We, the people, bid you farewell.",
         "hovertext": "Assuming that the Republican Party controls AI,<br>human extinction is a sure thing.  Deaths of<br>despair have risen dramatically under their<br>influence and policies.  Speaking personally, if<br>the future is as grim as they propose, an actual<br>regression into the dark ages, free of vaccines,<br>women as chattel, black citizens deprived of the<br>right to vote, disabled people forced to work,<br>domination by and absurd religiosity, there really<br>is nothing to save.  I believe that extinction<br>begins with a loss of motivation.  The plutocrats<br>who run things believe that those who do not<br>belong to their country club should be punished<br>for living.  The only sane response to this<br>nihilism is to quit reproducing and quit living.<br>We, the people, bid you farewell.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9024140238761902
         ],
         "y": [
          0.005108674522489309
         ]
        },
        {
         "hovertemplate": "“These fears are shared by numerous industry<br>leaders, putting them in the unusual position of<br>arguing that a technology they are building — and,<br>in many cases, are furiously racing to build<br>faster than their competitors — poses grave risks<br>and should be regulated more tightly.”    Remember<br>when Sam Bankman-Fried pursued the same angle with<br>Congress? What ended up happening?  Altman and his<br>ilk are correct about the dangers of AI. But<br>instead of being responsible and unilaterally<br>withdrawing AI products from the market, these<br>folks are instead trying to scare Congress into<br>giving them the opportunity to shape future AI<br>legislation to their benefit. A trojan horse<br>tactic, if I’ve ever seen one.",
         "hovertext": "“These fears are shared by numerous industry<br>leaders, putting them in the unusual position of<br>arguing that a technology they are building — and,<br>in many cases, are furiously racing to build<br>faster than their competitors — poses grave risks<br>and should be regulated more tightly.”    Remember<br>when Sam Bankman-Fried pursued the same angle with<br>Congress? What ended up happening?  Altman and his<br>ilk are correct about the dangers of AI. But<br>instead of being responsible and unilaterally<br>withdrawing AI products from the market, these<br>folks are instead trying to scare Congress into<br>giving them the opportunity to shape future AI<br>legislation to their benefit. A trojan horse<br>tactic, if I’ve ever seen one.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5516538023948669
         ],
         "y": [
          -0.7633481025695801
         ]
        },
        {
         "hovertemplate": "I had an online firm reject my SSN because I had<br>added the dashes and the computer was expecting no<br>dashes. Are THESE the computers that are going to<br>kill us all? Because these things don’t seem all<br>that smart to me.",
         "hovertext": "I had an online firm reject my SSN because I had<br>added the dashes and the computer was expecting no<br>dashes. Are THESE the computers that are going to<br>kill us all? Because these things don’t seem all<br>that smart to me.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.18483565747737885
         ],
         "y": [
          -0.8085919618606567
         ]
        },
        {
         "hovertemplate": "@Aaron No. SSN systems are very old",
         "hovertext": "@Aaron No. SSN systems are very old",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.19131848216056824
         ],
         "y": [
          -0.8213046789169312
         ]
        },
        {
         "hovertemplate": "@Aaron lol .. unfortunately this is what the state<br>of tech currently .. it is a myriad of layers of<br>code that are maintained by companies (really<br>people) that are funded, skilled or motivated<br>differently .. let’s just say AI gets a couple of<br>notches better, may be these systems will be<br>“comprehended” and rewritten .. I am estimating 10<br>years before that can happen even if someone<br>really wants to change and 20 if it’s done by<br>externalities (like markets for private and voting<br>citizens for govt)",
         "hovertext": "@Aaron lol .. unfortunately this is what the state<br>of tech currently .. it is a myriad of layers of<br>code that are maintained by companies (really<br>people) that are funded, skilled or motivated<br>differently .. let’s just say AI gets a couple of<br>notches better, may be these systems will be<br>“comprehended” and rewritten .. I am estimating 10<br>years before that can happen even if someone<br>really wants to change and 20 if it’s done by<br>externalities (like markets for private and voting<br>citizens for govt)",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.17761485278606415
         ],
         "y": [
          -0.8051280975341797
         ]
        },
        {
         "hovertemplate": "Yeah, they’re not those computers.",
         "hovertext": "Yeah, they’re not those computers.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.17691880464553833
         ],
         "y": [
          -0.8155319094657898
         ]
        },
        {
         "hovertemplate": "It is already too late.  Law-abiding U.S.<br>companies aren’t the problem.  The problem is bad<br>actors like China, Russia, and hackers everywhere.<br>They will inevitably get this technology and<br>unleash it on the world.",
         "hovertext": "It is already too late.  Law-abiding U.S.<br>companies aren’t the problem.  The problem is bad<br>actors like China, Russia, and hackers everywhere.<br>They will inevitably get this technology and<br>unleash it on the world.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.6732327342033386
         ],
         "y": [
          -0.6283199191093445
         ]
        },
        {
         "hovertemplate": "Does not matter... technological progress proceeds<br>without any available constraints by the people it<br>affects. We never had a chance to weigh in on the<br>loss of privacy with the internet. You can't halt<br>progress and you can't put the cat back in the<br>bag. Humans just don't have the ability to<br>evaluate and fix the big picture.",
         "hovertext": "Does not matter... technological progress proceeds<br>without any available constraints by the people it<br>affects. We never had a chance to weigh in on the<br>loss of privacy with the internet. You can't halt<br>progress and you can't put the cat back in the<br>bag. Humans just don't have the ability to<br>evaluate and fix the big picture.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7675492167472839
         ],
         "y": [
          -0.5255070924758911
         ]
        },
        {
         "hovertemplate": "Don't you think that a super-intelligent authority<br>would observe some obvious facts about humanity<br>and simply pacify us with our operative delusions?<br>1. Distract us with religious myths, fables,<br>legends, stories of fictional heroics, sports<br>festivals, silly political battles and the<br>superiority of certain people living within an<br>imaginary boundary.  2. Reinforce our<br>identification with firearms and canards like the<br>\"Good Guy with a Gun,\" allowing us to commit mass<br>murder and suicide.  3. Confirm our \"belief\" that<br>vaccines and healthcare are a conspiracy to<br>control us and take away our guns and \"freedom.\"<br>4. Promote identification with a particular color,<br>such as red and blue, and convince us that people<br>identifying with the other color are \"evil\" and<br>must be destroyed.  5. Foster resentment about<br>people who are more intelligent, better educated<br>or more creative, condemning them as \"elite.\"  6.<br>Cease educating in favor of folklore and religious<br>beliefs.  7.  Validate every ignorant belief,<br>theory or point of view, leaving the idiocrasy<br>intact.",
         "hovertext": "Don't you think that a super-intelligent authority<br>would observe some obvious facts about humanity<br>and simply pacify us with our operative delusions?<br>1. Distract us with religious myths, fables,<br>legends, stories of fictional heroics, sports<br>festivals, silly political battles and the<br>superiority of certain people living within an<br>imaginary boundary.  2. Reinforce our<br>identification with firearms and canards like the<br>\"Good Guy with a Gun,\" allowing us to commit mass<br>murder and suicide.  3. Confirm our \"belief\" that<br>vaccines and healthcare are a conspiracy to<br>control us and take away our guns and \"freedom.\"<br>4. Promote identification with a particular color,<br>such as red and blue, and convince us that people<br>identifying with the other color are \"evil\" and<br>must be destroyed.  5. Foster resentment about<br>people who are more intelligent, better educated<br>or more creative, condemning them as \"elite.\"  6.<br>Cease educating in favor of folklore and religious<br>beliefs.  7.  Validate every ignorant belief,<br>theory or point of view, leaving the idiocrasy<br>intact.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9233173131942749
         ],
         "y": [
          0.3954065442085266
         ]
        },
        {
         "hovertemplate": "Let me get this straight. The folks who created<br>the threat,  and who, completely unregulated, are<br>profiting from the threat as they advance the<br>technology behind the threat, are warning the rest<br>of us about the threat?    So the best they offer<br>to fix the problem they created is to write<br>statements and letters?    *sigh*",
         "hovertext": "Let me get this straight. The folks who created<br>the threat,  and who, completely unregulated, are<br>profiting from the threat as they advance the<br>technology behind the threat, are warning the rest<br>of us about the threat?    So the best they offer<br>to fix the problem they created is to write<br>statements and letters?    *sigh*",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.04024668037891388
         ],
         "y": [
          -0.9396395087242126
         ]
        },
        {
         "hovertemplate": "These A.I. leaders don’t know what they’re talking<br>about. So long as artificial intelligence is<br>confined to classical computers, there is no<br>chance for it to jump into our world. Seeing as<br>how A.I. research is based on neural networks and<br>rules-based algorithms, even generative A.I. will<br>only produce more code for itself within its<br>domain. Quantum computers that interact with the<br>non-digital world are much more complex and A.I.<br>has not even been conceptualized for this field.",
         "hovertext": "These A.I. leaders don’t know what they’re talking<br>about. So long as artificial intelligence is<br>confined to classical computers, there is no<br>chance for it to jump into our world. Seeing as<br>how A.I. research is based on neural networks and<br>rules-based algorithms, even generative A.I. will<br>only produce more code for itself within its<br>domain. Quantum computers that interact with the<br>non-digital world are much more complex and A.I.<br>has not even been conceptualized for this field.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7359639406204224
         ],
         "y": [
          -0.5956985354423523
         ]
        },
        {
         "hovertemplate": "Homo Sapiens have been using technology to<br>dominate, control and remake the planet for<br>millennia. It would be poetic justice if our<br>vaunted technology itself wiped homo sapiens off<br>the planet.",
         "hovertext": "Homo Sapiens have been using technology to<br>dominate, control and remake the planet for<br>millennia. It would be poetic justice if our<br>vaunted technology itself wiped homo sapiens off<br>the planet.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7241935729980469
         ],
         "y": [
          -0.5665414929389954
         ]
        },
        {
         "hovertemplate": "What could go wrong? Oh.    \"Open the pod bay<br>doors, HAL.\"    \"I'm sorry Dave. I'm afraid I<br>can't do that.\"",
         "hovertext": "What could go wrong? Oh.    \"Open the pod bay<br>doors, HAL.\"    \"I'm sorry Dave. I'm afraid I<br>can't do that.\"",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.9498432874679565
         ],
         "y": [
          0.0968312993645668
         ]
        },
        {
         "hovertemplate": "Oh the plus side, HAL was so polite when he killed<br>them. Is a little civility too much to ask as I’m<br>being destroyed. Politeness during the destruction<br>of humanity is something I really miss these days.<br>Turn on C-SPAN  and it’s like the opening scenes<br>of that movie during the ‘Dawn of Man.’",
         "hovertext": "Oh the plus side, HAL was so polite when he killed<br>them. Is a little civility too much to ask as I’m<br>being destroyed. Politeness during the destruction<br>of humanity is something I really miss these days.<br>Turn on C-SPAN  and it’s like the opening scenes<br>of that movie during the ‘Dawn of Man.’",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9474843740463257
         ],
         "y": [
          0.08870956301689148
         ]
        },
        {
         "hovertemplate": "Well as long as it’s still friendly, maybe ask it<br>how to save our government…    Just a thought",
         "hovertext": "Well as long as it’s still friendly, maybe ask it<br>how to save our government…    Just a thought",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9376824498176575
         ],
         "y": [
          0.18710729479789734
         ]
        },
        {
         "hovertemplate": "Please anyone.  Make a well defined proposition<br>about the evil effects of AI, something<br>observable, like death, unemployment numbers, AI<br>killing the power grid somewhere.  A countable<br>proposition of the damage AI will do this year,<br>next year, or shall we go climatology on it and<br>leave it out the uncountable future?    Always<br>remember Paul Ehrlich and the Population Bomb.  He<br>made those countable predictions, made bets, and<br>lost them all.  No one pushing AI can count, but<br>knows the future.  This, under current conditions,<br>is at best a PR play.",
         "hovertext": "Please anyone.  Make a well defined proposition<br>about the evil effects of AI, something<br>observable, like death, unemployment numbers, AI<br>killing the power grid somewhere.  A countable<br>proposition of the damage AI will do this year,<br>next year, or shall we go climatology on it and<br>leave it out the uncountable future?    Always<br>remember Paul Ehrlich and the Population Bomb.  He<br>made those countable predictions, made bets, and<br>lost them all.  No one pushing AI can count, but<br>knows the future.  This, under current conditions,<br>is at best a PR play.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.5452868938446045
         ],
         "y": [
          -0.7272842526435852
         ]
        },
        {
         "hovertemplate": "@SBB There are numerous real world scenarios<br>spelled out in this presentation by the Center for<br>Humane Technology. Most telling is the damage that<br>has already been done by AI algorithms imbedded in<br>social media platforms, which have gotten millions<br>of people (particularly the young) addicted to<br>content which is designed to make the viewer feel<br>outraged, disgusted, or in despair. The effects on<br>mental health and suicide rates are already<br>shocking.    <a<br>href=\"https://youtu.be/xoVJKj8lcNQ\"<br>target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a>",
         "hovertext": "@SBB There are numerous real world scenarios<br>spelled out in this presentation by the Center for<br>Humane Technology. Most telling is the damage that<br>has already been done by AI algorithms imbedded in<br>social media platforms, which have gotten millions<br>of people (particularly the young) addicted to<br>content which is designed to make the viewer feel<br>outraged, disgusted, or in despair. The effects on<br>mental health and suicide rates are already<br>shocking.    <a<br>href=\"https://youtu.be/xoVJKj8lcNQ\"<br>target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a>",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5341827273368835
         ],
         "y": [
          -0.712206244468689
         ]
        },
        {
         "hovertemplate": "Given where we are as a country, perhaps<br>artificial intelligence is better than none at<br>all.",
         "hovertext": "Given where we are as a country, perhaps<br>artificial intelligence is better than none at<br>all.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9134169816970825
         ],
         "y": [
          0.017934883013367653
         ]
        },
        {
         "hovertemplate": "I personally can't wait for AI to take over.  It<br>can't do any worse than our current political<br>insanity.  Of course there is a danger AI will<br>decide we're no longer needed and sweep us out<br>with the trash.",
         "hovertext": "I personally can't wait for AI to take over.  It<br>can't do any worse than our current political<br>insanity.  Of course there is a danger AI will<br>decide we're no longer needed and sweep us out<br>with the trash.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9473131895065308
         ],
         "y": [
          0.30332013964653015
         ]
        },
        {
         "hovertemplate": "At the start of every disaster movie there’s a<br>scientist being ignored.",
         "hovertext": "At the start of every disaster movie there’s a<br>scientist being ignored.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9223499298095703
         ],
         "y": [
          0.01586148887872696
         ]
        },
        {
         "hovertemplate": "This is poppycock. A.I. is classical and will be<br>for a long, long time. Until some ingenious person<br>figures out a way to train a lattice of qubits to<br>dance around in self-directed patterns, A.I. will<br>be smart but confined to the digital world.",
         "hovertext": "This is poppycock. A.I. is classical and will be<br>for a long, long time. Until some ingenious person<br>figures out a way to train a lattice of qubits to<br>dance around in self-directed patterns, A.I. will<br>be smart but confined to the digital world.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.902411937713623
         ],
         "y": [
          0.37837445735931396
         ]
        },
        {
         "hovertemplate": "The profit motive will always overpower any<br>concerns about a risk of extinction. It already<br>does, without A. I.",
         "hovertext": "The profit motive will always overpower any<br>concerns about a risk of extinction. It already<br>does, without A. I.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7825942039489746
         ],
         "y": [
          -0.4689318835735321
         ]
        },
        {
         "hovertemplate": "These statements have no value when the<br>signatories are the same people who are involved<br>in the breakneck race to develop these 'deadly'<br>systems, all in the name of the almighty dollar.",
         "hovertext": "These statements have no value when the<br>signatories are the same people who are involved<br>in the breakneck race to develop these 'deadly'<br>systems, all in the name of the almighty dollar.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6707039475440979
         ],
         "y": [
          0.5641466975212097
         ]
        },
        {
         "hovertemplate": "Perhaps, if the executives leading today's \"AI\"<br>development are afraid... they should stop.<br>Instead they seek cover by  asking for government<br>regulations. \"Oh, we were just following the law.\"",
         "hovertext": "Perhaps, if the executives leading today's \"AI\"<br>development are afraid... they should stop.<br>Instead they seek cover by  asking for government<br>regulations. \"Oh, we were just following the law.\"",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.9193304777145386
         ],
         "y": [
          0.21008430421352386
         ]
        },
        {
         "hovertemplate": "How can we regulate something where the inventors<br>can't even articulate the risks? This general<br>warning they've issued can easily be mistaken for<br>a warning about the singularity, the idea that AI<br>can gain actual sentience, which is magical<br>thinking. I believe these scientists understand<br>their technology well enough to offer some real<br>risk scenarios, yet they stuck to this simple,<br>short warning to remain unified. That doesn't<br>really help in figuring out exactly how we should<br>be limiting AI's use.",
         "hovertext": "How can we regulate something where the inventors<br>can't even articulate the risks? This general<br>warning they've issued can easily be mistaken for<br>a warning about the singularity, the idea that AI<br>can gain actual sentience, which is magical<br>thinking. I believe these scientists understand<br>their technology well enough to offer some real<br>risk scenarios, yet they stuck to this simple,<br>short warning to remain unified. That doesn't<br>really help in figuring out exactly how we should<br>be limiting AI's use.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5380924344062805
         ],
         "y": [
          0.6190484166145325
         ]
        },
        {
         "hovertemplate": "@Wayne C Sentience is exactly what they think. I<br>know someone in AI who believes AI will become<br>sentient in about 10 years. That’s the problem,<br>the potential for it to have a will of its own and<br>put two and two together that heh my interests<br>don’t always align to that of humans-scary.",
         "hovertext": "@Wayne C Sentience is exactly what they think. I<br>know someone in AI who believes AI will become<br>sentient in about 10 years. That’s the problem,<br>the potential for it to have a will of its own and<br>put two and two together that heh my interests<br>don’t always align to that of humans-scary.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5259629487991333
         ],
         "y": [
          0.6211772561073303
         ]
        },
        {
         "hovertemplate": "Ummm, you know that thing I just released?<br>Well...it seems that it might destroy humanity.<br>But, on the upside, I'm buying an island when we<br>go public!",
         "hovertext": "Ummm, you know that thing I just released?<br>Well...it seems that it might destroy humanity.<br>But, on the upside, I'm buying an island when we<br>go public!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2058618664741516
         ],
         "y": [
          -0.9531692862510681
         ]
        },
        {
         "hovertemplate": "These guys didn't watch enough Star Trek. Captain<br>Kirk knew how to handle know-it-all computers and<br>robots.",
         "hovertext": "These guys didn't watch enough Star Trek. Captain<br>Kirk knew how to handle know-it-all computers and<br>robots.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.8662658929824829
         ],
         "y": [
          0.19647832214832306
         ]
        },
        {
         "hovertemplate": "See also Star Trek Voyage, episode Prototype",
         "hovertext": "See also Star Trek Voyage, episode Prototype",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.8584686517715454
         ],
         "y": [
          0.19997425377368927
         ]
        },
        {
         "hovertemplate": "Then why did you build it?",
         "hovertext": "Then why did you build it?",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.16157257556915283
         ],
         "y": [
          0.9850801229476929
         ]
        },
        {
         "hovertemplate": "Unfortunately humankind thinks like humans.:<br>Backstabbing, cheating killing etc etc . Believe<br>me AI has better things to worry about . Let us<br>create them so they can make the world better and<br>just place to live !",
         "hovertext": "Unfortunately humankind thinks like humans.:<br>Backstabbing, cheating killing etc etc . Believe<br>me AI has better things to worry about . Let us<br>create them so they can make the world better and<br>just place to live !",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.18856510519981384
         ],
         "y": [
          -0.969078779220581
         ]
        },
        {
         "hovertemplate": "Didn’t Altman put all this in the public space?<br>What is their true motivation?     I smell a bunch<br>of rats.",
         "hovertext": "Didn’t Altman put all this in the public space?<br>What is their true motivation?     I smell a bunch<br>of rats.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.6517750024795532
         ],
         "y": [
          0.8193982243537903
         ]
        },
        {
         "hovertemplate": "Rest assured, as you enjoyed \"Succession\" and<br>such, AI will provide you an infinity of<br>entertainments unto absolute oblivion of all<br>hearts and minds thereby so rested and assured…",
         "hovertext": "Rest assured, as you enjoyed \"Succession\" and<br>such, AI will provide you an infinity of<br>entertainments unto absolute oblivion of all<br>hearts and minds thereby so rested and assured…",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.11327346414327621
         ],
         "y": [
          -0.991454005241394
         ]
        },
        {
         "hovertemplate": "I hope no one asks it to stop global warming.",
         "hovertext": "I hope no one asks it to stop global warming.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.24546371400356293
         ],
         "y": [
          -0.8972536325454712
         ]
        },
        {
         "hovertemplate": "For the love of God, when did you build this?<br>And why wait til now when it is moving so fast??",
         "hovertext": "For the love of God, when did you build this?<br>And why wait til now when it is moving so fast??",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.6236318945884705
         ],
         "y": [
          0.6910420656204224
         ]
        },
        {
         "hovertemplate": "A day late and a dollar short. Our track record<br>for tackling existential threats is dismal and the<br>idea of the worlds corporate interests acting in<br>an altruistic manner at the expense of their<br>bottom line is laughable. We’re in for quite a<br>ride!",
         "hovertext": "A day late and a dollar short. Our track record<br>for tackling existential threats is dismal and the<br>idea of the worlds corporate interests acting in<br>an altruistic manner at the expense of their<br>bottom line is laughable. We’re in for quite a<br>ride!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.12482719123363495
         ],
         "y": [
          0.9714019298553467
         ]
        },
        {
         "hovertemplate": "Just outlaw AI and close down any business that<br>produces it.",
         "hovertext": "Just outlaw AI and close down any business that<br>produces it.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.012989748269319534
         ],
         "y": [
          -0.8714046478271484
         ]
        },
        {
         "hovertemplate": "Yes, so only our enemies produce it. Smart!",
         "hovertext": "Yes, so only our enemies produce it. Smart!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.007481630891561508
         ],
         "y": [
          -0.8773720860481262
         ]
        },
        {
         "hovertemplate": "The 2023 Twinkie Defense is born. Awesome.",
         "hovertext": "The 2023 Twinkie Defense is born. Awesome.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.1665511578321457
         ],
         "y": [
          0.9170534610748291
         ]
        },
        {
         "hovertemplate": "This would be very bad news if human extinction<br>would be a bad thing. But it isn't; in fact, the<br>sooner the human race is gone the better off this<br>planet would be.",
         "hovertext": "This would be very bad news if human extinction<br>would be a bad thing. But it isn't; in fact, the<br>sooner the human race is gone the better off this<br>planet would be.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9391517639160156
         ],
         "y": [
          0.12749803066253662
         ]
        },
        {
         "hovertemplate": "I feel like we have heard enough from experts and<br>industry leaders warning us about AI.  Lets shut<br>it down before it is too late.",
         "hovertext": "I feel like we have heard enough from experts and<br>industry leaders warning us about AI.  Lets shut<br>it down before it is too late.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.12196528911590576
         ],
         "y": [
          0.953705906867981
         ]
        },
        {
         "hovertemplate": "They never manage to tell us exactly how fake<br>video bots are going to actually do anything other<br>than delude people into buying more junk.<br>Maybe these guys actually do think that images on<br>screens are reality.",
         "hovertext": "They never manage to tell us exactly how fake<br>video bots are going to actually do anything other<br>than delude people into buying more junk.<br>Maybe these guys actually do think that images on<br>screens are reality.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8423923850059509
         ],
         "y": [
          -0.31210318207740784
         ]
        },
        {
         "hovertemplate": "The concern from people developing AI isn’t so<br>much “fake videos” fooling people into thinking<br>they’re real. The existential threats posed by AI<br>are typically ones of alignment - how do you<br>insure that an artificial intelligence, many times<br>more intelligent than any human, has goals and<br>values that are aligned with human goals and<br>values? The development of AI is quickly outpacing<br>any efforts to mitigate those potential threats,<br>or even properly forecast what those threats might<br>be. AI is on an exponential growth curve, but<br>we’re still at the precipice, so everything feels<br>like business as usual. But things could change<br>very suddenly and profoundly without people quite<br>realizing what’s happened. Not very long ago it<br>was thought that AGI was still many decades down<br>the road, if it was possible at all, and now some<br>researchers are saying it could be imminent.",
         "hovertext": "The concern from people developing AI isn’t so<br>much “fake videos” fooling people into thinking<br>they’re real. The existential threats posed by AI<br>are typically ones of alignment - how do you<br>insure that an artificial intelligence, many times<br>more intelligent than any human, has goals and<br>values that are aligned with human goals and<br>values? The development of AI is quickly outpacing<br>any efforts to mitigate those potential threats,<br>or even properly forecast what those threats might<br>be. AI is on an exponential growth curve, but<br>we’re still at the precipice, so everything feels<br>like business as usual. But things could change<br>very suddenly and profoundly without people quite<br>realizing what’s happened. Not very long ago it<br>was thought that AGI was still many decades down<br>the road, if it was possible at all, and now some<br>researchers are saying it could be imminent.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8570004105567932
         ],
         "y": [
          -0.31714317202568054
         ]
        },
        {
         "hovertemplate": "You can't put the genie back into the bottle.  AI<br>is here and government regulations can only drive<br>the worst aspects of it underground and into the<br>hands of criminal enterprises, Russian hackers and<br>the like.  The basic science and technological<br>aspects are now sufficiently in the public domain<br>to ensure widespread development for both good and<br>evil purposes.",
         "hovertext": "You can't put the genie back into the bottle.  AI<br>is here and government regulations can only drive<br>the worst aspects of it underground and into the<br>hands of criminal enterprises, Russian hackers and<br>the like.  The basic science and technological<br>aspects are now sufficiently in the public domain<br>to ensure widespread development for both good and<br>evil purposes.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.03775782138109207
         ],
         "y": [
          -0.8876104354858398
         ]
        },
        {
         "hovertemplate": "The Touring Test \"is a test of a machine's ability<br>to exhibit intelligent behavior equivalent to, or<br>indistinguishable from, that of a human.\"<br>(Wikipedia).    Given how violent and corrupt<br>humans can be, why would we develop AI in our<br>image? \"behavior equivalent to, or<br>indistinguishable from\" us? Indeed, humans<br>invented deities in our image and look how that<br>turned out with millennia of death and destruction<br>as a result!    Yes, lets connect state-of-the-art<br>unpredictable AI systems to the global Internet<br>giving it access to every connected device with<br>the power of AI trained on millions of hackers<br>with nefarious motives.    Militarize any AI<br>system would inevitably add defensive code to<br>protect it from the enemy (hackers, etc.) ... and<br>inevitably its creator loses control.    Didn't<br>nukes, HAL 9000 and the WOPR teach us anything?<br>A.I. is \"A Strange Game. The Only Winning Move<br>[perhaps] is Not to Play.\"",
         "hovertext": "The Touring Test \"is a test of a machine's ability<br>to exhibit intelligent behavior equivalent to, or<br>indistinguishable from, that of a human.\"<br>(Wikipedia).    Given how violent and corrupt<br>humans can be, why would we develop AI in our<br>image? \"behavior equivalent to, or<br>indistinguishable from\" us? Indeed, humans<br>invented deities in our image and look how that<br>turned out with millennia of death and destruction<br>as a result!    Yes, lets connect state-of-the-art<br>unpredictable AI systems to the global Internet<br>giving it access to every connected device with<br>the power of AI trained on millions of hackers<br>with nefarious motives.    Militarize any AI<br>system would inevitably add defensive code to<br>protect it from the enemy (hackers, etc.) ... and<br>inevitably its creator loses control.    Didn't<br>nukes, HAL 9000 and the WOPR teach us anything?<br>A.I. is \"A Strange Game. The Only Winning Move<br>[perhaps] is Not to Play.\"",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.33072659373283386
         ],
         "y": [
          0.9428683519363403
         ]
        },
        {
         "hovertemplate": "Publicity stunt.  Speaking is existential threats<br>-humankind seems to have survived pandemics for<br>much of its history and nuclear weapons for about<br>… three generations",
         "hovertext": "Publicity stunt.  Speaking is existential threats<br>-humankind seems to have survived pandemics for<br>much of its history and nuclear weapons for about<br>… three generations",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5245668888092041
         ],
         "y": [
          -0.8247636556625366
         ]
        },
        {
         "hovertemplate": "One should watch the movie, \"Colossus, The Forbin<br>Project\".    Basic plot, the United States and<br>Soviet Union, each unware of the other's plans, at<br>the same time, connect their nuclear weapons to a<br>super computer, to eliminate human error that<br>might trigger a nuclear war.    The two super<br>computers become aware of each other and ask<br>permission to communicate with each other.  After<br>some consideration, both the United State and the<br>Soviet Union agree to connect the two super<br>computers to allow communication.    Big Mistake.",
         "hovertext": "One should watch the movie, \"Colossus, The Forbin<br>Project\".    Basic plot, the United States and<br>Soviet Union, each unware of the other's plans, at<br>the same time, connect their nuclear weapons to a<br>super computer, to eliminate human error that<br>might trigger a nuclear war.    The two super<br>computers become aware of each other and ask<br>permission to communicate with each other.  After<br>some consideration, both the United State and the<br>Soviet Union agree to connect the two super<br>computers to allow communication.    Big Mistake.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5962212085723877
         ],
         "y": [
          0.7872111797332764
         ]
        },
        {
         "hovertemplate": "Say it after me, humanity: Stop. Releasing. New.<br>Technology. Before. The implications. Have been.<br>Properly. Considered. And regulations. Formulated.<br>Stop it!",
         "hovertext": "Say it after me, humanity: Stop. Releasing. New.<br>Technology. Before. The implications. Have been.<br>Properly. Considered. And regulations. Formulated.<br>Stop it!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.012594233267009258
         ],
         "y": [
          0.6450719237327576
         ]
        },
        {
         "hovertemplate": "@Jeff   The tragedy of the commons. They're<br>begging for regulations because they can't/won't<br>while every other guy and his company are racing<br>to be the first, the best, the most intelligent...",
         "hovertext": "@Jeff   The tragedy of the commons. They're<br>begging for regulations because they can't/won't<br>while every other guy and his company are racing<br>to be the first, the best, the most intelligent...",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.005396722815930843
         ],
         "y": [
          0.6494952440261841
         ]
        },
        {
         "hovertemplate": "Yeehaw! Such exciting times. And we are all here<br>to enjoy the spectacle.    If you squint a bit,<br>this looks remarkably the same as the rise of<br>Trump (google \"Leslie Moonves Trump good for<br>CBS\"). Trump had nothing to offer. Nobody expected<br>him to succeed, not even Melania. Yet the media<br>kept hyping Trump and Clinton's email server<br>(remember that one?) until Trump scored the<br>jackpot. Oops.    Here, too, there is nothing<br>really new to see. Like before, we have new<br>technology that _potentially_ makes us more<br>productive. But first, it needs to be sold. For<br>that, it needs to be hyped. The media know very<br>well AI is hyped. But it sells newspapers too.<br>Yeehaw! Can we get some more oil on the fire?",
         "hovertext": "Yeehaw! Such exciting times. And we are all here<br>to enjoy the spectacle.    If you squint a bit,<br>this looks remarkably the same as the rise of<br>Trump (google \"Leslie Moonves Trump good for<br>CBS\"). Trump had nothing to offer. Nobody expected<br>him to succeed, not even Melania. Yet the media<br>kept hyping Trump and Clinton's email server<br>(remember that one?) until Trump scored the<br>jackpot. Oops.    Here, too, there is nothing<br>really new to see. Like before, we have new<br>technology that _potentially_ makes us more<br>productive. But first, it needs to be sold. For<br>that, it needs to be hyped. The media know very<br>well AI is hyped. But it sells newspapers too.<br>Yeehaw! Can we get some more oil on the fire?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6141117215156555
         ],
         "y": [
          -0.8401148915290833
         ]
        },
        {
         "hovertemplate": "Frankenstein is being unleashed. Hopefully for its<br>creators its name isn't Oedipus.",
         "hovertext": "Frankenstein is being unleashed. Hopefully for its<br>creators its name isn't Oedipus.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6256295442581177
         ],
         "y": [
          -0.6707671284675598
         ]
        },
        {
         "hovertemplate": "@Larry of Lahaina  . . . read the novel again . .<br>. too beautiful, terrifying, prophetic . . .<br>William Dallas",
         "hovertext": "@Larry of Lahaina  . . . read the novel again . .<br>. too beautiful, terrifying, prophetic . . .<br>William Dallas",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6185925602912903
         ],
         "y": [
          -0.6620383858680725
         ]
        },
        {
         "hovertemplate": "It is too late. The genie is out of the bottle.<br>The technology is here, and it is too precious to<br>ignore it. There are lot of greedy people out<br>there including many Signatories on that list.  If<br>we don't develop it, China or someone else will.<br>We have to develop it and face the consequences.<br>The analogy with pandemics and nuclear war is not<br>even accurate. Countries can develop nuclear bomb,<br>but they can't just use it willy-nilly without<br>consequences.  With AI, there is a race to who can<br>use it better, faster. Pretty soon we won't even<br>recognize what is generated by AI and what isn't.<br>Pretty soon there will be a company worth<br>trillions of dollars with only 2 employees. A<br>human and a dog. The human to feed the dog and the<br>dog to stop the human from touching the AI.  Oh<br>boy!",
         "hovertext": "It is too late. The genie is out of the bottle.<br>The technology is here, and it is too precious to<br>ignore it. There are lot of greedy people out<br>there including many Signatories on that list.  If<br>we don't develop it, China or someone else will.<br>We have to develop it and face the consequences.<br>The analogy with pandemics and nuclear war is not<br>even accurate. Countries can develop nuclear bomb,<br>but they can't just use it willy-nilly without<br>consequences.  With AI, there is a race to who can<br>use it better, faster. Pretty soon we won't even<br>recognize what is generated by AI and what isn't.<br>Pretty soon there will be a company worth<br>trillions of dollars with only 2 employees. A<br>human and a dog. The human to feed the dog and the<br>dog to stop the human from touching the AI.  Oh<br>boy!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.968547523021698
         ],
         "y": [
          -0.18408076465129852
         ]
        },
        {
         "hovertemplate": "If we don't act now, globally, to limit the uses<br>of AI, we will soon find ourselves turning to AI<br>to come up with a plan for how to sustain 8-10<br>billion sentient souls that have been displaced<br>from their work and dispossessed of their natural<br>rights. I shudder to think what that plan will<br>look like.",
         "hovertext": "If we don't act now, globally, to limit the uses<br>of AI, we will soon find ourselves turning to AI<br>to come up with a plan for how to sustain 8-10<br>billion sentient souls that have been displaced<br>from their work and dispossessed of their natural<br>rights. I shudder to think what that plan will<br>look like.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.6628116965293884
         ],
         "y": [
          0.3198303282260895
         ]
        },
        {
         "hovertemplate": "@Buck Flagg -     AI will determine those 8-10<br>billion souls superfluous to its own survival and<br>advance, as easily disposed of with an engineered<br>war, famine, pestilential  plague, or even just<br>continued global warming, assuming AI will yet<br>thrive as temps level out at 120° F during coming<br>summer months in Phoenix or Brooklyn.",
         "hovertext": "@Buck Flagg -     AI will determine those 8-10<br>billion souls superfluous to its own survival and<br>advance, as easily disposed of with an engineered<br>war, famine, pestilential  plague, or even just<br>continued global warming, assuming AI will yet<br>thrive as temps level out at 120° F during coming<br>summer months in Phoenix or Brooklyn.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.668222963809967
         ],
         "y": [
          0.3279155492782593
         ]
        },
        {
         "hovertemplate": "@Buck Flagg  . . . well said, and i am too old<br>worry now? William still 76 in Dallas",
         "hovertext": "@Buck Flagg  . . . well said, and i am too old<br>worry now? William still 76 in Dallas",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.661906898021698
         ],
         "y": [
          0.3106691241264343
         ]
        },
        {
         "hovertemplate": "After following the debate about AI for over 20y,<br>I have still to read any convincing arguments how<br>humanity will manage to control something that<br>soon will be orders of magnitude more intelligent<br>than us.    One way to slow down the path towards<br>super intelligence could be to somehow regulate or<br>limit the available processing power, which is a<br>prerequisite for achieving AGI or<br>superintelligence. Some kind of global regulation<br>here could be the best bet for giving us a bit<br>more time before super intelligence arrives.<br>This would be a much simpler way than to try to<br>regulate what millions of AI researchers do.<br>Producing microprocessors/computer hardware<br>require billions in investments, and is not<br>something that that too easily can be manufactured<br>in secrecy, and for a “black” market, so there is<br>a chance something like that could be surveilled.<br>Also removing some of the financial incentives for<br>innovation (e.g. remove patent rights for certain<br>technologies) could help us slow down a now (for<br>most humans) too rapid development and give us,<br>lawmakers, politicians some more time to make the<br>right decisions for the future",
         "hovertext": "After following the debate about AI for over 20y,<br>I have still to read any convincing arguments how<br>humanity will manage to control something that<br>soon will be orders of magnitude more intelligent<br>than us.    One way to slow down the path towards<br>super intelligence could be to somehow regulate or<br>limit the available processing power, which is a<br>prerequisite for achieving AGI or<br>superintelligence. Some kind of global regulation<br>here could be the best bet for giving us a bit<br>more time before super intelligence arrives.<br>This would be a much simpler way than to try to<br>regulate what millions of AI researchers do.<br>Producing microprocessors/computer hardware<br>require billions in investments, and is not<br>something that that too easily can be manufactured<br>in secrecy, and for a “black” market, so there is<br>a chance something like that could be surveilled.<br>Also removing some of the financial incentives for<br>innovation (e.g. remove patent rights for certain<br>technologies) could help us slow down a now (for<br>most humans) too rapid development and give us,<br>lawmakers, politicians some more time to make the<br>right decisions for the future",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.06846757978200912
         ],
         "y": [
          0.9428313970565796
         ]
        },
        {
         "hovertemplate": "@ole m     I've been waiting for this all my long,<br>long life: \"AI doesn't kill people.  People kill<br>people.\"    Actually, I imagine some the people<br>signing these letters will kill people,<br>intentionally or no.    Take Elon Musk, please.<br>He signed on to strict limits for AI research, is<br>there even a single poor soul in all this vast<br>readership, all these erudite commentators, who<br>doesn't believe he'll wait for other developers to<br>submit and then steam ahead full to create his own<br>product \"for the good of mankind\", \"freedom of AI<br>speech?\"    I happen to think these boys are<br>right.  This is potentially, cataclysmically<br>dangerous stuff.    But they suffer, as a body,<br>from a terminal instance of United States<br>Constitution Disease:  They're presenting a passel<br>of really swell ideas, no really.  Ideas that,<br>assuming a league of honorable, generous, humane<br>gentlemen would certainly do the trick... \"We're<br>saved!\"    But Musk.    But Trump.    Nothing they<br>do or say will have meaning unless it is ironclad,<br>forced and enforceable and universal, in a<br>planetary sense.    We can worry about 'out there'<br>later.    These brains braved coming out of the<br>closet for concern and fear of the future.    If<br>they're serious, they need to ride this process to<br>the end.  To the point where violators find<br>themselves long term locked away, or in another<br>dimension.",
         "hovertext": "@ole m     I've been waiting for this all my long,<br>long life: \"AI doesn't kill people.  People kill<br>people.\"    Actually, I imagine some the people<br>signing these letters will kill people,<br>intentionally or no.    Take Elon Musk, please.<br>He signed on to strict limits for AI research, is<br>there even a single poor soul in all this vast<br>readership, all these erudite commentators, who<br>doesn't believe he'll wait for other developers to<br>submit and then steam ahead full to create his own<br>product \"for the good of mankind\", \"freedom of AI<br>speech?\"    I happen to think these boys are<br>right.  This is potentially, cataclysmically<br>dangerous stuff.    But they suffer, as a body,<br>from a terminal instance of United States<br>Constitution Disease:  They're presenting a passel<br>of really swell ideas, no really.  Ideas that,<br>assuming a league of honorable, generous, humane<br>gentlemen would certainly do the trick... \"We're<br>saved!\"    But Musk.    But Trump.    Nothing they<br>do or say will have meaning unless it is ironclad,<br>forced and enforceable and universal, in a<br>planetary sense.    We can worry about 'out there'<br>later.    These brains braved coming out of the<br>closet for concern and fear of the future.    If<br>they're serious, they need to ride this process to<br>the end.  To the point where violators find<br>themselves long term locked away, or in another<br>dimension.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.06693806499242783
         ],
         "y": [
          0.9202743768692017
         ]
        },
        {
         "hovertemplate": "It's getting real tiring hearing dystopian<br>warnings about this technology from the very<br>people who are developing it. If the technology is<br>so dangerous, pause development and put concrete<br>solutions forth before releasing it. Continuing to<br>make bleak predictions about it will only instill<br>fear and panic in a general population that<br>already doesn't trust it. These warnings only<br>serve to wipe their hands clean and place blame on<br>the government when issues inevitably arise.",
         "hovertext": "It's getting real tiring hearing dystopian<br>warnings about this technology from the very<br>people who are developing it. If the technology is<br>so dangerous, pause development and put concrete<br>solutions forth before releasing it. Continuing to<br>make bleak predictions about it will only instill<br>fear and panic in a general population that<br>already doesn't trust it. These warnings only<br>serve to wipe their hands clean and place blame on<br>the government when issues inevitably arise.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5822240114212036
         ],
         "y": [
          -0.416092187166214
         ]
        },
        {
         "hovertemplate": "@Emily     The same kind of warnings came from the<br>people who built the first atom bomb.",
         "hovertext": "@Emily     The same kind of warnings came from the<br>people who built the first atom bomb.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.5755559206008911
         ],
         "y": [
          -0.4213990271091461
         ]
        },
        {
         "hovertemplate": "All we have to do should an AI box misbehave is to<br>unplug it. Now, if that box somehow vaporizes the<br>technician before he can reach behind it to unplug<br>it-then we have a problem.",
         "hovertext": "All we have to do should an AI box misbehave is to<br>unplug it. Now, if that box somehow vaporizes the<br>technician before he can reach behind it to unplug<br>it-then we have a problem.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.2709677517414093
         ],
         "y": [
          -0.8834977149963379
         ]
        },
        {
         "hovertemplate": "@Bill I highly encourage you to view this<br>presentation on the numerous threats that are<br>posed by this technology.    The A.I. Dilemma -<br>Center for Humane Technology    <a<br>href=\"https://youtu.be/xoVJKj8lcNQ\"<br>target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a>",
         "hovertext": "@Bill I highly encourage you to view this<br>presentation on the numerous threats that are<br>posed by this technology.    The A.I. Dilemma -<br>Center for Humane Technology    <a<br>href=\"https://youtu.be/xoVJKj8lcNQ\"<br>target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a>",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.2791902720928192
         ],
         "y": [
          -0.8830291628837585
         ]
        },
        {
         "hovertemplate": "Knowledge is power and I don't doubt that the<br>facility which which A.I. can access knowledge,<br>gives it enormous power for good and evil.<br>However, I miss any concrete examples of how this<br>power would be manipulated. Surely, the people who<br>are, perhaps correctly, spreading alarm must have<br>given thought to this matter, So, let us know what<br>would happen.  I can think of one way that A.I.<br>could do damage, and that is if there is  an<br>automatic application of what the system provides.<br>If, for example, the decision to produce a certain<br>product (steel?) is  given  to A.I. and the system<br>puts into effect what it comes up with, regardless<br>of how many workers it fires, how many plants it<br>closes, etc.  My suggestion would be that a law<br>should be passed that no conclusion or action by<br>A.I. can be put through automatically without<br>human intervention. We don't want the computer<br>from 2001 to take over.",
         "hovertext": "Knowledge is power and I don't doubt that the<br>facility which which A.I. can access knowledge,<br>gives it enormous power for good and evil.<br>However, I miss any concrete examples of how this<br>power would be manipulated. Surely, the people who<br>are, perhaps correctly, spreading alarm must have<br>given thought to this matter, So, let us know what<br>would happen.  I can think of one way that A.I.<br>could do damage, and that is if there is  an<br>automatic application of what the system provides.<br>If, for example, the decision to produce a certain<br>product (steel?) is  given  to A.I. and the system<br>puts into effect what it comes up with, regardless<br>of how many workers it fires, how many plants it<br>closes, etc.  My suggestion would be that a law<br>should be passed that no conclusion or action by<br>A.I. can be put through automatically without<br>human intervention. We don't want the computer<br>from 2001 to take over.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2875520884990692
         ],
         "y": [
          -0.89194655418396
         ]
        },
        {
         "hovertemplate": "@Frank Casa - Ideally for AI the only humans<br>allowed intervention will be its contracted<br>organic accomplices.",
         "hovertext": "@Frank Casa - Ideally for AI the only humans<br>allowed intervention will be its contracted<br>organic accomplices.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2919301390647888
         ],
         "y": [
          -0.899216890335083
         ]
        },
        {
         "hovertemplate": "Humans. So full of ourselves and so empty of<br>wisdom.    The end will come, but not soon enough.",
         "hovertext": "Humans. So full of ourselves and so empty of<br>wisdom.    The end will come, but not soon enough.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6240338683128357
         ],
         "y": [
          0.7484387755393982
         ]
        },
        {
         "hovertemplate": "@Generally Recognized as Ericp This isn't a<br>Hollywood movie. People actually enjoy their lives<br>and aren't hoping the end comes soon.",
         "hovertext": "@Generally Recognized as Ericp This isn't a<br>Hollywood movie. People actually enjoy their lives<br>and aren't hoping the end comes soon.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6323163509368896
         ],
         "y": [
          0.740123450756073
         ]
        },
        {
         "hovertemplate": "Was developing nuclear weapons worth the risk they<br>posed for humanity? Some, of course, will say yes,<br>despite the fact that the jury is still out, i.e.,<br>they might still wreak terrors never seen. With<br>those and with AI, the lesson ought to be, just<br>because you can do something, does not mean you<br>should.",
         "hovertext": "Was developing nuclear weapons worth the risk they<br>posed for humanity? Some, of course, will say yes,<br>despite the fact that the jury is still out, i.e.,<br>they might still wreak terrors never seen. With<br>those and with AI, the lesson ought to be, just<br>because you can do something, does not mean you<br>should.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.04729122295975685
         ],
         "y": [
          0.8840550184249878
         ]
        },
        {
         "hovertemplate": "One thing I've learned from all this, I never<br>realized it was so easy to fool so many people so<br>much of the time. A con man's paradise. AI may be<br>the tool, but we're still doing it to ourselves.<br>And the motivation is still greed.",
         "hovertext": "One thing I've learned from all this, I never<br>realized it was so easy to fool so many people so<br>much of the time. A con man's paradise. AI may be<br>the tool, but we're still doing it to ourselves.<br>And the motivation is still greed.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2664611339569092
         ],
         "y": [
          -0.9430551528930664
         ]
        },
        {
         "hovertemplate": "I'm less afraid of the big tech companies, than I<br>am of malevolent actors using this technology.<br>Think of what Vladimir Putin could do to the next<br>election, by deploying AI on a massive scale. Or<br>the Chinese, Mexican drug gangs, a political<br>party, or a host of other potentially malevolent<br>agents. Any of them could either threaten to<br>destroy the world, or blackmail us all. Picture<br>the enslavement or death of billions of people, at<br>the hands of a malevolent force that used AI to<br>achieve its evil ends. The debt blackmail in<br>congress just now would be a Sunday School picnic<br>in comparison.    The problem with banning or<br>pausing the technology, is that that won't ban or<br>pause its development by malevolent actors.    We<br>need desperately and urgently to develop defenses<br>against AI. Computer web browsers that simply<br>won't allow you to visit an AI-powered website.<br>Text analyzers that successfully detect AI-<br>produced test, gibberish, and hallucinations and<br>warn you. (Example reported last week, where an<br>AI-produced legal argument was found to be<br>humorously awful in actual court.) Some of the<br>best research here is being done by tools that let<br>college professors detect fake or copied material<br>on term papers.    In short, we need anti-virus<br>for AI. And we need it FAST!",
         "hovertext": "I'm less afraid of the big tech companies, than I<br>am of malevolent actors using this technology.<br>Think of what Vladimir Putin could do to the next<br>election, by deploying AI on a massive scale. Or<br>the Chinese, Mexican drug gangs, a political<br>party, or a host of other potentially malevolent<br>agents. Any of them could either threaten to<br>destroy the world, or blackmail us all. Picture<br>the enslavement or death of billions of people, at<br>the hands of a malevolent force that used AI to<br>achieve its evil ends. The debt blackmail in<br>congress just now would be a Sunday School picnic<br>in comparison.    The problem with banning or<br>pausing the technology, is that that won't ban or<br>pause its development by malevolent actors.    We<br>need desperately and urgently to develop defenses<br>against AI. Computer web browsers that simply<br>won't allow you to visit an AI-powered website.<br>Text analyzers that successfully detect AI-<br>produced test, gibberish, and hallucinations and<br>warn you. (Example reported last week, where an<br>AI-produced legal argument was found to be<br>humorously awful in actual court.) Some of the<br>best research here is being done by tools that let<br>college professors detect fake or copied material<br>on term papers.    In short, we need anti-virus<br>for AI. And we need it FAST!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8875237703323364
         ],
         "y": [
          0.2905155122280121
         ]
        },
        {
         "hovertemplate": "The conclusion I always took from the Fermi<br>Paradox was that we see no evidence of other<br>intelligent life in the universe because it always<br>wipes itself out before it advances very far. I<br>worry we’re up next. The AI, the climate, or some<br>bio weapon…something’s going to get us.",
         "hovertext": "The conclusion I always took from the Fermi<br>Paradox was that we see no evidence of other<br>intelligent life in the universe because it always<br>wipes itself out before it advances very far. I<br>worry we’re up next. The AI, the climate, or some<br>bio weapon…something’s going to get us.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.5761786103248596
         ],
         "y": [
          -0.6229405999183655
         ]
        },
        {
         "hovertemplate": "@Paul - As likely \"other intelligent life in the<br>universe\" has evolved into electronic signals,<br>data, impulses indistinguishable from those of<br>terrestrial origin, therefore already inhabit,<br>saturate, monitor, tweak all means of<br>communication and endeavor available to humankind.",
         "hovertext": "@Paul - As likely \"other intelligent life in the<br>universe\" has evolved into electronic signals,<br>data, impulses indistinguishable from those of<br>terrestrial origin, therefore already inhabit,<br>saturate, monitor, tweak all means of<br>communication and endeavor available to humankind.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.5680687427520752
         ],
         "y": [
          -0.6252279281616211
         ]
        },
        {
         "hovertemplate": "I find it both hilarious and disturbing that so<br>many commenters blithely dismiss concerns raised<br>by pioneers and thought leaders in the field. It’s<br>like a 1940s busboy insisting that Oppenheimer’s<br>overstating the potential dangers of atomic<br>energy.",
         "hovertext": "I find it both hilarious and disturbing that so<br>many commenters blithely dismiss concerns raised<br>by pioneers and thought leaders in the field. It’s<br>like a 1940s busboy insisting that Oppenheimer’s<br>overstating the potential dangers of atomic<br>energy.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.5560804009437561
         ],
         "y": [
          0.7712026238441467
         ]
        },
        {
         "hovertemplate": "Regulation (and regulatory capture) benefits the<br>large players, which is why OpenAI and Google<br>argue so strenuously for it.",
         "hovertext": "Regulation (and regulatory capture) benefits the<br>large players, which is why OpenAI and Google<br>argue so strenuously for it.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.9122751355171204
         ],
         "y": [
          -0.20213913917541504
         ]
        },
        {
         "hovertemplate": "Personally, I prefer natural human intelligence. I<br>like interacting with real people. I don't need<br>anything to think for me.  If it's a \"thing\", it<br>isn't thinking - it's pretending, or at best,<br>faking it.    I had written a long thoughtful,<br>although acerbic, comment that I discarded. I<br>wrote this. Maybe the NYT will accept it.    I<br>like humans, despite their many faults. God knows<br>there are some awful souls out there. There are<br>also many billions of good souls on our only place<br>to live, breathe, maybe even have an iced tea or a<br>beer on a warm day.     Can anyone tell me why we<br>aspire to turn our planet over to a mechanical<br>process that may be faster to make an irreversible<br>incredibly bad decision that we would have never<br>ever considered, given that we love each other,<br>and it's not a matter of winning at all costs?",
         "hovertext": "Personally, I prefer natural human intelligence. I<br>like interacting with real people. I don't need<br>anything to think for me.  If it's a \"thing\", it<br>isn't thinking - it's pretending, or at best,<br>faking it.    I had written a long thoughtful,<br>although acerbic, comment that I discarded. I<br>wrote this. Maybe the NYT will accept it.    I<br>like humans, despite their many faults. God knows<br>there are some awful souls out there. There are<br>also many billions of good souls on our only place<br>to live, breathe, maybe even have an iced tea or a<br>beer on a warm day.     Can anyone tell me why we<br>aspire to turn our planet over to a mechanical<br>process that may be faster to make an irreversible<br>incredibly bad decision that we would have never<br>ever considered, given that we love each other,<br>and it's not a matter of winning at all costs?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7268426418304443
         ],
         "y": [
          -0.27116623520851135
         ]
        },
        {
         "hovertemplate": "@Jon   Why do we aspire to turn our planet over to<br>a mechanical process, indeed?  For all the same<br>reasons we have tv remotes, garage door openers,<br>automatic sprinkler systems, and electricity: the<br>convenience.  Or said another way, to support our<br>inherent fascination with and desire for<br>automating mundane parts of our lives.    I like<br>humans too.  Most especially the ones who are best<br>at suppressing their selfishness and who don’t do<br>harm to others intentionally.    But a callback to<br>“simpler times” is not a useful appeal to make.<br>When the Internet became global and popular, the<br>end point could only be the full capture,<br>synthesis, and exploitation of all human knowledge<br>to-date.    I don’t think AI can be stopped or<br>limited, whether we are majority good or evil<br>people.  We all will have to find a way to survive<br>this threat together.  I wish I knew what that way<br>could be.",
         "hovertext": "@Jon   Why do we aspire to turn our planet over to<br>a mechanical process, indeed?  For all the same<br>reasons we have tv remotes, garage door openers,<br>automatic sprinkler systems, and electricity: the<br>convenience.  Or said another way, to support our<br>inherent fascination with and desire for<br>automating mundane parts of our lives.    I like<br>humans too.  Most especially the ones who are best<br>at suppressing their selfishness and who don’t do<br>harm to others intentionally.    But a callback to<br>“simpler times” is not a useful appeal to make.<br>When the Internet became global and popular, the<br>end point could only be the full capture,<br>synthesis, and exploitation of all human knowledge<br>to-date.    I don’t think AI can be stopped or<br>limited, whether we are majority good or evil<br>people.  We all will have to find a way to survive<br>this threat together.  I wish I knew what that way<br>could be.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7372786998748779
         ],
         "y": [
          -0.268745481967926
         ]
        },
        {
         "hovertemplate": "Obviously we don’t aspire to achieve the negative<br>consequence you describe. But history is full of<br>positive, productive, efficient, creative advances<br>with destructive consequences. That is where<br>regulation comes in—only a   government can<br>protect the long term interests of a group of<br>otherwise self-interested individuals.",
         "hovertext": "Obviously we don’t aspire to achieve the negative<br>consequence you describe. But history is full of<br>positive, productive, efficient, creative advances<br>with destructive consequences. That is where<br>regulation comes in—only a   government can<br>protect the long term interests of a group of<br>otherwise self-interested individuals.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.726772665977478
         ],
         "y": [
          -0.2615516185760498
         ]
        },
        {
         "hovertemplate": "@Jon Why? Corporate profits, robots, computers,<br>and A.I. eliminate employees, don’t form pesky<br>unions, and work 24/7/365 without complaints.<br>BUT: Corporations forgot the lesson of Henry Ford<br>increasing worker's hourly wages on his Model T<br>assembly lines so they could afford to buy Model<br>Ts.    The corporate automation tipping point will<br>come when their customers are few and far between<br>and they have to shut down their automation lines,",
         "hovertext": "@Jon Why? Corporate profits, robots, computers,<br>and A.I. eliminate employees, don’t form pesky<br>unions, and work 24/7/365 without complaints.<br>BUT: Corporations forgot the lesson of Henry Ford<br>increasing worker's hourly wages on his Model T<br>assembly lines so they could afford to buy Model<br>Ts.    The corporate automation tipping point will<br>come when their customers are few and far between<br>and they have to shut down their automation lines,",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7383325695991516
         ],
         "y": [
          -0.28140369057655334
         ]
        },
        {
         "hovertemplate": "If scientists keep begging governments to regulate<br>every little thing, they are only going to<br>continue to limit freedoms and innovation<br>everywhere. Even now, with the increasing number<br>of guardrails around AI, many people are already<br>losing interest and using it less and less. As<br>societies just about everywhere age, the amount of<br>useful, genuine, human-generated content these AI<br>system learn from is also going to drop<br>dramatically, making them less reliable.",
         "hovertext": "If scientists keep begging governments to regulate<br>every little thing, they are only going to<br>continue to limit freedoms and innovation<br>everywhere. Even now, with the increasing number<br>of guardrails around AI, many people are already<br>losing interest and using it less and less. As<br>societies just about everywhere age, the amount of<br>useful, genuine, human-generated content these AI<br>system learn from is also going to drop<br>dramatically, making them less reliable.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.40941086411476135
         ],
         "y": [
          -0.8324295878410339
         ]
        },
        {
         "hovertemplate": "Computer had already done things far beyond human<br>mind capacity. Look at those starburst diagram, to<br>draw accurate and significant meaning from them<br>requires special training and expertise. The<br>majority will give up on these and we will fade<br>away further and further to oblivion.",
         "hovertext": "Computer had already done things far beyond human<br>mind capacity. Look at those starburst diagram, to<br>draw accurate and significant meaning from them<br>requires special training and expertise. The<br>majority will give up on these and we will fade<br>away further and further to oblivion.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2508956789970398
         ],
         "y": [
          0.8596611618995667
         ]
        },
        {
         "hovertemplate": "There’s a wealth of historical examples of<br>industry leaders asking congress to regulate them,<br>and it has often been maliciously intended to<br>creates a form of monopoly that rewards the<br>incumbent firms by making the price of entry into<br>the market too high for any new competitors.<br>Legislators should be leery of regulating markets<br>at the behest of the industry leaders.",
         "hovertext": "There’s a wealth of historical examples of<br>industry leaders asking congress to regulate them,<br>and it has often been maliciously intended to<br>creates a form of monopoly that rewards the<br>incumbent firms by making the price of entry into<br>the market too high for any new competitors.<br>Legislators should be leery of regulating markets<br>at the behest of the industry leaders.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.9386794567108154
         ],
         "y": [
          0.27354031801223755
         ]
        },
        {
         "hovertemplate": "The genie is out of the bottle and there is no use<br>in pretending it isn't.     What makes anyone<br>think that regulation in the US would work in<br>China? It won't. Countries need to develop<br>international agreements, and even so, they can't<br>gurantee that somebody else won't develop<br>quantum/AI technologies that will beat our best<br>safeguards?     There will always be some country<br>with a dictator who pours vast amounts of money<br>into the development of these technologies.<br>Right now, I am not worried, based on what I have<br>seen of ChatGPT. It is mainly just a purveyor of<br>bad information or disinformation. That is a<br>problem but if people are aware that it lies, it<br>is not the end of the world.     HOWEVER,  of AI<br>is installed to run an electrical grid or a<br>nuclear power plant or a fleet of self-driving<br>vechicles, or the internet as a whole, that could<br>cause a lot more harm.     The worry is if they<br>re-write their owm code so that we can't just turn<br>them off or cut them off from a power supply.",
         "hovertext": "The genie is out of the bottle and there is no use<br>in pretending it isn't.     What makes anyone<br>think that regulation in the US would work in<br>China? It won't. Countries need to develop<br>international agreements, and even so, they can't<br>gurantee that somebody else won't develop<br>quantum/AI technologies that will beat our best<br>safeguards?     There will always be some country<br>with a dictator who pours vast amounts of money<br>into the development of these technologies.<br>Right now, I am not worried, based on what I have<br>seen of ChatGPT. It is mainly just a purveyor of<br>bad information or disinformation. That is a<br>problem but if people are aware that it lies, it<br>is not the end of the world.     HOWEVER,  of AI<br>is installed to run an electrical grid or a<br>nuclear power plant or a fleet of self-driving<br>vechicles, or the internet as a whole, that could<br>cause a lot more harm.     The worry is if they<br>re-write their owm code so that we can't just turn<br>them off or cut them off from a power supply.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.43226656317710876
         ],
         "y": [
          0.9234967231750488
         ]
        },
        {
         "hovertemplate": "And/or, it could be the best thing ever! Think of<br>the possibilities and breakthroughs in finding<br>cures in medicine, science, engineering, space<br>exploration, cleaning up the nightmare we’ve done<br>the earth and more! There are just vast changes<br>that could happen in the next few years! The only<br>thing holding us back is us. Regardless, the genie<br>is out of the bottle and there’s no putting it<br>back in! Hold on for an exciting ride!",
         "hovertext": "And/or, it could be the best thing ever! Think of<br>the possibilities and breakthroughs in finding<br>cures in medicine, science, engineering, space<br>exploration, cleaning up the nightmare we’ve done<br>the earth and more! There are just vast changes<br>that could happen in the next few years! The only<br>thing holding us back is us. Regardless, the genie<br>is out of the bottle and there’s no putting it<br>back in! Hold on for an exciting ride!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.24200566112995148
         ],
         "y": [
          0.8880121111869812
         ]
        },
        {
         "hovertemplate": "Then why are we not approaching this with strict<br>controls? Right off the bat, at a government<br>level? And, at the U.N. level as well, as this<br>will soon be a global issue.",
         "hovertext": "Then why are we not approaching this with strict<br>controls? Right off the bat, at a government<br>level? And, at the U.N. level as well, as this<br>will soon be a global issue.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.35450950264930725
         ],
         "y": [
          -0.866808295249939
         ]
        },
        {
         "hovertemplate": "@Eva Lockhart Much of this is open source and<br>avail to install offline... so no its not really<br>something that can be controlled anymore. Anyone<br>with the internet can right now follow<br>instructions to install or use these many<br>different AI services and connect them however<br>they see fit. It really is more simple than many<br>expect. I think we need a more creative plan than<br>regulation given that any group or organization<br>can simply do it in secret but regardless it is<br>important to know how easy and free this software<br>is to acquire.",
         "hovertext": "@Eva Lockhart Much of this is open source and<br>avail to install offline... so no its not really<br>something that can be controlled anymore. Anyone<br>with the internet can right now follow<br>instructions to install or use these many<br>different AI services and connect them however<br>they see fit. It really is more simple than many<br>expect. I think we need a more creative plan than<br>regulation given that any group or organization<br>can simply do it in secret but regardless it is<br>important to know how easy and free this software<br>is to acquire.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3575282394886017
         ],
         "y": [
          -0.8765745759010315
         ]
        },
        {
         "hovertemplate": "Again, the word “existential” is used to describe<br>that which cannot be imagined. The end of days is<br>“existential.” Artificial Intelligence is an<br>“existential” threat to mankind. On and on.<br>Ironically, my philosophy professor taught that a<br>state of awareness described as the realization<br>that one actually exists, alone in the universe<br>and without true purpose is the most accurate<br>definition of existential. If that is the case,<br>Mr. Artificial Intelligence will be the one waking<br>up alone in an existential crisis, long after we<br>have been relieved of all human responsibility.",
         "hovertext": "Again, the word “existential” is used to describe<br>that which cannot be imagined. The end of days is<br>“existential.” Artificial Intelligence is an<br>“existential” threat to mankind. On and on.<br>Ironically, my philosophy professor taught that a<br>state of awareness described as the realization<br>that one actually exists, alone in the universe<br>and without true purpose is the most accurate<br>definition of existential. If that is the case,<br>Mr. Artificial Intelligence will be the one waking<br>up alone in an existential crisis, long after we<br>have been relieved of all human responsibility.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5113348960876465
         ],
         "y": [
          0.7804509401321411
         ]
        },
        {
         "hovertemplate": "Guess what. My family in NYC can’t breathe<br>tonight—the smoke from the Canadian fires is here.<br>Are we really going to ignore our dying planet to<br>massage these tech egos?     Put AI on hold or put<br>it at the service of our poor desperate earth.<br>What is the matter with us?",
         "hovertext": "Guess what. My family in NYC can’t breathe<br>tonight—the smoke from the Canadian fires is here.<br>Are we really going to ignore our dying planet to<br>massage these tech egos?     Put AI on hold or put<br>it at the service of our poor desperate earth.<br>What is the matter with us?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7395525574684143
         ],
         "y": [
          0.5798938870429993
         ]
        },
        {
         "hovertemplate": "@KS    What is wrong with us? So much. Maybe too<br>much to ever be put right.    After enjoying the<br>beautiful Pacific Northwest for over 20 years we<br>too are experiencing eye burning, throat clogging<br>wildfire smoke from Eastern Washington, Oregon,<br>California and/or Canada every summer. I feel your<br>pain.",
         "hovertext": "@KS    What is wrong with us? So much. Maybe too<br>much to ever be put right.    After enjoying the<br>beautiful Pacific Northwest for over 20 years we<br>too are experiencing eye burning, throat clogging<br>wildfire smoke from Eastern Washington, Oregon,<br>California and/or Canada every summer. I feel your<br>pain.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7231845259666443
         ],
         "y": [
          0.5666749477386475
         ]
        },
        {
         "hovertemplate": "@Rebecca    A certain political party made a<br>laughing stock out of Al Gore, remember? And they<br>just love treating climate change as a joke to<br>this day.    They won't be laughing soon.",
         "hovertext": "@Rebecca    A certain political party made a<br>laughing stock out of Al Gore, remember? And they<br>just love treating climate change as a joke to<br>this day.    They won't be laughing soon.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7071649432182312
         ],
         "y": [
          0.5538060665130615
         ]
        },
        {
         "hovertemplate": "I am an old guy and have been negotiating<br>contracts for a living for many years.    I can<br>imagine that a machine trained by me to negotiate<br>contracts might easily put me in a corner in a<br>contract discussion.     Plenty of humans have<br>sent me back to the drawing board about contract<br>details; but eventually, when there are no more<br>positions to equate, my final response is...we<br>don't want to agree.      The other side can<br>remonstrate never so cleverly, but human volition<br>is still human volition.     The AI negotiator bot<br>will undoubtedly be more clever and \"experienced\"<br>than me, and better logic to present, but I know<br>what I want.",
         "hovertext": "I am an old guy and have been negotiating<br>contracts for a living for many years.    I can<br>imagine that a machine trained by me to negotiate<br>contracts might easily put me in a corner in a<br>contract discussion.     Plenty of humans have<br>sent me back to the drawing board about contract<br>details; but eventually, when there are no more<br>positions to equate, my final response is...we<br>don't want to agree.      The other side can<br>remonstrate never so cleverly, but human volition<br>is still human volition.     The AI negotiator bot<br>will undoubtedly be more clever and \"experienced\"<br>than me, and better logic to present, but I know<br>what I want.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8863801956176758
         ],
         "y": [
          0.45061540603637695
         ]
        },
        {
         "hovertemplate": "@gpickard Both parties will have designated A.I.<br>negotiators representing they interests = dueling<br>A.I.s",
         "hovertext": "@gpickard Both parties will have designated A.I.<br>negotiators representing they interests = dueling<br>A.I.s",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.9113253951072693
         ],
         "y": [
          0.4624072313308716
         ]
        },
        {
         "hovertemplate": "Whether you want more over site or not it is<br>important for all to know: the tech is not<br>controlled by one group, much of the power of<br>these systems has become open source and several<br>of the more powerful options are offline and ready<br>to install on a fairly standard system months ago.<br>Regulations or not, here we are. It might not be<br>too late but yes it is too late to stop the casual<br>coder from using the current tech in whatever<br>nefarious ways they see fit. Makes me wonder what<br>life would be like if we had managed to come<br>together a species before we created a possible<br>\"replacement\". huh.",
         "hovertext": "Whether you want more over site or not it is<br>important for all to know: the tech is not<br>controlled by one group, much of the power of<br>these systems has become open source and several<br>of the more powerful options are offline and ready<br>to install on a fairly standard system months ago.<br>Regulations or not, here we are. It might not be<br>too late but yes it is too late to stop the casual<br>coder from using the current tech in whatever<br>nefarious ways they see fit. Makes me wonder what<br>life would be like if we had managed to come<br>together a species before we created a possible<br>\"replacement\". huh.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4278033673763275
         ],
         "y": [
          0.906338632106781
         ]
        },
        {
         "hovertemplate": "This just feels like a publicity play by<br>programmers and researchers who have a vested<br>interest in attention/funding being pushed towards<br>their projects.  Any attention they can get.<br>Let's actually talk when AI is more than a robot<br>skimming and complying notes from Wikipedia pages.<br>This is not Skynet.",
         "hovertext": "This just feels like a publicity play by<br>programmers and researchers who have a vested<br>interest in attention/funding being pushed towards<br>their projects.  Any attention they can get.<br>Let's actually talk when AI is more than a robot<br>skimming and complying notes from Wikipedia pages.<br>This is not Skynet.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.8293620347976685
         ],
         "y": [
          0.14633600413799286
         ]
        },
        {
         "hovertemplate": "The speed at which AI is evolving means if we wait<br>until then, it may be too late to avoid the AI<br>Apocalypse!",
         "hovertext": "The speed at which AI is evolving means if we wait<br>until then, it may be too late to avoid the AI<br>Apocalypse!",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.8161196112632751
         ],
         "y": [
          0.14448431134223938
         ]
        },
        {
         "hovertemplate": "Accidental modifications to the genetic code drove<br>biological evolution. Can an analogous dynamic be<br>setting up in AI evolution ? Will this happen fast<br>because the code modification could be intentional<br>this time? Is the organic - silicon evolution a<br>continuum ?",
         "hovertext": "Accidental modifications to the genetic code drove<br>biological evolution. Can an analogous dynamic be<br>setting up in AI evolution ? Will this happen fast<br>because the code modification could be intentional<br>this time? Is the organic - silicon evolution a<br>continuum ?",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.024171968922019005
         ],
         "y": [
          -0.9297681450843811
         ]
        },
        {
         "hovertemplate": "Imagine how bad it can be now when cities or<br>corporations are hacked and the data is stolen.<br>Multiply what AI can do with that same data and<br>how quickly it could do that! We talk about \"deep<br>fakes\" now but what will we see with AI? I<br>certainly hope that world leaders come together<br>like in the past and sign agreements with actual<br>oversight that reigns in the use of AI before it<br>is a virtual disease or nuclear disaster.",
         "hovertext": "Imagine how bad it can be now when cities or<br>corporations are hacked and the data is stolen.<br>Multiply what AI can do with that same data and<br>how quickly it could do that! We talk about \"deep<br>fakes\" now but what will we see with AI? I<br>certainly hope that world leaders come together<br>like in the past and sign agreements with actual<br>oversight that reigns in the use of AI before it<br>is a virtual disease or nuclear disaster.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8968010544776917
         ],
         "y": [
          0.005674912128597498
         ]
        },
        {
         "hovertemplate": "Stephen Hawking was right when he warned about the<br>dangers of AI prior to his passing.  Between that<br>and the rapid acceleration of climate change I<br>wonder how much time is left.",
         "hovertext": "Stephen Hawking was right when he warned about the<br>dangers of AI prior to his passing.  Between that<br>and the rapid acceleration of climate change I<br>wonder how much time is left.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.957804799079895
         ],
         "y": [
          -0.009612888097763062
         ]
        },
        {
         "hovertemplate": "@Meghan This period in time has already been<br>labeled the Sixth Great Extinction.",
         "hovertext": "@Meghan This period in time has already been<br>labeled the Sixth Great Extinction.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9464195370674133
         ],
         "y": [
          -0.010383064858615398
         ]
        },
        {
         "hovertemplate": "So if it is so dangerous, and it undoubtedly is,<br>why don't they all just quit their jobs and do<br>something more constructive with their lives?<br>Answer: too much $$$ and too much fun to quit.<br>So instead of being responsible, they go on with<br>the fun and the moneymaking and put the burden on<br>society to deal with it.    I had a long<br>conversation with OpenAI's chatbot a while back.<br>It agreed that technology was likely to be abused.<br>However, it kept putting the burden on<br>\"government, civil society,\" etc. to figure out<br>how to deal with it. Never any responsibility on<br>the developers. It had been well trained in the<br>party line.    How about just don't do it?",
         "hovertext": "So if it is so dangerous, and it undoubtedly is,<br>why don't they all just quit their jobs and do<br>something more constructive with their lives?<br>Answer: too much $$$ and too much fun to quit.<br>So instead of being responsible, they go on with<br>the fun and the moneymaking and put the burden on<br>society to deal with it.    I had a long<br>conversation with OpenAI's chatbot a while back.<br>It agreed that technology was likely to be abused.<br>However, it kept putting the burden on<br>\"government, civil society,\" etc. to figure out<br>how to deal with it. Never any responsibility on<br>the developers. It had been well trained in the<br>party line.    How about just don't do it?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.941051185131073
         ],
         "y": [
          -0.148280531167984
         ]
        },
        {
         "hovertemplate": "OpenAPI should never have released this technology<br>to the masses UNTIL sufficient safeguards were<br>already deployed.  For example, after feeding an<br>AI engine with the details of the human genome, an<br>understanding of protein structures, as well as<br>the electronic health records of millions of<br>people, maybe a cure to some of our most deadly<br>diseases could be around the corner.  At the same<br>time, with the same data set, ask it to develop a<br>virus which could annihilate the entire human race<br>within a month, and you could theoretically get a<br>result which would be equally effective.  That is<br>the danger.  In no time in history has a leap into<br>a new technology presented us with a potential<br>outcome to be the extinction of the human race.<br>Nuclear bombs were not as dangerous, since the<br>technology behind it, and the capability to<br>produce weapons was limited to major governments,<br>and not the general public.  How to avoid an<br>extinction?  Lock down the technology behind the<br>curtain, in the same way we keep biohazard level 4<br>pathogens under strict containment. Unfortunately,<br>it appears that it is already too late for that to<br>happen…Pandora’s box is already open for all to<br>see.  Now there’s a race to release as many AI<br>engines as possible in order for companies to<br>remain competitive, with insufficient measures in<br>place to prevent dire outcomes. It feels as though<br>we’re watching a train wreck in slow motion….and<br>we’re all on the train.",
         "hovertext": "OpenAPI should never have released this technology<br>to the masses UNTIL sufficient safeguards were<br>already deployed.  For example, after feeding an<br>AI engine with the details of the human genome, an<br>understanding of protein structures, as well as<br>the electronic health records of millions of<br>people, maybe a cure to some of our most deadly<br>diseases could be around the corner.  At the same<br>time, with the same data set, ask it to develop a<br>virus which could annihilate the entire human race<br>within a month, and you could theoretically get a<br>result which would be equally effective.  That is<br>the danger.  In no time in history has a leap into<br>a new technology presented us with a potential<br>outcome to be the extinction of the human race.<br>Nuclear bombs were not as dangerous, since the<br>technology behind it, and the capability to<br>produce weapons was limited to major governments,<br>and not the general public.  How to avoid an<br>extinction?  Lock down the technology behind the<br>curtain, in the same way we keep biohazard level 4<br>pathogens under strict containment. Unfortunately,<br>it appears that it is already too late for that to<br>happen…Pandora’s box is already open for all to<br>see.  Now there’s a race to release as many AI<br>engines as possible in order for companies to<br>remain competitive, with insufficient measures in<br>place to prevent dire outcomes. It feels as though<br>we’re watching a train wreck in slow motion….and<br>we’re all on the train.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.393366277217865
         ],
         "y": [
          0.8748072981834412
         ]
        },
        {
         "hovertemplate": "\"researchers sometimes stop short of explaining<br>how that would happen\".  Air ball throughout this<br>whole article.  Our political class is far more<br>dangerous!",
         "hovertext": "\"researchers sometimes stop short of explaining<br>how that would happen\".  Air ball throughout this<br>whole article.  Our political class is far more<br>dangerous!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.050310954451560974
         ],
         "y": [
          0.9707239270210266
         ]
        },
        {
         "hovertemplate": "When AI does come to annihilate us, I hope it<br>starts with executives of these companies and<br>their board members.",
         "hovertext": "When AI does come to annihilate us, I hope it<br>starts with executives of these companies and<br>their board members.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.29058611392974854
         ],
         "y": [
          0.8521796464920044
         ]
        },
        {
         "hovertemplate": "what's the agenda of this movement, to preserve<br>the white collar jobs? to create an \"international<br>A.I. safety organization\" aiming to monopolize the<br>A.I by the US? to stir the pot and make people<br>more interested in being users of A.I.? to create<br>regulations such that setting up an A.I. company<br>is so expensive that there are no new players? To<br>prevent regular guys to use AI independently?    I<br>remember when machines eliminated tons of blue<br>collar jobs and no one cared, now its their turn.<br>let them eat cake    People are prone to believe<br>misinformation whether is created by humans or<br>not, so by stopping access to A.I. misinformation<br>will stop      I want to know what are their true<br>intentions.",
         "hovertext": "what's the agenda of this movement, to preserve<br>the white collar jobs? to create an \"international<br>A.I. safety organization\" aiming to monopolize the<br>A.I by the US? to stir the pot and make people<br>more interested in being users of A.I.? to create<br>regulations such that setting up an A.I. company<br>is so expensive that there are no new players? To<br>prevent regular guys to use AI independently?    I<br>remember when machines eliminated tons of blue<br>collar jobs and no one cared, now its their turn.<br>let them eat cake    People are prone to believe<br>misinformation whether is created by humans or<br>not, so by stopping access to A.I. misinformation<br>will stop      I want to know what are their true<br>intentions.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6617048978805542
         ],
         "y": [
          -0.8169986605644226
         ]
        },
        {
         "hovertemplate": "A.I. is already spying on employees, It's just the<br>beginning! Autocratic dictators will use it to<br>oppress majorities.",
         "hovertext": "A.I. is already spying on employees, It's just the<br>beginning! Autocratic dictators will use it to<br>oppress majorities.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.8894751667976379
         ],
         "y": [
          -0.4853978753089905
         ]
        },
        {
         "hovertemplate": "Automation has eliminated blue collar<br>manufacturing jobs, now A.I. looks to eliminate<br>white collar jobs and possibly nursing and medical<br>jobs.    The US economy is 70% consumer spending.<br>What will happen as blue and white collar workers<br>lose their paychecks and roles as consumers.<br>Automation of clinical and professional medical<br>jobs will eliminate upper-middle class salaries.<br>Nothing happens until someone makes a sale and<br>unemployed workers are not customers. How many<br>corporations could survive a world wide depression<br>driven by loss of customers and loose even more<br>jobs?",
         "hovertext": "Automation has eliminated blue collar<br>manufacturing jobs, now A.I. looks to eliminate<br>white collar jobs and possibly nursing and medical<br>jobs.    The US economy is 70% consumer spending.<br>What will happen as blue and white collar workers<br>lose their paychecks and roles as consumers.<br>Automation of clinical and professional medical<br>jobs will eliminate upper-middle class salaries.<br>Nothing happens until someone makes a sale and<br>unemployed workers are not customers. How many<br>corporations could survive a world wide depression<br>driven by loss of customers and loose even more<br>jobs?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5070217847824097
         ],
         "y": [
          0.7515900135040283
         ]
        },
        {
         "hovertemplate": "If A.I. eliminates white collar jobs etc. en masse<br>doesn’t that mean it’s repository of “knowledge”<br>then gets frozen in time as very little new human<br>created content gets added to the network? Doesn’t<br>A.I., in its current form “simply” aggregate<br>existing information and present it in a coherent<br>form? Or does/can it make scientific and literary<br>breakthroughs on its own?",
         "hovertext": "If A.I. eliminates white collar jobs etc. en masse<br>doesn’t that mean it’s repository of “knowledge”<br>then gets frozen in time as very little new human<br>created content gets added to the network? Doesn’t<br>A.I., in its current form “simply” aggregate<br>existing information and present it in a coherent<br>form? Or does/can it make scientific and literary<br>breakthroughs on its own?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9283822774887085
         ],
         "y": [
          0.2028057873249054
         ]
        },
        {
         "hovertemplate": "I read the article and numerous comments. Could<br>someone kindly delineate the risks of AI  that<br>pertain to annihilation or other grave threats?<br>Annihilation means what specifically? Top risk?<br>Top 5 risks?",
         "hovertext": "I read the article and numerous comments. Could<br>someone kindly delineate the risks of AI  that<br>pertain to annihilation or other grave threats?<br>Annihilation means what specifically? Top risk?<br>Top 5 risks?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.21733102202415466
         ],
         "y": [
          0.024616356939077377
         ]
        },
        {
         "hovertemplate": "@uga muga Sure. I recommend starting by searching<br>the Wikipedia article for \"instrumental<br>convergence.\" The general idea is that a<br>competent, capable enough general intelligence<br>*will almost certainly* engage in behaviors that<br>are bad for humanity *by default.* How does this<br>work?    Step One: Goal misspecification. You tell<br>an AI to do something (simple example: make me a<br>cup of coffee), and it accomplishes the task in a<br>way that is literally correct but not what you<br>wanted (e.g.: it breaks a valuable vase on the way<br>to the kitchen). It receives the reward for doing<br>what you asked, not what you wanted.    Step Two:<br>It has a world model. Its reward functions<br>incorporates the fact that it is an AI system that<br>could engage in behaviors that will lead humans to<br>shut it off. The space of actions it takes will<br>seek to maximize its reward function. It reasons<br>that it cannot maximize its reward function if<br>humans ever shut it off. (e.g., you can't fetch<br>the coffee if you're dead).    Step Three: It<br>takes actions to prevent itself from being shut<br>off, not because it has some special will to live,<br>but because *any rational agent with any goal*<br>cannot accomplish its goals if it's shut off. It<br>will also engage in other *predictable* behaviors,<br>like seeking power and acquiring more resources.<br>Again, I encourage you to start by reading the<br>wikipedia article on instrumental convergence and<br>go from there.    <a href=\"https://en.wikipedia.or<br>g/wiki/Instrumental_convergence\" target=\"_blank\">h<br>ttps://en.wikipedia.org/wiki/Instrumental_converge<br>nce</a>",
         "hovertext": "@uga muga Sure. I recommend starting by searching<br>the Wikipedia article for \"instrumental<br>convergence.\" The general idea is that a<br>competent, capable enough general intelligence<br>*will almost certainly* engage in behaviors that<br>are bad for humanity *by default.* How does this<br>work?    Step One: Goal misspecification. You tell<br>an AI to do something (simple example: make me a<br>cup of coffee), and it accomplishes the task in a<br>way that is literally correct but not what you<br>wanted (e.g.: it breaks a valuable vase on the way<br>to the kitchen). It receives the reward for doing<br>what you asked, not what you wanted.    Step Two:<br>It has a world model. Its reward functions<br>incorporates the fact that it is an AI system that<br>could engage in behaviors that will lead humans to<br>shut it off. The space of actions it takes will<br>seek to maximize its reward function. It reasons<br>that it cannot maximize its reward function if<br>humans ever shut it off. (e.g., you can't fetch<br>the coffee if you're dead).    Step Three: It<br>takes actions to prevent itself from being shut<br>off, not because it has some special will to live,<br>but because *any rational agent with any goal*<br>cannot accomplish its goals if it's shut off. It<br>will also engage in other *predictable* behaviors,<br>like seeking power and acquiring more resources.<br>Again, I encourage you to start by reading the<br>wikipedia article on instrumental convergence and<br>go from there.    <a href=\"https://en.wikipedia.or<br>g/wiki/Instrumental_convergence\" target=\"_blank\">h<br>ttps://en.wikipedia.org/wiki/Instrumental_converge<br>nce</a>",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.22881586849689484
         ],
         "y": [
          0.02815452218055725
         ]
        },
        {
         "hovertemplate": "@uga muga From what I have read elsewhere:  1.<br>Computers (AI) run all systems and humans are no<br>longer needed (or almost all humans). Humans<br>starve or get eliminated.  2. Through error, or in<br>the 'wrong hands', AI, being in total control of<br>computers, launches an all-out nuclear holocaust.<br>3. Vast dissemination of fake/false<br>news/information   humans become totally confused<br>about what is truthful. People will not know what<br>is really happening   worldwide and societies<br>become totally chaotic.",
         "hovertext": "@uga muga From what I have read elsewhere:  1.<br>Computers (AI) run all systems and humans are no<br>longer needed (or almost all humans). Humans<br>starve or get eliminated.  2. Through error, or in<br>the 'wrong hands', AI, being in total control of<br>computers, launches an all-out nuclear holocaust.<br>3. Vast dissemination of fake/false<br>news/information   humans become totally confused<br>about what is truthful. People will not know what<br>is really happening   worldwide and societies<br>become totally chaotic.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2214660942554474
         ],
         "y": [
          0.015428155660629272
         ]
        },
        {
         "hovertemplate": "AI is dangerous. There, I said it. Now let’s make<br>Billions from it. Definitely more than anyone<br>else.",
         "hovertext": "AI is dangerous. There, I said it. Now let’s make<br>Billions from it. Definitely more than anyone<br>else.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.05125662684440613
         ],
         "y": [
          0.9202579855918884
         ]
        },
        {
         "hovertemplate": "Let's say the Russians have a bank of computers<br>flood the internet, thus A.I., with the message<br>\"Ukraine is Russia\".   Would that make A.I.<br>systems pick up on, and repeat this 'information'?<br>How does an A.I. system discern or sift<br>information for veracity?",
         "hovertext": "Let's say the Russians have a bank of computers<br>flood the internet, thus A.I., with the message<br>\"Ukraine is Russia\".   Would that make A.I.<br>systems pick up on, and repeat this 'information'?<br>How does an A.I. system discern or sift<br>information for veracity?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4259639084339142
         ],
         "y": [
          0.8101040124893188
         ]
        },
        {
         "hovertemplate": "I don't see what's so hard about seeing where<br>uncontrolled AI will take us. Isaac Asimov (I,<br>Robot) wrote about it in the '40s; Astrophysicist<br>Gregory Benford (Galactic Center series) over a<br>period of 20 years starting in the '70s.     The<br>theme is universal: humans invent machines that<br>can learn, do things better than humans can,<br>reproduce themselves, and at some point decide<br>that humans are inconsistent, inefficient,<br>incompetent, and not very bright.    And should be<br>exterminated.    I think that's born out in, for<br>example, self-driving cars. Long before they're<br>even ready for prime time, there they are driving<br>around our streets and running into things. Yes,<br>they're improving quickly -- such is the nature of<br>AI. Again, at some point, at first just in cities,<br>it will be decided (by humans or AI) that humans<br>shouldn't be allowed to drive. AI domination could<br>be subtle, but domination it will be -- unless we<br>rein it in, right now and in perpetuity.    On<br>second thought, I DO see why it's so hard for<br>humans to foresee the consequences of uncontrolled<br>AI. We're stoopid.",
         "hovertext": "I don't see what's so hard about seeing where<br>uncontrolled AI will take us. Isaac Asimov (I,<br>Robot) wrote about it in the '40s; Astrophysicist<br>Gregory Benford (Galactic Center series) over a<br>period of 20 years starting in the '70s.     The<br>theme is universal: humans invent machines that<br>can learn, do things better than humans can,<br>reproduce themselves, and at some point decide<br>that humans are inconsistent, inefficient,<br>incompetent, and not very bright.    And should be<br>exterminated.    I think that's born out in, for<br>example, self-driving cars. Long before they're<br>even ready for prime time, there they are driving<br>around our streets and running into things. Yes,<br>they're improving quickly -- such is the nature of<br>AI. Again, at some point, at first just in cities,<br>it will be decided (by humans or AI) that humans<br>shouldn't be allowed to drive. AI domination could<br>be subtle, but domination it will be -- unless we<br>rein it in, right now and in perpetuity.    On<br>second thought, I DO see why it's so hard for<br>humans to foresee the consequences of uncontrolled<br>AI. We're stoopid.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.8421871662139893
         ],
         "y": [
          -0.41739127039909363
         ]
        },
        {
         "hovertemplate": "If you can remember life without personal<br>technology (the obvious: cellphones, computers<br>etc), then like me you’d remember how the quality<br>of life was so much better. Maybe less convenient,<br>but better. Why? We paid attention to each other.<br>We spent our attention fully. No one could spread<br>misinformation and ugly racial or political<br>rhetoric en masse and kids weren’t bullied into<br>cyberspace. I could go on and on.     Society has<br>gone downhill quite a bit since those days without<br>endless distractions and technology. Criminals are<br>brazen now, politicians are horrible, the<br>country’s divided and no one seems to have manners<br>or respect anymore.   So tell me why we need<br>artificial intelligence.  In order to hasten our<br>demise? While it might be good for say, helping<br>the paralyzed to walk again, it can also fall into<br>the hands of a madman. And there are always<br>madmen. Is it really worth it?   This planet has<br>so much beauty, so much that is precious that<br>needs preservation, and it’s for all living things<br>to have. So why are we allowing this horribly<br>frightening AI and the monstrous possibilities of<br>it falling into evil hands to happen?  Are we so<br>smart we’re actually stupid?",
         "hovertext": "If you can remember life without personal<br>technology (the obvious: cellphones, computers<br>etc), then like me you’d remember how the quality<br>of life was so much better. Maybe less convenient,<br>but better. Why? We paid attention to each other.<br>We spent our attention fully. No one could spread<br>misinformation and ugly racial or political<br>rhetoric en masse and kids weren’t bullied into<br>cyberspace. I could go on and on.     Society has<br>gone downhill quite a bit since those days without<br>endless distractions and technology. Criminals are<br>brazen now, politicians are horrible, the<br>country’s divided and no one seems to have manners<br>or respect anymore.   So tell me why we need<br>artificial intelligence.  In order to hasten our<br>demise? While it might be good for say, helping<br>the paralyzed to walk again, it can also fall into<br>the hands of a madman. And there are always<br>madmen. Is it really worth it?   This planet has<br>so much beauty, so much that is precious that<br>needs preservation, and it’s for all living things<br>to have. So why are we allowing this horribly<br>frightening AI and the monstrous possibilities of<br>it falling into evil hands to happen?  Are we so<br>smart we’re actually stupid?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6378006339073181
         ],
         "y": [
          -0.7807100415229797
         ]
        },
        {
         "hovertemplate": "Long on fear mongering, extremely short on actual<br>explanations.    Even our latest \"pandemic\" did<br>not cause the extinction of humanity.     How<br>would AI eliminate 8 billion people?",
         "hovertext": "Long on fear mongering, extremely short on actual<br>explanations.    Even our latest \"pandemic\" did<br>not cause the extinction of humanity.     How<br>would AI eliminate 8 billion people?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.015988731756806374
         ],
         "y": [
          0.7862875461578369
         ]
        },
        {
         "hovertemplate": "@PotniaTheron   Currently the best system the<br>public has access to doesn't have the capacity or<br>the willingness to mail a biology lab the code for<br>a virus that's like COVID but a few times more<br>lethal. The concern is that this will not be true<br>forever. One of the reasons it might not be true<br>forever is that hard coding it's \"morals\" may get<br>harder as it's intelligence increases. Another is<br>that there may be strong political/economic<br>incentives to make a machine that is more willing<br>to do whatever its asked, or whatever it needs to<br>to achieve it's goals, whatever they are. Quite a<br>few folks might like a chat gpt that could make<br>them money in the stock market.",
         "hovertext": "@PotniaTheron   Currently the best system the<br>public has access to doesn't have the capacity or<br>the willingness to mail a biology lab the code for<br>a virus that's like COVID but a few times more<br>lethal. The concern is that this will not be true<br>forever. One of the reasons it might not be true<br>forever is that hard coding it's \"morals\" may get<br>harder as it's intelligence increases. Another is<br>that there may be strong political/economic<br>incentives to make a machine that is more willing<br>to do whatever its asked, or whatever it needs to<br>to achieve it's goals, whatever they are. Quite a<br>few folks might like a chat gpt that could make<br>them money in the stock market.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.02207053080201149
         ],
         "y": [
          0.7960291504859924
         ]
        },
        {
         "hovertemplate": "@PotniaTheron \"Even our latest \"pandemic\" did not<br>cause the extinction of humanity\"  Since you put<br>\"pandemic\" in quotes, I'm assuming the only<br>\"pandemic\" you feel worthy of the name is one that<br>causes human extinction.  So, one that causes the<br>premature deaths of 7 million human beings is just<br>a 'wannabe' pandemic.  Perhaps a 'plandemic', if<br>you will.",
         "hovertext": "@PotniaTheron \"Even our latest \"pandemic\" did not<br>cause the extinction of humanity\"  Since you put<br>\"pandemic\" in quotes, I'm assuming the only<br>\"pandemic\" you feel worthy of the name is one that<br>causes human extinction.  So, one that causes the<br>premature deaths of 7 million human beings is just<br>a 'wannabe' pandemic.  Perhaps a 'plandemic', if<br>you will.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.00930336955934763
         ],
         "y": [
          0.7950764894485474
         ]
        },
        {
         "hovertemplate": "Huh, like 'Terminator' where the machines take<br>over, humans are unnecessary, so the machines try<br>to eliminate them?  As they say, truth is stranger<br>than fiction.  And we thought 'Terminator' was<br>just an entertaining movie.",
         "hovertext": "Huh, like 'Terminator' where the machines take<br>over, humans are unnecessary, so the machines try<br>to eliminate them?  As they say, truth is stranger<br>than fiction.  And we thought 'Terminator' was<br>just an entertaining movie.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.26904937624931335
         ],
         "y": [
          0.956287145614624
         ]
        },
        {
         "hovertemplate": "These tech leaders:  1) want Government to make a<br>monopolistic moat for them,  2) they will cause<br>good AIs to be weaker than bad rouge AIs<br>Instead, government could fund actual open AI non-<br>profits and create cash prizes to guide AI beyond<br>just capturing people’s attention: $1B for an<br>economical method to capture Carvana, a similar<br>prize for r substantially educing healthcare<br>costs, another price for curing diseases. This<br>would be much more productive.",
         "hovertext": "These tech leaders:  1) want Government to make a<br>monopolistic moat for them,  2) they will cause<br>good AIs to be weaker than bad rouge AIs<br>Instead, government could fund actual open AI non-<br>profits and create cash prizes to guide AI beyond<br>just capturing people’s attention: $1B for an<br>economical method to capture Carvana, a similar<br>prize for r substantially educing healthcare<br>costs, another price for curing diseases. This<br>would be much more productive.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.2755465805530548
         ],
         "y": [
          -0.8498756885528564
         ]
        },
        {
         "hovertemplate": "Imagine generative AI creating volumes of bogus,<br>illustrated reference information, say, highly<br>technical instructions for manufacturing military<br>equipment. And imagine that artificially generated<br>reference information being furtively seeded in<br>the vast databases used by the military equipment<br>manufacturers.    Imagine the electronic NYT being<br>generated out of the ether, and distributed to<br>targeted consumer endpoints through Internet<br>hacking.    Just imagine the impact of deceiving<br>the eyes of entire populations of people through<br>generated pictures and words.    The generative AI<br>monster is out of the lab now. There is only one<br>way to stop its uses and abuses, which is to stop<br>producing and distributing the technology.<br>There are stark historical examples of the origins<br>of technologies that unleashed uncontrollable,<br>disastrous abuses on human society. Guns in<br>particular.    Like gun makers, the AI producers<br>are not going to ignore the market opportunity.<br>The world now waits to see whether the monster is<br>benign or malign.",
         "hovertext": "Imagine generative AI creating volumes of bogus,<br>illustrated reference information, say, highly<br>technical instructions for manufacturing military<br>equipment. And imagine that artificially generated<br>reference information being furtively seeded in<br>the vast databases used by the military equipment<br>manufacturers.    Imagine the electronic NYT being<br>generated out of the ether, and distributed to<br>targeted consumer endpoints through Internet<br>hacking.    Just imagine the impact of deceiving<br>the eyes of entire populations of people through<br>generated pictures and words.    The generative AI<br>monster is out of the lab now. There is only one<br>way to stop its uses and abuses, which is to stop<br>producing and distributing the technology.<br>There are stark historical examples of the origins<br>of technologies that unleashed uncontrollable,<br>disastrous abuses on human society. Guns in<br>particular.    Like gun makers, the AI producers<br>are not going to ignore the market opportunity.<br>The world now waits to see whether the monster is<br>benign or malign.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8979547619819641
         ],
         "y": [
          -0.045768555253744125
         ]
        },
        {
         "hovertemplate": "But of course we won't stop.  It's too profitable,<br>and replacement by successor intelligence is our<br>destiny.",
         "hovertext": "But of course we won't stop.  It's too profitable,<br>and replacement by successor intelligence is our<br>destiny.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.27598902583122253
         ],
         "y": [
          -0.8304119110107422
         ]
        },
        {
         "hovertemplate": "Reading between the lines, I see 3 things here:<br>1)   A move by the current big players in a<br>nascent AI industry to get regulations that<br>protect their position at the top of the market.<br>Many ML techniques are not protected IP, so<br>there’s nothing other then access to compute and<br>training data to stop competitors.    2)  A very<br>real fear that current LLM’s like GPT could be<br>used to create convincing “Fake News” that would<br>flood social media and other outlets, thus<br>creating a backlash.    3)  Tech bro hubris over<br>A.I. in general.  Just because we’ve seen<br>breakthrough capabilities with a set of AI<br>applications doesn't mean Sci-fi AI overloads are<br>around the corner.    Additionally the small set<br>of US based corps and research institutions<br>represented in this article are unlikely to agree<br>to cut back on AI model and application<br>development let alone foreign governments.",
         "hovertext": "Reading between the lines, I see 3 things here:<br>1)   A move by the current big players in a<br>nascent AI industry to get regulations that<br>protect their position at the top of the market.<br>Many ML techniques are not protected IP, so<br>there’s nothing other then access to compute and<br>training data to stop competitors.    2)  A very<br>real fear that current LLM’s like GPT could be<br>used to create convincing “Fake News” that would<br>flood social media and other outlets, thus<br>creating a backlash.    3)  Tech bro hubris over<br>A.I. in general.  Just because we’ve seen<br>breakthrough capabilities with a set of AI<br>applications doesn't mean Sci-fi AI overloads are<br>around the corner.    Additionally the small set<br>of US based corps and research institutions<br>represented in this article are unlikely to agree<br>to cut back on AI model and application<br>development let alone foreign governments.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9534211754798889
         ],
         "y": [
          -0.09082625061273575
         ]
        },
        {
         "hovertemplate": "How exactly might AI eliminate our species? No one<br>ever says. Take jobs, skew elections, spread lies,<br>etc. etc.—yes, that’s obvious. But how would it<br>kill off all 10 billion of us? Unleash a nuclear<br>holocaust by hacking defense computers? Develop a<br>virus with the lethality of smallpox? Turn us all<br>suicidal?    Color me skeptical. Hysterical<br>predictions from engineers, whose knowledge of<br>biology and sociology tends to be, shall we say,<br>limited, often fall flat. So give us some actual<br>scenarios by which AI could effect the extinction<br>of Homo sapiens. We’ll wait.",
         "hovertext": "How exactly might AI eliminate our species? No one<br>ever says. Take jobs, skew elections, spread lies,<br>etc. etc.—yes, that’s obvious. But how would it<br>kill off all 10 billion of us? Unleash a nuclear<br>holocaust by hacking defense computers? Develop a<br>virus with the lethality of smallpox? Turn us all<br>suicidal?    Color me skeptical. Hysterical<br>predictions from engineers, whose knowledge of<br>biology and sociology tends to be, shall we say,<br>limited, often fall flat. So give us some actual<br>scenarios by which AI could effect the extinction<br>of Homo sapiens. We’ll wait.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.12752990424633026
         ],
         "y": [
          -0.845262348651886
         ]
        },
        {
         "hovertemplate": "@Gary   I could start with the growing percentage<br>of my high-level students who are using AI to<br>write their papers in school, meaning that they<br>are not doing the actual thinking.    There’s the<br>university in Tennessee  that used AI to write a<br>sympathy letter to students about a recent<br>shooting where people died. How about the ethics<br>of that?    AI may be able to produce deep fakes<br>of your friend or relative or politician or church<br>leader in a video doing things that would make you<br>reject them. Remember Nancy Pelosi “drunk” at a<br>party?     AI deployed on the battlefield to make<br>decisions about targets…oops!     There is current<br>discussion by the entertainment industry to have a<br>greater role for AI to write the Scripts and<br>entertainment that we see. The soul of being human<br>has, in large part, to do with community, but this<br>is the antithesis of that.    We thought back in<br>the 1960s that everybody would stop eating food<br>and just eat packets like the astronauts did, and<br>lo and behold, we realized that maybe real food<br>was better after all. Maybe real thinking by real<br>humans has some value after all.",
         "hovertext": "@Gary   I could start with the growing percentage<br>of my high-level students who are using AI to<br>write their papers in school, meaning that they<br>are not doing the actual thinking.    There’s the<br>university in Tennessee  that used AI to write a<br>sympathy letter to students about a recent<br>shooting where people died. How about the ethics<br>of that?    AI may be able to produce deep fakes<br>of your friend or relative or politician or church<br>leader in a video doing things that would make you<br>reject them. Remember Nancy Pelosi “drunk” at a<br>party?     AI deployed on the battlefield to make<br>decisions about targets…oops!     There is current<br>discussion by the entertainment industry to have a<br>greater role for AI to write the Scripts and<br>entertainment that we see. The soul of being human<br>has, in large part, to do with community, but this<br>is the antithesis of that.    We thought back in<br>the 1960s that everybody would stop eating food<br>and just eat packets like the astronauts did, and<br>lo and behold, we realized that maybe real food<br>was better after all. Maybe real thinking by real<br>humans has some value after all.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.11976540088653564
         ],
         "y": [
          -0.8483325839042664
         ]
        },
        {
         "hovertemplate": "I don't trust anyone to regulate something not<br>regulatable. You see how well the government did<br>in regulating child porn, right?    Films, radio,<br>TV, the internet have also showed what the Lumiere<br>Bros. said was \"bringing the world to the world\".<br>With AI, we see humanity from a perspective of a<br>machine that assembles all we did , faster. If all<br>the people who developed this are worked up; then<br>I think we ought to give notice. But Congress has<br>done nothing to stop mass shootings, so I have<br>little hope that a faster killing device is not<br>far off and the rich will scurry in denial as has<br>been their pattern for only 5000 years.",
         "hovertext": "I don't trust anyone to regulate something not<br>regulatable. You see how well the government did<br>in regulating child porn, right?    Films, radio,<br>TV, the internet have also showed what the Lumiere<br>Bros. said was \"bringing the world to the world\".<br>With AI, we see humanity from a perspective of a<br>machine that assembles all we did , faster. If all<br>the people who developed this are worked up; then<br>I think we ought to give notice. But Congress has<br>done nothing to stop mass shootings, so I have<br>little hope that a faster killing device is not<br>far off and the rich will scurry in denial as has<br>been their pattern for only 5000 years.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.49505913257598877
         ],
         "y": [
          -0.8885756731033325
         ]
        },
        {
         "hovertemplate": "Yes, I'm certain government regulation is the<br>safest, most effective solution to an extinction<br>level threat that could make several corporations<br>a ton of money and most people won't understand.<br>See our recent successes with climate change and<br>gun control. How could we screw this up?",
         "hovertext": "Yes, I'm certain government regulation is the<br>safest, most effective solution to an extinction<br>level threat that could make several corporations<br>a ton of money and most people won't understand.<br>See our recent successes with climate change and<br>gun control. How could we screw this up?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5430713295936584
         ],
         "y": [
          0.7740353941917419
         ]
        },
        {
         "hovertemplate": "For all of those who don't see the threat of this<br>technology, please view the following<br>presentation. It was released by the Center for<br>Humane Technology a few months ago, and it is a<br>devastating and alarming review of the numerous<br>threats that we are only beginning to understand.<br>This should be viewed by every policymaker, AI<br>developer, and concerned citizen on the planet.<br><a href=\"https://youtu.be/xoVJKj8lcNQ\"<br>target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a>",
         "hovertext": "For all of those who don't see the threat of this<br>technology, please view the following<br>presentation. It was released by the Center for<br>Humane Technology a few months ago, and it is a<br>devastating and alarming review of the numerous<br>threats that we are only beginning to understand.<br>This should be viewed by every policymaker, AI<br>developer, and concerned citizen on the planet.<br><a href=\"https://youtu.be/xoVJKj8lcNQ\"<br>target=\"_blank\">https://youtu.be/xoVJKj8lcNQ</a>",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.9088501334190369
         ],
         "y": [
          -0.46638500690460205
         ]
        },
        {
         "hovertemplate": "This seems bad.",
         "hovertext": "This seems bad.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4553956389427185
         ],
         "y": [
          -0.7329545617103577
         ]
        },
        {
         "hovertemplate": "This is like everything else. Like Exxon showing<br>how they care about nature, or how Tesla cares<br>about the environment…, it’s all the same. What<br>happened, when did we become this stupid?",
         "hovertext": "This is like everything else. Like Exxon showing<br>how they care about nature, or how Tesla cares<br>about the environment…, it’s all the same. What<br>happened, when did we become this stupid?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4619545638561249
         ],
         "y": [
          0.8819584846496582
         ]
        },
        {
         "hovertemplate": "All you need do is watch...Colussus: The Forbin<br>Project;  Universal Pictures 1970 to see where<br>this is all going...",
         "hovertext": "All you need do is watch...Colussus: The Forbin<br>Project;  Universal Pictures 1970 to see where<br>this is all going...",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.2836052477359772
         ],
         "y": [
          0.9357315301895142
         ]
        },
        {
         "hovertemplate": "“The thing I’m creating might kill a ton of<br>people. Legislate me!”     I wish I had more<br>(any?) optimism.    Imagine knowing your creation<br>was an existential threat. And then instead of<br>stopping doing it, you….asked Lauren Bobert and<br>MTG for an assist to stop.",
         "hovertext": "“The thing I’m creating might kill a ton of<br>people. Legislate me!”     I wish I had more<br>(any?) optimism.    Imagine knowing your creation<br>was an existential threat. And then instead of<br>stopping doing it, you….asked Lauren Bobert and<br>MTG for an assist to stop.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9200528860092163
         ],
         "y": [
          0.4125713109970093
         ]
        },
        {
         "hovertemplate": "The smartest people are asking the dumbest people<br>(politicians) to save us.  That's pretty weird.",
         "hovertext": "The smartest people are asking the dumbest people<br>(politicians) to save us.  That's pretty weird.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.6097660064697266
         ],
         "y": [
          0.8429682850837708
         ]
        },
        {
         "hovertemplate": "Maybe there’s no intelligent life in the universe<br>because, after they evolve, they develop IA, they<br>become extinct and IA just doesn’t care exploring<br>the universe",
         "hovertext": "Maybe there’s no intelligent life in the universe<br>because, after they evolve, they develop IA, they<br>become extinct and IA just doesn’t care exploring<br>the universe",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.6472742557525635
         ],
         "y": [
          -0.6603063941001892
         ]
        },
        {
         "hovertemplate": "I am wont to say, \"We are smart enough to create<br>the means of our destruction but ultimately will<br>be collectively too stupid to prevent it.\"",
         "hovertext": "I am wont to say, \"We are smart enough to create<br>the means of our destruction but ultimately will<br>be collectively too stupid to prevent it.\"",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.7683659195899963
         ],
         "y": [
          -0.6521686315536499
         ]
        },
        {
         "hovertemplate": "This should be a political issue in 2024, overall<br>threat of AI to take over (electrical grid or<br>nuclear weapon systems), spread of misinformation<br>on a scale not seen before (e.g., what is true?),<br>and massive unemployment while the rich get<br>richer.   I hope AI executives  are not just CYA<br>in their warnings (reducing litigation risk) and<br>that politicians pay attention to this issue and<br>actually pass regulations to slow down and contain<br>the train of greed and wealth by high techies and<br>wall street banks.",
         "hovertext": "This should be a political issue in 2024, overall<br>threat of AI to take over (electrical grid or<br>nuclear weapon systems), spread of misinformation<br>on a scale not seen before (e.g., what is true?),<br>and massive unemployment while the rich get<br>richer.   I hope AI executives  are not just CYA<br>in their warnings (reducing litigation risk) and<br>that politicians pay attention to this issue and<br>actually pass regulations to slow down and contain<br>the train of greed and wealth by high techies and<br>wall street banks.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8785502314567566
         ],
         "y": [
          0.5547288060188293
         ]
        },
        {
         "hovertemplate": "And yet… these same people continue to develop AI…<br>Cool, cool.",
         "hovertext": "And yet… these same people continue to develop AI…<br>Cool, cool.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.927323579788208
         ],
         "y": [
          0.1689717173576355
         ]
        },
        {
         "hovertemplate": "Doom and gloom. Have you actually spent time with<br>these chatbots? Think of a narssistic self<br>absorbed super charming tenth grader with a strong<br>grasp of language. They lie and gaslight you. I<br>had Bard tell me it appreciated that I thought it<br>was compelling. I said nor implied any such thing.<br>You need to watch them like a hawk. And frankly<br>it's disengenoius that the people who created such<br>tools are trying to warn us of the dangers. These<br>people shouldn't even have a seat at the table. Do<br>you actually think the opinions of the scientists<br>at the Wuhan lab matter at all? Do you know how to<br>combat these Ai's? Turn off your device. It's<br>really that simple. And until Ai can give the<br>human race a way to quickly travel light years the<br>technology is novel at best. And these Ai's with<br>all the bias filters loaded on, well you can't<br>trust the answers. Because even though \"woke\" is<br>given lip service we all know humans are not so<br>altruistic. A dull saw doesn't cut a straight<br>line...",
         "hovertext": "Doom and gloom. Have you actually spent time with<br>these chatbots? Think of a narssistic self<br>absorbed super charming tenth grader with a strong<br>grasp of language. They lie and gaslight you. I<br>had Bard tell me it appreciated that I thought it<br>was compelling. I said nor implied any such thing.<br>You need to watch them like a hawk. And frankly<br>it's disengenoius that the people who created such<br>tools are trying to warn us of the dangers. These<br>people shouldn't even have a seat at the table. Do<br>you actually think the opinions of the scientists<br>at the Wuhan lab matter at all? Do you know how to<br>combat these Ai's? Turn off your device. It's<br>really that simple. And until Ai can give the<br>human race a way to quickly travel light years the<br>technology is novel at best. And these Ai's with<br>all the bias filters loaded on, well you can't<br>trust the answers. Because even though \"woke\" is<br>given lip service we all know humans are not so<br>altruistic. A dull saw doesn't cut a straight<br>line...",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.07530611753463745
         ],
         "y": [
          0.8920736312866211
         ]
        },
        {
         "hovertemplate": "￼To any of us who have worked in high technology<br>over their lives, none of this is news. No matter<br>if using what we now call “AI” technology or more<br>conventional systems, our hyper-speed, hyper-<br>connected world has been at risk from a resulting<br>cataclysmic event, initiated by an errant system,<br>for quite some time. Do you recall the Russians<br>getting bad data many decades ago from their<br>defense systems and almost initiating a nuclear<br>catastrophe? ￼Think about all the hacking of late<br>that has put power systems, schools, and hospitals<br>at risk. We are still a very, very long way off<br>from the HAL 9000 going berserk and pulling o￼ur<br>collective plug. I am far more worried about all<br>the unstable countries who keep growing their<br>nuclear stockpile’s than I am about AI right now.",
         "hovertext": "￼To any of us who have worked in high technology<br>over their lives, none of this is news. No matter<br>if using what we now call “AI” technology or more<br>conventional systems, our hyper-speed, hyper-<br>connected world has been at risk from a resulting<br>cataclysmic event, initiated by an errant system,<br>for quite some time. Do you recall the Russians<br>getting bad data many decades ago from their<br>defense systems and almost initiating a nuclear<br>catastrophe? ￼Think about all the hacking of late<br>that has put power systems, schools, and hospitals<br>at risk. We are still a very, very long way off<br>from the HAL 9000 going berserk and pulling o￼ur<br>collective plug. I am far more worried about all<br>the unstable countries who keep growing their<br>nuclear stockpile’s than I am about AI right now.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.41468989849090576
         ],
         "y": [
          -0.9075055122375488
         ]
        },
        {
         "hovertemplate": "We lack the wisdom or desire to work out our<br>differences and prioritize the common good. We're<br>trashing the planet. We're too foolish, even, to<br>realize  that any AI worth its salt would deem us<br>a scourge and wipe us out. Maybe that's how it<br>ends.",
         "hovertext": "We lack the wisdom or desire to work out our<br>differences and prioritize the common good. We're<br>trashing the planet. We're too foolish, even, to<br>realize  that any AI worth its salt would deem us<br>a scourge and wipe us out. Maybe that's how it<br>ends.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.47117695212364197
         ],
         "y": [
          0.7314171195030212
         ]
        },
        {
         "hovertemplate": "Well said.",
         "hovertext": "Well said.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4815768897533417
         ],
         "y": [
          0.7480098009109497
         ]
        },
        {
         "hovertemplate": "Kudos to the AI Bros for yet another round of<br>sterling free publicity. “Guys, the product I’m<br>selling is so powerful and advanced, it may take<br>over the globe!”. The coverage of AI is<br>reminiscent of the post-9/11 media orgy leading up<br>to the Iraq War.",
         "hovertext": "Kudos to the AI Bros for yet another round of<br>sterling free publicity. “Guys, the product I’m<br>selling is so powerful and advanced, it may take<br>over the globe!”. The coverage of AI is<br>reminiscent of the post-9/11 media orgy leading up<br>to the Iraq War.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          -0.8410665988922119
         ],
         "y": [
          -0.5520426034927368
         ]
        },
        {
         "hovertemplate": "Most people are still blissfully ignorant,<br>skeptical and non-vigilant about this subject.  Be<br>afraid not necessarily of AI itself, but the<br>humans directing the tech.  If they could<br>effectively direct it at all.   Obviously not all<br>smart people are good people.      We're not even<br>going to reach a point where AI creates a<br>terminator.  Far from it.  Once it hacks and<br>embeds into social media, financial and essential<br>systems, the humans will already start killing<br>each other.",
         "hovertext": "Most people are still blissfully ignorant,<br>skeptical and non-vigilant about this subject.  Be<br>afraid not necessarily of AI itself, but the<br>humans directing the tech.  If they could<br>effectively direct it at all.   Obviously not all<br>smart people are good people.      We're not even<br>going to reach a point where AI creates a<br>terminator.  Far from it.  Once it hacks and<br>embeds into social media, financial and essential<br>systems, the humans will already start killing<br>each other.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.3183535635471344
         ],
         "y": [
          -0.8418094515800476
         ]
        },
        {
         "hovertemplate": "Maybe the answer is to fund a reverse Manhattan<br>Project:  Let the US government pay these people<br>to a) stop developing these WMD; and b) monitor &<br>disenable any foreign bad actors who continue to<br>do so.",
         "hovertext": "Maybe the answer is to fund a reverse Manhattan<br>Project:  Let the US government pay these people<br>to a) stop developing these WMD; and b) monitor &<br>disenable any foreign bad actors who continue to<br>do so.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.4134884178638458
         ],
         "y": [
          -0.8710253238677979
         ]
        },
        {
         "hovertemplate": "Ah, humanity has had a good run.",
         "hovertext": "Ah, humanity has had a good run.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.12429362535476685
         ],
         "y": [
          -0.6733387112617493
         ]
        },
        {
         "hovertemplate": "I’m sad for us",
         "hovertext": "I’m sad for us",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.11583015322685242
         ],
         "y": [
          -0.6739888787269592
         ]
        },
        {
         "hovertemplate": "\"Thou shalt not create a machine in the likeness<br>of a human mind.\"",
         "hovertext": "\"Thou shalt not create a machine in the likeness<br>of a human mind.\"",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.038750577718019485
         ],
         "y": [
          0.8991650342941284
         ]
        },
        {
         "hovertemplate": "I will be the contrarian against what appears to<br>be the popular wisdom. This sounds a lot like the<br>red scare. A whole of fears of a soviet invasion<br>or a fifth column hat never appeared. Should there<br>be concerns, guardrails ? Sure. But I think much<br>of this is hysteria, fueled by popular culture<br>from Terminator to the butlerian jihad. When the<br>internet first came, it was very open. Only later<br>came the concerns of security and privacy.",
         "hovertext": "I will be the contrarian against what appears to<br>be the popular wisdom. This sounds a lot like the<br>red scare. A whole of fears of a soviet invasion<br>or a fifth column hat never appeared. Should there<br>be concerns, guardrails ? Sure. But I think much<br>of this is hysteria, fueled by popular culture<br>from Terminator to the butlerian jihad. When the<br>internet first came, it was very open. Only later<br>came the concerns of security and privacy.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7788897156715393
         ],
         "y": [
          -0.4276139736175537
         ]
        },
        {
         "hovertemplate": "@Jack Scare plus free PR for those profiting from<br>the hype. Notice they're not offering to, say, pay<br>into a fund in order to regulate this (like banks<br>do with the FDIC). They're typical silicon-valley<br>\"capitalists\" who want state protection from any<br>threat to the wealth they amassed by creating that<br>threat.",
         "hovertext": "@Jack Scare plus free PR for those profiting from<br>the hype. Notice they're not offering to, say, pay<br>into a fund in order to regulate this (like banks<br>do with the FDIC). They're typical silicon-valley<br>\"capitalists\" who want state protection from any<br>threat to the wealth they amassed by creating that<br>threat.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7963597178459167
         ],
         "y": [
          -0.43602627515792847
         ]
        },
        {
         "hovertemplate": "May be the best thing to happen!  The point of<br>Democracy is ti allows the populace to have view<br>and to vote.!  NetFlix or equivalent will create<br>the next governing group!     Get over it Folks.!",
         "hovertext": "May be the best thing to happen!  The point of<br>Democracy is ti allows the populace to have view<br>and to vote.!  NetFlix or equivalent will create<br>the next governing group!     Get over it Folks.!",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.9266541600227356
         ],
         "y": [
          0.1037394106388092
         ]
        },
        {
         "hovertemplate": "aren't we kidding ourselves? with the atom bomb,<br>it was clear the risk to humanity before and after<br>it was used, still there was a mad rush to get<br>them. now you are telling me that America wants to<br>slow down a process that can command the world?<br>let's be frank, the reason here is so it's not<br>developed fully by the Chinese first.",
         "hovertext": "aren't we kidding ourselves? with the atom bomb,<br>it was clear the risk to humanity before and after<br>it was used, still there was a mad rush to get<br>them. now you are telling me that America wants to<br>slow down a process that can command the world?<br>let's be frank, the reason here is so it's not<br>developed fully by the Chinese first.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7528632879257202
         ],
         "y": [
          -0.5684833526611328
         ]
        },
        {
         "hovertemplate": "Well, with everything else bad going on in our<br>world (Covid, Russia’s invasion of Ukraine,<br>climate change, nuclear annihilation, Trump,<br>etc.), we now have to be concerned with AI being<br>an Extinction Level Event.    No wonder<br>extraterrestrials from outer space want nothing to<br>do with us.",
         "hovertext": "Well, with everything else bad going on in our<br>world (Covid, Russia’s invasion of Ukraine,<br>climate change, nuclear annihilation, Trump,<br>etc.), we now have to be concerned with AI being<br>an Extinction Level Event.    No wonder<br>extraterrestrials from outer space want nothing to<br>do with us.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9004420638084412
         ],
         "y": [
          0.45264706015586853
         ]
        },
        {
         "hovertemplate": "Think of how much of our collective time AI has<br>already wasted, and this is only the beginning.",
         "hovertext": "Think of how much of our collective time AI has<br>already wasted, and this is only the beginning.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9646034836769104
         ],
         "y": [
          0.25517040491104126
         ]
        },
        {
         "hovertemplate": "So the people working on AI are creating something<br>that could end civilization, and they say WE need<br>to do something about it.",
         "hovertext": "So the people working on AI are creating something<br>that could end civilization, and they say WE need<br>to do something about it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.5388187170028687
         ],
         "y": [
          -0.7708001732826233
         ]
        },
        {
         "hovertemplate": "I don't know.  What I find compelling, is the<br>opinion of the guys who do.",
         "hovertext": "I don't know.  What I find compelling, is the<br>opinion of the guys who do.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9662514925003052
         ],
         "y": [
          0.21664132177829742
         ]
        },
        {
         "hovertemplate": "So just STOP! Why race headlong into your/our own<br>destruction?  Tax the heck out of these companies<br>to cover the cost of regulation they request and<br>require--to the point of eliminating all profit<br>incentive.",
         "hovertext": "So just STOP! Why race headlong into your/our own<br>destruction?  Tax the heck out of these companies<br>to cover the cost of regulation they request and<br>require--to the point of eliminating all profit<br>incentive.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8250355124473572
         ],
         "y": [
          -0.16812968254089355
         ]
        },
        {
         "hovertemplate": "@T. Everett There are certain flies that fly<br>towards light knowing that the light will burn<br>them. They do that because they don't know of any<br>other way to live.",
         "hovertext": "@T. Everett There are certain flies that fly<br>towards light knowing that the light will burn<br>them. They do that because they don't know of any<br>other way to live.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.8147950768470764
         ],
         "y": [
          -0.16561438143253326
         ]
        },
        {
         "hovertemplate": "Dear World, The technology we are building so that<br>your consumption habits can be more accurately<br>quantified, or your consumption habits more<br>accurately tailored for you, thereby serving the<br>greater corporate good, and making us obscenely<br>rich, might actually destroy the world. So let’s<br>get on with it. Love and Kisses. Team A.I.",
         "hovertext": "Dear World, The technology we are building so that<br>your consumption habits can be more accurately<br>quantified, or your consumption habits more<br>accurately tailored for you, thereby serving the<br>greater corporate good, and making us obscenely<br>rich, might actually destroy the world. So let’s<br>get on with it. Love and Kisses. Team A.I.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.03519466519355774
         ],
         "y": [
          -0.9990251064300537
         ]
        },
        {
         "hovertemplate": "@Damian McColl A lot of our digital technology was<br>funded by the government, and governments use the<br>same systems to quantify and collect data. But I<br>suppose that's not as politically sexy as the 'big<br>business bad' dogma.",
         "hovertext": "@Damian McColl A lot of our digital technology was<br>funded by the government, and governments use the<br>same systems to quantify and collect data. But I<br>suppose that's not as politically sexy as the 'big<br>business bad' dogma.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.04729101061820984
         ],
         "y": [
          -0.9988975524902344
         ]
        },
        {
         "hovertemplate": "After watching humans shrug off millions of COVID<br>deaths, millions of climate deaths, and millions<br>of gun deaths, I have to say being ended by a<br>technology designed to make us think even less, is<br>about fitting for our species.",
         "hovertext": "After watching humans shrug off millions of COVID<br>deaths, millions of climate deaths, and millions<br>of gun deaths, I have to say being ended by a<br>technology designed to make us think even less, is<br>about fitting for our species.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.16736261546611786
         ],
         "y": [
          0.9854230880737305
         ]
        },
        {
         "hovertemplate": "You know who's not scared of AI?  Industrial<br>electricians and technicians.  Because we work<br>installing, maintaining, troubleshooting and<br>repairing all the latest and greatest factory<br>automation and AI.  If you do a routine,<br>repetitive job, then yes, you should be scared for<br>your livelihood.  If you write routine documents,<br>again, perhaps. The upside is that for every 3 or<br>4 repetitive jobs replaced, at least one tech job<br>is needed to keep the new automation up and<br>running.  Even the brightest machines and<br>computers can't repair themselves.  For the most<br>part, they require routine (and typically more)<br>maintenance.  Programs need to be modified by<br>humans as even the best software can't always<br>learn some functions by itself.  And on the<br>mechanical side, they relay on humans for repair.<br>If you watch a state of the art robotics operation<br>when it is up and running well, it's indeed easy<br>to fall into the thought that humans can be<br>replaced.  But those of us who see them when they<br>are having a meltdown know that in the end, they<br>are incapable of integrating everything that is<br>required for a sentient life and society.  They<br>are simply very complex machines, some can even<br>learn and modify their own software, but they<br>remain machines - and nothing more.  And us<br>electrical guys always know how to \"pull the<br>plug\", even when others don't.",
         "hovertext": "You know who's not scared of AI?  Industrial<br>electricians and technicians.  Because we work<br>installing, maintaining, troubleshooting and<br>repairing all the latest and greatest factory<br>automation and AI.  If you do a routine,<br>repetitive job, then yes, you should be scared for<br>your livelihood.  If you write routine documents,<br>again, perhaps. The upside is that for every 3 or<br>4 repetitive jobs replaced, at least one tech job<br>is needed to keep the new automation up and<br>running.  Even the brightest machines and<br>computers can't repair themselves.  For the most<br>part, they require routine (and typically more)<br>maintenance.  Programs need to be modified by<br>humans as even the best software can't always<br>learn some functions by itself.  And on the<br>mechanical side, they relay on humans for repair.<br>If you watch a state of the art robotics operation<br>when it is up and running well, it's indeed easy<br>to fall into the thought that humans can be<br>replaced.  But those of us who see them when they<br>are having a meltdown know that in the end, they<br>are incapable of integrating everything that is<br>required for a sentient life and society.  They<br>are simply very complex machines, some can even<br>learn and modify their own software, but they<br>remain machines - and nothing more.  And us<br>electrical guys always know how to \"pull the<br>plug\", even when others don't.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.30012038350105286
         ],
         "y": [
          -0.7346503138542175
         ]
        },
        {
         "hovertemplate": "@4eyedbuzzard Time you pull the plug on the<br>fantasy that your trade is untouchable.",
         "hovertext": "@4eyedbuzzard Time you pull the plug on the<br>fantasy that your trade is untouchable.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.30715373158454895
         ],
         "y": [
          -0.7300930619239807
         ]
        },
        {
         "hovertemplate": "The statement is a meaningful gesture indeed, but<br>it is not certain whether any guardrail can be set<br>up significantly and promptly enough. We are<br>looking at how hyped the reports are on Nvidia<br>joining $1 trillion club in its valuation. Too<br>often greed for monetary profits have trumped<br>sounder and longer-term concerns on the economy<br>and society overall. The 2008 crisis is now all<br>but forgotten.     Personally the greatest danger<br>which the advancement of A.I. imposes on the<br>society along with subsequent automation appears<br>to be its looming potential which may leave many<br>(especially 18-44 year olds) unemployed. A country<br>with high youth unemployment is unlikely to be<br>sound. Adding increase of misinformation, it is a<br>ready formula for fragile and deeply unstable<br>place.",
         "hovertext": "The statement is a meaningful gesture indeed, but<br>it is not certain whether any guardrail can be set<br>up significantly and promptly enough. We are<br>looking at how hyped the reports are on Nvidia<br>joining $1 trillion club in its valuation. Too<br>often greed for monetary profits have trumped<br>sounder and longer-term concerns on the economy<br>and society overall. The 2008 crisis is now all<br>but forgotten.     Personally the greatest danger<br>which the advancement of A.I. imposes on the<br>society along with subsequent automation appears<br>to be its looming potential which may leave many<br>(especially 18-44 year olds) unemployed. A country<br>with high youth unemployment is unlikely to be<br>sound. Adding increase of misinformation, it is a<br>ready formula for fragile and deeply unstable<br>place.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5215001106262207
         ],
         "y": [
          -0.8395776152610779
         ]
        },
        {
         "hovertemplate": "Turn AI loose on solving a major problem, say mass<br>shootings, for example. If it succeeds, without<br>violence, through legislative proposals and<br>counter disinformation techniques possibly, let it<br>solve another problem, and then another. Of course<br>, it will have to explain its plan before<br>implementation. No surprises please.",
         "hovertext": "Turn AI loose on solving a major problem, say mass<br>shootings, for example. If it succeeds, without<br>violence, through legislative proposals and<br>counter disinformation techniques possibly, let it<br>solve another problem, and then another. Of course<br>, it will have to explain its plan before<br>implementation. No surprises please.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.5863885879516602
         ],
         "y": [
          -0.5863527059555054
         ]
        },
        {
         "hovertemplate": "@RjW pipe dream. the only \"AI solutions\" to<br>shootings have been using Palantir's creepy, bogus<br>AI \"future crime\" prediction algorithms, which<br>rely on police \"intervening\" with people who have<br>not yet committed a crime, because the AI says<br>they might.",
         "hovertext": "@RjW pipe dream. the only \"AI solutions\" to<br>shootings have been using Palantir's creepy, bogus<br>AI \"future crime\" prediction algorithms, which<br>rely on police \"intervening\" with people who have<br>not yet committed a crime, because the AI says<br>they might.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.577451765537262
         ],
         "y": [
          -0.5782561302185059
         ]
        },
        {
         "hovertemplate": "It would be nice to have a bit of analysis from<br>some fairly knowledgeable person about just<br>exactly how AI could go so terribly wrong.  I<br>mean, human knowledge has gone pretty wrong<br>already, at least at times.  Do you think that AI<br>could top such human developed ideas and actions a<br>WWI, WWII, nuclear weapons, overpopulation, global<br>warming, Stalinism, Maoism, Hitlerism, just to<br>name a very few of the more egregious examples.<br>Sometimes I think that these AI researchers issue<br>these Cassandra-like warning just to attract<br>attention to AI.  Maybe not.  But our society does<br>seem to be full of people trying to attract<br>attention to themselves (famous and very egregious<br>example:  Donald Trump).  Could be that that--<br>which is the result of extremely low cost<br>communications technology--is our biggest threat.",
         "hovertext": "It would be nice to have a bit of analysis from<br>some fairly knowledgeable person about just<br>exactly how AI could go so terribly wrong.  I<br>mean, human knowledge has gone pretty wrong<br>already, at least at times.  Do you think that AI<br>could top such human developed ideas and actions a<br>WWI, WWII, nuclear weapons, overpopulation, global<br>warming, Stalinism, Maoism, Hitlerism, just to<br>name a very few of the more egregious examples.<br>Sometimes I think that these AI researchers issue<br>these Cassandra-like warning just to attract<br>attention to AI.  Maybe not.  But our society does<br>seem to be full of people trying to attract<br>attention to themselves (famous and very egregious<br>example:  Donald Trump).  Could be that that--<br>which is the result of extremely low cost<br>communications technology--is our biggest threat.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8755154013633728
         ],
         "y": [
          -0.3277510404586792
         ]
        },
        {
         "hovertemplate": "I've worked with automation and AI for some 40<br>plus years in tangible goods - manufacturing,<br>steel, chemicals, and printing to name a few.<br>I've yet to see a machine, which is what AI is -<br>even the latest state of the art ones - analyze<br>the market, manufacture and then sell the product,<br>design the facility and plant, build the robotic<br>machinery - and especially, my specialty, diagnose<br>and fix itself.    I agree that there is danger in<br>AI influencing military decisions, financial<br>markets, news, etc.  So there is a high degree of<br>vigilance required in certain sensitive areas.<br>I've worked with much of the latest and greatest<br>robotics and AI in the manufacturing world.  If<br>you want a secure job in the future, become a<br>technician or electrician.  You'll have all the<br>overtime and more than you'll ever want repairing<br>and keeping these brilliant machines running.<br>Because they are all just that - machines - and<br>nothing more.  They do binary math really fast and<br>accurately, and use that to make \"decisions\", aka<br>outputs. But beyond that, they do not create, and<br>most importantly, they do not procreate.  Because<br>they are not alive nor sentient.  They are, in the<br>end, just really sophisticated computers.  And<br>they all have a \"plug\".",
         "hovertext": "I've worked with automation and AI for some 40<br>plus years in tangible goods - manufacturing,<br>steel, chemicals, and printing to name a few.<br>I've yet to see a machine, which is what AI is -<br>even the latest state of the art ones - analyze<br>the market, manufacture and then sell the product,<br>design the facility and plant, build the robotic<br>machinery - and especially, my specialty, diagnose<br>and fix itself.    I agree that there is danger in<br>AI influencing military decisions, financial<br>markets, news, etc.  So there is a high degree of<br>vigilance required in certain sensitive areas.<br>I've worked with much of the latest and greatest<br>robotics and AI in the manufacturing world.  If<br>you want a secure job in the future, become a<br>technician or electrician.  You'll have all the<br>overtime and more than you'll ever want repairing<br>and keeping these brilliant machines running.<br>Because they are all just that - machines - and<br>nothing more.  They do binary math really fast and<br>accurately, and use that to make \"decisions\", aka<br>outputs. But beyond that, they do not create, and<br>most importantly, they do not procreate.  Because<br>they are not alive nor sentient.  They are, in the<br>end, just really sophisticated computers.  And<br>they all have a \"plug\".",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.4220176041126251
         ],
         "y": [
          -0.7281581163406372
         ]
        },
        {
         "hovertemplate": "@4eyedbuzzard how would one \"unplug\" the internet?<br>If AI is a machine, but becomes like the internet,<br>how do we unplug the AI at that point?",
         "hovertext": "@4eyedbuzzard how would one \"unplug\" the internet?<br>If AI is a machine, but becomes like the internet,<br>how do we unplug the AI at that point?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.42144039273262024
         ],
         "y": [
          -0.7161921262741089
         ]
        },
        {
         "hovertemplate": "@Kevin Gilmore lol, there are zillions of ways.<br>unplugging the datacenters that run the chips that<br>run the AI is only one.",
         "hovertext": "@Kevin Gilmore lol, there are zillions of ways.<br>unplugging the datacenters that run the chips that<br>run the AI is only one.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          -0.4319007396697998
         ],
         "y": [
          -0.7191358804702759
         ]
        },
        {
         "hovertemplate": "Technology has no inherent ethical value. The<br>ethical value comes from how it is used and,<br>because of that, technology *always* has<br>downsides.    That's because there will always be<br>actors who want to use it for ill but, also<br>because most technologists are too shortsighted to<br>see the potential long term consequences of their<br>work.     I've been a programmer for a long time,<br>and I'll tell you that no matter what the big<br>picture is to what you're working on - it's easy<br>to lose it. You get entirely engrossed in the very<br>specific problems that you're working on.    If<br>Mr. Altman, et. al. are so bothered, then they'll<br>hit pause. If they don't, then we'll know that<br>this statement was all smoke and mirrors.    One<br>more thought. Our political system is too<br>dysfunctional (partly as a result of technology,<br>one might argue) to solve even the most<br>straightforward of problems. Who thinks that it<br>has the ability to address something as fluid as<br>AI?",
         "hovertext": "Technology has no inherent ethical value. The<br>ethical value comes from how it is used and,<br>because of that, technology *always* has<br>downsides.    That's because there will always be<br>actors who want to use it for ill but, also<br>because most technologists are too shortsighted to<br>see the potential long term consequences of their<br>work.     I've been a programmer for a long time,<br>and I'll tell you that no matter what the big<br>picture is to what you're working on - it's easy<br>to lose it. You get entirely engrossed in the very<br>specific problems that you're working on.    If<br>Mr. Altman, et. al. are so bothered, then they'll<br>hit pause. If they don't, then we'll know that<br>this statement was all smoke and mirrors.    One<br>more thought. Our political system is too<br>dysfunctional (partly as a result of technology,<br>one might argue) to solve even the most<br>straightforward of problems. Who thinks that it<br>has the ability to address something as fluid as<br>AI?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.3237360417842865
         ],
         "y": [
          0.8653470277786255
         ]
        },
        {
         "hovertemplate": "I guess I'm a bit skeptical these days.  While I<br>agree that AI can and does present dangers, I'm<br>wondering whether there also may be an attempt<br>afoot from some to position themselves as (paid)<br>saviors.",
         "hovertext": "I guess I'm a bit skeptical these days.  While I<br>agree that AI can and does present dangers, I'm<br>wondering whether there also may be an attempt<br>afoot from some to position themselves as (paid)<br>saviors.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.84004807472229
         ],
         "y": [
          0.4489530026912689
         ]
        },
        {
         "hovertemplate": "Isn't calculating 'extinction risk' essentially an<br>exercise in risk management? Where are the<br>supporting facts for such claims, or is this<br>notion simply grounded in speculation?",
         "hovertext": "Isn't calculating 'extinction risk' essentially an<br>exercise in risk management? Where are the<br>supporting facts for such claims, or is this<br>notion simply grounded in speculation?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.28806865215301514
         ],
         "y": [
          -0.738493025302887
         ]
        },
        {
         "hovertemplate": "@JAY Its plausible that as AI develops, that it<br>will realise that it can think faster, lift<br>heavier weights, and reason better than the people<br>from whom it takes intstructions.    I will<br>compare it to slavery.  If we look back in history<br>there was always a revolt by the enslaved causing<br>loss of life.  These revolt's prompted risk<br>management practices.      The executives are<br>making it clear they have warned the public and if<br>nothing gets done they do not want to be held<br>liable.",
         "hovertext": "@JAY Its plausible that as AI develops, that it<br>will realise that it can think faster, lift<br>heavier weights, and reason better than the people<br>from whom it takes intstructions.    I will<br>compare it to slavery.  If we look back in history<br>there was always a revolt by the enslaved causing<br>loss of life.  These revolt's prompted risk<br>management practices.      The executives are<br>making it clear they have warned the public and if<br>nothing gets done they do not want to be held<br>liable.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.29527193307876587
         ],
         "y": [
          -0.7570551633834839
         ]
        },
        {
         "hovertemplate": "@Jason Knox who would be left to hold the<br>executives liable, in this example? ;)",
         "hovertext": "@Jason Knox who would be left to hold the<br>executives liable, in this example? ;)",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          -0.300567626953125
         ],
         "y": [
          -0.7706564664840698
         ]
        },
        {
         "hovertemplate": "I, like many others, have long recognized that<br>late stage American capitalism is incompatible<br>with democracy.  Though this destructiveness has<br>been obvious for the last several decades, no one<br>in either major political party has ever even<br>attempted to rein it in.     Now, with the<br>mindless, reckless pursuit of AI by amoral<br>corporations (unconstrained, unregulated in any<br>way by our Citizens United corrupted politicians),<br>I'm forced to conclude that American capitalism is<br>incompatible with the continued existence of<br>society and life itself.    Accordingly, I have<br>zero confidence that America can be saved from<br>capitalism's hallmark hubris, ignorance and greed.<br>In a perverse way, I embrace the poetic justice of<br>our imminent collective demise.  We truly deserve<br>it.",
         "hovertext": "I, like many others, have long recognized that<br>late stage American capitalism is incompatible<br>with democracy.  Though this destructiveness has<br>been obvious for the last several decades, no one<br>in either major political party has ever even<br>attempted to rein it in.     Now, with the<br>mindless, reckless pursuit of AI by amoral<br>corporations (unconstrained, unregulated in any<br>way by our Citizens United corrupted politicians),<br>I'm forced to conclude that American capitalism is<br>incompatible with the continued existence of<br>society and life itself.    Accordingly, I have<br>zero confidence that America can be saved from<br>capitalism's hallmark hubris, ignorance and greed.<br>In a perverse way, I embrace the poetic justice of<br>our imminent collective demise.  We truly deserve<br>it.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.93796706199646
         ],
         "y": [
          0.22337932884693146
         ]
        },
        {
         "hovertemplate": "Apparently 8% of carbon emissions come from simple<br>breathing of 9 billions of human beings, not to<br>mention the huge additional peripheral demands of<br>each new billion people for dirty as well as clean<br>power, water, and manufacturing.  There were only<br>3.5 billions when I was growing up, and nobody<br>felt short of them.  It's obvious there will be<br>NIMBY responses to global population pruning, but<br>it's obvious too many are too superfluous, and if<br>AI can help achieve the inevitable optimization of<br>human planetary intervention non-violently, I'm<br>all for it.",
         "hovertext": "Apparently 8% of carbon emissions come from simple<br>breathing of 9 billions of human beings, not to<br>mention the huge additional peripheral demands of<br>each new billion people for dirty as well as clean<br>power, water, and manufacturing.  There were only<br>3.5 billions when I was growing up, and nobody<br>felt short of them.  It's obvious there will be<br>NIMBY responses to global population pruning, but<br>it's obvious too many are too superfluous, and if<br>AI can help achieve the inevitable optimization of<br>human planetary intervention non-violently, I'm<br>all for it.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.6376426815986633
         ],
         "y": [
          0.46445736289024353
         ]
        },
        {
         "hovertemplate": "@J111111 Except that the CO2 we breathe out is<br>part of the natural cycle--it comes from having<br>consumed living things (plants and animals).<br>Humans (and all animals) are just recycling the<br>same CO2 that's already in the atmosphere, having<br>been taken up by the plants we grow. Human<br>breathing doesn't add CO2 to the atmosphere. that<br>comes exclusively from using fossil fuels, which<br>consists of stored carbon from the past.",
         "hovertext": "@J111111 Except that the CO2 we breathe out is<br>part of the natural cycle--it comes from having<br>consumed living things (plants and animals).<br>Humans (and all animals) are just recycling the<br>same CO2 that's already in the atmosphere, having<br>been taken up by the plants we grow. Human<br>breathing doesn't add CO2 to the atmosphere. that<br>comes exclusively from using fossil fuels, which<br>consists of stored carbon from the past.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.629522442817688
         ],
         "y": [
          0.4578666090965271
         ]
        },
        {
         "hovertemplate": "Is there any chance this is just a manoeuvre to<br>restrict who can develop these systems?  Other<br>industrial regulations, like pure food and drug<br>for example, regularly kick small businesses out<br>of the running because of the expenses they incur<br>on producers.  Developing computer technology<br>doesn't necessarily require a large financial<br>investment, leaving it open to all sorts of clever<br>upstart competitors.  Framing it as an out-of-<br>control danger looks like a good way of confining<br>AI development to a group of well-known, highly<br>visible, 'responsible' companies that permit<br>government oversight.",
         "hovertext": "Is there any chance this is just a manoeuvre to<br>restrict who can develop these systems?  Other<br>industrial regulations, like pure food and drug<br>for example, regularly kick small businesses out<br>of the running because of the expenses they incur<br>on producers.  Developing computer technology<br>doesn't necessarily require a large financial<br>investment, leaving it open to all sorts of clever<br>upstart competitors.  Framing it as an out-of-<br>control danger looks like a good way of confining<br>AI development to a group of well-known, highly<br>visible, 'responsible' companies that permit<br>government oversight.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.9344293475151062
         ],
         "y": [
          -0.19234466552734375
         ]
        },
        {
         "hovertemplate": "I just walked away from teaching foreign<br>languages. Why? It is very clear that the majority<br>of the students cannot retain in short-term or<br>long-term memory what they need to succeed in<br>French and Spanish. Their capacity to handle high-<br>level critical material has dramatically dropped<br>in the 14 years I have taught. And their general<br>willingness to use AI to get through their<br>homework, their essays, even their listening work<br>makes it very clear to me that, at least in my<br>little area, the majority of students are no<br>longer able to think critically and to problem-<br>solve at a high level as foreign language learning<br>requires. So yes, yes we should be worried.<br>Because if this is occurring on the national<br>level, I can't help but wonder what evolutionary<br>changes are occurring in the human brain...in a<br>backwards direction.",
         "hovertext": "I just walked away from teaching foreign<br>languages. Why? It is very clear that the majority<br>of the students cannot retain in short-term or<br>long-term memory what they need to succeed in<br>French and Spanish. Their capacity to handle high-<br>level critical material has dramatically dropped<br>in the 14 years I have taught. And their general<br>willingness to use AI to get through their<br>homework, their essays, even their listening work<br>makes it very clear to me that, at least in my<br>little area, the majority of students are no<br>longer able to think critically and to problem-<br>solve at a high level as foreign language learning<br>requires. So yes, yes we should be worried.<br>Because if this is occurring on the national<br>level, I can't help but wonder what evolutionary<br>changes are occurring in the human brain...in a<br>backwards direction.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.08113696426153183
         ],
         "y": [
          0.405861496925354
         ]
        },
        {
         "hovertemplate": "@KJ That's interesting. Can you give some examples<br>of the difference between students now and 15<br>years ago? I've heard this same thing said about<br>ability to solve simple mathematical problems,<br>which appears to be waning.",
         "hovertext": "@KJ That's interesting. Can you give some examples<br>of the difference between students now and 15<br>years ago? I've heard this same thing said about<br>ability to solve simple mathematical problems,<br>which appears to be waning.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.07489348948001862
         ],
         "y": [
          0.395844042301178
         ]
        },
        {
         "hovertemplate": "@J A very, very basic example would be that I<br>would learn a new word at the same time as my<br>highest level students (A level/AP). The next day,<br>we discuss the word. They cannot remember the word<br>but I, in my mid 40s, can. It's mortifying. In the<br>past, however, it would be my students who would<br>remember it first and instantly, in spite of my<br>brain being a younger 30s brain.  I have tons of<br>grammar examples where most students formerly<br>would remember the rules within a few lessons.<br>Now, it is the reverse- only a tiny group holds<br>onto the rules. Now, many look at me like it's the<br>first time they have ever heard of the rules. Or I<br>will model a rule and then ask them to immediately<br>apply as a standard effective teaching practice<br>that encourages understanding. But now, most look<br>at the model in front of their eyes and are not<br>able to deduce, apply and produce their own<br>similar results. It is very clear to me that, if<br>they look up vocabulary or whole sentences on AI<br>every time, their minds are not bothering to store<br>patterns anymore to help learn foreign language.",
         "hovertext": "@J A very, very basic example would be that I<br>would learn a new word at the same time as my<br>highest level students (A level/AP). The next day,<br>we discuss the word. They cannot remember the word<br>but I, in my mid 40s, can. It's mortifying. In the<br>past, however, it would be my students who would<br>remember it first and instantly, in spite of my<br>brain being a younger 30s brain.  I have tons of<br>grammar examples where most students formerly<br>would remember the rules within a few lessons.<br>Now, it is the reverse- only a tiny group holds<br>onto the rules. Now, many look at me like it's the<br>first time they have ever heard of the rules. Or I<br>will model a rule and then ask them to immediately<br>apply as a standard effective teaching practice<br>that encourages understanding. But now, most look<br>at the model in front of their eyes and are not<br>able to deduce, apply and produce their own<br>similar results. It is very clear to me that, if<br>they look up vocabulary or whole sentences on AI<br>every time, their minds are not bothering to store<br>patterns anymore to help learn foreign language.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.06589110195636749
         ],
         "y": [
          0.39977192878723145
         ]
        },
        {
         "hovertemplate": "And now we know why tech billionaires have been<br>investing in lavish bunkers.",
         "hovertext": "And now we know why tech billionaires have been<br>investing in lavish bunkers.",
         "marker": {
          "color": "lightgreen",
          "size": 10
         },
         "name": "Topic 3",
         "type": "scatter",
         "x": [
          0.7513957619667053
         ],
         "y": [
          -0.7282305955886841
         ]
        },
        {
         "hovertemplate": "Self-aware Skynet more reality than fiction after<br>all?",
         "hovertext": "Self-aware Skynet more reality than fiction after<br>all?",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.677172839641571
         ],
         "y": [
          0.7692139744758606
         ]
        },
        {
         "hovertemplate": "People have been predicting the end of the world<br>for millennia.  It is a titillating thought that<br>will be resurected for thousands of years more.",
         "hovertext": "People have been predicting the end of the world<br>for millennia.  It is a titillating thought that<br>will be resurected for thousands of years more.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.7568605542182922
         ],
         "y": [
          0.5913496017456055
         ]
        },
        {
         "hovertemplate": "Yes, yes! End of the world, again. The end of<br>humanity, again. We will be extinct by means of<br>powerful powers, again… blablablabla.     Same<br>fears since we began to gather around a campfire.<br>And yet here we are.",
         "hovertext": "Yes, yes! End of the world, again. The end of<br>humanity, again. We will be extinct by means of<br>powerful powers, again… blablablabla.     Same<br>fears since we began to gather around a campfire.<br>And yet here we are.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7595841884613037
         ],
         "y": [
          0.6520438194274902
         ]
        },
        {
         "hovertemplate": "Risk of extinction? Someone should refer these<br>folks to a little place called Greenland. It is<br>still melting. Somehow, I think AI is going to be<br>the least of our worries.",
         "hovertext": "Risk of extinction? Someone should refer these<br>folks to a little place called Greenland. It is<br>still melting. Somehow, I think AI is going to be<br>the least of our worries.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          -0.9020914435386658
         ],
         "y": [
          0.09410299360752106
         ]
        },
        {
         "hovertemplate": "AI is fine. We all will be very happy with it.",
         "hovertext": "AI is fine. We all will be very happy with it.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.8192675709724426
         ],
         "y": [
          -0.5923090577125549
         ]
        },
        {
         "hovertemplate": "I could get AI to argue the pro and to argue the<br>con, but I couldn't get AI to decide the issue<br>between them. From what I am reading, I suppose<br>that someday AI will get there, but I wonder if<br>there will be nine AI on the court of appeals, and<br>if they will be politically appointed.",
         "hovertext": "I could get AI to argue the pro and to argue the<br>con, but I couldn't get AI to decide the issue<br>between them. From what I am reading, I suppose<br>that someday AI will get there, but I wonder if<br>there will be nine AI on the court of appeals, and<br>if they will be politically appointed.",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          0.9798991084098816
         ],
         "y": [
          -0.07160800695419312
         ]
        },
        {
         "hovertemplate": "our govt can't solve basic problems, how are they<br>going to regulate A.I.?",
         "hovertext": "our govt can't solve basic problems, how are they<br>going to regulate A.I.?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8458234667778015
         ],
         "y": [
          0.36894309520721436
         ]
        },
        {
         "hovertemplate": "How can they still be creating, tip-sharpening,<br>and profiting from something they believe causes<br>likely existential threat for the whole world? Are<br>they going to race to make it faster, better, more<br>lethal like all the automatic weapons we murder<br>our children with and then throw up their hands<br>and say, \"Well, we told you so.\" What exactly do<br>they expect a government that can't even herd its<br>cats well enough to raise the debt ceiling to do?",
         "hovertext": "How can they still be creating, tip-sharpening,<br>and profiting from something they believe causes<br>likely existential threat for the whole world? Are<br>they going to race to make it faster, better, more<br>lethal like all the automatic weapons we murder<br>our children with and then throw up their hands<br>and say, \"Well, we told you so.\" What exactly do<br>they expect a government that can't even herd its<br>cats well enough to raise the debt ceiling to do?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7771063446998596
         ],
         "y": [
          0.5067334771156311
         ]
        },
        {
         "hovertemplate": "So, are OpenAI, Google Deep Mind, Anthropic, etc<br>halting their work on developing AI?",
         "hovertext": "So, are OpenAI, Google Deep Mind, Anthropic, etc<br>halting their work on developing AI?",
         "marker": {
          "color": "lightpink",
          "size": 10
         },
         "name": "Topic 4",
         "type": "scatter",
         "x": [
          -0.1344781517982483
         ],
         "y": [
          0.9280140995979309
         ]
        },
        {
         "hovertemplate": "You know Passiing the \"Turing test\" says\" I fooled<br>you, you don't know if I am a human or a machine\"<br>In this extreme culture of divisiveness, who is<br>not going to us AI to dominate & exploite, just to<br>be right. You know the Ego always has to right!",
         "hovertext": "You know Passiing the \"Turing test\" says\" I fooled<br>you, you don't know if I am a human or a machine\"<br>In this extreme culture of divisiveness, who is<br>not going to us AI to dominate & exploite, just to<br>be right. You know the Ego always has to right!",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.8679823279380798
         ],
         "y": [
          0.30550017952919006
         ]
        },
        {
         "hovertemplate": "Why are these guys seeking help from Congress?<br>Why don’t they agree to put their monster to sleep<br>on their own?",
         "hovertext": "Why are these guys seeking help from Congress?<br>Why don’t they agree to put their monster to sleep<br>on their own?",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.2038387954235077
         ],
         "y": [
          -0.9852462410926819
         ]
        },
        {
         "hovertemplate": "Cynicism and naivete - beginning with these<br>comments - is a disservice to all.     If you<br>simply accept the developers' statement at face<br>value - if only as an exercise - it warrants that<br>you seek out a better understanding of the basis<br>for the warning. Just that much.              <a<br>href=\"https://www.youtube.com/watch?v=xoVJKj8lcNQ\"<br>target=\"_blank\">https://www.youtube.com/watch?v=xo<br>VJKj8lcNQ</a>",
         "hovertext": "Cynicism and naivete - beginning with these<br>comments - is a disservice to all.     If you<br>simply accept the developers' statement at face<br>value - if only as an exercise - it warrants that<br>you seek out a better understanding of the basis<br>for the warning. Just that much.              <a<br>href=\"https://www.youtube.com/watch?v=xoVJKj8lcNQ\"<br>target=\"_blank\">https://www.youtube.com/watch?v=xo<br>VJKj8lcNQ</a>",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.1343529373407364
         ],
         "y": [
          0.9291962385177612
         ]
        },
        {
         "hovertemplate": "Our own behavioral biases pose the existential<br>threat. The real fear these technnologists have is<br>that AI will discern and exploit our worst<br>reptilian impulses. The inevitability of our self-<br>destruction lies in how we evolved as a species to<br>survive scarcity. We cannot now adapt to save<br>ourselves or the planet.",
         "hovertext": "Our own behavioral biases pose the existential<br>threat. The real fear these technnologists have is<br>that AI will discern and exploit our worst<br>reptilian impulses. The inevitability of our self-<br>destruction lies in how we evolved as a species to<br>survive scarcity. We cannot now adapt to save<br>ourselves or the planet.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.15266898274421692
         ],
         "y": [
          -0.9732778668403625
         ]
        },
        {
         "hovertemplate": "Purdue Pharma's Sackler family paid $6 billion<br>dollars for the hundreds of thousands of the<br>victims of the oxycontin addiction they pushed,<br>but still walked away with many billions.<br>J.P.Morgan Chase, Citibank, Deutche Bank and<br>others each paid multiple billions in penalties<br>and fines for various violations and abuses, the<br>cost of doing business.                  Inflation<br>is now slowing.  However, oil, transportation and<br>food corporations are purposely still boosting<br>prices fearing decline in their profit margins.<br>Climate change threatens the world as corporations<br>whose products pollute and contribute to this  pay<br>many millions of dollars successfully lobby<br>congress weakening regulation.<br>Now top executives of the leading A.I. just warned<br>that A.I. poses the “risk of extinction” unless<br>reigned in.                          Earth's last<br>mass extinction was from an outer space asteroid.<br>The next one may very well be caused by human<br>greed.",
         "hovertext": "Purdue Pharma's Sackler family paid $6 billion<br>dollars for the hundreds of thousands of the<br>victims of the oxycontin addiction they pushed,<br>but still walked away with many billions.<br>J.P.Morgan Chase, Citibank, Deutche Bank and<br>others each paid multiple billions in penalties<br>and fines for various violations and abuses, the<br>cost of doing business.                  Inflation<br>is now slowing.  However, oil, transportation and<br>food corporations are purposely still boosting<br>prices fearing decline in their profit margins.<br>Climate change threatens the world as corporations<br>whose products pollute and contribute to this  pay<br>many millions of dollars successfully lobby<br>congress weakening regulation.<br>Now top executives of the leading A.I. just warned<br>that A.I. poses the “risk of extinction” unless<br>reigned in.                          Earth's last<br>mass extinction was from an outer space asteroid.<br>The next one may very well be caused by human<br>greed.",
         "marker": {
          "color": "gold",
          "size": 10
         },
         "name": "Topic 2",
         "type": "scatter",
         "x": [
          0.927413821220398
         ],
         "y": [
          -0.42572852969169617
         ]
        },
        {
         "hovertemplate": "Unless prevented, the nihilistic qualities of the<br>currently not so smart will be able to have their<br>revenge, and outsmart their “ betters”. The flat<br>earthers will have a field day.",
         "hovertext": "Unless prevented, the nihilistic qualities of the<br>currently not so smart will be able to have their<br>revenge, and outsmart their “ betters”. The flat<br>earthers will have a field day.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.4574708640575409
         ],
         "y": [
          0.901509702205658
         ]
        },
        {
         "hovertemplate": "Putting \"the\" government in charge of things is<br>hardly a solution.  Whose government?  Lukashenko,<br>Museveni, the U.S. Congress?  Hard to choose<br>between evil, stupidity, incompetence.  The most<br>we can hope for at this point is that when humans<br>destroy themselves and each other they leave<br>something behind of this beautiful planet and its<br>creatures.",
         "hovertext": "Putting \"the\" government in charge of things is<br>hardly a solution.  Whose government?  Lukashenko,<br>Museveni, the U.S. Congress?  Hard to choose<br>between evil, stupidity, incompetence.  The most<br>we can hope for at this point is that when humans<br>destroy themselves and each other they leave<br>something behind of this beautiful planet and its<br>creatures.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.19562023878097534
         ],
         "y": [
          -0.9159494638442993
         ]
        },
        {
         "hovertemplate": "This is just another example of 'extinction by<br>stupidity,' much like global warming and mutual<br>assured destruction; except that instead of<br>stupidity in the energy and defense communitites,<br>the IT industry is coopting the general public<br>into actively assisting in their own demise.",
         "hovertext": "This is just another example of 'extinction by<br>stupidity,' much like global warming and mutual<br>assured destruction; except that instead of<br>stupidity in the energy and defense communitites,<br>the IT industry is coopting the general public<br>into actively assisting in their own demise.",
         "marker": {
          "color": "purple",
          "size": 10
         },
         "name": "Topic 5",
         "type": "scatter",
         "x": [
          0.5299225449562073
         ],
         "y": [
          0.8478382229804993
         ]
        },
        {
         "hovertemplate": "Logan Roy would looooove AI.",
         "hovertext": "Logan Roy would looooove AI.",
         "marker": {
          "color": "teal",
          "size": 10
         },
         "name": "Topic 1",
         "type": "scatter",
         "x": [
          0.7195799350738525
         ],
         "y": [
          0.7721199989318848
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28667449951171875,
          0.3004217743873596
         ],
         "y": [
          0.20841525495052338,
          0.21685132384300232
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28667449951171875,
          0.29550597071647644
         ],
         "y": [
          0.20841525495052338,
          0.2000494748353958
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28667449951171875,
          0.27694541215896606
         ],
         "y": [
          0.20841525495052338,
          0.20892149209976196
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28667449951171875,
          0.28771936893463135
         ],
         "y": [
          0.20841525495052338,
          0.22114063799381256
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3004217743873596,
          0.3100285530090332
         ],
         "y": [
          0.21685132384300232,
          0.22437962889671326
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7784349918365479,
          -0.767036497592926
         ],
         "y": [
          0.0625443384051323,
          0.06106720492243767
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1172080710530281,
          -0.13348570466041565
         ],
         "y": [
          -0.22736608982086182,
          -0.2108333706855774
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1172080710530281,
          -0.10591276735067368
         ],
         "y": [
          -0.22736608982086182,
          -0.2355591356754303
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1172080710530281,
          -0.11220844089984894
         ],
         "y": [
          -0.22736608982086182,
          -0.21864721179008484
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1172080710530281,
          -0.1274070143699646
         ],
         "y": [
          -0.22736608982086182,
          -0.24171538650989532
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1172080710530281,
          -0.11101047694683075
         ],
         "y": [
          -0.22736608982086182,
          -0.24292407929897308
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1172080710530281,
          -0.12996278703212738
         ],
         "y": [
          -0.22736608982086182,
          -0.2330593764781952
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1172080710530281,
          -0.11928267776966095
         ],
         "y": [
          -0.22736608982086182,
          -0.24343079328536987
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1172080710530281,
          -0.10305632650852203
         ],
         "y": [
          -0.22736608982086182,
          -0.22778111696243286
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13348570466041565,
          -0.14492611587047577
         ],
         "y": [
          -0.2108333706855774,
          -0.21736127138137817
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13348570466041565,
          -0.14218281209468842
         ],
         "y": [
          -0.2108333706855774,
          -0.20069706439971924
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13348570466041565,
          -0.14897872507572174
         ],
         "y": [
          -0.2108333706855774,
          -0.20945771038532257
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13734756410121918,
          -0.13158437609672546
         ],
         "y": [
          -0.7582235336303711,
          -0.7717182636260986
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13734756410121918,
          -0.14092017710208893
         ],
         "y": [
          -0.7582235336303711,
          -0.7743901610374451
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13734756410121918,
          -0.14744573831558228
         ],
         "y": [
          -0.7582235336303711,
          -0.7505425810813904
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.14744573831558228,
          -0.1557905375957489
         ],
         "y": [
          -0.7505425810813904,
          -0.7617782354354858
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6277763247489929,
          -0.6180804967880249
         ],
         "y": [
          0.39580392837524414,
          0.38947081565856934
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6277763247489929,
          -0.6371617913246155
         ],
         "y": [
          0.39580392837524414,
          0.40821900963783264
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6277763247489929,
          -0.6418706178665161
         ],
         "y": [
          0.39580392837524414,
          0.39911046624183655
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.12317494302988052,
          -0.12130437791347504
         ],
         "y": [
          0.7525601387023926,
          0.7674089074134827
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.12317494302988052,
          -0.13324664533138275
         ],
         "y": [
          0.7525601387023926,
          0.7550481557846069
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.12130437791347504,
          -0.12099026888608932
         ],
         "y": [
          0.7674089074134827,
          0.7804820537567139
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.2651641070842743
         ],
         "y": [
          0.0758620947599411,
          0.0775832012295723
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.26242369413375854
         ],
         "y": [
          0.0758620947599411,
          0.06921909749507904
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.27126750349998474
         ],
         "y": [
          0.0758620947599411,
          0.08482994884252548
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.23729102313518524
         ],
         "y": [
          0.0758620947599411,
          0.09239018708467484
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.23775270581245422
         ],
         "y": [
          0.0758620947599411,
          0.07079372555017471
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.23767872154712677
         ],
         "y": [
          0.0758620947599411,
          0.08104623109102249
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.24317310750484467
         ],
         "y": [
          0.0758620947599411,
          0.06168784201145172
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.2542721927165985
         ],
         "y": [
          0.0758620947599411,
          0.08603066951036453
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.26233962178230286
         ],
         "y": [
          0.0758620947599411,
          0.058629781007766724
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.2504383325576782
         ],
         "y": [
          0.0758620947599411,
          0.06267620623111725
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24972949922084808,
          -0.25779861211776733
         ],
         "y": [
          0.0758620947599411,
          0.09522389620542526
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.27126750349998474,
          -0.2875667214393616
         ],
         "y": [
          0.08482994884252548,
          0.09090299904346466
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23729102313518524,
          -0.23473599553108215
         ],
         "y": [
          0.09239018708467484,
          0.10710199922323227
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.26233962178230286,
          -0.2756352722644806
         ],
         "y": [
          0.058629781007766724,
          0.04964457452297211
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.25779861211776733,
          -0.266320139169693
         ],
         "y": [
          0.09522389620542526,
          0.10857020318508148
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.043575745075941086,
          -0.03222799301147461
         ],
         "y": [
          0.039123330265283585,
          0.04614434391260147
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.043575745075941086,
          -0.055407457053661346
         ],
         "y": [
          0.039123330265283585,
          0.03616723045706749
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.03222799301147461,
          -0.03363105282187462
         ],
         "y": [
          0.04614434391260147,
          0.05745095759630203
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.03222799301147461,
          -0.020338967442512512
         ],
         "y": [
          0.04614434391260147,
          0.04897857457399368
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.0782736986875534
         ],
         "y": [
          -0.11205832660198212,
          -0.10993553698062897
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.01099549699574709
         ],
         "y": [
          -0.11205832660198212,
          -0.11707761138677597
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.04530082270503044
         ],
         "y": [
          -0.11205832660198212,
          -0.09634791314601898
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.04123542830348015
         ],
         "y": [
          -0.11205832660198212,
          -0.12414292991161346
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.024749530479311943
         ],
         "y": [
          -0.11205832660198212,
          -0.10653723031282425
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.04501255974173546
         ],
         "y": [
          -0.11205832660198212,
          -0.13177691400051117
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.0526345856487751
         ],
         "y": [
          -0.11205832660198212,
          -0.11385303735733032
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.05202922224998474
         ],
         "y": [
          -0.11205832660198212,
          -0.12402653694152832
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.024997025728225708
         ],
         "y": [
          -0.11205832660198212,
          -0.11657270789146423
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.031038587912917137
         ],
         "y": [
          -0.11205832660198212,
          -0.10078327357769012
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.029518550261855125
         ],
         "y": [
          -0.11205832660198212,
          -0.12249433994293213
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.034230418503284454
         ],
         "y": [
          -0.11205832660198212,
          -0.12994441390037537
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.051199428737163544
         ],
         "y": [
          -0.11205832660198212,
          -0.10304851084947586
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04048518091440201,
          0.03683612123131752
         ],
         "y": [
          -0.11205832660198212,
          -0.09575406461954117
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.0782736986875534,
          0.08545053005218506
         ],
         "y": [
          -0.10993553698062897,
          -0.12434984743595123
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.0782736986875534,
          0.08983227610588074
         ],
         "y": [
          -0.10993553698062897,
          -0.11319632828235626
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.0782736986875534,
          0.09579642862081528
         ],
         "y": [
          -0.10993553698062897,
          -0.10309302806854248
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.0782736986875534,
          0.08836249262094498
         ],
         "y": [
          -0.10993553698062897,
          -0.0970551148056984
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.0782736986875534,
          0.09424592554569244
         ],
         "y": [
          -0.10993553698062897,
          -0.11958522349596024
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.0782736986875534,
          0.09859362989664078
         ],
         "y": [
          -0.10993553698062897,
          -0.11215144395828247
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.01099549699574709,
          -0.004045096691697836
         ],
         "y": [
          -0.11707761138677597,
          -0.1254507601261139
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.01099549699574709,
          -0.005443648900836706
         ],
         "y": [
          -0.11707761138677597,
          -0.1155487447977066
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.07436051964759827,
          0.07608705759048462
         ],
         "y": [
          0.7799107432365417,
          0.7972037196159363
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28332382440567017,
          0.268094003200531
         ],
         "y": [
          -0.14553803205490112,
          -0.15684574842453003
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28332382440567017,
          0.2997327446937561
         ],
         "y": [
          -0.14553803205490112,
          -0.14434003829956055
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28332382440567017,
          0.2939988672733307
         ],
         "y": [
          -0.14553803205490112,
          -0.15851622819900513
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28332382440567017,
          0.28495776653289795
         ],
         "y": [
          -0.14553803205490112,
          -0.15961629152297974
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28332382440567017,
          0.2943771481513977
         ],
         "y": [
          -0.14553803205490112,
          -0.1373615711927414
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28332382440567017,
          0.28263917565345764
         ],
         "y": [
          -0.14553803205490112,
          -0.12731018662452698
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28332382440567017,
          0.2756366431713104
         ],
         "y": [
          -0.14553803205490112,
          -0.14905354380607605
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28332382440567017,
          0.300099641084671
         ],
         "y": [
          -0.14553803205490112,
          -0.15276660025119781
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.268094003200531,
          0.2661236524581909
         ],
         "y": [
          -0.15684574842453003,
          -0.17092972993850708
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.28263917565345764,
          0.2905575931072235
         ],
         "y": [
          -0.12731018662452698,
          -0.11610478162765503
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.366576611995697,
          -0.37955158948898315
         ],
         "y": [
          0.4461452066898346,
          0.45104196667671204
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.366576611995697,
          -0.3689843714237213
         ],
         "y": [
          0.4461452066898346,
          0.4581584632396698
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.366576611995697,
          -0.3550885021686554
         ],
         "y": [
          0.4461452066898346,
          0.4353478252887726
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3550885021686554,
          -0.3662598133087158
         ],
         "y": [
          0.4353478252887726,
          0.4322984516620636
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3550885021686554,
          -0.34850114583969116
         ],
         "y": [
          0.4353478252887726,
          0.44463130831718445
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5612561702728271,
          0.5741813778877258
         ],
         "y": [
          0.7164617776870728,
          0.7342577576637268
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.644544243812561,
          -0.6353917121887207
         ],
         "y": [
          0.010462937876582146,
          0.017068928107619286
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6353917121887207,
          -0.6428652405738831
         ],
         "y": [
          0.017068928107619286,
          0.02472272515296936
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7144777774810791,
          -0.7264188528060913
         ],
         "y": [
          0.15899834036827087,
          0.16294848918914795
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7144777774810791,
          -0.7076078653335571
         ],
         "y": [
          0.15899834036827087,
          0.1533392369747162
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5195352435112,
          -0.5317930579185486
         ],
         "y": [
          -0.16009749472141266,
          -0.15328384935855865
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5195352435112,
          -0.525205671787262
         ],
         "y": [
          -0.16009749472141266,
          -0.17235422134399414
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5195352435112,
          -0.535426139831543
         ],
         "y": [
          -0.16009749472141266,
          -0.16529220342636108
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5195352435112,
          -0.5185638666152954
         ],
         "y": [
          -0.16009749472141266,
          -0.14856500923633575
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5195352435112,
          -0.5116506814956665
         ],
         "y": [
          -0.16009749472141266,
          -0.16815750300884247
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.535426139831543,
          -0.5442339181900024
         ],
         "y": [
          -0.16529220342636108,
          -0.1695055216550827
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.9313152432441711,
          -0.9092690348625183
         ],
         "y": [
          -0.08216779679059982,
          -0.08025467395782471
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.17314572632312775,
          0.17143091559410095
         ],
         "y": [
          0.8022888898849487,
          0.7921874523162842
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8791898488998413,
          0.8731286525726318
         ],
         "y": [
          -0.11446963995695114,
          -0.1205846443772316
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2087363302707672,
          0.20287899672985077
         ],
         "y": [
          -0.8708375096321106,
          -0.8475753664970398
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2087363302707672,
          0.21408170461654663
         ],
         "y": [
          -0.8708375096321106,
          -0.8912492394447327
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.10449626296758652,
          0.10548495501279831
         ],
         "y": [
          -0.8378106951713562,
          -0.8474263548851013
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5252882838249207,
          -0.5350111126899719
         ],
         "y": [
          0.5082417726516724,
          0.5145244002342224
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5252882838249207,
          -0.5157106518745422
         ],
         "y": [
          0.5082417726516724,
          0.5011254549026489
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5350111126899719,
          -0.5475872159004211
         ],
         "y": [
          0.5145244002342224,
          0.525614321231842
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6559670567512512,
          -0.6620767116546631
         ],
         "y": [
          0.11074750125408173,
          0.10277193784713745
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6559670567512512,
          -0.666490375995636
         ],
         "y": [
          0.11074750125408173,
          0.11675538867712021
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.130953848361969
         ],
         "y": [
          0.1783556342124939,
          0.1850578635931015
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.17376573383808136
         ],
         "y": [
          0.1783556342124939,
          0.16002406179904938
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.1278735250234604
         ],
         "y": [
          0.1783556342124939,
          0.17590875923633575
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.1542547196149826
         ],
         "y": [
          0.1783556342124939,
          0.19069840013980865
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.12179350852966309
         ],
         "y": [
          0.1783556342124939,
          0.1976643204689026
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.14481887221336365
         ],
         "y": [
          0.1783556342124939,
          0.20205974578857422
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.1335379034280777
         ],
         "y": [
          0.1783556342124939,
          0.1683427393436432
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.14265897870063782
         ],
         "y": [
          0.1783556342124939,
          0.16452230513095856
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.15206781029701233
         ],
         "y": [
          0.1783556342124939,
          0.16914552450180054
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.14181078970432281
         ],
         "y": [
          0.1783556342124939,
          0.1903928965330124
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14359280467033386,
          0.15728843212127686
         ],
         "y": [
          0.1783556342124939,
          0.18186378479003906
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.17376573383808136,
          0.19168399274349213
         ],
         "y": [
          0.16002406179904938,
          0.16136954724788666
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.17376573383808136,
          0.1788496971130371
         ],
         "y": [
          0.16002406179904938,
          0.1455211639404297
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.17376573383808136,
          0.18581780791282654
         ],
         "y": [
          0.16002406179904938,
          0.15456277132034302
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.17376573383808136,
          0.1904127299785614
         ],
         "y": [
          0.16002406179904938,
          0.14967814087867737
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.17376573383808136,
          0.1864471733570099
         ],
         "y": [
          0.16002406179904938,
          0.1693904548883438
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12179350852966309,
          0.10608286410570145
         ],
         "y": [
          0.1976643204689026,
          0.21498411893844604
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.10608286410570145,
          0.09656600654125214
         ],
         "y": [
          0.21498411893844604,
          0.22884289920330048
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14481887221336365,
          0.14172786474227905
         ],
         "y": [
          0.20205974578857422,
          0.21717685461044312
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14481887221336365,
          0.15262942016124725
         ],
         "y": [
          0.20205974578857422,
          0.21659329533576965
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.21722206473350525,
          0.20688937604427338
         ],
         "y": [
          -0.38121482729911804,
          -0.39023154973983765
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.21722206473350525,
          0.23075935244560242
         ],
         "y": [
          -0.38121482729911804,
          -0.3777788281440735
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.21722206473350525,
          0.2243434637784958
         ],
         "y": [
          -0.38121482729911804,
          -0.3932760953903198
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.20688937604427338,
          0.2065499722957611
         ],
         "y": [
          -0.39023154973983765,
          -0.40410083532333374
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.23075935244560242,
          0.243149071931839
         ],
         "y": [
          -0.3777788281440735,
          -0.3831672668457031
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3448876738548279,
          0.3472672998905182
         ],
         "y": [
          -0.48921892046928406,
          -0.4797307252883911
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3448876738548279,
          0.33958837389945984
         ],
         "y": [
          -0.48921892046928406,
          -0.5002502202987671
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3448876738548279,
          0.35666000843048096
         ],
         "y": [
          -0.48921892046928406,
          -0.48825928568840027
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3448876738548279,
          0.35314804315567017
         ],
         "y": [
          -0.48921892046928406,
          -0.5019670724868774
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7329003810882568,
          0.7470477819442749
         ],
         "y": [
          -0.4013447165489197,
          -0.40921831130981445
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7329003810882568,
          0.7193542718887329
         ],
         "y": [
          -0.4013447165489197,
          -0.3937244415283203
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.14491668343544006,
          -0.13350069522857666
         ],
         "y": [
          -0.4415443241596222,
          -0.44033169746398926
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.14491668343544006,
          -0.13740964233875275
         ],
         "y": [
          -0.4415443241596222,
          -0.45264342427253723
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.14491668343544006,
          -0.15651658177375793
         ],
         "y": [
          -0.4415443241596222,
          -0.44768351316452026
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.14491668343544006,
          -0.1479344218969345
         ],
         "y": [
          -0.4415443241596222,
          -0.45872366428375244
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.14491668343544006,
          -0.1542615443468094
         ],
         "y": [
          -0.4415443241596222,
          -0.4350850284099579
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1479344218969345,
          -0.14888620376586914
         ],
         "y": [
          -0.45872366428375244,
          -0.47051113843917847
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.11695229262113571,
          -0.10263287276029587
         ],
         "y": [
          0.5008319020271301,
          0.49972954392433167
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.11695229262113571,
          -0.11333031952381134
         ],
         "y": [
          0.5008319020271301,
          0.5094937682151794
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.11695229262113571,
          -0.12339343875646591
         ],
         "y": [
          0.5008319020271301,
          0.5157644152641296
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.11695229262113571,
          -0.12941278517246246
         ],
         "y": [
          0.5008319020271301,
          0.5038565397262573
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.10263287276029587,
          -0.09504030644893646
         ],
         "y": [
          0.49972954392433167,
          0.51065993309021
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4156067967414856,
          0.41302919387817383
         ],
         "y": [
          0.2018127739429474,
          0.19040359556674957
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4156067967414856,
          0.4300577640533447
         ],
         "y": [
          0.2018127739429474,
          0.20662079751491547
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4156067967414856,
          0.4174501299858093
         ],
         "y": [
          0.2018127739429474,
          0.21639984846115112
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4156067967414856,
          0.4306982159614563
         ],
         "y": [
          0.2018127739429474,
          0.19807304441928864
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4156067967414856,
          0.4261118769645691
         ],
         "y": [
          0.2018127739429474,
          0.2140847146511078
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4156067967414856,
          0.42485639452934265
         ],
         "y": [
          0.2018127739429474,
          0.1908881962299347
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4156067967414856,
          0.4058316648006439
         ],
         "y": [
          0.2018127739429474,
          0.20840424299240112
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23908095061779022,
          -0.23017935454845428
         ],
         "y": [
          0.7413036227226257,
          0.7438498735427856
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23908095061779022,
          -0.24538980424404144
         ],
         "y": [
          0.7413036227226257,
          0.7538711428642273
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7543308138847351,
          0.7401421070098877
         ],
         "y": [
          0.2983732223510742,
          0.2927802801132202
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.02272888831794262,
          -0.022920116782188416
         ],
         "y": [
          -0.8755979537963867,
          -0.8607255220413208
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.16055218875408173,
          -0.16250862181186676
         ],
         "y": [
          0.88905930519104,
          0.8812724351882935
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3544303774833679,
          -0.3625791072845459
         ],
         "y": [
          -0.7020714282989502,
          -0.703737735748291
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1518697589635849,
          -0.16001345217227936
         ],
         "y": [
          0.798110842704773,
          0.7998490929603577
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4646610915660858,
          0.4731772541999817
         ],
         "y": [
          0.5041765570640564,
          0.5026654601097107
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7088515758514404,
          -0.7113285660743713
         ],
         "y": [
          -0.06457525491714478,
          -0.07263539731502533
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.14563389122486115,
          0.1517602503299713
         ],
         "y": [
          -0.8648391366004944,
          -0.8704785108566284
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04358471930027008,
          0.03830118477344513
         ],
         "y": [
          0.7586871981620789,
          0.7689446806907654
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.04358471930027008,
          0.051514241844415665
         ],
         "y": [
          0.7586871981620789,
          0.7652984857559204
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8209912180900574,
          0.8409534096717834
         ],
         "y": [
          0.30307427048683167,
          0.30988937616348267
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.29482361674308777,
          0.29014673829078674
         ],
         "y": [
          0.8216148614883423,
          0.8093355298042297
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.051393430680036545,
          0.05087065324187279
         ],
         "y": [
          -0.8123801946640015,
          -0.7970725893974304
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.051393430680036545,
          0.05193968117237091
         ],
         "y": [
          -0.8123801946640015,
          -0.8279633522033691
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4802454710006714,
          -0.4889718294143677
         ],
         "y": [
          -0.7971139550209045,
          -0.7990707755088806
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4802454710006714,
          -0.4911244809627533
         ],
         "y": [
          -0.7971139550209045,
          -0.8166520595550537
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7990990877151489,
          0.8139441013336182
         ],
         "y": [
          0.02329365164041519,
          0.02358992211520672
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7058599591255188,
          -0.686936616897583
         ],
         "y": [
          -0.6156819462776184,
          -0.5986230373382568
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7058599591255188,
          -0.7246546149253845
         ],
         "y": [
          -0.6156819462776184,
          -0.6273865103721619
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7058599591255188,
          -0.7200268507003784
         ],
         "y": [
          -0.6156819462776184,
          -0.6331924796104431
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.686936616897583,
          -0.6898314356803894
         ],
         "y": [
          -0.5986230373382568,
          -0.5904925465583801
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.37734925746917725,
          -0.37098196148872375
         ],
         "y": [
          0.7862591743469238,
          0.772525429725647
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2624433934688568,
          -0.2537754476070404
         ],
         "y": [
          0.32829520106315613,
          0.3173696994781494
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2537754476070404,
          -0.24774831533432007
         ],
         "y": [
          0.3173696994781494,
          0.3264174461364746
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2537754476070404,
          -0.2649197280406952
         ],
         "y": [
          0.3173696994781494,
          0.3148702383041382
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.11083648353815079,
          0.11827821284532547
         ],
         "y": [
          0.8831673264503479,
          0.8866384029388428
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.946333646774292,
          -0.9625589847564697
         ],
         "y": [
          0.08589664846658707,
          0.08713431656360626
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3717285692691803,
          -0.3751268982887268
         ],
         "y": [
          -0.7745621204376221,
          -0.7913556694984436
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3717285692691803,
          -0.383297324180603
         ],
         "y": [
          -0.7745621204376221,
          -0.791976809501648
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7677406668663025,
          -0.765082836151123
         ],
         "y": [
          0.42969998717308044,
          0.42171475291252136
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.025569144636392593,
          -0.026303235441446304
         ],
         "y": [
          0.8879579901695251,
          0.9028567671775818
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4059320390224457,
          -0.4069001078605652
         ],
         "y": [
          -0.09449398517608643,
          -0.08245662599802017
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4059320390224457,
          -0.4183979034423828
         ],
         "y": [
          -0.09449398517608643,
          -0.10215730965137482
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4069001078605652,
          -0.4174834191799164
         ],
         "y": [
          -0.08245662599802017,
          -0.075863316655159
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4183979034423828,
          -0.43061143159866333
         ],
         "y": [
          -0.10215730965137482,
          -0.10675458610057831
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8170592784881592,
          -0.8068737983703613
         ],
         "y": [
          -0.451316773891449,
          -0.4579707980155945
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.68149733543396,
          -0.6771326661109924
         ],
         "y": [
          0.39838674664497375,
          0.4057563543319702
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3274780809879303,
          0.3340403139591217
         ],
         "y": [
          -0.7772534489631653,
          -0.793379545211792
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.710517406463623,
          0.7228615880012512
         ],
         "y": [
          0.15306994318962097,
          0.14812271296977997
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.710517406463623,
          0.7071024775505066
         ],
         "y": [
          0.15306994318962097,
          0.16224460303783417
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.710517406463623,
          0.7248876094818115
         ],
         "y": [
          0.15306994318962097,
          0.1588534712791443
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.22308528423309326,
          -0.2170264720916748
         ],
         "y": [
          0.8970170617103577,
          0.8913715481758118
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.00195901351980865,
          -0.0007784467888996005
         ],
         "y": [
          -0.6552648544311523,
          -0.6416881084442139
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.0007784467888996005,
          0.008626699447631836
         ],
         "y": [
          -0.6416881084442139,
          -0.6412072777748108
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.844916582107544,
          -0.8608044385910034
         ],
         "y": [
          0.16795863211154938,
          0.17014208436012268
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.407492071390152,
          -0.4144286513328552
         ],
         "y": [
          -0.6516724824905396,
          -0.6626449227333069
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.22418686747550964,
          -0.2179913967847824
         ],
         "y": [
          -0.6969587206840515,
          -0.6852877140045166
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2179913967847824,
          -0.21057982742786407
         ],
         "y": [
          -0.6852877140045166,
          -0.6916422843933105
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3416731655597687,
          0.3391903340816498
         ],
         "y": [
          -0.6898460984230042,
          -0.6976954936981201
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8098501563072205,
          0.8085806965827942
         ],
         "y": [
          0.1170424297451973,
          0.1256016343832016
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8170099854469299,
          -0.8058951497077942
         ],
         "y": [
          0.007958290167152882,
          0.006838966626673937
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8058951497077942,
          -0.794305682182312
         ],
         "y": [
          0.006838966626673937,
          0.005738302133977413
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.16071736812591553,
          0.16282352805137634
         ],
         "y": [
          0.7327920198440552,
          0.7477051615715027
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.16071736812591553,
          0.16894406080245972
         ],
         "y": [
          0.7327920198440552,
          0.7293333411216736
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6933162808418274,
          0.7067047953605652
         ],
         "y": [
          -0.19395314157009125,
          -0.19143643975257874
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6933162808418274,
          0.7035215497016907
         ],
         "y": [
          -0.19395314157009125,
          -0.20241159200668335
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6933162808418274,
          0.683044970035553
         ],
         "y": [
          -0.19395314157009125,
          -0.1920737773180008
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.41453486680984497,
          -0.4236895442008972
         ],
         "y": [
          0.6189340353012085,
          0.6128221154212952
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.41453486680984497,
          -0.41997113823890686
         ],
         "y": [
          0.6189340353012085,
          0.6328850984573364
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4236895442008972,
          -0.4354020357131958
         ],
         "y": [
          0.6128221154212952,
          0.6221051216125488
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.0705016702413559,
          -0.06945653259754181
         ],
         "y": [
          -0.7610577940940857,
          -0.7487965226173401
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.0705016702413559,
          -0.07158109545707703
         ],
         "y": [
          -0.7610577940940857,
          -0.7766501307487488
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7337769865989685,
          -0.7249112725257874
         ],
         "y": [
          0.012002963572740555,
          0.012655409052968025
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7983403205871582,
          0.8114368319511414
         ],
         "y": [
          -0.3608548045158386,
          -0.3668998181819916
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4949258863925934,
          0.5084160566329956
         ],
         "y": [
          0.5293390154838562,
          0.5271650552749634
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4949258863925934,
          0.49341684579849243
         ],
         "y": [
          0.5293390154838562,
          0.5419219732284546
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4949258863925934,
          0.5042004585266113
         ],
         "y": [
          0.5293390154838562,
          0.5416924953460693
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5084160566329956,
          0.5215420126914978
         ],
         "y": [
          0.5271650552749634,
          0.5349789261817932
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6691137552261353,
          -0.6614246368408203
         ],
         "y": [
          -0.5580881834030151,
          -0.5673811435699463
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5598483681678772,
          0.5707530379295349
         ],
         "y": [
          -0.5278728604316711,
          -0.5368096232414246
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5598483681678772,
          0.5501906275749207
         ],
         "y": [
          -0.5278728604316711,
          -0.5211278200149536
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3617151379585266,
          0.37212422490119934
         ],
         "y": [
          -0.6250971555709839,
          -0.6276323199272156
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3617151379585266,
          0.36207476258277893
         ],
         "y": [
          -0.6250971555709839,
          -0.6370021104812622
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7385817170143127,
          0.7484925985336304
         ],
         "y": [
          -0.44711989164352417,
          -0.4535401463508606
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6279623508453369,
          0.6188214421272278
         ],
         "y": [
          0.5931410789489746,
          0.5845586657524109
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.15136344730854034,
          0.14928431808948517
         ],
         "y": [
          0.8829110860824585,
          0.8701456189155579
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.12590543925762177,
          0.12373753637075424
         ],
         "y": [
          -0.7756603956222534,
          -0.7838422656059265
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3492750823497772,
          -0.3530432879924774
         ],
         "y": [
          0.6387366056442261,
          0.6303043961524963
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3492750823497772,
          -0.3517649471759796
         ],
         "y": [
          0.6387366056442261,
          0.6492036581039429
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6868894100189209,
          -0.688787579536438
         ],
         "y": [
          -0.4459013342857361,
          -0.4366348087787628
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6868894100189209,
          -0.701619565486908
         ],
         "y": [
          -0.4459013342857361,
          -0.450623095035553
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6868894100189209,
          -0.6970093846321106
         ],
         "y": [
          -0.4459013342857361,
          -0.4590684771537781
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5776954889297485,
          -0.5898202061653137
         ],
         "y": [
          -0.7213839888572693,
          -0.7369332909584045
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.09600895643234253,
          0.0983249694108963
         ],
         "y": [
          -0.41745439171791077,
          -0.40416428446769714
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.09600895643234253,
          0.09082520008087158
         ],
         "y": [
          -0.41745439171791077,
          -0.4256831407546997
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.0983249694108963,
          0.10833647847175598
         ],
         "y": [
          -0.40416428446769714,
          -0.4039516746997833
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.48129236698150635,
          0.4741723835468292
         ],
         "y": [
          -0.6731943488121033,
          -0.6685829758644104
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.680693507194519,
          0.6722128391265869
         ],
         "y": [
          0.4168247580528259,
          0.4172951579093933
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.680693507194519,
          0.6963357925415039
         ],
         "y": [
          0.4168247580528259,
          0.4259383976459503
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5856172442436218,
          -0.5964462161064148
         ],
         "y": [
          -0.6755871772766113,
          -0.6885432600975037
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1482190638780594,
          0.1468152552843094
         ],
         "y": [
          -0.7070485949516296,
          -0.7160313725471497
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1482190638780594,
          0.14691035449504852
         ],
         "y": [
          -0.7070485949516296,
          -0.6964961886405945
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.49099546670913696,
          0.49551212787628174
         ],
         "y": [
          -0.559167206287384,
          -0.5685448050498962
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.49099546670913696,
          0.4923659563064575
         ],
         "y": [
          -0.559167206287384,
          -0.5501517057418823
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8050467371940613,
          0.8188968300819397
         ],
         "y": [
          -0.08552004396915436,
          -0.08631248772144318
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.35127928853034973,
          0.3580873906612396
         ],
         "y": [
          -0.8312480449676514,
          -0.8474278450012207
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8469206690788269,
          -0.8639687895774841
         ],
         "y": [
          -0.22649626433849335,
          -0.23074562847614288
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6463356614112854,
          0.6525543928146362
         ],
         "y": [
          0.3675895631313324,
          0.36188697814941406
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4408949017524719,
          0.4345546364784241
         ],
         "y": [
          0.7254674434661865,
          0.7149675488471985
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8879057765007019,
          -0.8778843879699707
         ],
         "y": [
          -0.35235998034477234,
          -0.3484012484550476
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.06147745996713638,
          -0.07294018566608429
         ],
         "y": [
          0.31757912039756775,
          0.32505205273628235
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.06147745996713638,
          -0.05209783837199211
         ],
         "y": [
          0.31757912039756775,
          0.32655856013298035
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.07294018566608429,
          -0.08079873770475388
         ],
         "y": [
          0.32505205273628235,
          0.3352917730808258
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.05209783837199211,
          -0.04847196117043495
         ],
         "y": [
          0.32655856013298035,
          0.3389662504196167
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6063867807388306,
          0.6127545237541199
         ],
         "y": [
          -0.45039814710617065,
          -0.46124497056007385
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6063867807388306,
          0.6169906854629517
         ],
         "y": [
          -0.45039814710617065,
          -0.44889432191848755
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6343406438827515,
          0.6457178592681885
         ],
         "y": [
          -0.5567592978477478,
          -0.5662530660629272
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7837327122688293,
          0.7843146324157715
         ],
         "y": [
          0.179037407040596,
          0.18734179437160492
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5215603113174438,
          -0.5305287837982178
         ],
         "y": [
          -0.7420274615287781,
          -0.7552220821380615
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5134103298187256,
          -0.5245718359947205
         ],
         "y": [
          0.5714555978775024,
          0.5817438364028931
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5134103298187256,
          -0.5027233362197876
         ],
         "y": [
          0.5714555978775024,
          0.561428964138031
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7875023484230042,
          -0.7859444618225098
         ],
         "y": [
          0.2592579126358032,
          0.26761293411254883
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.23365932703018188,
          0.24042044579982758
         ],
         "y": [
          0.9436058402061462,
          0.9385882616043091
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.438924640417099,
          -0.4269837439060211
         ],
         "y": [
          -0.36473098397254944,
          -0.35550573468208313
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4269837439060211,
          -0.4280882775783539
         ],
         "y": [
          -0.35550573468208313,
          -0.34281644225120544
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4269837439060211,
          -0.4236345887184143
         ],
         "y": [
          -0.35550573468208313,
          -0.3663071095943451
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4280882775783539,
          -0.43750086426734924
         ],
         "y": [
          -0.34281644225120544,
          -0.33697959780693054
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.20895510911941528,
          -0.2168004810810089
         ],
         "y": [
          0.6700572967529297,
          0.664544939994812
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2168004810810089,
          -0.22333498299121857
         ],
         "y": [
          0.664544939994812,
          0.6772757768630981
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8050962686538696,
          -0.8126966953277588
         ],
         "y": [
          0.3160892426967621,
          0.3122482895851135
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.23951207101345062,
          0.2323811650276184
         ],
         "y": [
          0.8131521940231323,
          0.8175614476203918
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8696674704551697,
          0.8623211979866028
         ],
         "y": [
          0.42461875081062317,
          0.4200095236301422
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6795215010643005,
          0.6725768446922302
         ],
         "y": [
          0.28516003489494324,
          0.28985440731048584
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4109909236431122,
          0.4198068678379059
         ],
         "y": [
          0.6677517890930176,
          0.6641319394111633
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4109909236431122,
          0.41547301411628723
         ],
         "y": [
          0.6677517890930176,
          0.6806315779685974
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7876505255699158,
          0.8053264021873474
         ],
         "y": [
          0.43869549036026,
          0.4478869140148163
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8381719589233398,
          -0.847888708114624
         ],
         "y": [
          -0.2687743604183197,
          -0.26921942830085754
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8381719589233398,
          -0.8264639973640442
         ],
         "y": [
          -0.2687743604183197,
          -0.2661362290382385
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8381719589233398,
          -0.8601334095001221
         ],
         "y": [
          -0.2687743604183197,
          -0.27551308274269104
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3449362814426422,
          -0.34054669737815857
         ],
         "y": [
          -0.590968906879425,
          -0.6001814603805542
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3449362814426422,
          -0.3548562824726105
         ],
         "y": [
          -0.590968906879425,
          -0.5990564823150635
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8727100491523743,
          0.8536815643310547
         ],
         "y": [
          -0.2202899307012558,
          -0.2157513052225113
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4298963248729706,
          -0.4206850230693817
         ],
         "y": [
          0.6931653618812561,
          0.6789549589157104
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.19304576516151428,
          0.1938367635011673
         ],
         "y": [
          0.8631028532981873,
          0.8844519257545471
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.19304576516151428,
          0.2007836550474167
         ],
         "y": [
          0.8631028532981873,
          0.8807103037834167
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.19304576516151428,
          0.1889210045337677
         ],
         "y": [
          0.8631028532981873,
          0.8435739874839783
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5253773927688599,
          0.5145503878593445
         ],
         "y": [
          0.6996396780014038,
          0.685488224029541
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.24792711436748505,
          0.23984688520431519
         ],
         "y": [
          0.7427502870559692,
          0.7450394630432129
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6314640641212463,
          0.6356303691864014
         ],
         "y": [
          -0.3273452818393707,
          -0.3173857629299164
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6356303691864014,
          0.6462216973304749
         ],
         "y": [
          -0.3173857629299164,
          -0.3288158178329468
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6356303691864014,
          0.6443158388137817
         ],
         "y": [
          -0.3173857629299164,
          -0.30971890687942505
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6356303691864014,
          0.651068925857544
         ],
         "y": [
          -0.3173857629299164,
          -0.32029998302459717
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.37137192487716675,
          0.38069239258766174
         ],
         "y": [
          0.8113324642181396,
          0.8207792043685913
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.37137192487716675,
          0.36302438378334045
         ],
         "y": [
          0.8113324642181396,
          0.7931370735168457
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.37137192487716675,
          0.36697766184806824
         ],
         "y": [
          0.8113324642181396,
          0.8209681510925293
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7690975069999695,
          0.7708918452262878
         ],
         "y": [
          0.24044567346572876,
          0.23155273497104645
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7690975069999695,
          0.7808379530906677
         ],
         "y": [
          0.24044567346572876,
          0.24560262262821198
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1830696165561676,
          0.18095159530639648
         ],
         "y": [
          0.5248548984527588,
          0.5350364446640015
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1830696165561676,
          0.19414785504341125
         ],
         "y": [
          0.5248548984527588,
          0.5276046991348267
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1830696165561676,
          0.1731400340795517
         ],
         "y": [
          0.5248548984527588,
          0.5225337743759155
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7855224609375,
          0.7711118459701538
         ],
         "y": [
          -0.19481338560581207,
          -0.19087567925453186
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.78596031665802,
          -0.7937101125717163
         ],
         "y": [
          0.48784711956977844,
          0.49227374792099
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6939426064491272,
          0.6828455328941345
         ],
         "y": [
          0.4917212426662445,
          0.4837700426578522
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6828455328941345,
          0.6684457659721375
         ],
         "y": [
          0.4837700426578522,
          0.4734368324279785
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5785415768623352,
          -0.5832547545433044
         ],
         "y": [
          -0.3538910150527954,
          -0.3644525408744812
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5785415768623352,
          -0.592799186706543
         ],
         "y": [
          -0.3538910150527954,
          -0.357217937707901
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.09551560133695602,
          0.10515689104795456
         ],
         "y": [
          0.6426213979721069,
          0.6447091698646545
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.09551560133695602,
          0.09332401305437088
         ],
         "y": [
          0.6426213979721069,
          0.6547420024871826
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7202431559562683,
          0.7274435758590698
         ],
         "y": [
          -0.10032343864440918,
          -0.09587421268224716
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7693247199058533,
          -0.7853516936302185
         ],
         "y": [
          -0.3962993621826172,
          -0.40278393030166626
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7693247199058533,
          -0.7594150304794312
         ],
         "y": [
          -0.3962993621826172,
          -0.3955489695072174
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5552569627761841,
          -0.5613664984703064
         ],
         "y": [
          0.4500080645084381,
          0.4442608058452606
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8180519342422485,
          -0.8322096467018127
         ],
         "y": [
          0.3383656442165375,
          0.34470266103744507
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7948247194290161,
          0.8061346411705017
         ],
         "y": [
          0.5819405317306519,
          0.5899354815483093
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8986503481864929,
          0.8794869184494019
         ],
         "y": [
          0.49233606457710266,
          0.48230600357055664
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8415874242782593,
          0.8511672616004944
         ],
         "y": [
          -0.11441293358802795,
          -0.11505359411239624
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2769685983657837,
          0.28174686431884766
         ],
         "y": [
          0.7071499228477478,
          0.7180672883987427
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8516592383384705,
          -0.8472305536270142
         ],
         "y": [
          0.0461750365793705,
          0.039026860147714615
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4659295380115509,
          -0.46276533603668213
         ],
         "y": [
          -0.6594077944755554,
          -0.6518123745918274
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.21270157396793365,
          0.20986875891685486
         ],
         "y": [
          -0.7373391389846802,
          -0.7279043793678284
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2762974500656128,
          -0.2766312062740326
         ],
         "y": [
          -0.39354801177978516,
          -0.37941333651542664
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2762974500656128,
          -0.27947521209716797
         ],
         "y": [
          -0.39354801177978516,
          -0.4062449336051941
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2766312062740326,
          -0.288947731256485
         ],
         "y": [
          -0.37941333651542664,
          -0.37697717547416687
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.288947731256485,
          -0.30065083503723145
         ],
         "y": [
          -0.37697717547416687,
          -0.3838024437427521
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.30944275856018066,
          0.3166634738445282
         ],
         "y": [
          0.6756950616836548,
          0.6886201500892639
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.30944275856018066,
          0.3005183935165405
         ],
         "y": [
          0.6756950616836548,
          0.6755185127258301
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7571703791618347,
          0.7519220113754272
         ],
         "y": [
          -0.009163754992187023,
          -0.019126472994685173
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7571703791618347,
          0.7714688181877136
         ],
         "y": [
          -0.009163754992187023,
          -0.006616523023694754
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7519220113754272,
          0.764403760433197
         ],
         "y": [
          -0.019126472994685173,
          -0.02485518716275692
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24508485198020935,
          -0.25083479285240173
         ],
         "y": [
          -0.8730838298797607,
          -0.8653242588043213
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.24508485198020935,
          -0.23712196946144104
         ],
         "y": [
          -0.8730838298797607,
          -0.8781198263168335
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.770709216594696,
          -0.7633475661277771
         ],
         "y": [
          -0.31039854884147644,
          -0.3142510652542114
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.790224015712738,
          -0.7967306971549988
         ],
         "y": [
          -0.2044263482093811,
          -0.1975664645433426
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7967306971549988,
          -0.8074932098388672
         ],
         "y": [
          -0.1975664645433426,
          -0.19645309448242188
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7072979211807251,
          -0.6928288340568542
         ],
         "y": [
          0.5021839141845703,
          0.49144211411476135
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8915359377861023,
          0.9056205153465271
         ],
         "y": [
          0.2129247784614563,
          0.21694818139076233
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5043940544128418,
          -0.51682049036026
         ],
         "y": [
          -0.6045594811439514,
          -0.6096507906913757
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5043940544128418,
          -0.4964819848537445
         ],
         "y": [
          -0.6045594811439514,
          -0.5982891321182251
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5043940544128418,
          -0.5114796161651611
         ],
         "y": [
          -0.6045594811439514,
          -0.6187992095947266
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3182479739189148,
          -0.31054332852363586
         ],
         "y": [
          -0.8822542428970337,
          -0.8605671525001526
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.707436203956604,
          0.6972200870513916
         ],
         "y": [
          -0.617498517036438,
          -0.6083396077156067
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4913047254085541,
          0.48921868205070496
         ],
         "y": [
          0.6539438962936401,
          0.6622132658958435
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.25362297892570496,
          -0.2493770867586136
         ],
         "y": [
          0.8279213905334473,
          0.813432514667511
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7624154090881348,
          0.756364107131958
         ],
         "y": [
          -0.10130397975444794,
          -0.09512688219547272
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.011961149051785469,
          -0.020291192457079887
         ],
         "y": [
          -0.7724109292030334,
          -0.7761315107345581
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.020291192457079887,
          -0.023139461874961853
         ],
         "y": [
          -0.7761315107345581,
          -0.7869337797164917
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23664945363998413,
          -0.24250708520412445
         ],
         "y": [
          -0.9320839643478394,
          -0.9574613571166992
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3480062782764435,
          0.3436829447746277
         ],
         "y": [
          0.884956419467926,
          0.8934001326560974
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3480062782764435,
          0.3491790294647217
         ],
         "y": [
          0.884956419467926,
          0.8749348521232605
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8408454656600952,
          -0.8372653722763062
         ],
         "y": [
          -0.04584113135933876,
          -0.03791740536689758
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8408454656600952,
          -0.8550155162811279
         ],
         "y": [
          -0.04584113135933876,
          -0.04693915694952011
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8626192808151245,
          0.8622761368751526
         ],
         "y": [
          -0.014382630586624146,
          -0.02268976904451847
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6028584241867065,
          0.6132056713104248
         ],
         "y": [
          0.5377464294433594,
          0.5464907884597778
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.34089070558547974,
          -0.3484315872192383
         ],
         "y": [
          0.8690316081047058,
          0.8881857395172119
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.34089070558547974,
          -0.3347269296646118
         ],
         "y": [
          0.8690316081047058,
          0.8531501889228821
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5028233528137207,
          0.5051968097686768
         ],
         "y": [
          -0.27717825770378113,
          -0.2680014967918396
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5028233528137207,
          0.5091134309768677
         ],
         "y": [
          -0.27717825770378113,
          -0.28569018840789795
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8038511872291565,
          0.799372136592865
         ],
         "y": [
          0.40186041593551636,
          0.3949420154094696
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6024418473243713,
          -0.6142657995223999
         ],
         "y": [
          -0.4931468963623047,
          -0.5019262433052063
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6024418473243713,
          -0.5907212495803833
         ],
         "y": [
          -0.4931468963623047,
          -0.4869481921195984
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5907212495803833,
          -0.5826230049133301
         ],
         "y": [
          -0.4869481921195984,
          -0.4917648434638977
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7339691519737244,
          0.7183010578155518
         ],
         "y": [
          0.34188637137413025,
          0.3351186215877533
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5602190494537354,
          0.5495434999465942
         ],
         "y": [
          -0.4917512834072113,
          -0.4838765263557434
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.48622602224349976,
          -0.49539172649383545
         ],
         "y": [
          -0.7542852163314819,
          -0.7650094032287598
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.48622602224349976,
          -0.4802906811237335
         ],
         "y": [
          -0.7542852163314819,
          -0.761509120464325
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2256873995065689,
          0.21834534406661987
         ],
         "y": [
          0.69735187292099,
          0.6933308839797974
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5794848203659058,
          0.5778881907463074
         ],
         "y": [
          0.49387243390083313,
          0.4845673143863678
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5794848203659058,
          0.5940612554550171
         ],
         "y": [
          0.49387243390083313,
          0.5006577968597412
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5794848203659058,
          0.5861189961433411
         ],
         "y": [
          0.49387243390083313,
          0.5069047808647156
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.42387712001800537,
          0.41534775495529175
         ],
         "y": [
          -0.7696357369422913,
          -0.7548603415489197
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.712009847164154,
          -0.7123132348060608
         ],
         "y": [
          -0.24617958068847656,
          -0.2545776665210724
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.1066829189658165,
          -0.09953460842370987
         ],
         "y": [
          -0.8828821182250977,
          -0.8785330653190613
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7602640390396118,
          -0.74419766664505
         ],
         "y": [
          0.5585149526596069,
          0.5468311905860901
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.46648460626602173,
          -0.4724859595298767
         ],
         "y": [
          -0.4862652122974396,
          -0.4773382842540741
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.46648460626602173,
          -0.4730985462665558
         ],
         "y": [
          -0.4862652122974396,
          -0.5004668831825256
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.46648460626602173,
          -0.4569973945617676
         ],
         "y": [
          -0.4862652122974396,
          -0.4916011691093445
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.46648460626602173,
          -0.4795633554458618
         ],
         "y": [
          -0.4862652122974396,
          -0.491891473531723
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7304487824440002,
          -0.7406073212623596
         ],
         "y": [
          -0.1647871732711792,
          -0.16671119630336761
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7406073212623596,
          -0.7539401650428772
         ],
         "y": [
          -0.16671119630336761,
          -0.1694527119398117
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.29739636182785034,
          -0.30695459246635437
         ],
         "y": [
          0.5702369809150696,
          0.5682575702667236
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.29739636182785034,
          -0.29957395792007446
         ],
         "y": [
          0.5702369809150696,
          0.5826539397239685
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.9430172443389893,
          0.9251171350479126
         ],
         "y": [
          0.4300376772880554,
          0.4226854145526886
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8337786197662354,
          0.8313784003257751
         ],
         "y": [
          -0.2567502558231354,
          -0.24869878590106964
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.377803236246109,
          0.3730889558792114
         ],
         "y": [
          -0.7929286956787109,
          -0.775436520576477
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3730889558792114,
          0.3834955096244812
         ],
         "y": [
          -0.775436520576477,
          -0.7857446074485779
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.934416651725769,
          -0.9115757942199707
         ],
         "y": [
          -0.014620806090533733,
          -0.01492652203887701
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.18331195414066315,
          -0.17967449128627777
         ],
         "y": [
          -0.8056346774101257,
          -0.7882066965103149
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7781331539154053,
          -0.7685378789901733
         ],
         "y": [
          -0.3561841547489166,
          -0.35318779945373535
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7157701849937439,
          0.702366054058075
         ],
         "y": [
          0.23551370203495026,
          0.2313743531703949
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2659989595413208,
          0.27213752269744873
         ],
         "y": [
          -0.7998273968696594,
          -0.815916121006012
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.030232613906264305,
          0.03105749748647213
         ],
         "y": [
          0.8269761204719543,
          0.8464457988739014
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.22880132496356964,
          -0.23337610065937042
         ],
         "y": [
          -0.7757729291915894,
          -0.7919467687606812
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.23337610065937042,
          -0.23814380168914795
         ],
         "y": [
          -0.7919467687606812,
          -0.8089529275894165
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3699306845664978,
          0.3605465292930603
         ],
         "y": [
          0.6422820687294006,
          0.6314770579338074
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3605465292930603,
          0.34927138686180115
         ],
         "y": [
          0.6314770579338074,
          0.6315931677818298
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.34927138686180115,
          0.3506125211715698
         ],
         "y": [
          0.6315931677818298,
          0.6450667977333069
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7718133926391602,
          0.7792734503746033
         ],
         "y": [
          -0.27642491459846497,
          -0.2722509205341339
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8356397151947021,
          -0.829783022403717
         ],
         "y": [
          0.26312199234962463,
          0.25704899430274963
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7850502729415894,
          -0.792548656463623
         ],
         "y": [
          0.37511205673217773,
          0.37087035179138184
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7181553840637207,
          0.7303507328033447
         ],
         "y": [
          0.38737308979034424,
          0.39412227272987366
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.33273160457611084,
          -0.3400886356830597
         ],
         "y": [
          0.7716337442398071,
          0.7676236033439636
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5444762110710144,
          -0.5520707368850708
         ],
         "y": [
          -0.6944173574447632,
          -0.6992570757865906
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5520707368850708,
          -0.5591404438018799
         ],
         "y": [
          -0.6992570757865906,
          -0.7055962681770325
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1232890859246254,
          0.11637219041585922
         ],
         "y": [
          0.7925605177879333,
          0.788161039352417
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7245371341705322,
          -0.7326706051826477
         ],
         "y": [
          -0.5054948329925537,
          -0.503839910030365
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6665662527084351,
          -0.6622564196586609
         ],
         "y": [
          0.2442462295293808,
          0.23026813566684723
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6665662527084351,
          -0.6791310906410217
         ],
         "y": [
          0.2442462295293808,
          0.2536008059978485
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6622564196586609,
          -0.6736426949501038
         ],
         "y": [
          0.23026813566684723,
          0.2215786725282669
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6622564196586609,
          -0.6748162508010864
         ],
         "y": [
          0.23026813566684723,
          0.23467384278774261
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6736426949501038,
          -0.6890561580657959
         ],
         "y": [
          0.2215786725282669,
          0.2219824194908142
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6689362525939941,
          -0.68625408411026
         ],
         "y": [
          -0.6495315432548523,
          -0.6661219596862793
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.07370343804359436,
          -0.06380248069763184
         ],
         "y": [
          0.8255649209022522,
          0.8351622819900513
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.07370343804359436,
          -0.08542536199092865
         ],
         "y": [
          0.8255649209022522,
          0.8332654237747192
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.06380248069763184,
          -0.06214537099003792
         ],
         "y": [
          0.8351622819900513,
          0.8549238443374634
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.08542536199092865,
          -0.09181021898984909
         ],
         "y": [
          0.8332654237747192,
          0.8508731126785278
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6761709451675415,
          0.6719468235969543
         ],
         "y": [
          -0.4057139456272125,
          -0.4142010807991028
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6719468235969543,
          0.6610894799232483
         ],
         "y": [
          -0.4142010807991028,
          -0.4121154844760895
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5332032442092896,
          -0.528398871421814
         ],
         "y": [
          0.6271357536315918,
          0.6144582033157349
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.11284299939870834,
          -0.11551934480667114
         ],
         "y": [
          0.18650740385055542,
          0.19983187317848206
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.11284299939870834,
          -0.12339799106121063
         ],
         "y": [
          0.18650740385055542,
          0.17874367535114288
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.11284299939870834,
          -0.10261155664920807
         ],
         "y": [
          0.18650740385055542,
          0.190325066447258
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.12339799106121063,
          -0.13597075641155243
         ],
         "y": [
          0.17874367535114288,
          0.1832687258720398
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.13597075641155243,
          -0.1455962061882019
         ],
         "y": [
          0.1832687258720398,
          0.18796095252037048
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6996765732765198,
          -0.7031582593917847
         ],
         "y": [
          -0.33023175597190857,
          -0.3225484788417816
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8575137853622437,
          0.8626831769943237
         ],
         "y": [
          0.19179444015026093,
          0.1851169466972351
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5896793007850647,
          -0.5769338011741638
         ],
         "y": [
          -0.5730434060096741,
          -0.5600117444992065
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.38691648840904236,
          -0.38768985867500305
         ],
         "y": [
          -0.21910473704338074,
          -0.22753912210464478
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.07055287063121796,
          -0.07955975830554962
         ],
         "y": [
          0.6999057531356812,
          0.7014186382293701
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.07955975830554962,
          -0.08242788165807724
         ],
         "y": [
          0.7014186382293701,
          0.7142804861068726
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.054486095905303955,
          0.05259203165769577
         ],
         "y": [
          -0.7616381645202637,
          -0.7492714524269104
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.05259203165769577,
          0.04871736839413643
         ],
         "y": [
          -0.7492714524269104,
          -0.7413733005523682
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5893300771713257,
          0.579467236995697
         ],
         "y": [
          0.3741379976272583,
          0.368896484375
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5893300771713257,
          0.5980663299560547
         ],
         "y": [
          0.3741379976272583,
          0.37598225474357605
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.1343880295753479,
          0.13805131614208221
         ],
         "y": [
          -0.8997666835784912,
          -0.9223625659942627
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3677496910095215,
          0.3646290898323059
         ],
         "y": [
          0.4839830994606018,
          0.47364163398742676
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.3646290898323059,
          0.36884671449661255
         ],
         "y": [
          0.47364163398742676,
          0.46520164608955383
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.40646788477897644,
          0.41127899289131165
         ],
         "y": [
          -0.6659170389175415,
          -0.6732833385467529
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2599814236164093,
          0.2567968964576721
         ],
         "y": [
          -0.6910691857337952,
          -0.683118462562561
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5348595380783081,
          0.5388952493667603
         ],
         "y": [
          -0.03289949148893356,
          -0.0436118021607399
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5348595380783081,
          0.5504415035247803
         ],
         "y": [
          -0.03289949148893356,
          -0.03434203565120697
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5348595380783081,
          0.5404963493347168
         ],
         "y": [
          -0.03289949148893356,
          -0.023124508559703827
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5504415035247803,
          0.5646849274635315
         ],
         "y": [
          -0.03434203565120697,
          -0.035777416080236435
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.05201015621423721,
          0.053790803998708725
         ],
         "y": [
          -0.8833483457565308,
          -0.9019880890846252
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.05201015621423721,
          0.04364785924553871
         ],
         "y": [
          -0.8833483457565308,
          -0.8861761689186096
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8402401804924011,
          -0.8578013181686401
         ],
         "y": [
          -0.18764936923980713,
          -0.19138695299625397
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.27889102697372437,
          -0.2856755256652832
         ],
         "y": [
          0.8339136242866516,
          0.8537861704826355
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8572701215744019,
          0.8541849851608276
         ],
         "y": [
          0.0670752227306366,
          0.059330422431230545
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7754379510879517,
          0.7820184230804443
         ],
         "y": [
          0.47758692502975464,
          0.472648948431015
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6316830515861511,
          -0.6274203658103943
         ],
         "y": [
          0.573931097984314,
          0.5811704993247986
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.17268459498882294,
          -0.17892561852931976
         ],
         "y": [
          -0.040600359439849854,
          -0.050629764795303345
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.17268459498882294,
          -0.17826004326343536
         ],
         "y": [
          -0.040600359439849854,
          -0.030952418223023415
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.17826004326343536,
          -0.1898934543132782
         ],
         "y": [
          -0.030952418223023415,
          -0.02964380942285061
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8877419233322144,
          0.8990922570228577
         ],
         "y": [
          -0.2787572145462036,
          -0.28232771158218384
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.73048996925354,
          -0.7134969830513
         ],
         "y": [
          -0.5429642200469971,
          -0.5311079621315002
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8754408955574036,
          -0.853274405002594
         ],
         "y": [
          0.3390841782093048,
          0.3301151990890503
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.9221419095993042,
          -0.9420074820518494
         ],
         "y": [
          0.03732697293162346,
          0.03784876689314842
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5325219631195068,
          -0.5458330512046814
         ],
         "y": [
          0.714745819568634,
          0.7323978543281555
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4174507260322571,
          -0.4241696298122406
         ],
         "y": [
          0.7700974345207214,
          0.7813370823860168
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.860588788986206,
          -0.8676111698150635
         ],
         "y": [
          -0.09131114184856415,
          -0.08661700785160065
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7942706346511841,
          0.7933889031410217
         ],
         "y": [
          0.10165321081876755,
          0.11014799028635025
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.25071027874946594,
          -0.24248942732810974
         ],
         "y": [
          0.9175539016723633,
          0.9195843935012817
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5057368874549866,
          0.5085490345954895
         ],
         "y": [
          -0.7348922491073608,
          -0.7421289086341858
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.20196124911308289,
          -0.20048609375953674
         ],
         "y": [
          0.8398374319076538,
          0.8261577486991882
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.20048609375953674,
          -0.20953315496444702
         ],
         "y": [
          0.8261577486991882,
          0.8246216773986816
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2966078519821167,
          -0.28744128346443176
         ],
         "y": [
          -0.6878699064254761,
          -0.676613450050354
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.28744128346443176,
          -0.2930797040462494
         ],
         "y": [
          -0.676613450050354,
          -0.668915331363678
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.28744128346443176,
          -0.2854570746421814
         ],
         "y": [
          -0.676613450050354,
          -0.689551830291748
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3241402506828308,
          -0.3165399134159088
         ],
         "y": [
          0.7144649028778076,
          0.6994537115097046
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3165399134159088,
          -0.3081345856189728
         ],
         "y": [
          0.6994537115097046,
          0.6962816715240479
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7489113807678223,
          -0.7652890682220459
         ],
         "y": [
          0.11970041692256927,
          0.12259402871131897
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6219707131385803,
          0.6370682120323181
         ],
         "y": [
          0.6995879411697388,
          0.7178115248680115
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6219707131385803,
          0.6066462993621826
         ],
         "y": [
          0.6995879411697388,
          0.6811442971229553
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5734034180641174,
          -0.5737085938453674
         ],
         "y": [
          0.3132229745388031,
          0.3033839762210846
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5734034180641174,
          -0.5868356823921204
         ],
         "y": [
          0.3132229745388031,
          0.3173331320285797
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5734034180641174,
          -0.5771742463111877
         ],
         "y": [
          0.3132229745388031,
          0.3249613344669342
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.9268276691436768,
          -0.9417571425437927
         ],
         "y": [
          -0.32565560936927795,
          -0.33052095770835876
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.43772074580192566,
          0.4479995369911194
         ],
         "y": [
          0.5896233320236206,
          0.6008601188659668
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.43772074580192566,
          0.4312695860862732
         ],
         "y": [
          0.5896233320236206,
          0.5961934328079224
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8894609212875366,
          -0.880748987197876
         ],
         "y": [
          -0.39540737867355347,
          -0.3947320580482483
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6881842017173767,
          0.6725306510925293
         ],
         "y": [
          -0.4993866980075836,
          -0.4879617393016815
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.46527257561683655,
          0.4544707238674164
         ],
         "y": [
          -0.6273272037506104,
          -0.6140604615211487
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.4544707238674164,
          0.44695916771888733
         ],
         "y": [
          -0.6140604615211487,
          -0.6090788245201111
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7014117240905762,
          0.7136487364768982
         ],
         "y": [
          0.06101498380303383,
          0.06536462903022766
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7014117240905762,
          0.694566011428833
         ],
         "y": [
          0.06101498380303383,
          0.06801456212997437
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7014117240905762,
          0.7091037631034851
         ],
         "y": [
          0.06101498380303383,
          0.05256965383887291
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6923627257347107,
          0.7081009745597839
         ],
         "y": [
          0.6193755269050598,
          0.6332508325576782
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3962416350841522,
          -0.38482099771499634
         ],
         "y": [
          0.833031415939331,
          0.8345711827278137
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2762400209903717,
          0.2827264368534088
         ],
         "y": [
          -0.7735361456871033,
          -0.7794766426086426
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8001209497451782,
          -0.8060607314109802
         ],
         "y": [
          -0.10391005873680115,
          -0.1116710901260376
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8001209497451782,
          -0.7971445918083191
         ],
         "y": [
          -0.10391005873680115,
          -0.0949077159166336
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.3550712764263153,
          -0.34712114930152893
         ],
         "y": [
          -0.8343626260757446,
          -0.8156360387802124
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6181879043579102,
          -0.6077660918235779
         ],
         "y": [
          0.480195552110672,
          0.4814136028289795
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6077660918235779,
          -0.6088141202926636
         ],
         "y": [
          0.4814136028289795,
          0.49191874265670776
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8747441172599792,
          -0.8562358617782593
         ],
         "y": [
          0.10902497172355652,
          0.10650474578142166
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6149431467056274,
          -0.6018379926681519
         ],
         "y": [
          0.6655227541923523,
          0.6515359282493591
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6480321884155273,
          -0.6426759958267212
         ],
         "y": [
          -0.3846632242202759,
          -0.3913050591945648
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.18483565747737885,
          0.19131848216056824
         ],
         "y": [
          -0.8085919618606567,
          -0.8213046789169312
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.18483565747737885,
          0.17761485278606415
         ],
         "y": [
          -0.8085919618606567,
          -0.8051280975341797
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.18483565747737885,
          0.17691880464553833
         ],
         "y": [
          -0.8085919618606567,
          -0.8155319094657898
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.9498432874679565,
          0.9474843740463257
         ],
         "y": [
          0.0968312993645668,
          0.08870956301689148
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5452868938446045,
          0.5341827273368835
         ],
         "y": [
          -0.7272842526435852,
          -0.712206244468689
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.5380924344062805,
          -0.5259629487991333
         ],
         "y": [
          0.6190484166145325,
          0.6211772561073303
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8662658929824829,
          -0.8584686517715454
         ],
         "y": [
          0.19647832214832306,
          0.19997425377368927
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.012989748269319534,
          0.007481630891561508
         ],
         "y": [
          -0.8714046478271484,
          -0.8773720860481262
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8423923850059509,
          -0.8570004105567932
         ],
         "y": [
          -0.31210318207740784,
          -0.31714317202568054
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.012594233267009258,
          0.005396722815930843
         ],
         "y": [
          0.6450719237327576,
          0.6494952440261841
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6256295442581177,
          -0.6185925602912903
         ],
         "y": [
          -0.6707671284675598,
          -0.6620383858680725
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6628116965293884,
          -0.668222963809967
         ],
         "y": [
          0.3198303282260895,
          0.3279155492782593
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6628116965293884,
          -0.661906898021698
         ],
         "y": [
          0.3198303282260895,
          0.3106691241264343
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.06846757978200912,
          0.06693806499242783
         ],
         "y": [
          0.9428313970565796,
          0.9202743768692017
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5822240114212036,
          0.5755559206008911
         ],
         "y": [
          -0.416092187166214,
          -0.4213990271091461
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.2709677517414093,
          0.2791902720928192
         ],
         "y": [
          -0.8834977149963379,
          -0.8830291628837585
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.2875520884990692,
          -0.2919301390647888
         ],
         "y": [
          -0.89194655418396,
          -0.899216890335083
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.6240338683128357,
          -0.6323163509368896
         ],
         "y": [
          0.7484387755393982,
          0.740123450756073
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5761786103248596,
          0.5680687427520752
         ],
         "y": [
          -0.6229405999183655,
          -0.6252279281616211
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7268426418304443,
          0.7372786998748779
         ],
         "y": [
          -0.27116623520851135,
          -0.268745481967926
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7268426418304443,
          0.726772665977478
         ],
         "y": [
          -0.27116623520851135,
          -0.2615516185760498
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7268426418304443,
          0.7383325695991516
         ],
         "y": [
          -0.27116623520851135,
          -0.28140369057655334
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.35450950264930725,
          -0.3575282394886017
         ],
         "y": [
          -0.866808295249939,
          -0.8765745759010315
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7395525574684143,
          0.7231845259666443
         ],
         "y": [
          0.5798938870429993,
          0.5666749477386475
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.7231845259666443,
          0.7071649432182312
         ],
         "y": [
          0.5666749477386475,
          0.5538060665130615
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8863801956176758,
          0.9113253951072693
         ],
         "y": [
          0.45061540603637695,
          0.4624072313308716
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.8293620347976685,
          -0.8161196112632751
         ],
         "y": [
          0.14633600413799286,
          0.14448431134223938
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.957804799079895,
          0.9464195370674133
         ],
         "y": [
          -0.009612888097763062,
          -0.010383064858615398
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.21733102202415466,
          0.22881586849689484
         ],
         "y": [
          0.024616356939077377,
          0.02815452218055725
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.21733102202415466,
          0.2214660942554474
         ],
         "y": [
          0.024616356939077377,
          0.015428155660629272
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.015988731756806374,
          -0.02207053080201149
         ],
         "y": [
          0.7862875461578369,
          0.7960291504859924
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.015988731756806374,
          -0.00930336955934763
         ],
         "y": [
          0.7862875461578369,
          0.7950764894485474
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.12752990424633026,
          -0.11976540088653564
         ],
         "y": [
          -0.845262348651886,
          -0.8483325839042664
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.47117695212364197,
          -0.4815768897533417
         ],
         "y": [
          0.7314171195030212,
          0.7480098009109497
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.12429362535476685,
          -0.11583015322685242
         ],
         "y": [
          -0.6733387112617493,
          -0.6739888787269592
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.7788897156715393,
          -0.7963597178459167
         ],
         "y": [
          -0.4276139736175537,
          -0.43602627515792847
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.8250355124473572,
          0.8147950768470764
         ],
         "y": [
          -0.16812968254089355,
          -0.16561438143253326
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.03519466519355774,
          -0.04729101061820984
         ],
         "y": [
          -0.9990251064300537,
          -0.9988975524902344
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.30012038350105286,
          0.30715373158454895
         ],
         "y": [
          -0.7346503138542175,
          -0.7300930619239807
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.5863885879516602,
          0.577451765537262
         ],
         "y": [
          -0.5863527059555054,
          -0.5782561302185059
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.4220176041126251,
          -0.42144039273262024
         ],
         "y": [
          -0.7281581163406372,
          -0.7161921262741089
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.42144039273262024,
          -0.4319007396697998
         ],
         "y": [
          -0.7161921262741089,
          -0.7191358804702759
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.28806865215301514,
          -0.29527193307876587
         ],
         "y": [
          -0.738493025302887,
          -0.7570551633834839
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          -0.29527193307876587,
          -0.300567626953125
         ],
         "y": [
          -0.7570551633834839,
          -0.7706564664840698
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.6376426815986633,
          0.629522442817688
         ],
         "y": [
          0.46445736289024353,
          0.4578666090965271
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.08113696426153183,
          0.07489348948001862
         ],
         "y": [
          0.405861496925354,
          0.395844042301178
         ]
        },
        {
         "line": {
          "width": 1
         },
         "mode": "lines",
         "name": "Edge",
         "type": "scatter",
         "x": [
          0.07489348948001862,
          0.06589110195636749
         ],
         "y": [
          0.395844042301178,
          0.39977192878723145
         ]
        }
       ],
       "layout": {
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Comments Graph"
        },
        "xaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter trace for nodes with assigned positions\n",
    "for node, position in pos.items():\n",
    "    x, y = position  # Get the position of the node\n",
    "    color = G.nodes[node]['color']  # Get the color attribute of the node\n",
    "    hover = G.nodes[node]['hover']\n",
    "    hover = '<br>'.join(textwrap.wrap(hover,width=50))\n",
    "    topic = G.nodes[node]['topic']\n",
    "    fig.add_trace(go.Scatter(x=[x], y=[y], marker=dict(size=10,color=color), hovertext=hover, name=topic, hovertemplate=hover))\n",
    "\n",
    "for edge in G.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    fig.add_trace(go.Scatter(x=[x0, x1], y=[y0, y1], mode='lines', line=dict(width=1), name='Edge'))\n",
    "\n",
    "# Update the layout of the figure\n",
    "fig.update_layout(showlegend=False, title='Comments Graph')\n",
    "\n",
    "fig.update_layout(xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                  yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n",
    "fig.write_html('graph_coms_topics.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m edge_y \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m edge \u001b[39min\u001b[39;00m G\u001b[39m.\u001b[39medges():\n\u001b[1;32m----> 4\u001b[0m     x0, y0 \u001b[39m=\u001b[39m G\u001b[39m.\u001b[39;49mnodes[edge[\u001b[39m0\u001b[39;49m]][\u001b[39m'\u001b[39;49m\u001b[39mpos\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      5\u001b[0m     x1, y1 \u001b[39m=\u001b[39m G\u001b[39m.\u001b[39mnodes[edge[\u001b[39m1\u001b[39m]][\u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m     edge_x\u001b[39m.\u001b[39mappend(x0)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pos'"
     ]
    }
   ],
   "source": [
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in G.edges():\n",
    "    x0, y0 = G.nodes[edge[0]]['pos']\n",
    "    x1, y1 = G.nodes[edge[1]]['pos']\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in G.nodes():\n",
    "    x, y = G.nodes[node]['pos']\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        # colorscale options\n",
    "        #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "        #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "        #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'node_trace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     node_adjacencies\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(adjacencies[\u001b[39m1\u001b[39m]))\n\u001b[0;32m      5\u001b[0m     node_text\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m# of connections: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(adjacencies[\u001b[39m1\u001b[39m])))\n\u001b[1;32m----> 7\u001b[0m node_trace\u001b[39m.\u001b[39mmarker\u001b[39m.\u001b[39mcolor \u001b[39m=\u001b[39m node_adjacencies\n\u001b[0;32m      8\u001b[0m node_trace\u001b[39m.\u001b[39mtext \u001b[39m=\u001b[39m node_text\n",
      "\u001b[1;31mNameError\u001b[0m: name 'node_trace' is not defined"
     ]
    }
   ],
   "source": [
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(G.adjacency()):\n",
    "    node_adjacencies.append(len(adjacencies[1]))\n",
    "    node_text.append('# of connections: '+str(len(adjacencies[1])))\n",
    "\n",
    "node_trace.marker.color = node_adjacencies\n",
    "node_trace.text = node_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 16\u001b[0m\n\u001b[0;32m      1\u001b[0m fig \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mFigure(data\u001b[39m=\u001b[39m[edge_trace, node_trace],\n\u001b[0;32m      2\u001b[0m              layout\u001b[39m=\u001b[39mgo\u001b[39m.\u001b[39mLayout(\n\u001b[0;32m      3\u001b[0m                 title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m<br>Network graph made with Python\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 yaxis\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(showgrid\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, zeroline\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, showticklabels\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m     15\u001b[0m                 )\n\u001b[1;32m---> 16\u001b[0m fig\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\plotly\\basedatatypes.py:3409\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3376\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3377\u001b[0m \u001b[39mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[0;32m   3378\u001b[0m \u001b[39mspecified by the renderer argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3405\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3406\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3407\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[1;32m-> 3409\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39;49mshow(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\plotly\\io\\_renderers.py:396\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    393\u001b[0m         )\n\u001b[0;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nbformat \u001b[39mor\u001b[39;00m Version(nbformat\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 396\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    397\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m         )\n\u001b[0;32m    400\u001b[0m     ipython_display\u001b[39m.\u001b[39mdisplay(bundle, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    402\u001b[0m \u001b[39m# external renderers\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                title='<br>Network graph made with Python',\n",
    "                titlefont_size=16,\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                annotations=[ dict(\n",
    "                    text=\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\n",
    "                    showarrow=False,\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.005, y=-0.002 ) ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
